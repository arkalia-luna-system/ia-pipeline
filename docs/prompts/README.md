# ü§ñ Documentation des Prompts IA - Athalia

**Date :** 20/07/2025  
**Version :** 1.0  
**Auteur :** Athalia Dev Setup

---

## üìã **Vue d'ensemble**

Les prompts IA d'Athalia sont des instructions sp√©cialis√©es pour guider les mod√®les d'intelligence artificielle dans la g√©n√©ration de code, l'analyse et l'am√©lioration de projets. Ils sont utilis√©s par le syst√®me d'IA robuste pour fournir des r√©ponses contextuelles et pertinentes.

---

## üèóÔ∏è **Architecture des Prompts**

### **Structure des Dossiers**

```
prompts/
‚îú‚îÄ‚îÄ code_refactor.yaml          # Refactorisation de code
‚îú‚îÄ‚îÄ custom_prompts.yaml         # Prompts personnalis√©s
‚îú‚îÄ‚îÄ design_review.md            # Review de design
‚îú‚îÄ‚îÄ dev_debug.yaml             # D√©bogage d√©veloppement
‚îú‚îÄ‚îÄ security_audit.md          # Audit de s√©curit√©
‚îú‚îÄ‚îÄ test_strategy.md           # Strat√©gie de tests
‚îî‚îÄ‚îÄ ux_fun_boost.md            # Am√©lioration UX
```

### **Types de Prompts**

1. **Prompts de G√©n√©ration** - Cr√©ation de code et documentation
2. **Prompts d'Analyse** - Audit et review de code
3. **Prompts d'Am√©lioration** - Refactorisation et optimisation
4. **Prompts de S√©curit√©** - Audit de s√©curit√© et vuln√©rabilit√©s
5. **Prompts de Tests** - Strat√©gies et g√©n√©ration de tests

---

## üîß **Utilisation des Prompts**

### **Utilisation via CLI**

```bash
# Test de l'IA avec prompts
python -m athalia_core.cli test-ai "Mon id√©e de projet"

# Statut de l'IA robuste
python -m athalia_core.cli ai-status
```

### **Utilisation Programmatique**

```python
from athalia_core.ai_robust import RobustAI, PromptContext

# Initialiser l'IA robuste
ai = RobustAI()

# Utiliser un prompt sp√©cifique
response = ai.generate_response(
    context=PromptContext.BLUEPRINT,
    idea="API REST pour gestion de t√¢ches",
    project_type="web_api",
    complexity="medium"
)

print(response)
```

---

## üìù **Contextes de Prompts Disponibles**

### **1. BLUEPRINT - G√©n√©ration de Blueprints**

**Objectif :** G√©n√©rer des blueprints YAML complets pour les projets.

**Variables disponibles :**
- `idea` - Description du projet
- `project_type` - Type de projet d√©tect√©
- `complexity` - Complexit√© estim√©e

**Exemple d'utilisation :**
```python
response = ai.generate_response(
    context=PromptContext.BLUEPRINT,
    idea="Application de gestion de t√¢ches avec API REST",
    project_type="web_api",
    complexity="medium"
)
```

### **2. CODE_REVIEW - Analyse de Code**

**Objectif :** Analyser et am√©liorer le code existant.

**Variables disponibles :**
- `code` - Code √† analyser
- `filename` - Nom du fichier
- `project_type` - Type de projet
- `current_score` - Score actuel

**Exemple d'utilisation :**
```python
response = ai.generate_response(
    context=PromptContext.CODE_REVIEW,
    code=code_content,
    filename="main.py",
    project_type="web_api",
    current_score=75
)
```

### **3. DOCUMENTATION - G√©n√©ration de Documentation**

**Objectif :** G√©n√©rer de la documentation technique.

**Variables disponibles :**
- `code` - Code √† documenter
- `project_type` - Type de projet
- `doc_type` - Type de documentation

**Exemple d'utilisation :**
```python
response = ai.generate_response(
    context=PromptContext.DOCUMENTATION,
    code=code_content,
    project_type="web_api",
    doc_type="api_docs"
)
```

### **4. TESTING - G√©n√©ration de Tests**

**Objectif :** Cr√©er des tests unitaires et d'int√©gration.

**Variables disponibles :**
- `code` - Code √† tester
- `project_type` - Type de projet
- `test_framework` - Framework de test

**Exemple d'utilisation :**
```python
response = ai.generate_response(
    context=PromptContext.TESTING,
    code=code_content,
    project_type="web_api",
    test_framework="pytest"
)
```

### **5. SECURITY - Audit de S√©curit√©**

**Objectif :** Analyser la s√©curit√© du code.

**Variables disponibles :**
- `code` - Code √† analyser
- `project_type` - Type de projet
- `environment` - Environnement de d√©ploiement

**Exemple d'utilisation :**
```python
response = ai.generate_response(
    context=PromptContext.SECURITY,
    code=code_content,
    project_type="web_api",
    environment="production"
)
```

---

## üéØ **Prompts Sp√©cialis√©s**

### **1. Code Refactor (`code_refactor.yaml`)**

**Objectif :** Am√©liorer la qualit√© et la structure du code.

**Caract√©ristiques :**
- Analyse de la complexit√© cyclomatique
- Suggestions de refactorisation
- Am√©lioration de la lisibilit√©
- Optimisation des performances

**Utilisation :**
```yaml
# Dans le fichier prompts/code_refactor.yaml
context: "Tu es un expert en refactorisation de code Python"
task: "Analyse et am√©liore le code fourni"
output_format: "yaml"
```

### **2. Design Review (`design_review.md`)**

**Objectif :** √âvaluer et am√©liorer le design des interfaces.

**Caract√©ristiques :**
- Analyse UX/UI
- Suggestions d'am√©lioration
- Bonnes pratiques de design
- Accessibilit√©

### **3. Security Audit (`security_audit.md`)**

**Objectif :** Identifier et corriger les vuln√©rabilit√©s de s√©curit√©.

**Caract√©ristiques :**
- D√©tection d'injections
- Analyse des permissions
- Gestion des secrets
- Validation des entr√©es

### **4. Test Strategy (`test_strategy.md`)**

**Objectif :** D√©finir une strat√©gie de tests compl√®te.

**Caract√©ristiques :**
- Planification des tests
- Couverture de code
- Tests d'int√©gration
- Tests de performance

### **5. UX Fun Boost (`ux_fun_boost.md`)**

**Objectif :** Am√©liorer l'exp√©rience utilisateur et l'engagement.

**Caract√©ristiques :**
- Gamification
- Animations et transitions
- Feedback utilisateur
- Interface intuitive

---

## üõ†Ô∏è **Personnalisation des Prompts**

### **Cr√©er un Nouveau Prompt**

1. **Cr√©er le fichier prompt :**
```bash
# Cr√©er un nouveau prompt
touch prompts/my_custom_prompt.yaml
```

2. **D√©finir la structure :**
```yaml
# prompts/my_custom_prompt.yaml
context: "Tu es un expert en [domaine]"
task: "T√¢che sp√©cifique √† accomplir"
input_variables:
  - variable1
  - variable2
output_format: "yaml|json|text"
examples:
  - input: "exemple d'entr√©e"
    output: "exemple de sortie"
```

3. **Enregistrer dans le syst√®me :**
```python
# Ajouter √† athalia_core/ai_robust.py
class PromptContext(Enum):
    # ... autres contextes ...
    CUSTOM = "custom"

# Dans _load_prompt_templates()
PromptContext.CUSTOM.value: """
[Contenu du prompt personnalis√©]
"""
```

### **Modifier un Prompt Existant**

1. **Localiser le prompt :**
```bash
# Voir tous les prompts
ls prompts/

# √âditer un prompt
nano prompts/code_refactor.yaml
```

2. **Tester les modifications :**
```python
# Test du prompt modifi√©
ai = RobustAI()
response = ai.generate_response(
    context=PromptContext.CODE_REVIEW,
    code="def test(): pass",
    filename="test.py"
)
print(response)
```

---

## üß™ **Tests des Prompts**

### **Tests Automatiques**

```bash
# Ex√©cuter les tests de prompts
python -m pytest tests/test_prompts_documentation.py -v

# Tests sp√©cifiques
python -m pytest tests/test_prompts_documentation.py::TestPrompts::test_code_refactor_prompt -v
```

### **Tests Manuels**

```python
# Test de g√©n√©ration de r√©ponse
from athalia_core.ai_robust import RobustAI, PromptContext

ai = RobustAI()

# Test avec diff√©rents contextes
contexts = [
    PromptContext.BLUEPRINT,
    PromptContext.CODE_REVIEW,
    PromptContext.DOCUMENTATION,
    PromptContext.TESTING,
    PromptContext.SECURITY
]

for context in contexts:
    try:
        response = ai.generate_response(
            context=context,
            idea="Test project",
            project_type="test"
        )
        print(f"‚úÖ {context.value}: OK")
    except Exception as e:
        print(f"‚ùå {context.value}: {e}")
```

---

## üìä **M√©triques et Performance**

### **M√©triques de Qualit√©**

- **Pertinence** - R√©ponses adapt√©es au contexte
- **Coh√©rence** - R√©ponses coh√©rentes entre les ex√©cutions
- **Compl√©tude** - R√©ponses compl√®tes et d√©taill√©es
- **Pr√©cision** - R√©ponses exactes et correctes

### **Optimisation des Prompts**

1. **Clart√© des instructions** - Instructions pr√©cises et non ambigu√´s
2. **Exemples concrets** - Exemples pour guider le mod√®le
3. **Format de sortie** - Format structur√© pour faciliter le parsing
4. **Gestion d'erreurs** - Instructions pour les cas d'erreur

---

## üìö **Documentation Associ√©e**

- **[REFERENCE.md](REFERENCE.md)** - R√©f√©rence technique des prompts
- **[BEST_PRACTICES.md](GUIDES/BEST_PRACTICES.md)** - Bonnes pratiques
- **[EXAMPLES/](EXAMPLES/)** - Exemples par cat√©gorie

---

## üö® **D√©pannage**

### **Probl√®mes Courants**

1. **Prompt non trouv√© :**
   - V√©rifier le nom du contexte dans `PromptContext`
   - S'assurer que le prompt est charg√© dans `_load_prompt_templates()`

2. **Variable manquante :**
   - V√©rifier toutes les variables requises dans le prompt
   - Utiliser des valeurs par d√©faut si possible

3. **R√©ponse incoh√©rente :**
   - Am√©liorer la clart√© des instructions
   - Ajouter des exemples concrets
   - Sp√©cifier le format de sortie attendu

### **Logs de Debug**

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Les logs afficheront les d√©tails de g√©n√©ration
ai = RobustAI()
response = ai.generate_response(...)
```

---

## üîÑ **Mise √† Jour**

Pour mettre √† jour cette documentation :

1. **Modifier le fichier README.md**
2. **Tester les exemples**
3. **Mettre √† jour les tests**
4. **Valider avec `python -m pytest tests/test_prompts_documentation.py`**

---

**üìû Support :** Consultez la documentation compl√®te dans `docs/prompts/` ou cr√©ez une issue pour toute question. 