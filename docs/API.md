# API Documentation - athalia-dev-setup"

## Vue densemble

Cette documentation d√©crit lAPI de athalia-dev-setup.

## Modules

### athalia_unified

Athalia Unified - Pipeline d'industrialisation IA complet
Interface unifi√©e pour tous les modules Athalia

#### Classes

##### AthaliaOrchestrator

**M√©thodes :**

- `industrialize_project()`
- `audit_project()`
- `scan_projects()`

#### Fonctions

##### main

Fonction principale du CLI unifi√©

##### industrialize_project

**Param√®tres :**

- `project_path`
- `config`

##### audit_project

**Param√®tres :**

- `project_path`

##### scan_projects

**Param√®tres :**

- `project_path`

---

### get-pip

#### Fonctions

##### include_setuptools

Install setuptools only if absent, not excluded and when using Python <3.12.

**Param√®tres :**

- `args`

##### include_wheel

Install wheel only if absent, not excluded and when using Python <3.12.

**Param√®tres :**

- `args`

##### determine_pip_install_arguments

##### monkeypatch_for_cert

Patches `pip install` to provide default certificate with the lowest priority.

This ensures that the bundled certificates are used unless the user specifies a
custom cert via any of pip's option passing mechanisms (config, env-var, CLI).

A monkeypatch is the easiest way to achieve this, without messing too much with
the rest of pip's internals.

**Param√®tres :**

- `tmpdir`

##### bootstrap

**Param√®tres :**

- `tmpdir`

##### main

##### cert_parse_args

**Param√®tres :**

- `args`

---

### test_cleanup

Tests pour le module cleanup

#### Fonctions

##### test_clean_old_tests_and_caches

Test de nettoyage des anciens tests et caches

**Param√®tres :**

- `tmp_path`

##### test_cleanup_module_import

Test d'import du module cleanup

---

### audit

Module d'audit intelligent pour analyser la qualit√© des projets g√©n√©r√©s.
Analyse le code, d√©tecte la dette technique, et propose des am√©liorations.

#### Classes

##### ProjectAuditor

Auditeur intelligent de projets g√©n√©r√©s.

**M√©thodes :**

- `__init__()`
- `audit_project()`
- `_analyze_structure()`
- `_analyze_code_quality()`
- `_analyze_python_file()`
- `_analyze_tests()`
- `_analyze_documentation()`
- `_analyze_security()`
- `_analyze_performance()`
- `_calculate_score()`
- `_generate_report()`
- `_find_modules()`

#### Fonctions

##### audit_project_intelligent

Fonction principale pour l'audit intelligent.

**Param√®tres :**

- `project_path`

##### generate_audit_report

**Param√®tres :**

- `project_path`

##### __init__

**Param√®tres :**

- `project_path`

##### audit_project

Audit complet du projet.

##### _analyze_structure

Analyse la structure du projet.

##### _analyze_code_quality

Analyse la qualit√© du code Python.

##### _analyze_python_file

Analyse un fichier Python avec AST.

**Param√®tres :**

- `tree`
- `content`

##### _analyze_tests

Analyse la couverture de tests.

##### _analyze_documentation

Analyse la documentation.

##### _analyze_security

Analyse la s√©curit√©.

##### _analyze_performance

Analyse la performance.

##### _calculate_score

Calcule le score global du projet.

##### _generate_report

G√©n√®re le rapport d'audit.

##### _find_modules

Trouve les modules Python dans le projet.

---

### test_i18n

Tests pour le module i18n

#### Fonctions

##### test_i18n_module_import

Test d'import du module i18n

##### test_french_translations

Test des traductions fran√ßaises

##### test_english_translations

Test des traductions anglaises

##### test_translation_consistency

Test de la coh√©rence des traductions

---

### audit_complet_dossiers

üîç AUDIT COMPLET DOSSIERS ET SOUS-DOSSIERS
==========================================
Script pour analyser chaque dossier et sous-dossier du projet Athalia.
V√©rifie : utilit√©, impl√©mentation, tests, documentation, int√©gration.

#### Classes

##### DossierInfo

Informations sur un dossier

##### ModuleInfo

Informations sur un module Python

##### AuditResult

R√©sultat d'audit pour un dossier

##### AuditCompletDossiers

Auditeur complet des dossiers et sous-dossiers

**M√©thodes :**

- `__init__()`
- `analyser_tous_dossiers()`
- `_trouver_sous_dossiers_caches()`
- `_analyser_dossier_complet()`
- `_analyser_dossier_info()`
- `_analyser_module()`
- `_chercher_tests_associes()`
- `_chercher_documentation_associee()`
- `_verifier_integration_orchestrateur()`
- `_calculer_score_utilite()`
- `_calculer_score_implementation()`
- `_calculer_score_tests()`
- `_calculer_score_documentation()`
- `_calculer_score_integration()`
- `_generer_recommandations()`
- `_chercher_pepites()`
- `generer_rapport()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `root_path`

##### analyser_tous_dossiers

Analyser tous les dossiers et sous-dossiers

##### _trouver_sous_dossiers_caches

Trouver les sous-dossiers cach√©s qui pourraient contenir des p√©pites

##### _analyser_dossier_complet

Analyser un dossier complet

**Param√®tres :**

- `dossier_path`
- `nom_dossier`

##### _analyser_dossier_info

Analyser les informations d'un dossier

**Param√®tres :**

- `dossier_path`
- `nom_dossier`

##### _analyser_module

Analyser un module Python

**Param√®tres :**

- `file_path`

##### _chercher_tests_associes

Chercher les tests associ√©s √† un module

**Param√®tres :**

- `file_path`

##### _chercher_documentation_associee

Chercher la documentation associ√©e √† un module

**Param√®tres :**

- `file_path`

##### _verifier_integration_orchestrateur

V√©rifier si le module est int√©gr√© dans l'orchestrateur

**Param√®tres :**

- `content`
- `imports`

##### _calculer_score_utilite

Calculer le score d'utilit√©

**Param√®tres :**

- `dossier_info`
- `modules`

##### _calculer_score_implementation

Calculer le score d'impl√©mentation

**Param√®tres :**

- `modules`

##### _calculer_score_tests

Calculer le score des tests

**Param√®tres :**

- `dossier_info`
- `modules`

##### _calculer_score_documentation

Calculer le score de documentation

**Param√®tres :**

- `dossier_info`
- `modules`

##### _calculer_score_integration

Calculer le score d'int√©gration

**Param√®tres :**

- `modules`

##### _generer_recommandations

G√©n√©rer des recommandations

**Param√®tres :**

- `dossier_info`
- `modules`
- `score_total`

##### _chercher_pepites

Chercher des p√©pites dans le dossier

**Param√®tres :**

- `dossier_info`
- `modules`

##### generer_rapport

G√©n√©rer un rapport complet

---

### debug_correction

Script de d√©bogage pour le syst√®me de correction

#### Fonctions

##### test_correction

Test simple de correction

---

### correction_chaiÃÇnes

Script de correction des cha√Ænes non termin√©es dans athalia_core

#### Fonctions

##### corriger_cha√Ænes_fichier

Corrige les cha√Ænes non termin√©es dans un fichier

**Param√®tres :**

- `file_path`

##### main

Fonction principale

---

### correction_finale

Script de correction finale pour Athalia
Corrige toutes les erreurs restantes dans les fichiers principaux

#### Fonctions

##### corriger_fichier

Corrige un fichier en rempla√ßant les patterns probl√©matiques

**Param√®tres :**

- `file_path`

##### main

Fonction principale

---

### test_plugin_complet

Test complet du plugin VS Code Athalia
V√©rifie tous les composants n√©cessaires au fonctionnement

#### Fonctions

##### print_status

**Param√®tres :**

- `message`
- `status`

##### test_vscode_installation

Test si VS Code est install√© et accessible

##### test_plugin_compilation

Test si le plugin est compil√©

##### test_package_json

Test la configuration package.json

##### test_ai_server

Test si le serveur d'autocompl√©tion IA fonctionne

##### test_apple_double_files

Test s'il y a des fichiers AppleDouble parasites

##### generate_test_report

G√©n√®re un rapport de test complet

---

### test_plugins

Tests pour le syst√®me de plugins dynamiques Athalia

#### Classes

##### TestPlugins

**M√©thodes :**

- `test_list_plugins()`
- `test_load_plugin()`
- `test_run_all_plugins()`
- `test_export_docker_plugin()`

##### MockPlugin

**M√©thodes :**

- `run()`

#### Fonctions

##### list_plugins

Simulation de la fonction list_plugins

##### load_plugin

Simulation de la fonction load_plugin

**Param√®tres :**

- `name`

##### run_all_plugins

Simulation de la fonction run_all_plugins

##### test_list_plugins

##### test_load_plugin

##### test_run_all_plugins

##### test_export_docker_plugin

##### run

---

### test_adaptive_distillation

#### Classes

##### TestAdaptiveDistiller

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_majority_voting()`
- `test_empty()`
- `test_update_preferences()`
- `test_feedback_success_failure()`
- `test_save_and_load_history()`

#### Fonctions

##### setUp

##### tearDown

##### test_majority_voting

##### test_empty

##### test_update_preferences

##### test_feedback_success_failure

##### test_save_and_load_history

---

### optimize_performance

Script d'optimisation des performances des tests
Version: 1.0
Auteur: Athalia Team

#### Classes

##### TestPerformanceOptimizer

Optimiseur de performances des tests

**M√©thodes :**

- `__init__()`
- `analyze_test_performance()`
- `_parse_durations()`
- `_extract_duration()`
- `identify_slow_tests()`
- `identify_fast_tests()`
- `generate_optimization_report()`
- `save_report()`
- `run_fast_tests_only()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `test_dir`

##### analyze_test_performance

Analyse les performances de tous les tests

Returns:
    Dict avec les temps d'ex√©cution par test

##### _parse_durations

Parse la sortie de pytest --durations

**Param√®tres :**

- `output`

##### _extract_duration

Extrait la dur√©e d'une ligne de test

**Param√®tres :**

- `line`

##### identify_slow_tests

Identifie les tests lents

Args:
    threshold: Seuil en secondes pour consid√©rer un test comme lent
    
Returns:
    Liste des tests lents

**Param√®tres :**

- `threshold`

##### identify_fast_tests

Identifie les tests rapides

Args:
    threshold: Seuil en secondes pour consid√©rer un test comme rapide
    
Returns:
    Liste des tests rapides

**Param√®tres :**

- `threshold`

##### generate_optimization_report

G√©n√®re un rapport d'optimisation

Returns:
    Contenu du rapport

##### save_report

Sauvegarde le rapport d'optimisation

Args:
    filename: Nom du fichier de rapport

**Param√®tres :**

- `filename`

##### run_fast_tests_only

Ex√©cute seulement les tests rapides

Returns:
    True si tous les tests rapides passent

---

### test_advanced_analytics_unit

#### Classes

##### TestAdvancedAnalytics

**M√©thodes :**

- `setUp()`
- `test_constructor()`
- `test_run()`
- `test_analyze_coverage()`
- `test_analyze_performance()`
- `test_generate_dashboard()`
- `test_generate_summary()`
- `test_print_report()`

#### Fonctions

##### setUp

##### test_constructor

##### test_run

##### test_analyze_coverage

##### test_analyze_performance

##### test_generate_dashboard

##### test_generate_summary

##### test_print_report

---

### test_ai_robust_integration

#### Classes

##### TestAIRobustIntegration

Tests d'int√©gration pour l'IA robuste.

**M√©thodes :**

- `setup_method()`
- `test_complete_workflow_simple_project()`
- `test_fallback_chain_behavior()`
- `test_different_project_complexities()`
- `test_prompt_contexts()`
- `test_model_detection()`
- `test_error_handling()`

#### Fonctions

##### test_ai_robust_performance

Test de performance de l'IA robuste.

##### test_ai_robust_memory_usage

Test de l'utilisation m√©moire de l'IA robuste.

##### setup_method

Initialise l'IA robuste pour les tests.

##### test_complete_workflow_simple_project

Test du workflow complet pour un projet simple.

##### test_fallback_chain_behavior

Test du comportement de la cha√Æne de fallback.

##### test_different_project_complexities

Test avec diff√©rents niveaux de complexit√©.

##### test_prompt_contexts

Test de tous les contextes de prompts.

##### test_model_detection

Test de la d√©tection des mod√®les.

##### test_error_handling

Test de la gestion d'erreurs.

##### mock_call_fail

**Param√®tres :**

- `model`
- `prompt`
- `timeout`

---

### test_plugins_validator

#### Fonctions

##### test_validate_plugin_ok

##### test_validate_plugin_fail

---

### test_agent_network

Tests pour les agents unifi√©s
Corrig√© apr√®s consolidation des agents

#### Classes

##### TestAgentUnified

Tests pour les agents unifi√©s (corrig√©)

**M√©thodes :**

- `test_agent_unified_basic()`
- `test_agent_imports()`

#### Fonctions

##### test_agent_unified_basic

Test basique des agents unifi√©s

**Param√®tres :**

- `mock_qwen`

##### test_agent_imports

Test des imports d'agents unifi√©s

---

### test_ai_robust

#### Classes

##### TestRobustAI

Tests pour list_data'IA robuste.

**M√©thodes :**

- `setup_method()`
- `test_detect_available_models()`
- `test_build_fallback_chain()`
- `test_classify_project_complexity()`
- `test_get_dynamic_prompt()`
- `test_generate_blueprint_with_mock()`
- `test_review_code_with_mock()`
- `test_generate_documentation_with_mock()`
- `test_call_ollama_timeout()`
- `test_fallback_chain_behavior()`

#### Fonctions

##### test_robust_ai_integration

Test dict_data'int√©gration de list_data'IA robuste.

##### test_prompt_templates

Test que tous les templates de prompts sont charg√©s.

##### test_fallback_and_distillation_qwen_mistral

Teste la g√©n√©ration de r√©ponse avec fallback et distillation (Qwen/Mistral).

##### test_fallback_ia_qwen_mistral

**Param√®tres :**

- `monkeypatch`

##### setup_method

Initialise list_data'IA robuste pour les tests.

##### test_detect_available_models

Test la d√©tection des mod√®les disponibles.

##### test_build_fallback_chain

Test la construction de la cha√Æne de fallback.

##### test_classify_project_complexity

##### test_get_dynamic_prompt

Test la g√©n√©ration de prompts dynamiques.

##### test_generate_blueprint_with_mock

Test la g√©n√©ration de blueprint avec fallback mock.

##### test_review_code_with_mock

Test la revue de code avec fallback mock.

##### test_generate_documentation_with_mock

Test la g√©n√©ration de documentation avec fallback mock.

##### test_call_ollama_timeout

Test la gestion du timeout dict_data'Ollama.

##### test_fallback_chain_behavior

Test le comportement de la cha√Æne de fallback.

##### mock_query_qwen

**Param√®tres :**

- `prompt`

##### mock_query_mistral

**Param√®tres :**

- `prompt`

##### mock_call_fail

**Param√®tres :**

- `model`
- `prompt`
- `timeout`

---

### test_ai_robust_unit

#### Classes

##### TestAiRobust

**M√©thodes :**

- `test_robust_ai_instance()`
- `test_fallback_ia()`
- `test_query_qwen()`
- `test_query_mistral()`
- `test_robustai_generate_blueprint()`
- `test_robustai_review_code()`
- `test_robustai_generate_documentation()`
- `test_robustai_classify_project_complexity()`
- `test_robustai_get_dynamic_prompt()`

#### Fonctions

##### test_robust_ai_instance

##### test_fallback_ia

##### test_query_qwen

##### test_query_mistral

##### test_robustai_generate_blueprint

##### test_robustai_review_code

##### test_robustai_generate_documentation

##### test_robustai_classify_project_complexity

##### test_robustai_get_dynamic_prompt

---

### test_analytics

Tests pour le module analytics

#### Classes

##### TestAnalyticsModule

Tests pour le module analytics d'Athalia

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `create_test_project()`
- `test_analytics_module_import()`
- `test_analyze_project()`
- `test_generate_heatmap_data()`
- `test_generate_technical_debt_analysis()`
- `test_generate_analytics_html()`
- `test_analytics_with_empty_project()`
- `test_analytics_with_nonexistent_project()`

#### Fonctions

##### test_analytics_integration

Test d'int√©gration du module analytics

##### setup_method

Configuration avant chaque test

##### teardown_method

Nettoyage apr√®s chaque test

##### create_test_project

Cr√©er un projet de test pour les analyses

##### test_analytics_module_import

Test d'import du module analytics

##### test_analyze_project

Test d'analyse de projet

##### test_generate_heatmap_data

Test de g√©n√©ration de donn√©es pour heatmap

##### test_generate_technical_debt_analysis

Test d'analyse de dette technique

##### test_generate_analytics_html

Test de g√©n√©ration de rapport HTML

##### test_analytics_with_empty_project

Test d'analyse avec un projet vide

##### test_analytics_with_nonexistent_project

Test d'analyse avec un projet inexistant

---

### test_athalia_simple

Tests simples pour Athalia

#### Fonctions

##### test_athalia_core_import

Test d'import du module core

##### test_essential_files_exist

Test que les fichiers essentiels existent

##### test_project_structure

Test de la structure du projet

---

### test_analytics_unit

#### Classes

##### TestAnalytics

**M√©thodes :**

- `setUp()`
- `test_generate_heatmap_data()`
- `test_generate_technical_debt_analysis()`
- `test_generate_analytics_html()`
- `test_analyze_project()`

#### Fonctions

##### setUp

##### test_generate_heatmap_data

##### test_generate_technical_debt_analysis

##### test_generate_analytics_html

##### test_analyze_project

---

### test_predictive_cache

#### Classes

##### TestPredictiveCache

**M√©thodes :**

- `test_set_get()`
- `test_predict_key()`
- `test_pre_generate()`
- `test_invalidate()`
- `test_stats()`
- `test_ttl()`

#### Fonctions

##### test_set_get

##### test_predict_key

##### test_pre_generate

##### test_invalidate

##### test_stats

##### test_ttl

##### gen

**Param√®tres :**

- `ctx`

---

### test_continue_models

Test de pr√©sence des mod√®les dans la config Continue

#### Fonctions

##### test_models_presence

V√©rifie la pr√©sence des mod√®les Claude et Mistral dans la config Continue.

---

### test_audit_agent

Tests pour le module audit_agent.py
Tests unitaires et d'int√©gration pour AuditAgent

#### Classes

##### TestAuditAgent

Tests pour la classe AuditAgent

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_audit_agent_initialization()`
- `test_act_method_with_simple_prompt()`
- `test_act_method_with_complex_prompt()`
- `test_act_method_with_empty_prompt()`
- `test_act_method_with_special_characters()`
- `test_act_method_with_multiline_prompt()`
- `test_act_method_error_handling()`
- `test_agent_inheritance()`
- `test_agent_consistency()`
- `test_agent_attributes()`
- `test_agent_performance()`

##### TestAuditAgentIntegration

Tests d'int√©gration pour AuditAgent

**M√©thodes :**

- `setUp()`
- `test_integration_with_real_audit_scenario()`
- `test_integration_with_code_analysis()`

#### Fonctions

##### setUp

Configuration initiale pour chaque test

##### tearDown

Nettoyage apr√®s chaque test

##### test_audit_agent_initialization

Test de l'initialisation de l'agent

##### test_act_method_with_simple_prompt

Test de la m√©thode act avec un prompt simple

**Param√®tres :**

- `mock_query_qwen`

##### test_act_method_with_complex_prompt

Test de la m√©thode act avec un prompt complexe

**Param√®tres :**

- `mock_query_qwen`

##### test_act_method_with_empty_prompt

Test de la m√©thode act avec un prompt vide

**Param√®tres :**

- `mock_query_qwen`

##### test_act_method_with_special_characters

Test de la m√©thode act avec des caract√®res sp√©ciaux

**Param√®tres :**

- `mock_query_qwen`

##### test_act_method_with_multiline_prompt

Test de la m√©thode act avec un prompt multi-lignes

**Param√®tres :**

- `mock_query_qwen`

##### test_act_method_error_handling

Test de la gestion d'erreur dans la m√©thode act

**Param√®tres :**

- `mock_query_qwen`

##### test_agent_inheritance

Test de l'h√©ritage de l'agent

##### test_agent_consistency

Test de la coh√©rence de l'agent sur plusieurs appels

**Param√®tres :**

- `mock_query_qwen`

##### test_agent_attributes

Test des attributs de l'agent

##### test_agent_performance

Test de performance de l'agent

**Param√®tres :**

- `mock_query_qwen`

##### setUp

Configuration initiale pour chaque test

##### test_integration_with_real_audit_scenario

Test d'int√©gration avec un sc√©nario d'audit r√©el

**Param√®tres :**

- `mock_query_qwen`

##### test_integration_with_code_analysis

Test d'int√©gration avec analyse de code

**Param√®tres :**

- `mock_query_qwen`

---

### test_coverage_threshold

Test de seuil de couverture de code
V√©rifie que la couverture de code est suffisante

#### Classes

##### TestCoverageThreshold

Tests de seuil de couverture

**M√©thodes :**

- `test_coverage_file_exists()`
- `test_minimum_coverage_threshold()`
- `test_core_modules_coverage()`
- `test_test_files_exist()`
- `test_test_coverage_structure()`
- `test_no_untested_critical_modules()`
- `test_coverage_report_readable()`
- `test_coverage_configuration()`
- `test_test_execution_coverage()`
- `test_coverage_quality_metrics()`

#### Fonctions

##### test_coverage_file_exists

V√©rifie que le fichier de couverture existe

##### test_minimum_coverage_threshold

V√©rifie le seuil minimum de couverture

##### test_core_modules_coverage

V√©rifie la couverture des modules core

##### test_test_files_exist

V√©rifie que les fichiers de test existent

##### test_test_coverage_structure

V√©rifie la structure de couverture des tests

##### test_no_untested_critical_modules

V√©rifie qu'il n'y a pas de modules critiques non test√©s

##### test_coverage_report_readable

V√©rifie que le rapport de couverture est lisible

##### test_coverage_configuration

V√©rifie la configuration de couverture

##### test_test_execution_coverage

V√©rifie que les tests s'ex√©cutent avec couverture

##### test_coverage_quality_metrics

V√©rifie les m√©triques de qualit√© de la couverture

---

### test_audit_intelligent

Tests pour le syst√®me d'audit intelligent Athalia

#### Classes

##### TestAuditIntelligent

Tests pour l'audit intelligent.

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `create_test_project()`
- `test_audit_project_structure()`
- `test_audit_code_quality()`
- `test_audit_security()`
- `test_audit_performance()`
- `test_audit_complete()`
- `test_generate_audit_report()`
- `test_audit_project_not_found()`
- `test_audit_empty_project()`

#### Fonctions

##### test_audit_integration

Test d'int√©gration de l'audit avec un vrai projet.

##### setup_method

Pr√©pare un projet de test pour l'audit.

##### teardown_method

Nettoie apr√®s les tests.

##### create_test_project

Cr√©e un projet de test avec des probl√®mes connus.

##### test_audit_project_structure

##### test_audit_code_quality

##### test_audit_security

##### test_audit_performance

##### test_audit_complete

##### test_generate_audit_report

##### test_audit_project_not_found

##### test_audit_empty_project

---

### test_project_importer

#### Fonctions

##### test_project_import_concept

---

### test_auto_cicd_unit

#### Classes

##### TestAutoCICD

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_constructor()`
- `test_setup_cicd()`
- `test_detect_project_type_python()`
- `test_detect_project_type_nodejs()`
- `test_detect_languages()`
- `test_extract_dependencies_python()`
- `test_find_entry_points()`
- `test_has_tests()`
- `test_has_documentation()`
- `test_generate_github_actions()`
- `test_generate_docker_config()`
- `test_generate_deployment_config()`
- `test_get_created_files()`

#### Fonctions

##### test_generate_github_ci_yaml

##### setUp

##### tearDown

##### test_constructor

##### test_setup_cicd

##### test_detect_project_type_python

##### test_detect_project_type_nodejs

##### test_detect_languages

##### test_extract_dependencies_python

##### test_find_entry_points

##### test_has_tests

##### test_has_documentation

##### test_generate_github_actions

##### test_generate_docker_config

##### test_generate_deployment_config

##### test_get_created_files

---

### test_auto_cleaner_unit

#### Classes

##### TestAutoCleaner

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_constructor()`
- `test_clean_project_dry_run()`
- `test_clean_system_files()`
- `test_clean_cache_files()`
- `test_clean_backup_files()`
- `test_clean_temp_files()`
- `test_clean_duplicate_files()`
- `test_clean_empty_directories()`
- `test_is_code_file()`
- `test_is_important_file()`
- `test_is_empty_directory()`
- `test_calculate_file_hash()`
- `test_generate_cleanup_report()`
- `test_optimize_project_structure()`

#### Fonctions

##### setUp

##### tearDown

##### test_constructor

##### test_clean_project_dry_run

##### test_clean_system_files

##### test_clean_cache_files

##### test_clean_backup_files

##### test_clean_temp_files

##### test_clean_duplicate_files

##### test_clean_empty_directories

##### test_is_code_file

##### test_is_important_file

##### test_is_empty_directory

##### test_calculate_file_hash

##### test_generate_cleanup_report

##### test_optimize_project_structure

---

### test_ready_check

Tests pour ready_check.py

#### Fonctions

##### test_check_ready_ok

Test que le projet est pr√™t

##### test_check_ready_missing

Test avec un projet manquant

---

### test_auto_correction_advanced_complete

Tests complets pour le module auto_correction_advanced.py
Tests unitaires et d'int√©gration pour AutoCorrectionAvancee

#### Classes

##### TestAutoCorrectionAvancee

Tests pour la classe AutoCorrectionAvancee

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `create_test_files()`
- `test_initialization()`
- `test_analyser_et_corriger_dry_run()`
- `test_analyser_et_corriger_real_run()`
- `test_corriger_syntaxe_avancee()`
- `test_corriger_erreur_syntaxe()`
- `test_corriger_indentation()`
- `test_corriger_parentheses()`
- `test_corriger_guillemets()`
- `test_corriger_virgules()`
- `test_optimiser_code()`
- `test_optimiser_list_comprehensions()`
- `test_optimiser_imports()`
- `test_optimiser_boucles()`
- `test_refactoring_automatique()`
- `test_extraire_methodes()`
- `test_renommer_variables()`
- `test_simplifier_conditions()`
- `test_corriger_anti_patterns()`
- `test_ameliorer_lisibilite()`
- `test_generer_rapport()`

##### TestAutoCorrectionAvanceeIntegration

Tests d'int√©gration pour AutoCorrectionAvancee

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_integration_complete_workflow()`
- `test_integration_with_empty_project()`
- `test_integration_with_large_project()`

##### MockSyntaxError

**M√©thodes :**

- `__init__()`

#### Fonctions

##### setUp

Configuration initiale pour chaque test

##### tearDown

Nettoyage apr√®s chaque test

##### create_test_files

Cr√©ation de fichiers de test avec diff√©rents types d'erreurs

##### test_initialization

Test de l'initialisation de la classe

##### test_analyser_et_corriger_dry_run

Test de l'analyse et correction en mode dry_run

##### test_analyser_et_corriger_real_run

Test de l'analyse et correction en mode r√©el

##### test_corriger_syntaxe_avancee

Test de la correction syntaxique avanc√©e

##### test_corriger_erreur_syntaxe

Test de la correction d'erreur syntaxique

##### test_corriger_indentation

Test de la correction d'indentation

##### test_corriger_parentheses

Test de la correction de parenth√®ses

##### test_corriger_guillemets

Test de la correction de guillemets

##### test_corriger_virgules

Test de la correction de virgules

##### test_optimiser_code

Test de l'optimisation de code

##### test_optimiser_list_comprehensions

Test de l'optimisation des list comprehensions

##### test_optimiser_imports

Test de l'optimisation des imports

##### test_optimiser_boucles

Test de l'optimisation des boucles

##### test_refactoring_automatique

Test du refactoring automatique

##### test_extraire_methodes

Test de l'extraction de m√©thodes

##### test_renommer_variables

Test du renommage de variables

##### test_simplifier_conditions

Test de la simplification de conditions

##### test_corriger_anti_patterns

Test de la correction d'anti-patterns

##### test_ameliorer_lisibilite

Test de l'am√©lioration de la lisibilit√©

##### test_generer_rapport

Test de la g√©n√©ration de rapport

##### setUp

Configuration initiale pour chaque test

##### tearDown

Nettoyage apr√®s chaque test

##### test_integration_complete_workflow

Test d'int√©gration du workflow complet

##### test_integration_with_empty_project

Test d'int√©gration avec un projet vide

##### test_integration_with_large_project

Test d'int√©gration avec un projet de grande taille

##### __init__

---

### test_cache_simple

Test simple du cache de performance

#### Classes

##### TestCacheSimple

Tests simples pour le cache.

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_cache_basic()`
- `test_cache_miss()`
- `test_cache_decorator()`
- `test_performance_improvement()`

#### Fonctions

##### setUp

Configuration initiale.

##### tearDown

Nettoyage.

##### test_cache_basic

Test basique du cache.

##### test_cache_miss

Test de cache miss.

##### test_cache_decorator

Test du d√©corateur.

##### test_performance_improvement

Test d'am√©lioration des performances.

##### test_function

**Param√®tres :**

- `project_path`
- `param`

##### slow_function

**Param√®tres :**

- `project_path`

---

### test_auto_correction_avancee

Tests pour le module d'auto-correction avanc√©e
Corrig√© apr√®s r√©organisation des modules

#### Classes

##### TestAutoCorrectionAdvanced

Tests pour l'auto-correction avanc√©e (corrig√©)

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_import_auto_correction()`
- `test_import_dashboard_unified()`
- `test_import_user_profiles()`
- `test_advanced_modules_structure()`

#### Fonctions

##### setUp

Configuration des tests

##### tearDown

Nettoyage apr√®s les tests

##### test_import_auto_correction

Test d'import du module d'auto-correction

##### test_import_dashboard_unified

Test d'import du dashboard unifi√©

##### test_import_user_profiles

Test d'import des profils utilisateur

##### test_advanced_modules_structure

Test de la structure des modules avanc√©s

---

### test_hardcoded_paths

Tests pour d√©tecter les chemins hardcod√©s

#### Classes

##### TestHardcodedPaths

Tests pour d√©tecter les chemins hardcod√©s

**M√©thodes :**

- `test_no_absolute_paths_in_source()`
- `test_no_absolute_paths()`
- `test_no_desktop_paths()`
- `_is_acceptable_path()`

#### Fonctions

##### test_no_absolute_paths_in_source

Test qu'il n'y a pas de chemins absolus dans le code source (sauf tests)

##### test_no_absolute_paths

Test qu'il n'y a pas de chemins absolus hardcod√©s

##### test_no_desktop_paths

Test qu'il n'y a pas de chemins Desktop hardcod√©s

##### _is_acceptable_path

V√©rifie si un chemin absolu est acceptable

**Param√®tres :**

- `path`

---

### test_auto_documenter_unit

#### Classes

##### TestAutoDocumenter

**M√©thodes :**

- `setUp()`
- `test_constructor()`
- `test_load_translations()`
- `test_document_project()`
- `test_generate_readme()`
- `test_generate_api_documentation()`
- `test_generate_setup_guide()`
- `test_generate_usage_guide()`
- `test_get_created_files()`

#### Fonctions

##### setUp

##### test_constructor

##### test_load_translations

##### test_document_project

##### test_generate_readme

##### test_generate_api_documentation

##### test_generate_setup_guide

##### test_generate_usage_guide

##### test_get_created_files

---

### test_auto_tester_unit

#### Classes

##### TestAutoTester

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_constructor()`
- `test_analyze_modules()`
- `test_generate_unit_tests()`
- `test_generate_integration_tests()`
- `test_generate_performance_tests()`
- `test_generate_test_report()`
- `test_generate_tests()`

#### Fonctions

##### setUp

##### tearDown

##### test_constructor

##### test_analyze_modules

##### test_generate_unit_tests

##### test_generate_integration_tests

##### test_generate_performance_tests

##### test_generate_test_report

##### test_generate_tests

---

### test_autocomplete_server

#### Classes

##### MockResp

**M√©thodes :**

- `raise_for_status()`
- `json()`

#### Fonctions

##### test_autocomplete_nominal

##### test_autocomplete_empty_prompt

##### test_ollama_autocomplete_engine

**Param√®tres :**

- `monkeypatch`

##### mock_post

##### raise_for_status

##### json

---

### test_profils_utilisateur_avances

Tests pour les profils utilisateur avanc√©s
Corrig√© apr√®s r√©organisation des modules

#### Classes

##### TestUserProfilesAdvanced

Tests pour les profils utilisateur avanc√©s (corrig√©)

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_import_user_profiles()`
- `test_profiles_structure()`
- `test_profiles_functionality()`

#### Fonctions

##### setUp

Configuration des tests

##### tearDown

Nettoyage apr√®s les tests

##### test_import_user_profiles

Test d'import des profils utilisateur

##### test_profiles_structure

Test de la structure des profils

##### test_profiles_functionality

Test de la fonctionnalit√© des profils

---

### test_benchmark_critical

#### Fonctions

##### import_critical_function

**Param√®tres :**

- `module_name`
- `func_name`

##### test_critical_function_benchmark

**Param√®tres :**

- `benchmark`
- `module_name`
- `func_name`
- `needs_path`

##### test_global_coverage_threshold

Ce test √©choue si la couverture descend sous 80%.

---

### test_ci_robust

üß™ Tests CI Robustes - Athalia/Arkalia
=====================================

Tests robustes pour la validation CI/CD compl√®te
Tests plus approfondis pour validation de qualit√©

#### Classes

##### TestCIRobust

Tests CI robustes pour validation compl√®te

**M√©thodes :**

- `test_python_environment()`
- `test_project_structure_complete()`
- `test_config_files_complete()`
- `test_test_suite_structure()`
- `test_requirements_validation()`
- `test_ci_workflow_validation()`
- `test_file_permissions_complete()`
- `test_encoding_validation()`
- `test_json_yaml_parsing()`
- `test_subprocess_functionality()`
- `test_time_functionality()`
- `test_pathlib_functionality()`
- `test_environment_robustness()`
- `test_error_handling()`
- `test_assertion_functionality()`

#### Fonctions

##### test_python_environment

V√©rifie l'environnement Python complet

##### test_project_structure_complete

V√©rifie la structure compl√®te du projet

##### test_config_files_complete

V√©rifie tous les fichiers de configuration

##### test_test_suite_structure

V√©rifie la structure de la suite de tests

##### test_requirements_validation

Valide les fichiers requirements

##### test_ci_workflow_validation

Valide le workflow CI

##### test_file_permissions_complete

V√©rifie les permissions compl√®tes

##### test_encoding_validation

Valide l'encodage UTF-8 complet

##### test_json_yaml_parsing

Teste le parsing JSON et YAML

##### test_subprocess_functionality

Teste la fonctionnalit√© subprocess

##### test_time_functionality

Teste la fonctionnalit√© time

##### test_pathlib_functionality

Teste la fonctionnalit√© pathlib

##### test_environment_robustness

Teste la robustesse de l'environnement

##### test_error_handling

Teste la gestion d'erreurs

##### test_assertion_functionality

Teste la fonctionnalit√© d'assertion

---

### test_imports_all

Test d'importation exhaustive de tous les modules
V√©rifie que tous les modules peuvent √™tre import√©s sans erreur

#### Classes

##### TestImportsAll

Tests d'importation exhaustive

**M√©thodes :**

- `test_core_modules_import()`
- `test_distillation_modules_import()`
- `test_classification_modules_import()`
- `test_i18n_modules_import()`
- `test_plugins_modules_import()`
- `test_modules_import()`
- `test_agents_import()`
- `test_templates_import()`
- `test_all_python_files_importable()`
- `test_no_circular_imports()`
- `test_third_party_imports()`

#### Fonctions

##### test_core_modules_import

Test d'import des modules core

##### test_distillation_modules_import

Test d'import des modules de distillation

##### test_classification_modules_import

Test d'import des modules de classification

##### test_i18n_modules_import

Test d'import des modules i18n

##### test_plugins_modules_import

Test d'import des modules plugins

##### test_modules_import

Test d'import des modules externes

##### test_agents_import

Test que tous les modules agents peuvent √™tre import√©s

##### test_templates_import

Test que tous les modules templates peuvent √™tre import√©s

##### test_all_python_files_importable

Test que tous les fichiers Python peuvent √™tre import√©s

##### test_no_circular_imports

Test qu'il n'y a pas d'imports circulaires

##### test_third_party_imports

Test des imports de biblioth√®ques tierces

---

### test_ci_ultra_fast

Tests CI ultra-rapides pour Athalia
Tests essentiels qui ne doivent jamais bloquer le CI

#### Classes

##### TestCIUltraFast

Tests CI ultra-rapides et essentiels

**M√©thodes :**

- `test_project_structure()`
- `test_essential_files()`
- `test_python_syntax_basic()`
- `test_imports_basic()`
- `test_config_validity()`
- `test_requirements_format()`
- `test_ci_workflow_exists()`
- `test_no_critical_errors()`
- `test_project_ready()`

#### Fonctions

##### test_project_structure

Test que la structure de base du projet existe

##### test_essential_files

Test que les fichiers essentiels existent

##### test_python_syntax_basic

Test de syntaxe Python basique sur les fichiers principaux

##### test_imports_basic

Test d'imports basiques

##### test_config_validity

Test de validit√© basique de la configuration

##### test_requirements_format

Test de format basique des requirements

##### test_ci_workflow_exists

Test que le workflow CI existe

##### test_no_critical_errors

Test qu'il n'y a pas d'erreurs critiques

##### test_project_ready

Test que le projet est pr√™t pour le d√©veloppement

---

### test_security_comprehensive

üß™ TESTS COMPLETS - SECURITY MODULE
===================================
Tests complets pour am√©liorer la couverture du module security.py.

#### Classes

##### TestSecurityComprehensive

Tests complets pour le module security

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_security_audit_project_clean_project()`
- `test_security_audit_project_with_password()`
- `test_security_audit_project_with_api_key()`
- `test_security_audit_project_with_os_system()`
- `test_security_audit_project_multiple_issues()`
- `test_security_audit_project_with_f_files()`
- `test_security_audit_project_file_read_error()`
- `test_security_audit_project_empty_directory()`
- `test_security_audit_project_ignores_non_python_files()`
- `test_security_audit_project_case_insensitive()`
- `test_security_audit_project_creates_audit_file()`
- `test_security_audit_project_score_calculation()`
- `test_security_audit_project_with_subdirectories()`
- `test_security_audit_project_complex_patterns()`

#### Fonctions

##### setup_method

Configuration avant chaque test

##### teardown_method

Nettoyage apr√®s chaque test

##### test_security_audit_project_clean_project

Test d'audit de s√©curit√© sur un projet propre

##### test_security_audit_project_with_password

Test d'audit avec mot de passe en clair

##### test_security_audit_project_with_api_key

Test d'audit avec cl√© API

##### test_security_audit_project_with_os_system

Test d'audit avec appel syst√®me

##### test_security_audit_project_multiple_issues

Test d'audit avec plusieurs probl√®mes

##### test_security_audit_project_with_f_files

Test d'audit avec fichiers .f(f

##### test_security_audit_project_file_read_error

Test d'audit avec erreur de lecture de fichier

##### test_security_audit_project_empty_directory

Test d'audit sur un r√©pertoire vide

##### test_security_audit_project_ignores_non_python_files

Test que l'audit ignore les fichiers non Python

##### test_security_audit_project_case_insensitive

Test que l'audit est insensible √† la casse

##### test_security_audit_project_creates_audit_file

Test que l'audit cr√©e le fichier de rapport

##### test_security_audit_project_score_calculation

Test du calcul du score de s√©curit√©

##### test_security_audit_project_with_subdirectories

Test d'audit avec sous-r√©pertoires

##### test_security_audit_project_complex_patterns

Test d'audit avec des patterns complexes

---

### test_cli_complete

Tests complets pour athalia_core.cli
Couverture maximale avec tests professionnels

#### Classes

##### TestCLIComplete

Tests complets pour la CLI athalia_core

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_cli_group_creation()`
- `test_cli_verbose_option()`
- `test_generate_command_success()`
- `test_generate_command_dry_run()`
- `test_generate_command_no_blueprint()`
- `test_generate_command_exception()`
- `test_audit_command_success()`
- `test_audit_command_exception()`
- `test_ai_status_command_success()`
- `test_ai_status_command_import_error()`
- `test_ai_status_command_exception()`
- `test_test_ai_command_success()`
- `test_test_ai_command_import_error()`
- `test_test_ai_command_exception()`
- `test_generate_command_output_directory_creation()`
- `test_audit_command_report_creation()`
- `test_cli_help_output()`
- `test_generate_command_default_output()`
- `test_test_ai_command_review_code_parameters()`
- `test_test_ai_command_documentation_parameters()`

##### TestCLIIntegration

Tests d'int√©gration pour la CLI

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_cli_workflow_complete()`
- `test_cli_error_handling_robustness()`

#### Fonctions

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_cli_group_creation

Test la cr√©ation du groupe CLI principal

##### test_cli_verbose_option

Test l'option verbose du CLI principal

##### test_generate_command_success

Test la commande generate avec succ√®s

**Param√®tres :**

- `mock_echo`
- `mock_generate_project`
- `mock_robust_ai`

##### test_generate_command_dry_run

Test la commande generate en mode dry-run

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_generate_command_no_blueprint

Test la commande generate quand le blueprint ne peut pas √™tre g√©n√©r√©

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_generate_command_exception

Test la commande generate avec exception

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_audit_command_success

Test la commande audit avec succ√®s

**Param√®tres :**

- `mock_echo`
- `mock_audit`

##### test_audit_command_exception

Test la commande audit avec exception

**Param√®tres :**

- `mock_echo`
- `mock_audit`

##### test_ai_status_command_success

Test la commande ai_status avec succ√®s

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_ai_status_command_import_error

Test la commande ai_status avec ImportError

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_ai_status_command_exception

Test la commande ai_status avec exception g√©n√©rale

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_test_ai_command_success

Test la commande test_ai avec succ√®s

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_test_ai_command_import_error

Test la commande test_ai avec ImportError

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_test_ai_command_exception

Test la commande test_ai avec exception g√©n√©rale

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_generate_command_output_directory_creation

Test que la commande generate cr√©e le dossier de sortie

##### test_audit_command_report_creation

Test que la commande audit cr√©e un rapport YAML

**Param√®tres :**

- `mock_echo`
- `mock_audit`

##### test_cli_help_output

Test que la CLI affiche l'aide correctement

##### test_generate_command_default_output

Test que la commande generate utilise le dossier par d√©faut

##### test_test_ai_command_review_code_parameters

Test que test_ai appelle review_code avec les bons param√®tres

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### test_test_ai_command_documentation_parameters

Test que test_ai appelle generate_documentation avec les bons param√®tres

**Param√®tres :**

- `mock_echo`
- `mock_robust_ai`

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_cli_workflow_complete

Test un workflow complet de la CLI

**Param√®tres :**

- `mock_audit`
- `mock_generate_project`
- `mock_robust_ai`

##### test_cli_error_handling_robustness

Test la robustesse de la gestion d'erreurs de la CLI

---

### test_requirements_consistency

Test de coh√©rence des d√©pendances
V√©rifie que les fichiers de d√©pendances sont coh√©rents

#### Classes

##### TestRequirementsConsistency

Tests de coh√©rence des d√©pendances

**M√©thodes :**

- `test_requirements_txt_exists()`
- `test_requirements_txt_readable()`
- `test_requirements_format()`
- `test_essential_dependencies()`
- `test_no_duplicate_dependencies()`
- `test_pyproject_toml_exists()`
- `test_pyproject_toml_readable()`
- `test_requirements_vs_pyproject_consistency()`
- `test_no_conflicting_versions()`
- `test_no_obsolete_dependencies()`
- `test_requirements_installable()`

#### Fonctions

##### test_requirements_txt_exists

V√©rifie que requirements.txt existe

##### test_requirements_txt_readable

V√©rifie que requirements.txt est lisible

##### test_requirements_format

V√©rifie le format de requirements.txt

##### test_essential_dependencies

V√©rifie que les d√©pendances essentielles sont pr√©sentes

##### test_no_duplicate_dependencies

Test qu'il n'y a pas de d√©pendances dupliqu√©es

##### test_pyproject_toml_exists

V√©rifie que pyproject.toml existe

##### test_pyproject_toml_readable

V√©rifie que pyproject.toml est lisible

##### test_requirements_vs_pyproject_consistency

V√©rifie la coh√©rence entre requirements.txt et pyproject.toml

##### test_no_conflicting_versions

V√©rifie qu'il n'y a pas de versions conflictuelles

##### test_no_obsolete_dependencies

V√©rifie qu'il n'y a pas de d√©pendances obsol√®tes

##### test_requirements_installable

V√©rifie que requirements.txt est installable

---

### test_code_genetics

#### Classes

##### TestCodeGenetics

**M√©thodes :**

- `setUp()`
- `test_crossover()`
- `test_mutate()`
- `test_select()`
- `test_evolve()`
- `test_empty()`

#### Fonctions

##### setUp

##### test_crossover

##### test_mutate

##### test_select

##### test_evolve

##### test_empty

---

### test_security_patterns

Test de d√©tection des patterns de s√©curit√© dangereux
V√©rifie qu'il n'y a pas de code dangereux dans le projet

#### Classes

##### TestSecurityPatterns

Tests de d√©tection des patterns de s√©curit√©

**M√©thodes :**

- `test_no_hardcoded_passwords()`
- `test_no_sql_injection_patterns()`
- `test_no_eval_usage()`
- `test_no_shell_injection()`
- `test_no_debug_code()`
- `test_no_hardcoded_urls()`
- `test_no_weak_crypto()`

#### Fonctions

##### test_no_hardcoded_passwords

Test qu'il n'y a pas de mots de passe hardcod√©s

##### test_no_sql_injection_patterns

Test qu'il n'y a pas de patterns d'injection SQL

##### test_no_eval_usage

Test qu'il n'y a pas d'utilisation de fonctions dangereuses

##### test_no_shell_injection

Test qu'il n'y a pas d'injection shell

##### test_no_debug_code

Test qu'il n'y a pas de code de debug

##### test_no_hardcoded_urls

V√©rifie qu'il n'y a pas d'URLs hardcod√©es

##### test_no_weak_crypto

V√©rifie qu'il n'y a pas de crypto faible

---

### test_security

#### Fonctions

##### test_security_audit_project

**Param√®tres :**

- `tmp_path`

---

### test_correction

Script de test pour la correction du projet EmotionSensingRoboticEyes

#### Fonctions

##### test_audit

Test de l'audit du f

##### test_correction

Test de la correction du f

##### test_generation_improvement

Test d'am√©lioration du service de f

##### main

Fonction principale de f

---

### test_unified_orchestrator_complete

üß™ TESTS COMPLETS POUR L'ORCHESTRATEUR UNIFI√â ATHALIA

Ce fichier teste TOUTES les fonctionnalit√©s de l'orchestrateur unifi√©
pour atteindre une couverture de test √©lev√©e.

#### Classes

##### TestUnifiedOrchestratorComplete

Tests complets pour l'orchestrateur unifi√©

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_orchestrator_initialization()`
- `test_database_initialization()`
- `test_orchestrate_project_complete_basic()`
- `test_orchestrate_project_complete_with_industrialization()`
- `test_run_audit()`
- `test_run_linting()`
- `test_run_security_audit()`
- `test_run_analytics()`
- `test_run_cleanup()`
- `test_run_documentation()`
- `test_run_testing()`
- `test_run_cicd()`
- `test_run_robotics_audit()`
- `test_generate_predictions()`
- `test_generate_optimizations()`
- `test_learn_from_results()`
- `test_generate_unified_report()`
- `test_save_unified_results()`
- `test_get_orchestration_insights()`
- `test_phase2_backup()`
- `test_phase2_error_handling()`
- `test_validate_phase2_inputs()`
- `test_get_phase2_backup_stats()`
- `test_orchestrate_with_phase2_features()`
- `test_error_handling_in_industrialization()`
- `test_cli_entry_point()`
- `test_main_entry_point()`
- `test_main_with_args()`
- `test_orchestrator_auto_backup()`

#### Fonctions

##### setup_method

Configuration avant chaque test

##### teardown_method

Nettoyage apr√®s chaque test

##### test_orchestrator_initialization

Test l'initialisation compl√®te de l'orchestrateur

##### test_database_initialization

Test l'initialisation de la base de donn√©es

##### test_orchestrate_project_complete_basic

Test l'orchestration compl√®te basique

##### test_orchestrate_project_complete_with_industrialization

Test l'orchestration avec industrialisation

##### test_run_audit

Test l'ex√©cution de l'audit

##### test_run_linting

Test l'ex√©cution du linting

##### test_run_security_audit

Test l'ex√©cution de l'audit de s√©curit√©

##### test_run_analytics

Test l'ex√©cution de l'analytics

##### test_run_cleanup

Test l'ex√©cution du nettoyage

##### test_run_documentation

Test l'ex√©cution de la documentation

##### test_run_testing

Test l'ex√©cution des tests

##### test_run_cicd

Test l'ex√©cution du CI/CD

##### test_run_robotics_audit

Test l'ex√©cution de l'audit robotique

##### test_generate_predictions

Test la g√©n√©ration de pr√©dictions

##### test_generate_optimizations

Test la g√©n√©ration d'optimisations

##### test_learn_from_results

Test l'apprentissage des r√©sultats

##### test_generate_unified_report

Test la g√©n√©ration du rapport unifi√©

##### test_save_unified_results

Test la sauvegarde des r√©sultats

##### test_get_orchestration_insights

Test la r√©cup√©ration des insights d'orchestration

##### test_phase2_backup

Test la sauvegarde Phase 2

##### test_phase2_error_handling

Test la gestion d'erreurs Phase 2

##### test_validate_phase2_inputs

Test la validation des entr√©es Phase 2

##### test_get_phase2_backup_stats

Test les statistiques de sauvegarde Phase 2

##### test_orchestrate_with_phase2_features

Test l'orchestration avec fonctionnalit√©s Phase 2

##### test_error_handling_in_industrialization

Test la gestion d'erreurs dans l'industrialisation

##### test_cli_entry_point

Test le point d'entr√©e CLI

##### test_main_entry_point

Test le point d'entr√©e principal

##### test_main_with_args

Test le point d'entr√©e principal avec arguments

##### test_orchestrator_auto_backup

Test la sauvegarde automatique de l'orchestrateur

##### test_operation

---

### test_encoding_utf8

Test de v√©rification de l'encodage UTF-8
V√©rifie que tous les fichiers sont correctement encod√©s en UTF-8

#### Classes

##### TestEncodingUTF8

Tests de v√©rification de l'encodage UTF-8

**M√©thodes :**

- `test_python_files_utf8()`
- `test_markdown_files_utf8()`
- `test_yaml_files_utf8()`
- `test_txt_files_utf8()`
- `test_requirements_utf8()`
- `test_config_utf8()`
- `test_no_bom_marker()`
- `test_consistent_line_endings()`

#### Fonctions

##### test_python_files_utf8

V√©rifie que tous les fichiers Python sont en UTF-8

##### test_markdown_files_utf8

V√©rifie que tous les fichiers Markdown sont en UTF-8

##### test_yaml_files_utf8

V√©rifie que tous les fichiers YAML sont en UTF-8

##### test_txt_files_utf8

V√©rifie que tous les fichiers TXT sont en UTF-8

##### test_requirements_utf8

V√©rifie que requirements.txt est en UTF-8

##### test_config_utf8

V√©rifie que les fichiers de config sont en UTF-8

##### test_no_bom_marker

V√©rifie qu'il n'y a pas de marqueur BOM UTF-8

##### test_consistent_line_endings

Test que tous les fichiers ont des fins de ligne coh√©rentes

---

### test_generation

#### Fonctions

##### test_save_and_inject

**Param√®tres :**

- `tmp_path`

##### test_scan_existing_project

**Param√®tres :**

- `tmp_path`

##### test_generate_project_dry_run

**Param√®tres :**

- `tmp_path`

##### test_merge_or_suffix_file

**Param√®tres :**

- `tmp_path`

##### test_merge_or_suffix_file_types

**Param√®tres :**

- `tmp_path`

##### test_backup_file

**Param√®tres :**

- `tmp_path`

---

### test_robotics_docker_complete

Tests complets pour athalia_core.robotics.docker_robotics

#### Classes

##### TestDockerRoboticsComplete

Tests unitaires complets pour DockerRoboticsManager

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_init()`
- `test_validate_docker_setup_no_compose()`
- `test_validate_docker_setup_with_valid_compose()`
- `test_validate_docker_setup_with_invalid_compose()`
- `test_validate_docker_setup_without_reachy_service()`
- `test_parse_service_config_valid()`
- `test_parse_service_config_minimal()`
- `test_parse_service_config_invalid()`
- `test_validate_reachy_service_complete()`
- `test_validate_reachy_service_missing_image()`
- `test_validate_reachy_service_wrong_image()`
- `test_validate_reachy_service_missing_ros_domain()`
- `test_validate_reachy_service_missing_display()`
- `test_validate_reachy_service_missing_volumes()`
- `test_validate_reachy_service_wrong_network_mode()`
- `test_create_reachy_compose_template()`
- `test_create_dockerfile_template()`
- `test_create_start_script_template()`
- `test_setup_reachy_environment_success()`
- `test_setup_reachy_environment_exception()`
- `test_run_docker_compose_success()`
- `test_run_docker_compose_failure()`
- `test_run_docker_compose_exception()`
- `test_run_docker_compose_no_compose_file()`
- `test_generate_docker_report()`

##### TestDockerRoboticsIntegration

Tests d'int√©gration pour DockerRoboticsManager

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_full_docker_workflow()`
- `test_docker_validation_with_real_files()`
- `test_docker_service_config_parsing_real()`

##### TestDockerRoboticsEdgeCases

Tests des cas limites pour DockerRoboticsManager

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_validate_docker_setup_empty_compose()`
- `test_validate_docker_setup_compose_without_services()`
- `test_validate_reachy_service_environment_list()`
- `test_validate_reachy_service_environment_mixed()`
- `test_generate_docker_report_empty_result()`
- `test_generate_docker_report_with_issues()`
- `test_docker_service_config_dataclass()`
- `test_docker_validation_result_dataclass()`

##### TestMainFunction

Tests pour les fonctions principales

**M√©thodes :**

- `test_docker_service_config_creation()`
- `test_docker_validation_result_creation()`

#### Fonctions

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_init

Test initialisation

##### test_validate_docker_setup_no_compose

Test validation sans docker-compose.yaml

##### test_validate_docker_setup_with_valid_compose

Test validation avec docker-compose.yaml valide

##### test_validate_docker_setup_with_invalid_compose

Test validation avec docker-compose.yaml invalide

##### test_validate_docker_setup_without_reachy_service

Test validation sans service Reachy

##### test_parse_service_config_valid

Test parsing de configuration de service valide

##### test_parse_service_config_minimal

Test parsing de configuration de service minimale

##### test_parse_service_config_invalid

Test parsing de configuration de service invalide

##### test_validate_reachy_service_complete

Test validation compl√®te du service Reachy

##### test_validate_reachy_service_missing_image

Test validation service Reachy sans image

##### test_validate_reachy_service_wrong_image

Test validation service Reachy avec mauvaise image

##### test_validate_reachy_service_missing_ros_domain

Test validation service Reachy sans ROS_DOMAIN_ID

##### test_validate_reachy_service_missing_display

Test validation service Reachy sans DISPLAY

##### test_validate_reachy_service_missing_volumes

Test validation service Reachy sans volumes

##### test_validate_reachy_service_wrong_network_mode

Test validation service Reachy avec mauvais network_mode

##### test_create_reachy_compose_template

Test cr√©ation du template docker-compose

##### test_create_dockerfile_template

Test cr√©ation du template Dockerfile

##### test_create_start_script_template

Test cr√©ation du template de script de d√©marrage

##### test_setup_reachy_environment_success

Test setup complet de l'environnement Reachy

##### test_setup_reachy_environment_exception

Test setup avec exception

##### test_run_docker_compose_success

Test lancement docker-compose r√©ussi

**Param√®tres :**

- `mock_run`

##### test_run_docker_compose_failure

Test lancement docker-compose √©chou√©

**Param√®tres :**

- `mock_run`

##### test_run_docker_compose_exception

Test lancement docker-compose avec exception

**Param√®tres :**

- `mock_run`

##### test_run_docker_compose_no_compose_file

Test lancement docker-compose sans fichier

##### test_generate_docker_report

Test g√©n√©ration de rapport Docker

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_full_docker_workflow

Test workflow Docker complet

##### test_docker_validation_with_real_files

Test validation avec de vrais fichiers

##### test_docker_service_config_parsing_real

Test parsing de configuration de service avec de vrais fichiers

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_validate_docker_setup_empty_compose

Test validation avec docker-compose.yaml vide

##### test_validate_docker_setup_compose_without_services

Test validation avec docker-compose.yaml sans services

##### test_validate_reachy_service_environment_list

Test validation service Reachy avec environment en liste

##### test_validate_reachy_service_environment_mixed

Test validation service Reachy avec environment mixte

##### test_generate_docker_report_empty_result

Test g√©n√©ration de rapport avec r√©sultat vide

##### test_generate_docker_report_with_issues

Test g√©n√©ration de rapport avec probl√®mes

##### test_docker_service_config_dataclass

Test cr√©ation et utilisation de DockerServiceConfig

##### test_docker_validation_result_dataclass

Test cr√©ation et utilisation de DockerValidationResult

##### test_docker_service_config_creation

Test cr√©ation de DockerServiceConfig

##### test_docker_validation_result_creation

Test cr√©ation de DockerValidationResult

---

### test_robotics_reachy_auditor_complete

Tests complets pour athalia_core.robotics.reachy_auditor

#### Classes

##### TestReachyAuditorComplete

Tests complets pour ReachyAuditor

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_init()`
- `test_audit_complete_all_valid()`
- `test_audit_complete_ros2_invalid()`
- `test_audit_complete_docker_invalid()`
- `test_audit_ros2_success()`
- `test_audit_ros2_no_src()`
- `test_audit_ros2_no_packages()`
- `test_audit_docker_success()`
- `test_audit_docker_no_compose()`
- `test_audit_docker_invalid_yaml()`
- `test_audit_docker_no_reachy_service()`
- `test_audit_rust_success()`
- `test_audit_rust_no_projects()`
- `test_audit_rust_invalid_cargo()`
- `test_audit_structure_success()`
- `test_audit_structure_no_readme()`
- `test_audit_structure_no_tests()`
- `test_generate_report()`
- `test_save_report()`
- `test_save_report_custom_path()`

##### TestReachyAuditorIntegration

Tests d'int√©gration pour ReachyAuditor

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_full_reachy_audit_integration()`
- `test_reachy_audit_report_integration()`

##### TestReachyAuditorEdgeCases

Tests des cas limites pour ReachyAuditor

**M√©thodes :**

- `setup_method()`
- `teardown_method()`
- `test_audit_complete_empty_project()`
- `test_audit_complete_perfect_score()`
- `test_generate_report_empty_result()`
- `test_save_report_permission_error()`

##### TestMainFunction

Tests pour les fonctions principales

**M√©thodes :**

- `test_reachy_audit_result_dataclass()`

#### Fonctions

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_init

Test l'initialisation de ReachyAuditor

##### test_audit_complete_all_valid

Test audit complet avec tout valide

##### test_audit_complete_ros2_invalid

Test audit complet avec ROS2 invalide

##### test_audit_complete_docker_invalid

Test audit complet avec Docker invalide

##### test_audit_ros2_success

Test audit ROS2 - succ√®s

##### test_audit_ros2_no_src

Test audit ROS2 - pas de dossier src

##### test_audit_ros2_no_packages

Test audit ROS2 - pas de packages

##### test_audit_docker_success

Test audit Docker - succ√®s

##### test_audit_docker_no_compose

Test audit Docker - pas de docker-compose

##### test_audit_docker_invalid_yaml

Test audit Docker - YAML invalide

##### test_audit_docker_no_reachy_service

Test audit Docker - pas de service reachy_2023

##### test_audit_rust_success

Test audit Rust - succ√®s

##### test_audit_rust_no_projects

Test audit Rust - pas de projets

##### test_audit_rust_invalid_cargo

Test audit Rust - Cargo.toml invalide

##### test_audit_structure_success

Test audit structure - succ√®s

##### test_audit_structure_no_readme

Test audit structure - pas de README

##### test_audit_structure_no_tests

Test audit structure - pas de tests

##### test_generate_report

Test g√©n√©ration de rapport

##### test_save_report

Test sauvegarde de rapport

##### test_save_report_custom_path

Test sauvegarde de rapport avec chemin personnalis√©

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_full_reachy_audit_integration

Test int√©gration audit Reachy complet

##### test_reachy_audit_report_integration

Test int√©gration g√©n√©ration et sauvegarde de rapport

##### setup_method

Setup pour chaque test

##### teardown_method

Cleanup apr√®s chaque test

##### test_audit_complete_empty_project

Test audit complet avec projet vide

##### test_audit_complete_perfect_score

Test audit complet avec score parfait

##### test_generate_report_empty_result

Test g√©n√©ration rapport avec r√©sultat vide

##### test_save_report_permission_error

Test sauvegarde rapport avec erreur de permission

##### test_reachy_audit_result_dataclass

Test dataclass ReachyAuditResult

---

### test_intelligent_memory

Tests pour le module intelligent_memory.py
Teste le syst√®me de m√©moire intelligente d'Athalia

#### Classes

##### TestIntelligentMemory

Tests pour le syst√®me de m√©moire intelligente

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_init_database()`
- `test_learn_from_error()`
- `test_learn_from_correction()`
- `test_learn_from_duplicate()`
- `test_predict_issues()`
- `test_suggest_corrections()`
- `test_get_learning_insights()`
- `test_analyze_code_pattern()`
- `test_normalize_code()`
- `test_calculate_code_similarity()`
- `test_record_learning_event()`
- `test_find_similar_patterns()`
- `test_check_antipatterns()`
- `test_check_potential_duplicates()`
- `test_save_correction_suggestion()`
- `test_learning_event_dataclass()`
- `test_prediction_dataclass()`
- `test_correction_suggestion_dataclass()`
- `test_integration_workflow()`

#### Fonctions

##### setUp

Configuration initiale pour chaque test

##### tearDown

Nettoyage apr√®s chaque test

##### test_init_database

Test de l'initialisation de la base de donn√©es

##### test_learn_from_error

Test d'apprentissage d'une erreur

##### test_learn_from_correction

Test d'apprentissage d'une correction

##### test_learn_from_duplicate

Test d'apprentissage d'un doublon

##### test_predict_issues

Test de pr√©diction d'issues

##### test_suggest_corrections

Test de suggestions de corrections

##### test_get_learning_insights

Test de r√©cup√©ration des insights d'apprentissage

##### test_analyze_code_pattern

Test d'analyse de pattern de code

##### test_normalize_code

Test de normalisation de code

##### test_calculate_code_similarity

Test de calcul de similarit√© de code

##### test_record_learning_event

Test d'enregistrement d'√©v√©nement d'apprentissage

##### test_find_similar_patterns

Test de recherche de patterns similaires

##### test_check_antipatterns

Test de v√©rification d'anti-patterns

##### test_check_potential_duplicates

Test de v√©rification de doublons potentiels

##### test_save_correction_suggestion

Test de sauvegarde de suggestion de correction

##### test_learning_event_dataclass

Test de la dataclass LearningEvent

##### test_prediction_dataclass

Test de la dataclass Prediction

##### test_correction_suggestion_dataclass

Test de la dataclass CorrectionSuggestion

##### test_integration_workflow

Test d'un workflow d'int√©gration complet

---

### test_lint_flake8

Tests pour le linting flake8

#### Fonctions

##### test_flake8_clean

Test que le code passe flake8 sans erreurs

---

### test_multi_file_editor

#### Fonctions

##### test_apply_corrections_and_rollback

##### test_apply_corrections_error

##### corr_fn

**Param√®tres :**

- `content`

##### corr_fn

**Param√®tres :**

- `content`

---

### test_multimodal_distiller

#### Classes

##### TestMultimodalDistiller

**M√©thodes :**

- `test_distill()`
- `test_empty()`

#### Fonctions

##### test_distill

**Param√®tres :**

- `mock_model`
- `mock_llava`

##### test_empty

---

### test_no_polluting_files

Tests pour d√©tecter les fichiers polluants

#### Classes

##### TestNoPollutingFiles

Tests pour d√©tecter les fichiers polluants

**M√©thodes :**

- `test_no_macos_hidden_files()`
- `test_no_python_cache_files()`
- `test_no_temp_files()`
- `test_no_corrupted_files()`
- `test_no_editor_files()`
- `test_no_archive_files()`
- `test_no_secret_files()`
- `test_no_large_files()`
- `test_no_duplicate_files()`
- `test_no_empty_directories()`

#### Fonctions

##### test_no_macos_hidden_files

Test qu'il n'y a pas de fichiers cach√©s macOS

##### test_no_python_cache_files

Test qu'il n'y a pas de fichiers cache Python

##### test_no_temp_files

Test qu'il n'y a pas de fichiers temporaires

##### test_no_corrupted_files

Test qu'il n'y a pas de fichiers corrompus

##### test_no_editor_files

Test qu'il n'y a pas de fichiers d'√©diteur

##### test_no_archive_files

Test qu'il n'y a pas de fichiers d'archive dans le projet

##### test_no_secret_files

Test qu'il n'y a pas de fichiers de secrets

##### test_no_large_files

Test qu'il n'y a pas de fichiers trop volumineux

##### test_no_duplicate_files

Test qu'il n'y a pas de fichiers dupliqu√©s

##### test_no_empty_directories

Test qu'il n'y a pas de r√©pertoires vides

---

### test_onboarding

#### Fonctions

##### test_onboarding

**Param√®tres :**

- `tmp_path`

---

### test_user_profiles_advanced_complete

Tests complets pour le module user_profiles_advanced.py
Tests unitaires et d'int√©gration pour ProfilUtilisateur et GestionnaireProfils

#### Classes

##### TestProfilUtilisateur

Tests pour la classe ProfilUtilisateur

**M√©thodes :**

- `setUp()`
- `test_initialization()`
- `test_initialization_with_preferences()`
- `test_to_dict()`
- `test_from_dict()`
- `test_from_dict_with_missing_fields()`

##### TestGestionnaireProfils

Tests pour la classe GestionnaireProfils

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_initialization()`
- `test_init_database()`
- `test_creer_profil()`
- `test_creer_profil_with_preferences()`
- `test_obtenir_profil()`
- `test_obtenir_profil_inexistant()`
- `test_mettre_a_jour_profil()`
- `test_enregistrer_action()`
- `test_enregistrer_consultation_projet()`
- `test_obtenir_statistiques()`
- `test_generer_rapport_profil()`
- `test_lister_profils()`
- `test_supprimer_profil()`
- `test_supprimer_profil_inexistant()`
- `test_exporter_profil()`
- `test_importer_profil()`

##### TestGestionnaireProfilsIntegration

Tests d'int√©gration pour GestionnaireProfils

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_integration_complete_workflow()`
- `test_integration_with_multiple_users()`
- `test_integration_error_handling()`

#### Fonctions

##### setUp

Configuration initiale pour chaque test

##### test_initialization

Test de l'initialisation du profil

##### test_initialization_with_preferences

Test de l'initialisation avec des pr√©f√©rences

##### test_to_dict

Test de la conversion en dictionnaire

##### test_from_dict

Test de la cr√©ation depuis un dictionnaire

##### test_from_dict_with_missing_fields

Test de la cr√©ation depuis un dictionnaire avec champs manquants

##### setUp

Configuration initiale pour chaque test

##### tearDown

Nettoyage apr√®s chaque test

##### test_initialization

Test de l'initialisation du gestionnaire

##### test_init_database

Test de l'initialisation de la base de donn√©es

##### test_creer_profil

Test de la cr√©ation d'un profil

##### test_creer_profil_with_preferences

Test de la cr√©ation d'un profil avec pr√©f√©rences

##### test_obtenir_profil

Test de l'obtention d'un profil

##### test_obtenir_profil_inexistant

Test de l'obtention d'un profil inexistant

##### test_mettre_a_jour_profil

Test de la mise √† jour d'un profil

##### test_enregistrer_action

Test de l'enregistrement d'une action

##### test_enregistrer_consultation_projet

Test de l'enregistrement d'une consultation de projet

##### test_obtenir_statistiques

Test de l'obtention des statistiques

##### test_generer_rapport_profil

Test de la g√©n√©ration de rapport de profil

##### test_lister_profils

Test de la liste des profils

##### test_supprimer_profil

Test de la suppression d'un profil

##### test_supprimer_profil_inexistant

Test de la suppression d'un profil inexistant

##### test_exporter_profil

Test de l'export d'un profil

##### test_importer_profil

Test de l'import d'un profil

##### setUp

Configuration initiale pour chaque test

##### tearDown

Nettoyage apr√®s chaque test

##### test_integration_complete_workflow

Test d'int√©gration du workflow complet

##### test_integration_with_multiple_users

Test d'int√©gration avec plusieurs utilisateurs

##### test_integration_error_handling

Test d'int√©gration de la gestion d'erreurs

---

### test_ath_audit

#### Fonctions

##### test_ath_audit_runs

---

### test_ath_build

#### Fonctions

##### test_ath_build_runs

Test que ath-build.py peut √™tre ex√©cut√© sans se bloquer

---

### test_ath_coverage

#### Fonctions

##### cleanup_coverage_files

##### test_ath_coverage_runs

Test que ath-coverage.py fonctionne sans r√©cursivit√©

---

### test_ath_lint

#### Fonctions

##### test_ath_lint_runs

---

### test_ath_test

#### Fonctions

##### test_ath_test_runs

Test que ath-test.py fonctionne sans r√©cursivit√©

---

### test_cli_robustesse

Test d'int√©gration CLI robuste pour Athalia

#### Fonctions

##### test_cli_robustesse

Test simple de la CLI sans interaction complexe

---

### test_end_to_end

Test d'int√©gration end-to-end pour la g√©n√©ration de projet Athalia

#### Fonctions

##### test_generation_end_to_end

G√©n√®re un projet API complet et v√©rifie tous les artefacts essentiels.
Rend le test plus robuste pour la CI : skip si d√©pendances manquantes.

**Param√®tres :**

- `tmp_path`

---

### test_yaml_validity

Test de validit√© YAML pour tous les fichiers openapi.yaml du repo

#### Fonctions

##### test_all_openapi_yaml_valid

V√©rifie que tous les fichiers openapi*.yaml sont valides.

---

### export_docker_plugin

Plugin d'export Docker

#### Fonctions

##### run

Fonction principale du plugin Docker

##### get_info

Informations sur le plugin

---

### hello_plugin

Plugin de d√©monstration Hello World

#### Fonctions

##### run

Fonction principale du plugin

##### get_info

Informations sur le plugin

---

### audit_complet_dossiers

Audit Complet des Dossiers - Athalia/Arkalia
Analyse approfondie de tous les dossiers du projet

#### Classes

##### DossierInfo

Informations sur un dossier

##### ModuleInfo

Informations sur un module Python

##### AuditResult

R√©sultat d'audit pour un dossier

##### AuditCompletDossiers

Audit complet de tous les dossiers du projet

**M√©thodes :**

- `__init__()`
- `analyser_tous_dossiers()`
- `_trouver_sous_dossiers_caches()`
- `_analyser_dossier_complet()`
- `_analyser_dossier_info()`
- `_analyser_module()`
- `_chercher_tests_associes()`
- `_chercher_documentation_associee()`
- `_verifier_integration_orchestrateur()`
- `_calculer_score_utilite()`
- `_calculer_score_implementation()`
- `_calculer_score_tests()`
- `_calculer_score_documentation()`
- `_calculer_score_integration()`
- `_generer_recommandations()`
- `_chercher_pepites()`
- `generer_rapport()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `root_path`

##### analyser_tous_dossiers

Analyser tous les dossiers principaux

##### _trouver_sous_dossiers_caches

Trouver les sous-dossiers cach√©s qui pourraient contenir des p√©pites

##### _analyser_dossier_complet

Analyser un dossier complet

**Param√®tres :**

- `dossier_path`
- `nom_dossier`

##### _analyser_dossier_info

Analyser les informations d'un dossier

**Param√®tres :**

- `dossier_path`
- `nom_dossier`

##### _analyser_module

Analyser un module Python

**Param√®tres :**

- `file_path`

##### _chercher_tests_associes

Chercher les tests associ√©s √† un module

**Param√®tres :**

- `file_path`

##### _chercher_documentation_associee

Chercher la documentation associ√©e √† un module

**Param√®tres :**

- `file_path`

##### _verifier_integration_orchestrateur

V√©rifier si le module s'int√®gre avec l'orchestrateur principal

**Param√®tres :**

- `content`
- `imports`

##### _calculer_score_utilite

Calculer le score d'utilit√© du dossier

**Param√®tres :**

- `dossier_info`
- `modules`

##### _calculer_score_implementation

Calculer le score d'impl√©mentation

**Param√®tres :**

- `modules`

##### _calculer_score_tests

Calculer le score de tests

**Param√®tres :**

- `dossier_info`
- `modules`

##### _calculer_score_documentation

Calculer le score de documentation

**Param√®tres :**

- `dossier_info`
- `modules`

##### _calculer_score_integration

Calculer le score d'int√©gration

**Param√®tres :**

- `modules`

##### _generer_recommandations

G√©n√©rer des recommandations d'am√©lioration

**Param√®tres :**

- `dossier_info`
- `modules`
- `score_total`

##### _chercher_pepites

Chercher des p√©pites (fonctionnalit√©s int√©ressantes)

**Param√®tres :**

- `dossier_info`
- `modules`

##### generer_rapport

G√©n√©rer un rapport complet d'audit

---

### verification_integration_simple

üîç V√âRIFICATION SIMPLE D'INT√âGRATION ORCHESTRATEUR
==================================================
Script simple pour v√©rifier l'int√©gration actuelle de l'orchestrateur unifi√©.

#### Fonctions

##### main

Fonction principale

---

### system_monitor

Script de monitoring syst√®me pour Athalia
Surveille les performances, l'espace disque, et l'√©tat des processus

#### Classes

##### SystemMonitor

Moniteur syst√®me pour Athalia

**M√©thodes :**

- `__init__()`
- `get_system_info()`
- `get_project_stats()`
- `check_critical_paths()`
- `generate_report()`
- `save_report()`
- `monitor()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `project_path`

##### get_system_info

R√©cup√®re les informations syst√®me

##### get_project_stats

R√©cup√®re les statistiques du projet

##### check_critical_paths

V√©rifie les chemins critiques

##### generate_report

G√©n√®re un rapport complet

##### save_report

Sauvegarde le rapport

**Param√®tres :**

- `report`

##### monitor

Ex√©cute le monitoring complet

---

### cleanup_archives

üßπ Nettoyeur d'Archives Documentation Athalia

Script pour nettoyer et organiser les archives de documentation
afin de r√©duire les liens cass√©s et am√©liorer la structure.

#### Classes

##### ArchiveCleaner

Nettoyeur d'archives professionnel

**M√©thodes :**

- `__init__()`
- `cleanup_archives()`
- `_organize_by_date()`
- `_remove_duplicates()`
- `_cleanup_obsolete_files()`
- `_create_archive_index()`
- `_extract_date_from_filename()`
- `generate_cleanup_report()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `root_path`

##### cleanup_archives

Nettoie et organise les archives

**Param√®tres :**

- `dry_run`

##### _organize_by_date

Organise les archives par date

**Param√®tres :**

- `dry_run`

##### _remove_duplicates

Supprime les fichiers dupliqu√©s

**Param√®tres :**

- `dry_run`

##### _cleanup_obsolete_files

Nettoie les fichiers obsol√®tes

**Param√®tres :**

- `dry_run`

##### _create_archive_index

Cr√©e un index des archives

**Param√®tres :**

- `dry_run`

##### _extract_date_from_filename

Extrait la date du nom de fichier

**Param√®tres :**

- `filename`

##### generate_cleanup_report

G√©n√®re un rapport de nettoyage

---

### cleanup_documentation

Script de nettoyage et d'organisation de la documentation

#### Classes

##### DocumentationCleaner

Classe pour nettoyer et organiser la documentation

**M√©thodes :**

- `__init__()`
- `scan_documentation()`
- `archive_obsolete_docs()`
- `create_documentation_report()`
- `cleanup()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `docs_dir`

##### scan_documentation

Scanne la documentation et cat√©gorise les fichiers

##### archive_obsolete_docs

Archive les documents obsol√®tes

**Param√®tres :**

- `obsolete_files`

##### create_documentation_report

Cr√©e un rapport de nettoyage de la documentation

**Param√®tres :**

- `categories`
- `archived_count`

##### cleanup

Ex√©cute le nettoyage complet de la documentation

**Param√®tres :**

- `dry_run`

---

### cleanup_old_data

Script de nettoyage des anciennes donn√©es d'analyse

#### Classes

##### DataCleaner

Classe pour nettoyer les anciennes donn√©es d'analyse

**M√©thodes :**

- `__init__()`
- `get_file_hash()`
- `find_analysis_files()`
- `categorize_files()`
- `archive_important_files()`
- `is_file_important()`
- `remove_duplicates()`
- `remove_old_files()`
- `generate_report()`
- `cleanup()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `data_dir`

##### get_file_hash

Calcule le hash MD5 d'un fichier

**Param√®tres :**

- `file_path`

##### find_analysis_files

Trouve tous les fichiers d'analyse

##### categorize_files

Cat√©gorise les fichiers par √¢ge et importance

**Param√®tres :**

- `files`

##### archive_important_files

Archive les fichiers importants

**Param√®tres :**

- `files`

##### is_file_important

D√©termine si un fichier est important √† archiver

**Param√®tres :**

- `file_path`
- `mtime`

##### remove_duplicates

Supprime les fichiers en double

**Param√®tres :**

- `duplicates`

##### remove_old_files

Supprime les anciens fichiers non importants

**Param√®tres :**

- `old_files`

##### generate_report

G√©n√®re un rapport de nettoyage

**Param√®tres :**

- `categories`
- `archived_count`
- `removed_duplicates`
- `removed_old`

##### cleanup

Ex√©cute le nettoyage complet

**Param√®tres :**

- `dry_run`

---

### generate_docs_index

üìã G√©n√©rateur d'Index Documentation Athalia

Script pour g√©n√©rer automatiquement un index complet
de la documentation du projet Athalia.

#### Classes

##### IndexGenerator

G√©n√©rateur d'index de documentation

**M√©thodes :**

- `__init__()`
- `generate_index()`
- `_scan_documentation()`
- `_extract_title()`
- `_generate_main_index()`
- `generate_section_index()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `root_path`

##### generate_index

G√©n√®re un index complet de la documentation

##### _scan_documentation

Scanne toute la documentation

##### _extract_title

Extrait le titre d'un fichier Markdown

**Param√®tres :**

- `file_path`

##### _generate_main_index

G√©n√®re le contenu de l'index principal

##### generate_section_index

G√©n√®re un index pour une section sp√©cifique

**Param√®tres :**

- `section`

---

### validation_documentation

Script de Validation Documentation - Athalia
V√©rifie la coh√©rence entre la documentation et le code r√©el

#### Classes

##### DocumentationValidator

Validateur de documentation pour Athalia

**M√©thodes :**

- `__init__()`
- `validate_all()`
- `_analyze_real_code()`
- `_analyze_python_file()`
- `_extract_cli_commands()`
- `_analyze_documentation()`
- `_analyze_markdown_file()`
- `_find_line_number()`
- `_compare_code_and_docs()`
- `_calculate_score()`
- `_generate_report()`
- `_generate_recommendations()`

#### Fonctions

##### main

Fonction principale

##### __init__

**Param√®tres :**

- `project_root`

##### validate_all

Validation compl√®te de la documentation

##### _analyze_real_code

Analyser le code r√©el du projet

##### _analyze_python_file

Analyser un fichier Python pour extraire les fonctions et classes

**Param√®tres :**

- `file_path`

##### _extract_cli_commands

Extraire les commandes CLI du code

**Param√®tres :**

- `content`
- `file_path`

##### _analyze_documentation

Analyser la documentation pour extraire les informations

##### _analyze_markdown_file

Analyser un fichier Markdown

**Param√®tres :**

- `file_path`

##### _find_line_number

Trouver le num√©ro de ligne d'un texte dans le contenu

**Param√®tres :**

- `content`
- `text`

##### _compare_code_and_docs

Comparer le code et la documentation

##### _calculate_score

Calculer le score de coh√©rence

##### _generate_report

G√©n√©rer le rapport de validation

##### _generate_recommendations

G√©n√©rer des recommandations d'am√©lioration

---

### typing_extensions

#### Classes

##### _Sentinel

**M√©thodes :**

- `__repr__()`

##### _SpecialForm

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `__mro_entries__()`
- `__repr__()`
- `__reduce__()`
- `__call__()`
- `__or__()`
- `__ror__()`
- `__instancecheck__()`
- `__subclasscheck__()`
- `__getitem__()`

##### _ExtensionsSpecialForm

**M√©thodes :**

- `__repr__()`

##### _DefaultMixin

Mixin for TypeVarLike defaults.

##### _TypeVarLikeMeta

**M√©thodes :**

- `__instancecheck__()`

##### _EllipsisDummy

##### Sentinel

Create a unique sentinel object.

*name* should be the name of the variable to which the return value shall be assigned.

*repr*, if supplied, will be used for the repr of the sentinel object.
If not provided, "<name>" will be used.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__getstate__()`

##### _AnyMeta

**M√©thodes :**

- `__instancecheck__()`
- `__repr__()`

##### Any

Special type indicating an unconstrained type.
- Any is compatible with every type.
- Any assumed to have all methods.
- All values assumed to be instances of Any.
Note that all the above statements are true from the point of view of
static type checkers. At runtime, Any should not be used with instance
checks.

**M√©thodes :**

- `__new__()`

##### _LiteralGenericAlias

**M√©thodes :**

- `__eq__()`
- `__hash__()`

##### _LiteralForm

**M√©thodes :**

- `__init__()`
- `__getitem__()`

##### _SpecialGenericAlias

**M√©thodes :**

- `__init__()`
- `__setattr__()`
- `__getitem__()`

##### _ProtocolMeta

**M√©thodes :**

- `__new__()`
- `__init__()`
- `__subclasscheck__()`
- `__instancecheck__()`
- `__eq__()`
- `__hash__()`

##### Protocol

**M√©thodes :**

- `__init_subclass__()`

##### SupportsInt

An ABC with one abstract method __int__.

**M√©thodes :**

- `__int__()`

##### SupportsFloat

An ABC with one abstract method __float__.

**M√©thodes :**

- `__float__()`

##### SupportsComplex

An ABC with one abstract method __complex__.

**M√©thodes :**

- `__complex__()`

##### SupportsBytes

An ABC with one abstract method __bytes__.

**M√©thodes :**

- `__bytes__()`

##### SupportsIndex

**M√©thodes :**

- `__index__()`

##### SupportsAbs

An ABC with one abstract method __abs__ that is covariant in its return type.

**M√©thodes :**

- `__abs__()`

##### SupportsRound

An ABC with one abstract method __round__ that is covariant in its return type.

**M√©thodes :**

- `__round__()`

##### Reader

Protocol for simple I/O reader instances.

This protocol only supports blocking I/O.

**M√©thodes :**

- `read()`

##### Writer

Protocol for simple I/O writer instances.

This protocol only supports blocking I/O.

**M√©thodes :**

- `write()`

##### SingletonMeta

**M√©thodes :**

- `__setattr__()`

##### NoDefaultType

The type of the NoDefault singleton.

**M√©thodes :**

- `__new__()`
- `__repr__()`
- `__reduce__()`

##### NoExtraItemsType

The type of the NoExtraItems singleton.

**M√©thodes :**

- `__new__()`
- `__repr__()`
- `__reduce__()`

##### _TypedDictMeta

**M√©thodes :**

- `__new__()`
- `__subclasscheck__()`

##### _TypedDictSpecialForm

**M√©thodes :**

- `__call__()`
- `__mro_entries__()`

##### TypeVar

Type variable.

**M√©thodes :**

- `__new__()`
- `__init_subclass__()`

##### _Immutable

Mixin to indicate that object should not be copied.

**M√©thodes :**

- `__copy__()`
- `__deepcopy__()`

##### ParamSpecArgs

The args for a ParamSpec object.

Given a ParamSpec object P, P.args is an instance of ParamSpecArgs.

ParamSpecArgs objects have a reference back to their ParamSpec:

P.args.__origin__ is P

This type is meant for runtime introspection and has no special meaning to
static type checkers.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__eq__()`

##### ParamSpecKwargs

The kwargs for a ParamSpec object.

Given a ParamSpec object P, P.kwargs is an instance of ParamSpecKwargs.

ParamSpecKwargs objects have a reference back to their ParamSpec:

P.kwargs.__origin__ is P

This type is meant for runtime introspection and has no special meaning to
static type checkers.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__eq__()`

##### _ConcatenateGenericAlias

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__hash__()`
- `__call__()`
- `__parameters__()`
- `copy_with()`
- `__getitem__()`

##### _TypeFormForm

**M√©thodes :**

- `__call__()`

##### _UnpackSpecialForm

**M√©thodes :**

- `__init__()`

##### _UnpackAlias

**M√©thodes :**

- `__typing_unpacked_tuple_args__()`
- `__typing_is_unpacked_typevartuple__()`
- `__getitem__()`

##### deprecated

Indicate that a class, function or overload is deprecated.

When this decorator is applied to an object, the type checker
will generate a diagnostic on usage of the deprecated object.

Usage:

    @deprecated("Use B instead")
    class A:
        pass

    @deprecated("Use g instead")
    def f():
        pass

    @overload
    @deprecated("int support is deprecated")
    def g(x: int) -> int: ...
    @overload
    def g(x: str) -> int: ...

The warning specified by *category* will be emitted at runtime
on use of deprecated objects. For functions, that happens on calls;
for classes, on instantiation and on creation of subclasses.
If the *category* is ``None``, no warning is emitted at runtime.
The *stacklevel* determines where the
warning is emitted. If it is ``1`` (the default), the warning
is emitted at the direct caller of the deprecated object; if it
is higher, it is emitted further up the stack.
Static type checker behavior is not affected by the *category*
and *stacklevel* arguments.

The deprecation message passed to the decorator is saved in the
``__deprecated__`` attribute on the decorated object.
If applied to an overload, the decorator
must be after the ``@overload`` decorator for the attribute to
exist on the overload as returned by ``get_overloads()``.

See PEP 702 for details.

**M√©thodes :**

- `__init__()`
- `__call__()`

##### _NamedTupleMeta

**M√©thodes :**

- `__new__()`

##### Buffer

Base class for classes that implement the buffer protocol.

The buffer protocol allows Python objects to expose a low-level
memory buffer interface. Before Python 3.12, it is not possible
to implement the buffer protocol in pure Python code, or even
to check whether a class implements the buffer protocol. In
Python 3.12 and higher, the ``__buffer__`` method allows access
to the buffer protocol from Python code, and the
``collections.abc.Buffer`` ABC allows checking whether a class
implements the buffer protocol.

To indicate support for the buffer protocol in earlier versions,
inherit from this ABC, either in a stub file or at runtime,
or use ABC registration. This ABC provides no methods, because
there is no Python-accessible methods shared by pre-3.12 buffer
classes. It is useful primarily for static checks.

##### NewType

NewType creates simple unique types with almost zero
runtime overhead. NewType(name, tp) is considered a subtype of tp
by static type checkers. At runtime, NewType(name, tp) returns
a dummy callable that simply returns its argument. Usage::
    UserId = NewType('UserId', int)
    def name_by_id(user_id: UserId) -> str:
        ...
    UserId('user')          # Fails type check
    name_by_id(42)          # Fails type check
    name_by_id(UserId(42))  # OK
    num = UserId(5) + 1     # type: int

**M√©thodes :**

- `__call__()`
- `__init__()`
- `__mro_entries__()`
- `__repr__()`
- `__reduce__()`

##### TypeAliasType

Create named, parameterized type aliases.

This provides a backport of the new `type` statement in Python 3.12:

    type ListOrSet[T] = list[T] | set[T]

is equivalent to:

    T = TypeVar("T")
    ListOrSet = TypeAliasType("ListOrSet", list[T] | set[T], type_params=(T,))

The name ListOrSet can then be used as an alias for the type it refers to.

The type_params argument should contain all the type parameters used
in the value of the type alias. If the alias is not generic, this
argument is omitted.

Static type checkers should only support type aliases declared using
TypeAliasType that follow these rules:

- The first argument (the name) must be a string literal.
- The TypeAliasType instance must be immediately assigned to a variable
  of the same name. (For example, 'X = TypeAliasType("Y", int)' is invalid,
  as is 'X, Y = TypeAliasType("X", int), TypeAliasType("Y", int)').

**M√©thodes :**

- `__init__()`
- `__setattr__()`
- `__delattr__()`
- `_raise_attribute_error()`
- `__repr__()`
- `_check_parameters()`
- `__getitem__()`
- `__reduce__()`
- `__init_subclass__()`
- `__call__()`

##### Doc

Define the documentation of a type annotation using ``Annotated``, to be
 used in class attributes, function and method parameters, return values,
 and variables.

The value should be a positional-only string literal to allow static tools
like editors and documentation generators to use it.

This complements docstrings.

The string value passed is available in the attribute ``documentation``.

Example::

    >>> from typing_extensions import Annotated, Doc
    >>> def hi(to: Annotated[str, Doc("Who to say hi to")]) -> None: ...

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`

##### Format

##### ParamSpec

Parameter specification.

**M√©thodes :**

- `__new__()`
- `__init_subclass__()`

##### ParamSpec

Parameter specification variable.

Usage::

   P = ParamSpec('P')

Parameter specification variables exist primarily for the benefit of static
type checkers.  They are used to forward the parameter types of one
callable to another callable, a pattern commonly found in higher order
functions and decorators.  They are only valid when used in ``Concatenate``,
or s the first argument to ``Callable``. In Python 3.10 and higher,
they are also supported in user-defined Generics at runtime.
See class Generic for more information on generic types.  An
example for annotating a decorator::

   T = TypeVar('T')
   P = ParamSpec('P')

   def add_logging(f: Callable[P, T]) -> Callable[P, T]:
       '''A type-safe decorator to add logging to a function.'''
       def inner(*args: P.args, **kwargs: P.kwargs) -> T:
           logging.info(f'{f.__name__} was called')
           return f(*args, **kwargs)
       return inner

   @add_logging
   def add_two(x: float, y: float) -> float:
       '''Add two numbers together.'''
       return x + y

Parameter specification variables defined with covariant=True or
contravariant=True can be used to declare covariant or contravariant
generic types.  These keyword arguments are valid, but their actual semantics
are yet to be decided.  See PEP 612 for details.

Parameter specification variables can be introspected. e.g.:

   P.__name__ == 'T'
   P.__bound__ == None
   P.__covariant__ == False
   P.__contravariant__ == False

Note that only parameter specification variables defined in global scope can
be pickled.

**M√©thodes :**

- `args()`
- `kwargs()`
- `__init__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `__reduce__()`
- `__call__()`

##### _ConcatenateGenericAlias

**M√©thodes :**

- `copy_with()`
- `__getitem__()`

##### TypeVarTuple

Type variable tuple.

**M√©thodes :**

- `__new__()`
- `__init_subclass__()`

##### TypeVarTuple

Type variable tuple.

Usage::

    Ts = TypeVarTuple('Ts')

In the same way that a normal type variable is a stand-in for a single
type such as ``int``, a type variable *tuple* is a stand-in for a *tuple*
type such as ``Tuple[int, str]``.

Type variable tuples can be used in ``Generic`` declarations.
Consider the following example::

    class Array(Generic[*Ts]): ...

The ``Ts`` type variable tuple here behaves like ``tuple[T1, T2]``,
where ``T1`` and ``T2`` are type variables. To use these type variables
as type parameters of ``Array``, we must *unpack* the type variable tuple using
the star operator: ``*Ts``. The signature of ``Array`` then behaves
as if we had simply written ``class Array(Generic[T1, T2]): ...``.
In contrast to ``Generic[T1, T2]``, however, ``Generic[*Shape]`` allows
us to parameterise the class with an *arbitrary* number of type parameters.

Type variable tuples can be used anywhere a normal ``TypeVar`` can.
This includes class definitions, as shown above, as well as function
signatures and variable annotations::

    class Array(Generic[*Ts]):

        def __init__(self, shape: Tuple[*Ts]):
            self._shape: Tuple[*Ts] = shape

        def get_shape(self) -> Tuple[*Ts]:
            return self._shape

    shape = (Height(480), Width(640))
    x: Array[Height, Width] = Array(shape)
    y = abs(x)  # Inferred type is Array[Height, Width]
    z = x + x   #        ...    is Array[Height, Width]
    x.get_shape()  #     ...    is tuple[Height, Width]

**M√©thodes :**

- `__iter__()`
- `__init__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `__reduce__()`
- `__init_subclass__()`

##### _TypeAliasGenericAlias

**M√©thodes :**

- `__getattr__()`

##### Dummy

**M√©thodes :**

- `__init_subclass__()`

#### Fonctions

##### IntVar

**Param√®tres :**

- `name`

##### _get_protocol_attrs

**Param√®tres :**

- `cls`

##### _caller

**Param√®tres :**

- `depth`
- `default`

##### _set_default

**Param√®tres :**

- `type_param`
- `default`

##### _set_module

**Param√®tres :**

- `typevarlike`

##### _create_concatenate_alias

**Param√®tres :**

- `origin`
- `parameters`

##### _concatenate_getitem

**Param√®tres :**

- `parameters`

##### _unpack_args

##### _has_generic_or_protocol_as_origin

##### _is_unpacked_typevartuple

**Param√®tres :**

- `x`

##### __repr__

##### _should_collect_from_parameters

**Param√®tres :**

- `t`

##### _should_collect_from_parameters

**Param√®tres :**

- `t`

##### __init__

**Param√®tres :**

- `getitem`

##### __getattr__

**Param√®tres :**

- `item`

##### __mro_entries__

**Param√®tres :**

- `bases`

##### __repr__

##### __reduce__

##### __call__

##### __or__

**Param√®tres :**

- `other`

##### __ror__

**Param√®tres :**

- `other`

##### __instancecheck__

**Param√®tres :**

- `obj`

##### __subclasscheck__

**Param√®tres :**

- `cls`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __repr__

##### final

This decorator can be used to indicate to type checkers that
the decorated method cannot be overridden, and decorated class
cannot be subclassed. For example:

    class Base:
        @final
        def done(self) -> None:
            ...
    class Sub(Base):
        def done(self) -> None:  # Error reported by type checker
            ...
    @final
    class Leaf:
        ...
    class Other(Leaf):  # Error reported by type checker
        ...

There is no runtime checking of these properties. The decorator
sets the ``__final__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

**Param√®tres :**

- `f`

##### _flatten_literal_params

An internal helper for Literal creation: flatten Literals among parameters

**Param√®tres :**

- `parameters`

##### _value_and_type_iter

**Param√®tres :**

- `params`

##### overload

Decorator for overloaded functions/methods.

In a stub file, place two or more stub definitions for the same
function in a row, each decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...

In a non-stub file (i.e. a regular .py file), do the same but
follow it with an implementation.  The implementation should *not*
be decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...
def utf8(value):
    # implementation goes here

The overloads for a function can be retrieved at runtime using the
get_overloads() function.

**Param√®tres :**

- `func`

##### get_overloads

Return all defined overloads for *func* as a sequence.

**Param√®tres :**

- `func`

##### clear_overloads

Clear all overloads in the registry.

##### _is_dunder

**Param√®tres :**

- `attr`

##### _allow_reckless_class_checks

Allow instance and class checks for special stdlib modules.
The abc and functools modules indiscriminately call isinstance() and
issubclass() on the whole MRO of a user class, which may contain protocols.

**Param√®tres :**

- `depth`

##### _no_init

##### _type_check_issubclass_arg_1

Raise TypeError if `arg` is not an instance of `type`
in `issubclass(arg, <protocol>)`.

In most cases, this is verified by type.__subclasscheck__.
Checking it again unnecessarily would slow down issubclass() checks,
so, we don't perform this check unless we absolutely have to.

For various error paths, however,
we want to ensure that *this* error message is shown to the user
where relevant, rather than a typing.py-specific error message.

**Param√®tres :**

- `arg`

##### _proto_hook

**Param√®tres :**

- `cls`
- `other`

##### runtime_checkable

Mark a protocol class as a runtime protocol.

Such protocol can be used with isinstance() and issubclass().
Raise TypeError if applied to a non-protocol class.
This allows a simple-minded structural check very similar to
one trick ponies in collections.abc such as Iterable.

For example::

    @runtime_checkable
    class Closable(Protocol):
        def close(self): ...

    assert isinstance(open('/some/file'), Closable)

Warning: this will check only the presence of the required methods,
not their type signatures!

**Param√®tres :**

- `cls`

##### _get_typeddict_qualifiers

**Param√®tres :**

- `annotation_type`

##### _create_typeddict

##### TypedDict

A simple typed namespace. At runtime it is equivalent to a plain dict.

TypedDict creates a dictionary type such that a type checker will expect all
instances to have a certain set of keys, where each key is
associated with a value of a consistent type. This expectation
is not checked at runtime.

Usage::

    class Point2D(TypedDict):
        x: int
        y: int
        label: str

    a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
    b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check

    assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')

The type info can be accessed via the Point2D.__annotations__ dict, and
the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
TypedDict supports an additional equivalent form::

    Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})

By default, all keys must be present in a TypedDict. It is possible
to override this by specifying totality::

    class Point2D(TypedDict, total=False):
        x: int
        y: int

This means that a Point2D TypedDict can have any of the keys omitted. A type
checker is only expected to support a literal False or True as the value of
the total argument. True is the default, and makes all items defined in the
class body be required.

The Required and NotRequired special forms can also be used to mark
individual keys as being required or not required::

    class Point2D(TypedDict):
        x: int  # the "x" key must always be present (Required is the default)
        y: NotRequired[int]  # the "y" key can be omitted

See PEP 655 for more details on Required and NotRequired.

**Param√®tres :**

- `args`

##### is_typeddict

Check if an annotation is a TypedDict class

For example::
    class Film(TypedDict):
        title: str
        year: int

    is_typeddict(Film)  # => True
    is_typeddict(Union[list, str])  # => False

**Param√®tres :**

- `tp`

##### assert_type

Assert (to the type checker) that the value is of the given type.

When the type checker encounters a call to assert_type(), it
emits an error if the value is not of the specified type::

    def greet(name: str) -> None:
        assert_type(name, str)  # ok
        assert_type(name, int)  # type checker error

At runtime this returns the first argument unchanged and otherwise
does nothing.

##### _strip_extras

Strips Annotated, Required and NotRequired from a given type.

**Param√®tres :**

- `t`

##### get_type_hints

Return type hints for an object.

This is often the same as obj.__annotations__, but it handles
forward references encoded as string literals, adds Optional[t] if a
default value equal to None is set and recursively replaces all
'Annotated[T, ...]', 'Required[T]' or 'NotRequired[T]' with 'T'
(unless 'include_extras=True').

The argument may be a module, class, method, or function. The annotations
are returned as a dictionary. For classes, annotations include also
inherited members.

TypeError is raised if the argument is not of a type that can contain
annotations, and an empty dictionary is returned if no annotations are
present.

BEWARE -- the behavior of globalns and localns is counterintuitive
(unless you are familiar with how eval() and exec() work).  The
search order is locals first, then globals.

- If no dict arguments are passed, an attempt is made to use the
  globals from obj (or the respective module's globals for classes),
  and these are also used as the locals.  If the object does not appear
  to have globals, an empty dictionary is used.

- If one dict argument is passed, it is used for both globals and
  locals.

- If two dict arguments are passed, they specify globals and
  locals, respectively.

**Param√®tres :**

- `obj`
- `globalns`
- `localns`
- `include_extras`

##### _could_be_inserted_optional

detects Union[..., None] pattern

**Param√®tres :**

- `t`

##### _clean_optional

**Param√®tres :**

- `obj`
- `hints`
- `globalns`
- `localns`

##### get_origin

Get the unsubscripted version of a type.

This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
and Annotated. Return None for unsupported types. Examples::

    get_origin(Literal[42]) is Literal
    get_origin(int) is None
    get_origin(ClassVar[int]) is ClassVar
    get_origin(Generic) is Generic
    get_origin(Generic[T]) is Generic
    get_origin(Union[T, int]) is Union
    get_origin(List[Tuple[T, T]][int]) == list
    get_origin(P.args) is P

**Param√®tres :**

- `tp`

##### get_args

Get type arguments with all substitutions performed.

For unions, basic simplifications used by Union constructor are performed.
Examples::
    get_args(Dict[str, int]) == (str, int)
    get_args(int) == ()
    get_args(Union[int, Union[T, int], str][int]) == (int, str)
    get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
    get_args(Callable[[], T][int]) == ([], int)

**Param√®tres :**

- `tp`

##### TypeAlias

Special marker indicating that an assignment should
be recognized as a proper type alias definition by type
checkers.

For example::

    Predicate: TypeAlias = Callable[..., bool]

It's invalid when used anywhere except as in the example above.

**Param√®tres :**

- `parameters`

##### __instancecheck__

**Param√®tres :**

- `cls`
- `__instance`

##### Concatenate

Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
higher order function which adds, removes or transforms parameters of a
callable.

For example::

   Callable[Concatenate[int, P], int]

See PEP 612 for detailed information.

**Param√®tres :**

- `parameters`

##### TypeGuard

Special typing form used to annotate the return type of a user-defined
type guard function.  ``TypeGuard`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeGuard[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeGuard`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the type inside ``TypeGuard``.

For example::

    def is_str(val: Union[str, float]):
        # "isinstance" type guard
        if isinstance(val, str):
            # Type of ``val`` is narrowed to ``str``
            ...
        else:
            # Else, type of ``val`` is narrowed to ``float``.
            ...

Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
form of ``TypeA`` (it can even be a wider form) and this may lead to
type-unsafe results.  The main reason is to allow for things like
narrowing ``List[object]`` to ``List[str]`` even though the latter is not
a subtype of the former, since ``List`` is invariant.  The responsibility of
writing type-safe type guards is left to the user.

``TypeGuard`` also works with type variables.  For more information, see
PEP 647 (User-Defined Type Guards).

**Param√®tres :**

- `parameters`

##### TypeIs

Special typing form used to annotate the return type of a user-defined
type narrower function.  ``TypeIs`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeIs`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeIs[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeIs`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the intersection of the type inside ``TypeIs`` and the argument's
previously known type.

For example::

    def is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
        return hasattr(val, '__await__')

    def f(val: Union[int, Awaitable[int]]) -> int:
        if is_awaitable(val):
            assert_type(val, Awaitable[int])
        else:
            assert_type(val, int)

``TypeIs`` also works with type variables.  For more information, see
PEP 742 (Narrowing types with TypeIs).

**Param√®tres :**

- `parameters`

##### TypeForm

A special form representing the value that results from the evaluation
of a type expression. This value encodes the information supplied in the
type expression, and it represents the type described by that type expression.

When used in a type expression, TypeForm describes a set of type form objects.
It accepts a single type argument, which must be a valid type expression.
``TypeForm[T]`` describes the set of all type form objects that represent
the type T or types that are assignable to T.

Usage:

    def cast[T](typ: TypeForm[T], value: Any) -> T: ...

    reveal_type(cast(int, "x"))  # int

See PEP 747 for more information.

**Param√®tres :**

- `parameters`

##### LiteralString

Represents an arbitrary literal string.

Example::

  from typing_extensions import LiteralString

  def query(sql: LiteralString) -> ...:
      ...

  query("SELECT * FROM table")  # ok
  query(f"SELECT * FROM {input()}")  # not ok

See PEP 675 for details.

**Param√®tres :**

- `params`

##### Self

Used to spell the type of "self" in classes.

Example::

  from typing import Self

  class ReturnsSelf:
      def parse(self, data: bytes) -> Self:
          ...
          return self

**Param√®tres :**

- `params`

##### Never

The bottom type, a type that has no members.

This can be used to define a function that should never be
called, or a function that never returns::

    from typing_extensions import Never

    def never_call_me(arg: Never) -> None:
        pass

    def int_or_str(arg: int | str) -> None:
        never_call_me(arg)  # type checker error
        match arg:
            case int():
                print("It's an int")
            case str():
                print("It's a str")
            case _:
                never_call_me(arg)  # ok, arg is of type Never

**Param√®tres :**

- `params`

##### Required

A special typing construct to mark a key of a total=False TypedDict
as required. For example:

    class Movie(TypedDict, total=False):
        title: Required[str]
        year: int

    m = Movie(
        title='The Matrix',  # typechecker error if key is omitted
        year=1999,
    )

There is no runtime checking that a required key is actually provided
when instantiating a related TypedDict.

**Param√®tres :**

- `parameters`

##### NotRequired

A special typing construct to mark a key of a TypedDict as
potentially missing. For example:

    class Movie(TypedDict):
        title: str
        year: NotRequired[int]

    m = Movie(
        title='The Matrix',  # typechecker error if key is omitted
        year=1999,
    )

**Param√®tres :**

- `parameters`

##### ReadOnly

A special typing construct to mark an item of a TypedDict as read-only.

For example:

    class Movie(TypedDict):
        title: ReadOnly[str]
        year: int

    def mutate_movie(m: Movie) -> None:
        m["year"] = 1992  # allowed
        m["title"] = "The Matrix"  # typechecker error

There is no runtime checking for this property.

**Param√®tres :**

- `parameters`

##### _is_unpack

**Param√®tres :**

- `obj`

##### Unpack

**Param√®tres :**

- `parameters`

##### _is_unpack

**Param√®tres :**

- `obj`

##### reveal_type

Reveal the inferred type of a variable.

When a static type checker encounters a call to ``reveal_type()``,
it will emit the inferred type of the argument::

    x: int = 1
    reveal_type(x)

Running a static type checker (e.g., ``mypy``) on this example
will produce output similar to 'Revealed type is "builtins.int"'.

At runtime, the function prints the runtime type of the
argument and returns it unchanged.

##### assert_never

Assert to the type checker that a line of code is unreachable.

Example::

    def int_or_str(arg: int | str) -> None:
        match arg:
            case int():
                print("It's an int")
            case str():
                print("It's a str")
            case _:
                assert_never(arg)

If a type checker finds that a call to assert_never() is
reachable, it will emit an error.

At runtime, this throws an exception when called.

##### dataclass_transform

Decorator that marks a function, class, or metaclass as providing
dataclass-like behavior.

Example:

    from typing_extensions import dataclass_transform

    _T = TypeVar("_T")

    # Used on a decorator function
    @dataclass_transform()
    def create_model(cls: type[_T]) -> type[_T]:
        ...
        return cls

    @create_model
    class CustomerModel:
        id: int
        name: str

    # Used on a base class
    @dataclass_transform()
    class ModelBase: ...

    class CustomerModel(ModelBase):
        id: int
        name: str

    # Used on a metaclass
    @dataclass_transform()
    class ModelMeta(type): ...

    class ModelBase(metaclass=ModelMeta): ...

    class CustomerModel(ModelBase):
        id: int
        name: str

Each of the ``CustomerModel`` classes defined in this example will now
behave similarly to a dataclass created with the ``@dataclasses.dataclass``
decorator. For example, the type checker will synthesize an ``__init__``
method.

The arguments to this decorator can be used to customize this behavior:
- ``eq_default`` indicates whether the ``eq`` parameter is assumed to be
  True or False if it is omitted by the caller.
- ``order_default`` indicates whether the ``order`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``kw_only_default`` indicates whether the ``kw_only`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``frozen_default`` indicates whether the ``frozen`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``field_specifiers`` specifies a static list of supported classes
  or functions that describe fields, similar to ``dataclasses.field()``.

At runtime, this decorator records its arguments in the
``__dataclass_transform__`` attribute on the decorated object.

See PEP 681 for details.

##### override

Indicate that a method is intended to override a method in a base class.

Usage:

    class Base:
        def method(self) -> None:
            pass

    class Child(Base):
        @override
        def method(self) -> None:
            super().method()

When this decorator is applied to a method, the type checker will
validate that it overrides a method with the same name on a base class.
This helps prevent bugs that may occur when a base class is changed
without an equivalent change to a child class.

There is no runtime checking of these properties. The decorator
sets the ``__override__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

See PEP 698 for details.

##### _is_param_expr

**Param√®tres :**

- `arg`

##### _is_param_expr

**Param√®tres :**

- `arg`

##### _check_generic

Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Param√®tres :**

- `cls`
- `parameters`
- `elen`

##### _check_generic

Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Param√®tres :**

- `cls`
- `parameters`
- `elen`

##### _collect_type_vars

Collect all type variable contained in types in order of
first appearance (lexicographic order). For example::

    _collect_type_vars((T, List[S, T])) == (T, S)

**Param√®tres :**

- `types`
- `typevar_types`

##### _collect_parameters

Collect all type variables and parameter specifications in args
in order of first appearance (lexicographic order).

For example::

    assert _collect_parameters((T, Callable[P, T])) == (T, P)

**Param√®tres :**

- `args`

##### _make_nmtuple

**Param√®tres :**

- `name`
- `types`
- `module`
- `defaults`

##### _namedtuple_mro_entries

**Param√®tres :**

- `bases`

##### NamedTuple

Typed version of namedtuple.

Usage::

    class Employee(NamedTuple):
        name: str
        id: int

This is equivalent to::

    Employee = collections.namedtuple('Employee', ['name', 'id'])

The resulting class has an extra __annotations__ attribute, giving a
dict that maps field names to types.  (The field names are also in
the _fields attribute, which is part of the namedtuple API.)
An alternative equivalent functional syntax is also accepted::

    Employee = NamedTuple('Employee', [('name', str), ('id', int)])

##### get_original_bases

Return the class's "original" bases prior to modification by `__mro_entries__`.

Examples::

    from typing import TypeVar, Generic
    from typing_extensions import NamedTuple, TypedDict

    T = TypeVar("T")
    class Foo(Generic[T]): ...
    class Bar(Foo[int], float): ...
    class Baz(list[str]): ...
    Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])
    Spam = TypedDict("Spam", {"a": int, "b": str})

    assert get_original_bases(Bar) == (Foo[int], float)
    assert get_original_bases(Baz) == (list[str],)
    assert get_original_bases(Eggs) == (NamedTuple,)
    assert get_original_bases(Spam) == (TypedDict,)
    assert get_original_bases(int) == (object,)

##### is_protocol

Return True if the given type is a Protocol.

Example::

    >>> from typing_extensions import Protocol, is_protocol
    >>> class P(Protocol):
    ...     def a(self) -> str: ...
    ...     b: int
    >>> is_protocol(P)
    True
    >>> is_protocol(int)
    False

##### get_protocol_members

Return the set of members defined in a Protocol.

Example::

    >>> from typing_extensions import Protocol, get_protocol_members
    >>> class P(Protocol):
    ...     def a(self) -> str: ...
    ...     b: int
    >>> get_protocol_members(P)
    frozenset({'a', 'b'})

Raise a TypeError for arguments that are not Protocols.

##### get_annotations

Compute the annotations dict for an object.

obj may be a callable, class, or module.
Passing in an object of any other type raises TypeError.

Returns a dict.  get_annotations() returns a new dict every time
it's called; calling it twice on the same object will return two
different but equivalent dicts.

This is a backport of `inspect.get_annotations`, which has been
in the standard library since Python 3.10. See the standard library
documentation for more:

    https://docs.python.org/3/library/inspect.html#inspect.get_annotations

This backport adds the *format* argument introduced by PEP 649. The
three formats supported are:
* VALUE: the annotations are returned as-is. This is the default and
  it is compatible with the behavior on previous Python versions.
* FORWARDREF: return annotations as-is if possible, but replace any
  undefined names with ForwardRef objects. The implementation proposed by
  PEP 649 relies on language changes that cannot be backported; the
  typing-extensions implementation simply returns the same result as VALUE.
* STRING: return annotations as strings, in a format close to the original
  source. Again, this behavior cannot be replicated directly in a backport.
  As an approximation, typing-extensions retrieves the annotations under
  VALUE semantics and then stringifies them.

The purpose of this backport is to allow users who would like to use
FORWARDREF or STRING semantics once PEP 649 is implemented, but who also
want to support earlier Python versions, to simply write:

    typing_extensions.get_annotations(obj, format=Format.FORWARDREF)

**Param√®tres :**

- `obj`

##### _eval_with_owner

**Param√®tres :**

- `forward_ref`

##### evaluate_forward_ref

Evaluate a forward reference as a type hint.

This is similar to calling the ForwardRef.evaluate() method,
but unlike that method, evaluate_forward_ref() also:

* Recursively evaluates forward references nested within the type hint.
* Rejects certain objects that are not valid type hints.
* Replaces type hints that evaluate to None with types.NoneType.
* Supports the *FORWARDREF* and *STRING* formats.

*forward_ref* must be an instance of ForwardRef. *owner*, if given,
should be the object that holds the annotations that the forward reference
derived from, such as a module, class object, or function. It is used to
infer the namespaces to use for looking up names. *globals* and *locals*
can also be explicitly given to provide the global and local namespaces.
*type_params* is a tuple of type parameters that are in scope when
evaluating the forward reference. This parameter must be provided (though
it may be an empty tuple) if *owner* is not given and the forward reference
does not already have an owner set. *format* specifies the format of the
annotation and is a member of the annotationlib.Format enum.

**Param√®tres :**

- `forward_ref`

##### __init__

**Param√®tres :**

- `name`
- `repr`

##### __repr__

##### __getstate__

##### __instancecheck__

**Param√®tres :**

- `obj`

##### __repr__

##### __new__

**Param√®tres :**

- `cls`

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __init__

**Param√®tres :**

- `doc`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __init__

**Param√®tres :**

- `origin`
- `nparams`

##### __setattr__

**Param√®tres :**

- `attr`
- `val`

##### __getitem__

**Param√®tres :**

- `params`

##### __new__

**Param√®tres :**

- `mcls`
- `name`
- `bases`
- `namespace`

##### __init__

**Param√®tres :**

- `cls`

##### __subclasscheck__

**Param√®tres :**

- `cls`
- `other`

##### __instancecheck__

**Param√®tres :**

- `cls`
- `instance`

##### __eq__

**Param√®tres :**

- `cls`
- `other`

##### __hash__

**Param√®tres :**

- `cls`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __int__

##### __float__

##### __complex__

##### __bytes__

##### __index__

##### __abs__

##### __round__

**Param√®tres :**

- `ndigits`

##### read

Read data from the input stream and return it.

If *size* is specified, at most *size* items (bytes/characters) will be
read.

##### write

Write *data* to the output stream and return the number of items written.

##### __setattr__

**Param√®tres :**

- `cls`
- `attr`
- `value`

##### __new__

**Param√®tres :**

- `cls`

##### __repr__

##### __reduce__

##### __new__

**Param√®tres :**

- `cls`

##### __repr__

##### __reduce__

##### __new__

Create new typed dict class object.

This method is called when TypedDict is subclassed,
or when TypedDict is instantiated. This way
TypedDict supports all three syntax forms described in its docstring.
Subclasses and instances of TypedDict return actual dictionaries.

**Param√®tres :**

- `cls`
- `name`
- `bases`
- `ns`

##### __subclasscheck__

**Param√®tres :**

- `cls`
- `other`

##### __call__

##### __mro_entries__

**Param√®tres :**

- `bases`

##### __new__

**Param√®tres :**

- `cls`
- `name`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __copy__

##### __deepcopy__

**Param√®tres :**

- `memo`

##### __init__

**Param√®tres :**

- `origin`

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __init__

**Param√®tres :**

- `origin`

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### _type_convert

For converting None to type(None), and strings to ForwardRef.

**Param√®tres :**

- `arg`
- `module`

##### __init__

**Param√®tres :**

- `origin`
- `args`

##### __repr__

##### __hash__

##### __call__

##### __parameters__

##### copy_with

**Param√®tres :**

- `params`

##### __getitem__

**Param√®tres :**

- `args`

##### __call__

##### __init__

**Param√®tres :**

- `getitem`

##### __typing_unpacked_tuple_args__

##### __typing_is_unpacked_typevartuple__

##### __getitem__

**Param√®tres :**

- `args`

##### decorator

**Param√®tres :**

- `cls_or_fn`

##### __init__

##### __call__

##### __new__

**Param√®tres :**

- `cls`
- `typename`
- `bases`
- `ns`

##### __call__

##### __init__

**Param√®tres :**

- `name`
- `tp`

##### __mro_entries__

**Param√®tres :**

- `bases`

##### __repr__

##### __reduce__

##### _is_unionable

Corresponds to is_unionable() in unionobject.c in CPython.

**Param√®tres :**

- `obj`

##### _is_unionable

Corresponds to is_unionable() in unionobject.c in CPython.

**Param√®tres :**

- `obj`

##### __init__

**Param√®tres :**

- `name`
- `value`

##### __setattr__

##### __delattr__

##### _raise_attribute_error

**Param√®tres :**

- `name`

##### __repr__

##### _check_parameters

**Param√®tres :**

- `parameters`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __reduce__

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __call__

##### __init__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __call__

##### __or__

**Param√®tres :**

- `other`

##### __ror__

**Param√®tres :**

- `other`

##### _tvar_prepare_subst

**Param√®tres :**

- `alias`
- `args`

##### __new__

**Param√®tres :**

- `cls`
- `name`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### args

##### kwargs

##### __init__

**Param√®tres :**

- `name`

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __reduce__

##### __call__

##### copy_with

**Param√®tres :**

- `params`

##### __getitem__

**Param√®tres :**

- `args`

##### __new__

**Param√®tres :**

- `cls`
- `name`

##### __init_subclass__

##### __iter__

##### __init__

**Param√®tres :**

- `name`

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __reduce__

##### __init_subclass__

##### __or__

**Param√®tres :**

- `other`

##### __ror__

**Param√®tres :**

- `other`

##### __getattr__

**Param√®tres :**

- `attr`

##### _check_single_param

**Param√®tres :**

- `param`
- `recursion`

##### __or__

**Param√®tres :**

- `right`

##### __ror__

**Param√®tres :**

- `left`

##### __annotate__

**Param√®tres :**

- `format`

##### _paramspec_prepare_subst

**Param√®tres :**

- `alias`
- `args`

##### _typevartuple_prepare_subst

**Param√®tres :**

- `alias`
- `args`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __new__

##### __init_subclass__

##### __init_subclass__

##### wrapper

---

### py

---

### mccabe

Meager code path measurement tool.
Ned Batchelder
http://nedbatchelder.com/blog/200803/python_code_complexity_microtool.html
MIT License.

#### Classes

##### ASTVisitor

Performs a depth-first walk of the AST.

**M√©thodes :**

- `__init__()`
- `default()`
- `dispatch()`
- `preorder()`

##### PathNode

**M√©thodes :**

- `__init__()`
- `to_dot()`
- `dot_id()`

##### PathGraph

**M√©thodes :**

- `__init__()`
- `connect()`
- `to_dot()`
- `complexity()`

##### PathGraphingAstVisitor

A visitor for a parsed Abstract Syntax Tree which finds executable
statements.

**M√©thodes :**

- `__init__()`
- `reset()`
- `dispatch_list()`
- `visitFunctionDef()`
- `visitClassDef()`
- `appendPathNode()`
- `visitSimpleStatement()`
- `default()`
- `visitLoop()`
- `visitIf()`
- `_subgraph()`
- `_subgraph_parse()`
- `visitTryExcept()`
- `visitWith()`

##### McCabeChecker

McCabe cyclomatic complexity checker.

**M√©thodes :**

- `__init__()`
- `add_options()`
- `parse_options()`
- `run()`

#### Fonctions

##### get_code_complexity

**Param√®tres :**

- `code`
- `threshold`
- `filename`

##### get_module_complexity

Returns the complexity of a module

**Param√®tres :**

- `module_path`
- `threshold`

##### _read

**Param√®tres :**

- `filename`

##### main

**Param√®tres :**

- `argv`

##### __init__

##### default

**Param√®tres :**

- `node`

##### dispatch

**Param√®tres :**

- `node`

##### preorder

Do preorder walk of tree using visitor

**Param√®tres :**

- `tree`
- `visitor`

##### __init__

**Param√®tres :**

- `name`
- `look`

##### to_dot

##### dot_id

##### __init__

**Param√®tres :**

- `name`
- `entity`
- `lineno`
- `column`

##### connect

**Param√®tres :**

- `n1`
- `n2`

##### to_dot

##### complexity

Return the McCabe complexity for the graph.
V-E+2

##### __init__

##### reset

##### dispatch_list

**Param√®tres :**

- `node_list`

##### visitFunctionDef

**Param√®tres :**

- `node`

##### visitClassDef

**Param√®tres :**

- `node`

##### appendPathNode

**Param√®tres :**

- `name`

##### visitSimpleStatement

**Param√®tres :**

- `node`

##### default

**Param√®tres :**

- `node`

##### visitLoop

**Param√®tres :**

- `node`

##### visitIf

**Param√®tres :**

- `node`

##### _subgraph

create the subgraphs representing any `if` and `for` statements

**Param√®tres :**

- `node`
- `name`
- `extra_blocks`

##### _subgraph_parse

parse the body and any `else` block of `if` and `for` statements

**Param√®tres :**

- `node`
- `pathnode`
- `extra_blocks`

##### visitTryExcept

**Param√®tres :**

- `node`

##### visitWith

**Param√®tres :**

- `node`

##### __init__

**Param√®tres :**

- `tree`
- `filename`

##### add_options

**Param√®tres :**

- `cls`
- `parser`

##### parse_options

**Param√®tres :**

- `cls`
- `options`

##### run

---

### pycodestyle

Check Python source code formatting, according to PEP 8.

For usage and a list of options, try this:
$ python pycodestyle.py -h

This program and its regression test suite live here:
https://github.com/pycqa/pycodestyle

Groups of errors and warnings:
E errors
W warnings
100 indentation
200 whitespace
300 blank lines
400 imports
500 line length
600 deprecation
700 statements
900 syntax error

#### Classes

##### Checker

Load a Python source file, tokenize it, check coding style.

**M√©thodes :**

- `__init__()`
- `report_invalid_syntax()`
- `readline()`
- `run_check()`
- `init_checker_state()`
- `check_physical()`
- `build_tokens_line()`
- `check_logical()`
- `check_ast()`
- `generate_tokens()`
- `maybe_check_physical()`
- `check_all()`

##### BaseReport

Collect the results of the checks.

**M√©thodes :**

- `__init__()`
- `start()`
- `stop()`
- `init_file()`
- `increment_logical_line()`
- `error()`
- `get_file_results()`
- `get_count()`
- `get_statistics()`
- `print_statistics()`
- `print_benchmark()`

##### FileReport

Collect the results of the checks and print the filenames.

##### StandardReport

Collect and print the results of the checks.

**M√©thodes :**

- `__init__()`
- `init_file()`
- `error()`
- `get_file_results()`

##### DiffReport

Collect and print the results for the changed lines only.

**M√©thodes :**

- `__init__()`
- `error()`

##### StyleGuide

Initialize a PEP-8 instance with few options.

**M√©thodes :**

- `__init__()`
- `init_report()`
- `check_files()`
- `input_file()`
- `input_dir()`
- `excluded()`
- `ignore_code()`
- `get_checks()`

#### Fonctions

##### _get_parameters

**Param√®tres :**

- `function`

##### register_check

Register a new check object.

**Param√®tres :**

- `check`
- `codes`

##### tabs_or_spaces

Never mix tabs and spaces.

The most popular way of indenting Python is with spaces only.  The
second-most popular way is with tabs only.  Code indented with a
mixture of tabs and spaces should be converted to using spaces
exclusively.  When invoking the Python command line interpreter with
the -t option, it issues warnings about code that illegally mixes
tabs and spaces.  When using -tt these warnings become errors.
These options are highly recommended!

Okay: if a == 0:\n    a = 1\n    b = 1

**Param√®tres :**

- `physical_line`
- `indent_char`

##### tabs_obsolete

On new projects, spaces-only are strongly recommended over tabs.

Okay: if True:\n    return
W191: if True:\n\treturn

**Param√®tres :**

- `physical_line`

##### trailing_whitespace

Trailing whitespace is superfluous.

The warning returned varies on whether the line itself is blank,
for easier filtering for those who want to indent their blank lines.

Okay: spam(1)\n#
W291: spam(1) \n#
W293: class Foo(object):\n    \n    bang = 12

**Param√®tres :**

- `physical_line`

##### trailing_blank_lines

Trailing blank lines are superfluous.

Okay: spam(1)
W391: spam(1)\n

However the last line should end with a new line (warning W292).

**Param√®tres :**

- `physical_line`
- `lines`
- `line_number`
- `total_lines`

##### maximum_line_length

Limit all lines to a maximum of 79 characters.

There are still many devices around that are limited to 80 character
lines; plus, limiting windows to 80 characters makes it possible to
have several windows side-by-side.  The default wrapping on such
devices looks ugly.  Therefore, please limit all lines to a maximum
of 79 characters. For flowing long blocks of text (docstrings or
comments), limiting the length to 72 characters is recommended.

Reports error E501.

**Param√®tres :**

- `physical_line`
- `max_line_length`
- `multiline`
- `line_number`
- `noqa`

##### _is_one_liner

**Param√®tres :**

- `logical_line`
- `indent_level`
- `lines`
- `line_number`

##### blank_lines

Separate top-level function and class definitions with two blank
lines.

Method definitions inside a class are separated by a single blank
line.

Extra blank lines may be used (sparingly) to separate groups of
related functions.  Blank lines may be omitted between a bunch of
related one-liners (e.g. a set of dummy implementations).

Use blank lines in functions, sparingly, to indicate logical
sections.

Okay: def a():\n    pass\n\n\ndef b():\n    pass
Okay: def a():\n    pass\n\n\nasync def b():\n    pass
Okay: def a():\n    pass\n\n\n# Foo\n# Bar\n\ndef b():\n    pass
Okay: default = 1\nfoo = 1
Okay: classify = 1\nfoo = 1

E301: class Foo:\n    b = 0\n    def bar():\n        pass
E302: def a():\n    pass\n\ndef b(n):\n    pass
E302: def a():\n    pass\n\nasync def b(n):\n    pass
E303: def a():\n    pass\n\n\n\ndef b(n):\n    pass
E303: def a():\n\n\n\n    pass
E304: @decorator\n\ndef a():\n    pass
E305: def a():\n    pass\na()
E306: def a():\n    def b():\n        pass\n    def c():\n        pass

**Param√®tres :**

- `logical_line`
- `blank_lines`
- `indent_level`
- `line_number`
- `blank_before`
- `previous_logical`
- `previous_unindented_logical_line`
- `previous_indent_level`
- `lines`

##### extraneous_whitespace

Avoid extraneous whitespace.

Avoid extraneous whitespace in these situations:
- Immediately inside parentheses, brackets or braces.
- Immediately before a comma, semicolon, or colon.

Okay: spam(ham[1], {eggs: 2})
E201: spam( ham[1], {eggs: 2})
E201: spam(ham[ 1], {eggs: 2})
E201: spam(ham[1], { eggs: 2})
E202: spam(ham[1], {eggs: 2} )
E202: spam(ham[1 ], {eggs: 2})
E202: spam(ham[1], {eggs: 2 })

E203: if x == 4: print x, y; x, y = y , x
E203: if x == 4: print x, y ; x, y = y, x
E203: if x == 4 : print x, y; x, y = y, x

Okay: @decorator
E204: @ decorator

**Param√®tres :**

- `logical_line`

##### whitespace_around_keywords

Avoid extraneous whitespace around keywords.

Okay: True and False
E271: True and  False
E272: True  and False
E273: True and\tFalse
E274: True\tand False

**Param√®tres :**

- `logical_line`

##### missing_whitespace_after_keyword

Keywords should be followed by whitespace.

Okay: from foo import (bar, baz)
E275: from foo import(bar, baz)
E275: from importable.module import(bar, baz)
E275: if(foo): bar

**Param√®tres :**

- `logical_line`
- `tokens`

##### indentation

Use indent_size (PEP8 says 4) spaces per indentation level.

For really old code that you don't want to mess up, you can continue
to use 8-space tabs.

Okay: a = 1
Okay: if a == 0:\n    a = 1
E111:   a = 1
E114:   # a = 1

Okay: for item in items:\n    pass
E112: for item in items:\npass
E115: for item in items:\n# Hi\n    pass

Okay: a = 1\nb = 2
E113: a = 1\n    b = 2
E116: a = 1\n    # b = 2

**Param√®tres :**

- `logical_line`
- `previous_logical`
- `indent_char`
- `indent_level`
- `previous_indent_level`
- `indent_size`

##### continued_indentation

Continuation lines indentation.

Continuation lines should align wrapped elements either vertically
using Python's implicit line joining inside parentheses, brackets
and braces, or using a hanging indent.

When using a hanging indent these considerations should be applied:
- there should be no arguments on the first line, and
- further indentation should be used to clearly distinguish itself
  as a continuation line.

Okay: a = (\n)
E123: a = (\n    )

Okay: a = (\n    42)
E121: a = (\n   42)
E122: a = (\n42)
E123: a = (\n    42\n    )
E124: a = (24,\n     42\n)
E125: if (\n    b):\n    pass
E126: a = (\n        42)
E127: a = (24,\n      42)
E128: a = (24,\n    42)
E129: if (a or\n    b):\n    pass
E131: a = (\n    42\n 24)

**Param√®tres :**

- `logical_line`
- `tokens`
- `indent_level`
- `hang_closing`
- `indent_char`
- `indent_size`
- `noqa`
- `verbose`

##### whitespace_before_parameters

Avoid extraneous whitespace.

Avoid extraneous whitespace in the following situations:
- before the open parenthesis that starts the argument list of a
  function call.
- before the open parenthesis that starts an indexing or slicing.

Okay: spam(1)
E211: spam (1)

Okay: dict['key'] = list[index]
E211: dict ['key'] = list[index]
E211: dict['key'] = list [index]

**Param√®tres :**

- `logical_line`
- `tokens`

##### whitespace_around_operator

Avoid extraneous whitespace around an operator.

Okay: a = 12 + 3
E221: a = 4  + 5
E222: a = 4 +  5
E223: a = 4\t+ 5
E224: a = 4 +\t5

**Param√®tres :**

- `logical_line`

##### missing_whitespace

Surround operators with the correct amount of whitespace.

- Always surround these binary operators with a single space on
  either side: assignment (=), augmented assignment (+=, -= etc.),
  comparisons (==, <, >, !=, <=, >=, in, not in, is, is not),
  Booleans (and, or, not).

- Each comma, semicolon or colon should be followed by whitespace.

- If operators with different priorities are used, consider adding
  whitespace around the operators with the lowest priorities.

Okay: i = i + 1
Okay: submitted += 1
Okay: x = x * 2 - 1
Okay: hypot2 = x * x + y * y
Okay: c = (a + b) * (a - b)
Okay: foo(bar, key='word', *args, **kwargs)
Okay: alpha[:-i]
Okay: [a, b]
Okay: (3,)
Okay: a[3,] = 1
Okay: a[1:4]
Okay: a[:4]
Okay: a[1:]
Okay: a[1:4:2]

E225: i=i+1
E225: submitted +=1
E225: x = x /2 - 1
E225: z = x **y
E225: z = 1and 1
E226: c = (a+b) * (a-b)
E226: hypot2 = x*x + y*y
E227: c = a|b
E228: msg = fmt%(errno, errmsg)
E231: ['a','b']
E231: foo(bar,baz)
E231: [{'a':'b'}]

**Param√®tres :**

- `logical_line`
- `tokens`

##### whitespace_around_comma

Avoid extraneous whitespace after a comma or a colon.

Note: these checks are disabled by default

Okay: a = (1, 2)
E241: a = (1,  2)
E242: a = (1,\t2)

**Param√®tres :**

- `logical_line`

##### whitespace_around_named_parameter_equals

Don't use spaces around the '=' sign in function arguments.

Don't use spaces around the '=' sign when used to indicate a
keyword argument or a default parameter value, except when
using a type annotation.

Okay: def complex(real, imag=0.0):
Okay: return magic(r=real, i=imag)
Okay: boolean(a == b)
Okay: boolean(a != b)
Okay: boolean(a <= b)
Okay: boolean(a >= b)
Okay: def foo(arg: int = 42):
Okay: async def foo(arg: int = 42):

E251: def complex(real, imag = 0.0):
E251: return magic(r = real, i = imag)
E252: def complex(real, image: float=0.0):

**Param√®tres :**

- `logical_line`
- `tokens`

##### whitespace_before_comment

Separate inline comments by at least two spaces.

An inline comment is a comment on the same line as a statement.
Inline comments should be separated by at least two spaces from the
statement. They should start with a # and a single space.

Each line of a block comment starts with a # and one or multiple
spaces as there can be indented text inside the comment.

Okay: x = x + 1  # Increment x
Okay: x = x + 1    # Increment x
Okay: # Block comments:
Okay: #  - Block comment list
Okay: # ¬†- Block comment list
E261: x = x + 1 # Increment x
E262: x = x + 1  #Increment x
E262: x = x + 1  #  Increment x
E262: x = x + 1  # ¬†Increment x
E265: #Block comment
E266: ### Block comment

**Param√®tres :**

- `logical_line`
- `tokens`

##### imports_on_separate_lines

Place imports on separate lines.

Okay: import os\nimport sys
E401: import sys, os

Okay: from subprocess import Popen, PIPE
Okay: from myclas import MyClass
Okay: from foo.bar.yourclass import YourClass
Okay: import myclass
Okay: import foo.bar.yourclass

**Param√®tres :**

- `logical_line`

##### module_imports_on_top_of_file

Place imports at the top of the file.

Always put imports at the top of the file, just after any module
comments and docstrings, and before module globals and constants.

Okay: import os
Okay: # this is a comment\nimport os
Okay: '''this is a module docstring'''\nimport os
Okay: r'''this is a module docstring'''\nimport os
E402: a=1\nimport os
E402: 'One string'\n"Two string"\nimport os
E402: a=1\nfrom sys import x

Okay: if x:\n    import os

**Param√®tres :**

- `logical_line`
- `indent_level`
- `checker_state`
- `noqa`

##### compound_statements

Compound statements (on the same line) are generally
discouraged.

While sometimes it's okay to put an if/for/while with a small body
on the same line, never do this for multi-clause statements.
Also avoid folding such long lines!

Always use a def statement instead of an assignment statement that
binds a lambda expression directly to a name.

Okay: if foo == 'blah':\n    do_blah_thing()
Okay: do_one()
Okay: do_two()
Okay: do_three()

E701: if foo == 'blah': do_blah_thing()
E701: for x in lst: total += x
E701: while t < 10: t = delay()
E701: if foo == 'blah': do_blah_thing()
E701: else: do_non_blah_thing()
E701: try: something()
E701: finally: cleanup()
E701: if foo == 'blah': one(); two(); three()
E702: do_one(); do_two(); do_three()
E703: do_four();  # useless semicolon
E704: def f(x): return 2*x
E731: f = lambda x: 2*x

**Param√®tres :**

- `logical_line`

##### explicit_line_join

Avoid explicit line join between brackets.

The preferred way of wrapping long lines is by using Python's
implied line continuation inside parentheses, brackets and braces.
Long lines can be broken over multiple lines by wrapping expressions
in parentheses.  These should be used in preference to using a
backslash for line continuation.

E502: aaa = [123, \\n       123]
E502: aaa = ("bbb " \\n       "ccc")

Okay: aaa = [123,\n       123]
Okay: aaa = ("bbb "\n       "ccc")
Okay: aaa = "bbb " \\n    "ccc"
Okay: aaa = 123  # \\

**Param√®tres :**

- `logical_line`
- `tokens`

##### _is_binary_operator

**Param√®tres :**

- `token_type`
- `text`

##### _break_around_binary_operators

Private function to reduce duplication.

This factors out the shared details between
:func:`break_before_binary_operator` and
:func:`break_after_binary_operator`.

**Param√®tres :**

- `tokens`

##### break_before_binary_operator

Avoid breaks before binary operators.

The preferred place to break around a binary operator is after the
operator, not before it.

W503: (width == 0\n + height == 0)
W503: (width == 0\n and height == 0)
W503: var = (1\n       & ~2)
W503: var = (1\n       / -2)
W503: var = (1\n       + -1\n       + -2)

Okay: foo(\n    -x)
Okay: foo(x\n    [])
Okay: x = '''\n''' + ''
Okay: foo(x,\n    -y)
Okay: foo(x,  # comment\n    -y)

**Param√®tres :**

- `logical_line`
- `tokens`

##### break_after_binary_operator

Avoid breaks after binary operators.

The preferred place to break around a binary operator is before the
operator, not after it.

W504: (width == 0 +\n height == 0)
W504: (width == 0 and\n height == 0)
W504: var = (1 &\n       ~2)

Okay: foo(\n    -x)
Okay: foo(x\n    [])
Okay: x = '''\n''' + ''
Okay: x = '' + '''\n'''
Okay: foo(x,\n    -y)
Okay: foo(x,  # comment\n    -y)

The following should be W504 but unary_context is tricky with these
Okay: var = (1 /\n       -2)
Okay: var = (1 +\n       -1 +\n       -2)

**Param√®tres :**

- `logical_line`
- `tokens`

##### comparison_to_singleton

Comparison to singletons should use "is" or "is not".

Comparisons to singletons like None should always be done
with "is" or "is not", never the equality operators.

Okay: if arg is not None:
E711: if arg != None:
E711: if None == arg:
E712: if arg == True:
E712: if False == arg:

Also, beware of writing if x when you really mean if x is not None
-- e.g. when testing whether a variable or argument that defaults to
None was set to some other value.  The other value might have a type
(such as a container) that could be false in a boolean context!

**Param√®tres :**

- `logical_line`
- `noqa`

##### comparison_negative

Negative comparison should be done using "not in" and "is not".

Okay: if x not in y:\n    pass
Okay: assert (X in Y or X is Z)
Okay: if not (X in Y):\n    pass
Okay: zz = x is not y
E713: Z = not X in Y
E713: if not X.B in Y:\n    pass
E714: if not X is Y:\n    pass
E714: Z = not X.B is Y

**Param√®tres :**

- `logical_line`

##### comparison_type

Object type comparisons should `is` / `is not` / `isinstance()`.

Do not compare types directly.

Okay: if isinstance(obj, int):
Okay: if type(obj) is int:
E721: if type(obj) == type(1):

**Param√®tres :**

- `logical_line`
- `noqa`

##### bare_except

When catching exceptions, mention specific exceptions when
possible.

Okay: except Exception:
Okay: except BaseException:
E722: except:

**Param√®tres :**

- `logical_line`
- `noqa`

##### ambiguous_identifier

Never use the characters 'l', 'O', or 'I' as variable names.

In some fonts, these characters are indistinguishable from the
numerals one and zero. When tempted to use 'l', use 'L' instead.

Okay: L = 0
Okay: o = 123
Okay: i = 42
E741: l = 0
E741: O = 123
E741: I = 42

Variables can be bound in several other contexts, including class
and function definitions, lambda functions, 'global' and 'nonlocal'
statements, exception handlers, and 'with' and 'for' statements.
In addition, we have a special handling for function parameters.

Okay: except AttributeError as o:
Okay: with lock as L:
Okay: foo(l=12)
Okay: foo(l=I)
Okay: for a in foo(l=12):
Okay: lambda arg: arg * l
Okay: lambda a=l[I:5]: None
Okay: lambda x=a.I: None
Okay: if l >= 12:
E741: except AttributeError as O:
E741: with lock as l:
E741: global I
E741: nonlocal l
E741: def foo(l):
E741: def foo(l=12):
E741: l = foo(l=12)
E741: for l in range(10):
E741: [l for l in lines if l]
E741: lambda l: None
E741: lambda a=x[1:5], l: None
E741: lambda **l:
E741: def f(**l):
E742: class I(object):
E743: def l(x):

**Param√®tres :**

- `logical_line`
- `tokens`

##### python_3000_invalid_escape_sequence

Invalid escape sequences are deprecated in Python 3.6.

Okay: regex = r'\.png$'
W605: regex = '\.png$'

**Param√®tres :**

- `logical_line`
- `tokens`
- `noqa`

##### maximum_doc_length

Limit all doc lines to a maximum of 72 characters.

For flowing long blocks of text (docstrings or comments), limiting
the length to 72 characters is recommended.

Reports warning W505

**Param√®tres :**

- `logical_line`
- `max_doc_length`
- `noqa`
- `tokens`

##### readlines

Read the source code.

**Param√®tres :**

- `filename`

##### stdin_get_value

Read the value from stdin.

##### expand_indent

Return the amount of indentation.

Tabs are expanded to the next multiple of 8.

**Param√®tres :**

- `line`

##### mute_string

Replace contents with 'xxx' to prevent syntax matching.

**Param√®tres :**

- `text`

##### parse_udiff

Return a dictionary of matching lines.

**Param√®tres :**

- `diff`
- `patterns`
- `parent`

##### normalize_paths

Parse a comma-separated list of paths.

Return a list of absolute paths.

**Param√®tres :**

- `value`
- `parent`

##### filename_match

Check if patterns contains a pattern that matches filename.

If patterns is unspecified, this always returns True.

**Param√®tres :**

- `filename`
- `patterns`
- `default`

##### update_counts

Adds one to the counts of each appearance of characters in s,
for characters in counts

**Param√®tres :**

- `s`
- `counts`

##### _is_eol_token

**Param√®tres :**

- `token`

##### get_parser

Create the parser for the program.

**Param√®tres :**

- `prog`
- `version`

##### read_config

Read and parse configurations.

If a config file is specified on the command line with the
"--config" option, then only it is used for configuration.

Otherwise, the user configuration (~/.config/pycodestyle) and any
local configurations in the current directory or above will be
merged together (in that order) using the read method of
ConfigParser.

**Param√®tres :**

- `options`
- `args`
- `arglist`
- `parser`

##### process_options

Process options passed either via arglist or command line args.

Passing in the ``config_file`` parameter allows other tools, such as
flake8 to specify their own options to be processed in pycodestyle.

**Param√®tres :**

- `arglist`
- `parse_argv`
- `config_file`
- `parser`
- `verbose`

##### _parse_multi_options

Split and strip and discard empties.

Turns the following:

A,
B,

into ["A", "B"]

**Param√®tres :**

- `options`
- `split_token`

##### _main

Parse options and run checks on Python source.

##### _add_check

**Param√®tres :**

- `check`
- `kind`
- `codes`
- `args`

##### is_string_literal

**Param√®tres :**

- `line`

##### __init__

**Param√®tres :**

- `filename`
- `lines`
- `options`
- `report`

##### report_invalid_syntax

Check if the syntax is valid.

##### readline

Get the next line from the input buffer.

##### run_check

Run a check plugin.

**Param√®tres :**

- `check`
- `argument_names`

##### init_checker_state

Prepare custom state for the specific checker plugin.

**Param√®tres :**

- `name`
- `argument_names`

##### check_physical

Run all physical checks on a raw input line.

**Param√®tres :**

- `line`

##### build_tokens_line

Build a logical line from tokens.

##### check_logical

Build a line from tokens and run all logical checks on it.

##### check_ast

Build the file's AST and run all AST checks.

##### generate_tokens

Tokenize file, run physical line checks and yield tokens.

##### maybe_check_physical

If appropriate for token, check current physical line(s).

**Param√®tres :**

- `token`
- `prev_physical`

##### check_all

Run all checks on the input file.

**Param√®tres :**

- `expected`
- `line_offset`

##### __init__

**Param√®tres :**

- `options`

##### start

Start the timer.

##### stop

Stop the timer.

##### init_file

Signal a new file.

**Param√®tres :**

- `filename`
- `lines`
- `expected`
- `line_offset`

##### increment_logical_line

Signal a new logical line.

##### error

Report an error, according to options.

**Param√®tres :**

- `line_number`
- `offset`
- `text`
- `check`

##### get_file_results

Return the count of errors and warnings for this file.

##### get_count

Return the total count of errors and warnings.

**Param√®tres :**

- `prefix`

##### get_statistics

Get statistics for message codes that start with the prefix.

prefix='' matches all errors and warnings
prefix='E' matches all errors
prefix='W' matches all warnings
prefix='E4' matches all errors that have to do with imports

**Param√®tres :**

- `prefix`

##### print_statistics

Print overall statistics (number of errors and warnings).

**Param√®tres :**

- `prefix`

##### print_benchmark

Print benchmark numbers.

##### __init__

**Param√®tres :**

- `options`

##### init_file

Signal a new file.

**Param√®tres :**

- `filename`
- `lines`
- `expected`
- `line_offset`

##### error

Report an error, according to options.

**Param√®tres :**

- `line_number`
- `offset`
- `text`
- `check`

##### get_file_results

Print results and return the overall count for this file.

##### __init__

**Param√®tres :**

- `options`

##### error

**Param√®tres :**

- `line_number`
- `offset`
- `text`
- `check`

##### __init__

##### init_report

Initialize the report instance.

**Param√®tres :**

- `reporter`

##### check_files

Run all checks on the paths.

**Param√®tres :**

- `paths`

##### input_file

Run all checks on a Python source file.

**Param√®tres :**

- `filename`
- `lines`
- `expected`
- `line_offset`

##### input_dir

Check all files in this directory and all subdirectories.

**Param√®tres :**

- `dirname`

##### excluded

Check if the file should be excluded.

Check if 'options.exclude' contains a pattern matching filename.

**Param√®tres :**

- `filename`
- `parent`

##### ignore_code

Check if the error code should be ignored.

If 'options.select' contains a prefix of the error code,
return False.  Else, if 'options.ignore' contains a prefix of
the error code, return True.

**Param√®tres :**

- `code`

##### get_checks

Get all the checks for this category.

Find all globally visible functions where the first argument
name starts with argument_name and which contain selected tests.

**Param√®tres :**

- `argument_name`

---

### .!26417!six

---

### .!29912!py

---

### .!25581!pycodestyle

---

### .!25928!typing_extensions

---

### .!26318!mccabe

---

### .!26349!jsonref

---

### .!26352!mypy_extensions

---

### .!26643!proxytypes

---

### .!26709!_black_version

---

### __main__

Wheel command line tool (enable python -m wheel syntax)

#### Fonctions

##### main

---

### _bdist_wheel

Create a wheel (.whl) distribution.

A wheel is a built archive format.

#### Classes

##### bdist_wheel

**M√©thodes :**

- `initialize_options()`
- `finalize_options()`
- `wheel_dist_name()`
- `get_tag()`
- `run()`
- `write_wheelfile()`
- `_ensure_relative()`
- `license_paths()`
- `egg2dist()`

#### Fonctions

##### safe_name

Convert an arbitrary string to a standard distribution name
Any runs of non-alphanumeric/. characters are replaced with a single '-'.

**Param√®tres :**

- `name`

##### safe_version

Convert an arbitrary string to a standard version string

**Param√®tres :**

- `version`

##### _is_32bit_interpreter

##### python_tag

##### get_platform

Return our platform name 'win32', 'linux_x86_64'

**Param√®tres :**

- `archive_root`

##### get_flag

Use a fallback value for determining SOABI flags if the needed config
var is unset or unavailable.

**Param√®tres :**

- `var`
- `fallback`
- `expected`
- `warn`

##### get_abi_tag

Return the ABI tag based on SOABI (if available) or emulate SOABI (PyPy2).

##### safer_name

**Param√®tres :**

- `name`

##### safer_version

**Param√®tres :**

- `version`

##### remove_readonly

**Param√®tres :**

- `func`
- `path`
- `excinfo`

##### remove_readonly_exc

**Param√®tres :**

- `func`
- `path`
- `exc`

##### initialize_options

##### finalize_options

##### wheel_dist_name

Return distribution full name with - replaced with _

##### get_tag

##### run

##### write_wheelfile

**Param√®tres :**

- `wheelfile_base`
- `generator`

##### _ensure_relative

**Param√®tres :**

- `path`

##### license_paths

##### egg2dist

Convert an .egg-info directory into a .dist-info directory

**Param√®tres :**

- `egginfo_path`
- `distinfo_path`

##### adios

Appropriately delete directory, file or link.

**Param√®tres :**

- `p`

---

### _setuptools_logging

#### Fonctions

##### _not_warning

**Param√®tres :**

- `record`

##### configure

Configure logging to emit warning and above to stderr
and everything else to stdout. This behavior is provided
for compatibility with distutils.log but may change in
the future.

---

### bdist_wheel

---

### macosx_libfile

This module contains function to analyse dynamic library
headers to extract system information

Currently only for MacOSX

Library file on macosx system starts with Mach-O or Fat field.
This can be distinguish by first 32 bites and it is called magic number.
Proper value of magic number is with suffix _MAGIC. Suffix _CIGAM means
reversed bytes order.
Both fields can occur in two types: 32 and 64 bytes.

FAT field inform that this library contains few version of library
(typically for different types version). It contains
information where Mach-O headers starts.

Each section started with Mach-O header contains one library
(So if file starts with this field it contains only one version).

After filed Mach-O there are section fields.
Each of them starts with two fields:
cmd - magic number for this command
cmdsize - total size occupied by this section information.

In this case only sections LC_VERSION_MIN_MACOSX (for macosx 10.13 and earlier)
and LC_BUILD_VERSION (for macosx 10.14 and newer) are interesting,
because them contains information about minimal system version.

Important remarks:
- For fat files this implementation looks for maximum number version.
  It not check if it is 32 or 64 and do not compare it with currently built package.
  So it is possible to false report higher version that needed.
- All structures signatures are taken form macosx header files.
- I think that binary format will be more stable than `otool` output.
  and if apple introduce some changes both implementation will need to be updated.
- The system compile will set the deployment target no lower than
  11.0 for arm64 builds. For "Universal 2" builds use the x86_64 deployment
  target when the arm64 target is 11.0.

#### Classes

##### SegmentBase

##### MachHeader

##### MachHeader

##### FatHeader

##### VersionMinCommand

##### FatArch

##### FatArch

##### VersionBuild

#### Fonctions

##### swap32

**Param√®tres :**

- `x`

##### get_base_class_and_magic_number

**Param√®tres :**

- `lib_file`
- `seek`

##### read_data

**Param√®tres :**

- `struct_class`
- `lib_file`

##### extract_macosx_min_system_version

**Param√®tres :**

- `path_to_lib`

##### read_mach_header

This function parses a Mach-O header and extracts
information about the minimal macOS version.

:param lib_file: reference to opened library file with pointer

**Param√®tres :**

- `lib_file`
- `seek`

##### parse_version

**Param√®tres :**

- `version`

##### calculate_macosx_platform_tag

Calculate proper macosx platform tag basing on files which are included to wheel

Example platform tag `macosx-10.14-x86_64`

**Param√®tres :**

- `archive_root`
- `platform_tag`

---

### metadata

Tools for converting old- to new-style metadata.

#### Fonctions

##### _nonblank

**Param√®tres :**

- `str`

##### yield_lines

Yield valid lines of a string or iterable.
>>> list(yield_lines(''))
[]
>>> list(yield_lines(['foo', 'bar']))
['foo', 'bar']
>>> list(yield_lines('foo\nbar'))
['foo', 'bar']
>>> list(yield_lines('\nfoo\n#bar\nbaz #comment'))
['foo', 'baz #comment']
>>> list(yield_lines(['foo\nbar', 'baz', 'bing\n\n\n']))
['foo', 'bar', 'baz', 'bing']

**Param√®tres :**

- `iterable`

##### _

**Param√®tres :**

- `text`

##### split_sections

Split a string or iterable thereof into (section, content) pairs
Each ``section`` is a stripped version of the section header ("[section]")
and each ``content`` is a list of stripped lines excluding blank lines and
comment-only lines.  If there are any such lines before the first section
header, they're returned in a first ``section`` of ``None``.

**Param√®tres :**

- `s`

##### safe_extra

Convert an arbitrary string to a standard 'extra' name
Any runs of non-alphanumeric characters are replaced with a single '_',
and the result is always lowercased.

**Param√®tres :**

- `extra`

##### safe_name

Convert an arbitrary string to a standard distribution name
Any runs of non-alphanumeric/. characters are replaced with a single '-'.

**Param√®tres :**

- `name`

##### requires_to_requires_dist

Return the version specifier for a requirement in PEP 345/566 fashion.

**Param√®tres :**

- `requirement`

##### convert_requirements

Yield Requires-Dist: strings for parsed requirements strings.

**Param√®tres :**

- `requirements`

##### generate_requirements

Convert requirements from a setup()-style dictionary to
('Requires-Dist', 'requirement') and ('Provides-Extra', 'extra') tuples.

extras_require is a dictionary of {extra: [requirements]} as passed to setup(),
using the empty extra {'': [requirements]} to hold install_requires.

**Param√®tres :**

- `extras_require`

##### pkginfo_to_metadata

Convert .egg-info directory with PKG-INFO to the Metadata 2.1 format

**Param√®tres :**

- `egg_info_path`
- `pkginfo_path`

---

### util

#### Fonctions

##### urlsafe_b64encode

urlsafe_b64encode without padding

**Param√®tres :**

- `data`

##### urlsafe_b64decode

urlsafe_b64decode without padding

**Param√®tres :**

- `data`

---

### wheelfile

#### Classes

##### WheelFile

A ZipFile derivative class that also reads SHA-256 hashes from
.dist-info/RECORD and checks any read files against those.

**M√©thodes :**

- `__init__()`
- `open()`
- `write_files()`
- `write()`
- `writestr()`
- `close()`

##### SizedBuffer

#### Fonctions

##### get_zipinfo_datetime

**Param√®tres :**

- `timestamp`

##### __init__

**Param√®tres :**

- `file`
- `mode`
- `compression`

##### open

**Param√®tres :**

- `name_or_info`
- `mode`
- `pwd`

##### write_files

**Param√®tres :**

- `base_dir`

##### write

**Param√®tres :**

- `filename`
- `arcname`
- `compress_type`

##### writestr

**Param√®tres :**

- `zinfo_or_arcname`
- `data`
- `compress_type`

##### close

##### _update_crc

**Param√®tres :**

- `newdata`

---

### convert

#### Classes

##### ConvertSource

**M√©thodes :**

- `dist_info_dir()`
- `generate_contents()`

##### EggFileSource

**M√©thodes :**

- `__init__()`
- `generate_contents()`

##### EggDirectorySource

**M√©thodes :**

- `generate_contents()`

##### WininstFileSource

Handles distributions created with ``bdist_wininst``.

The egginfo filename has the format::

    name-ver(-pyver)(-arch).egg-info

The installer filename has the format::

    name-ver.arch(-pyver).exe

Some things to note:

1. The installer filename is not definitive. An installer can be renamed
   and work perfectly well as an installer. So more reliable data should
   be used whenever possible.
2. The egg-info data should be preferred for the name and version, because
   these come straight from the distutils metadata, and are mandatory.
3. The pyver from the egg-info data should be ignored, as it is
   constructed from the version of Python used to build the installer,
   which is irrelevant - the installer filename is correct here (even to
   the point that when it's not there, any version is implied).
4. The architecture must be taken from the installer filename, as it is
   not included in the egg-info data.
5. Architecture-neutral installers still have an architecture because the
   installer format itself (being executable) is architecture-specific. We
   should therefore ignore the architecture if the content is pure-python.

**M√©thodes :**

- `__init__()`
- `generate_contents()`

#### Fonctions

##### convert_requires

**Param√®tres :**

- `requires`
- `metadata`

##### convert_pkg_info

**Param√®tres :**

- `pkginfo`
- `metadata`

##### normalize

**Param√®tres :**

- `name`

##### convert

**Param√®tres :**

- `files`
- `dest_dir`
- `verbose`

##### dist_info_dir

##### generate_contents

##### __init__

**Param√®tres :**

- `path`

##### generate_contents

##### generate_contents

##### __init__

**Param√®tres :**

- `path`

##### generate_contents

---

### pack

#### Fonctions

##### pack

Repack a previously unpacked wheel directory into a new wheel file.

The .dist-info/WHEEL file must contain one or more tags so that the target
wheel file name can be determined.

:param directory: The unpacked wheel directory
:param dest_dir: Destination directory (defaults to the current directory)

**Param√®tres :**

- `directory`
- `dest_dir`
- `build_number`

##### compute_tagline

Compute a tagline from a list of tags.

:param tags: A list of tags
:return: A tagline

**Param√®tres :**

- `tags`

---

### tags

#### Fonctions

##### _compute_tags

Add or replace tags. Supports dot-separated tags

**Param√®tres :**

- `original_tags`
- `new_tags`

##### tags

Change the tags on a wheel file.

The tags are left unchanged if they are not specified. To specify "none",
use ["none"]. To append to the previous tags, a tag should start with a
"+".  If a tag starts with "-", it will be removed from existing tags.
Processing is done left to right.

:param wheel: The paths to the wheels
:param python_tags: The Python tags to set
:param abi_tags: The ABI tags to set
:param platform_tags: The platform tags to set
:param build_tag: The build tag to set
:param remove: Remove the original wheel

**Param√®tres :**

- `wheel`
- `python_tags`
- `abi_tags`
- `platform_tags`
- `build_tag`
- `remove`

---

### unpack

#### Fonctions

##### unpack

Unpack a wheel.

Wheel content will be unpacked to {dest}/{name}-{ver}, where {name}
is the package name and {ver} its version.

:param path: The path to the wheel.
:param dest: Destination directory (default to current directory).

**Param√®tres :**

- `path`
- `dest`

---

### _elffile

ELF file parser.

This provides a class ``ELFFile`` that parses an ELF executable in a similar
interface to ``ZipFile``. Only the read interface is implemented.

Based on: https://gist.github.com/lyssdod/f51579ae8d93c8657a5564aefc2ffbca
ELF header: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html

#### Classes

##### ELFInvalid

##### EIClass

##### EIData

##### EMachine

##### ELFFile

Representation of an ELF executable.

**M√©thodes :**

- `__init__()`
- `_read()`
- `interpreter()`

#### Fonctions

##### __init__

**Param√®tres :**

- `f`

##### _read

**Param√®tres :**

- `fmt`

##### interpreter

The path recorded in the ``PT_INTERP`` section header.

---

### _manylinux

#### Classes

##### _GLibCVersion

#### Fonctions

##### _parse_elf

**Param√®tres :**

- `path`

##### _is_linux_armhf

**Param√®tres :**

- `executable`

##### _is_linux_i686

**Param√®tres :**

- `executable`

##### _have_compatible_abi

**Param√®tres :**

- `executable`
- `archs`

##### _glibc_version_string_confstr

Primary implementation of glibc_version_string using os.confstr.

##### _glibc_version_string_ctypes

Fallback implementation of glibc_version_string using ctypes.

##### _glibc_version_string

Returns glibc version string, or None if not using glibc.

##### _parse_glibc_version

Parse glibc version.

We use a regexp instead of str.split because we want to discard any
random junk that might come after the minor version -- this might happen
in patched/forked versions of glibc (e.g. Linaro's version of glibc
uses version strings like "2.20-2014.11"). See gh-3588.

**Param√®tres :**

- `version_str`

##### _get_glibc_version

##### _is_compatible

**Param√®tres :**

- `arch`
- `version`

##### platform_tags

Generate manylinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
    The first one shall be the closest to the actual architecture and be the part of
    platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
    The ``linux_`` prefix is assumed as a prerequisite for the current platform to
    be manylinux-compatible.

:returns: An iterator of compatible manylinux tags.

**Param√®tres :**

- `archs`

---

### _musllinux

PEP 656 support.

This module implements logic to detect if the currently running Python is
linked against musl, and what musl version is used.

#### Classes

##### _MuslVersion

#### Fonctions

##### _parse_musl_version

**Param√®tres :**

- `output`

##### _get_musl_version

Detect currently-running musl runtime version.

This is done by checking the specified executable's dynamic linking
information, and invoking the loader to parse its output for a version
string. If the loader is musl, the output would be something like::

    musl libc (x86_64)
    Version 1.2.2
    Dynamic Program Loader

**Param√®tres :**

- `executable`

##### platform_tags

Generate musllinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
    The first one shall be the closest to the actual architecture and be the part of
    platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
    The ``linux_`` prefix is assumed as a prerequisite for the current platform to
    be musllinux-compatible.

:returns: An iterator of compatible musllinux tags.

**Param√®tres :**

- `archs`

---

### _parser

Handwritten parser of dependency specifiers.

The docstring for each __parse_* function contains EBNF-inspired grammar representing
the implementation.

#### Classes

##### Node

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `serialize()`

##### Variable

**M√©thodes :**

- `serialize()`

##### Value

**M√©thodes :**

- `serialize()`

##### Op

**M√©thodes :**

- `serialize()`

##### ParsedRequirement

#### Fonctions

##### parse_requirement

**Param√®tres :**

- `source`

##### _parse_requirement

requirement = WS? IDENTIFIER WS? extras WS? requirement_details

**Param√®tres :**

- `tokenizer`

##### _parse_requirement_details

requirement_details = AT URL (WS requirement_marker?)?
                    | specifier WS? (requirement_marker)?

**Param√®tres :**

- `tokenizer`

##### _parse_requirement_marker

requirement_marker = SEMICOLON marker WS?

**Param√®tres :**

- `tokenizer`

##### _parse_extras

extras = (LEFT_BRACKET wsp* extras_list? wsp* RIGHT_BRACKET)?

**Param√®tres :**

- `tokenizer`

##### _parse_extras_list

extras_list = identifier (wsp* ',' wsp* identifier)*

**Param√®tres :**

- `tokenizer`

##### _parse_specifier

specifier = LEFT_PARENTHESIS WS? version_many WS? RIGHT_PARENTHESIS
          | WS? version_many WS?

**Param√®tres :**

- `tokenizer`

##### _parse_version_many

version_many = (SPECIFIER (WS? COMMA WS? SPECIFIER)*)?

**Param√®tres :**

- `tokenizer`

##### parse_marker

**Param√®tres :**

- `source`

##### _parse_full_marker

**Param√®tres :**

- `tokenizer`

##### _parse_marker

marker = marker_atom (BOOLOP marker_atom)+

**Param√®tres :**

- `tokenizer`

##### _parse_marker_atom

marker_atom = WS? LEFT_PARENTHESIS WS? marker WS? RIGHT_PARENTHESIS WS?
            | WS? marker_item WS?

**Param√®tres :**

- `tokenizer`

##### _parse_marker_item

marker_item = WS? marker_var WS? marker_op WS? marker_var WS?

**Param√®tres :**

- `tokenizer`

##### _parse_marker_var

marker_var = VARIABLE | QUOTED_STRING

**Param√®tres :**

- `tokenizer`

##### process_env_var

**Param√®tres :**

- `env_var`

##### process_python_str

**Param√®tres :**

- `python_str`

##### _parse_marker_op

marker_op = IN | NOT IN | OP

**Param√®tres :**

- `tokenizer`

##### __init__

**Param√®tres :**

- `value`

##### __str__

##### __repr__

##### serialize

##### serialize

##### serialize

##### serialize

---

### _structures

#### Classes

##### InfinityType

**M√©thodes :**

- `__repr__()`
- `__hash__()`
- `__lt__()`
- `__le__()`
- `__eq__()`
- `__gt__()`
- `__ge__()`
- `__neg__()`

##### NegativeInfinityType

**M√©thodes :**

- `__repr__()`
- `__hash__()`
- `__lt__()`
- `__le__()`
- `__eq__()`
- `__gt__()`
- `__ge__()`
- `__neg__()`

#### Fonctions

##### __repr__

##### __hash__

##### __lt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __neg__

##### __repr__

##### __hash__

##### __lt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __neg__

---

### _tokenizer

#### Classes

##### Token

##### ParserSyntaxError

The provided source text could not be parsed correctly.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### Tokenizer

Context-sensitive token parsing.

Provides methods to examine the input stream to check whether the next token
matches.

**M√©thodes :**

- `__init__()`
- `consume()`
- `check()`
- `expect()`
- `read()`
- `raise_syntax_error()`
- `enclosing_tokens()`

#### Fonctions

##### __init__

**Param√®tres :**

- `message`

##### __str__

##### __init__

**Param√®tres :**

- `source`

##### consume

Move beyond provided token name, if at current position.

**Param√®tres :**

- `name`

##### check

Check whether the next token has the provided name.

By default, if the check succeeds, the token *must* be read before
another check. If `peek` is set to `True`, the token is not loaded and
would need to be checked again.

**Param√®tres :**

- `name`

##### expect

Expect a certain token name next, failing with a syntax error otherwise.

The token is *not* read.

**Param√®tres :**

- `name`

##### read

Consume the next token and return it.

##### raise_syntax_error

Raise ParserSyntaxError at the given position.

**Param√®tres :**

- `message`

##### enclosing_tokens

**Param√®tres :**

- `open_token`
- `close_token`

---

### markers

#### Classes

##### InvalidMarker

An invalid marker was found, users should refer to PEP 508.

##### UndefinedComparison

An invalid operation was attempted on a value that doesn't support it.

##### UndefinedEnvironmentName

A name was attempted to be used that does not exist inside of the
environment.

##### Marker

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `evaluate()`

#### Fonctions

##### _normalize_extra_values

Normalize extra values.

**Param√®tres :**

- `results`

##### _format_marker

**Param√®tres :**

- `marker`
- `first`

##### _eval_op

**Param√®tres :**

- `lhs`
- `op`
- `rhs`

##### _normalize

##### _evaluate_markers

**Param√®tres :**

- `markers`
- `environment`

##### format_full_version

**Param√®tres :**

- `info`

##### default_environment

##### __init__

**Param√®tres :**

- `marker`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### evaluate

Evaluate a marker.

Return the boolean from evaluating the given marker against the
environment. environment is an optional argument to override all or
part of the determined environment.

The environment is determined from the current Python process.

**Param√®tres :**

- `environment`

---

### requirements

#### Classes

##### InvalidRequirement

An invalid requirement was found, users should refer to PEP 508.

##### Requirement

Parse a requirement.

Parse a given requirement string into its parts, such as name, specifier,
URL, and extras. Raises InvalidRequirement on a badly-formed requirement
string.

**M√©thodes :**

- `__init__()`
- `_iter_parts()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `requirement_string`

##### _iter_parts

**Param√®tres :**

- `name`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

---

### specifiers

.. testsetup::

    from packaging.specifiers import Specifier, SpecifierSet, InvalidSpecifier
    from packaging.version import Version

#### Classes

##### InvalidSpecifier

Raised when attempting to create a :class:`Specifier` with a specifier
string that is invalid.

>>> Specifier("lolwat")
Traceback (most recent call last):
    ...
packaging.specifiers.InvalidSpecifier: Invalid specifier: 'lolwat'

##### BaseSpecifier

**M√©thodes :**

- `__str__()`
- `__hash__()`
- `__eq__()`
- `prereleases()`
- `prereleases()`
- `contains()`
- `filter()`

##### Specifier

This class abstracts handling of version specifiers.

.. tip::

    It is generally not required to instantiate this manually. You should instead
    prefer to work with :class:`SpecifierSet` instead, which can parse
    comma-separated version specifiers (which is what package metadata contains).

**M√©thodes :**

- `__init__()`
- `prereleases()`
- `prereleases()`
- `operator()`
- `version()`
- `__repr__()`
- `__str__()`
- `_canonical_spec()`
- `__hash__()`
- `__eq__()`
- `_get_operator()`
- `_compare_compatible()`
- `_compare_equal()`
- `_compare_not_equal()`
- `_compare_less_than_equal()`
- `_compare_greater_than_equal()`
- `_compare_less_than()`
- `_compare_greater_than()`
- `_compare_arbitrary()`
- `__contains__()`
- `contains()`
- `filter()`

##### SpecifierSet

This class abstracts handling of a set of version specifiers.

It can be passed a single specifier (``>=3.0``), a comma-separated list of
specifiers (``>=3.0,!=3.1``), or no specifier at all.

**M√©thodes :**

- `__init__()`
- `prereleases()`
- `prereleases()`
- `__repr__()`
- `__str__()`
- `__hash__()`
- `__and__()`
- `__eq__()`
- `__len__()`
- `__iter__()`
- `__contains__()`
- `contains()`
- `filter()`

#### Fonctions

##### _coerce_version

**Param√®tres :**

- `version`

##### _version_split

Split version into components.

The split components are intended for version comparison. The logic does
not attempt to retain the original version string, so joining the
components back with :func:`_version_join` may not produce the original
version string.

**Param√®tres :**

- `version`

##### _version_join

Join split version components into a version string.

This function assumes the input came from :func:`_version_split`, where the
first component must be the epoch (either empty or numeric), and all other
components numeric.

**Param√®tres :**

- `components`

##### _is_not_suffix

**Param√®tres :**

- `segment`

##### _pad_version

**Param√®tres :**

- `left`
- `right`

##### __str__

Returns the str representation of this Specifier-like object. This
should be representative of the Specifier itself.

##### __hash__

Returns a hash value for this Specifier-like object.

##### __eq__

Returns a boolean representing whether or not the two Specifier-like
objects are equal.

:param other: The other object to check against.

**Param√®tres :**

- `other`

##### prereleases

Whether or not pre-releases as a whole are allowed.

This can be set to either ``True`` or ``False`` to explicitly enable or disable
prereleases or it can be set to ``None`` (the default) to use default semantics.

##### prereleases

Setter for :attr:`prereleases`.

:param value: The value to set.

**Param√®tres :**

- `value`

##### contains

Determines if the given item is contained within this specifier.

**Param√®tres :**

- `item`
- `prereleases`

##### filter

Takes an iterable of items and filters them so that only items which
are contained within this specifier are allowed in it.

**Param√®tres :**

- `iterable`
- `prereleases`

##### __init__

Initialize a Specifier instance.

:param spec:
    The string representation of a specifier which will be parsed and
    normalized before use.
:param prereleases:
    This tells the specifier if it should accept prerelease versions if
    applicable or not. The default of ``None`` will autodetect it from the
    given specifiers.
:raises InvalidSpecifier:
    If the given specifier is invalid (i.e. bad syntax).

**Param√®tres :**

- `spec`
- `prereleases`

##### prereleases

##### prereleases

**Param√®tres :**

- `value`

##### operator

The operator of this specifier.

>>> Specifier("==1.2.3").operator
'=='

##### version

The version of this specifier.

>>> Specifier("==1.2.3").version
'1.2.3'

##### __repr__

A representation of the Specifier that shows all internal state.

>>> Specifier('>=1.0.0')
<Specifier('>=1.0.0')>
>>> Specifier('>=1.0.0', prereleases=False)
<Specifier('>=1.0.0', prereleases=False)>
>>> Specifier('>=1.0.0', prereleases=True)
<Specifier('>=1.0.0', prereleases=True)>

##### __str__

A string representation of the Specifier that can be round-tripped.

>>> str(Specifier('>=1.0.0'))
'>=1.0.0'
>>> str(Specifier('>=1.0.0', prereleases=False))
'>=1.0.0'

##### _canonical_spec

##### __hash__

##### __eq__

Whether or not the two Specifier-like objects are equal.

:param other: The other object to check against.

The value of :attr:`prereleases` is ignored.

>>> Specifier("==1.2.3") == Specifier("== 1.2.3.0")
True
>>> (Specifier("==1.2.3", prereleases=False) ==
...  Specifier("==1.2.3", prereleases=True))
True
>>> Specifier("==1.2.3") == "==1.2.3"
True
>>> Specifier("==1.2.3") == Specifier("==1.2.4")
False
>>> Specifier("==1.2.3") == Specifier("~=1.2.3")
False

**Param√®tres :**

- `other`

##### _get_operator

**Param√®tres :**

- `op`

##### _compare_compatible

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_not_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_less_than_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_greater_than_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_less_than

**Param√®tres :**

- `prospective`
- `spec_str`

##### _compare_greater_than

**Param√®tres :**

- `prospective`
- `spec_str`

##### _compare_arbitrary

**Param√®tres :**

- `prospective`
- `spec`

##### __contains__

Return whether or not the item is contained in this specifier.

:param item: The item to check for.

This is used for the ``in`` operator and behaves the same as
:meth:`contains` with no ``prereleases`` argument passed.

>>> "1.2.3" in Specifier(">=1.2.3")
True
>>> Version("1.2.3") in Specifier(">=1.2.3")
True
>>> "1.0.0" in Specifier(">=1.2.3")
False
>>> "1.3.0a1" in Specifier(">=1.2.3")
False
>>> "1.3.0a1" in Specifier(">=1.2.3", prereleases=True)
True

**Param√®tres :**

- `item`

##### contains

Return whether or not the item is contained in this specifier.

:param item:
    The item to check for, which can be a version string or a
    :class:`Version` instance.
:param prereleases:
    Whether or not to match prereleases with this Specifier. If set to
    ``None`` (the default), it uses :attr:`prereleases` to determine
    whether or not prereleases are allowed.

>>> Specifier(">=1.2.3").contains("1.2.3")
True
>>> Specifier(">=1.2.3").contains(Version("1.2.3"))
True
>>> Specifier(">=1.2.3").contains("1.0.0")
False
>>> Specifier(">=1.2.3").contains("1.3.0a1")
False
>>> Specifier(">=1.2.3", prereleases=True).contains("1.3.0a1")
True
>>> Specifier(">=1.2.3").contains("1.3.0a1", prereleases=True)
True

**Param√®tres :**

- `item`
- `prereleases`

##### filter

Filter items in the given iterable, that match the specifier.

:param iterable:
    An iterable that can contain version strings and :class:`Version` instances.
    The items in the iterable will be filtered according to the specifier.
:param prereleases:
    Whether or not to allow prereleases in the returned iterator. If set to
    ``None`` (the default), it will be intelligently decide whether to allow
    prereleases or not (based on the :attr:`prereleases` attribute, and
    whether the only versions matching are prereleases).

This method is smarter than just ``filter(Specifier().contains, [...])``
because it implements the rule from :pep:`440` that a prerelease item
SHOULD be accepted if no other versions match the given specifier.

>>> list(Specifier(">=1.2.3").filter(["1.2", "1.3", "1.5a1"]))
['1.3']
>>> list(Specifier(">=1.2.3").filter(["1.2", "1.2.3", "1.3", Version("1.4")]))
['1.2.3', '1.3', <Version('1.4')>]
>>> list(Specifier(">=1.2.3").filter(["1.2", "1.5a1"]))
['1.5a1']
>>> list(Specifier(">=1.2.3").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']
>>> list(Specifier(">=1.2.3", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']

**Param√®tres :**

- `iterable`
- `prereleases`

##### __init__

Initialize a SpecifierSet instance.

:param specifiers:
    The string representation of a specifier or a comma-separated list of
    specifiers which will be parsed and normalized before use.
:param prereleases:
    This tells the SpecifierSet if it should accept prerelease versions if
    applicable or not. The default of ``None`` will autodetect it from the
    given specifiers.

:raises InvalidSpecifier:
    If the given ``specifiers`` are not parseable than this exception will be
    raised.

**Param√®tres :**

- `specifiers`
- `prereleases`

##### prereleases

##### prereleases

**Param√®tres :**

- `value`

##### __repr__

A representation of the specifier set that shows all internal state.

Note that the ordering of the individual specifiers within the set may not
match the input string.

>>> SpecifierSet('>=1.0.0,!=2.0.0')
<SpecifierSet('!=2.0.0,>=1.0.0')>
>>> SpecifierSet('>=1.0.0,!=2.0.0', prereleases=False)
<SpecifierSet('!=2.0.0,>=1.0.0', prereleases=False)>
>>> SpecifierSet('>=1.0.0,!=2.0.0', prereleases=True)
<SpecifierSet('!=2.0.0,>=1.0.0', prereleases=True)>

##### __str__

A string representation of the specifier set that can be round-tripped.

Note that the ordering of the individual specifiers within the set may not
match the input string.

>>> str(SpecifierSet(">=1.0.0,!=1.0.1"))
'!=1.0.1,>=1.0.0'
>>> str(SpecifierSet(">=1.0.0,!=1.0.1", prereleases=False))
'!=1.0.1,>=1.0.0'

##### __hash__

##### __and__

Return a SpecifierSet which is a combination of the two sets.

:param other: The other object to combine with.

>>> SpecifierSet(">=1.0.0,!=1.0.1") & '<=2.0.0,!=2.0.1'
<SpecifierSet('!=1.0.1,!=2.0.1,<=2.0.0,>=1.0.0')>
>>> SpecifierSet(">=1.0.0,!=1.0.1") & SpecifierSet('<=2.0.0,!=2.0.1')
<SpecifierSet('!=1.0.1,!=2.0.1,<=2.0.0,>=1.0.0')>

**Param√®tres :**

- `other`

##### __eq__

Whether or not the two SpecifierSet-like objects are equal.

:param other: The other object to check against.

The value of :attr:`prereleases` is ignored.

>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> (SpecifierSet(">=1.0.0,!=1.0.1", prereleases=False) ==
...  SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True))
True
>>> SpecifierSet(">=1.0.0,!=1.0.1") == ">=1.0.0,!=1.0.1"
True
>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0,!=1.0.2")
False

**Param√®tres :**

- `other`

##### __len__

Returns the number of specifiers in this specifier set.

##### __iter__

Returns an iterator over all the underlying :class:`Specifier` instances
in this specifier set.

>>> sorted(SpecifierSet(">=1.0.0,!=1.0.1"), key=str)
[<Specifier('!=1.0.1')>, <Specifier('>=1.0.0')>]

##### __contains__

Return whether or not the item is contained in this specifier.

:param item: The item to check for.

This is used for the ``in`` operator and behaves the same as
:meth:`contains` with no ``prereleases`` argument passed.

>>> "1.2.3" in SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> Version("1.2.3") in SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> "1.0.1" in SpecifierSet(">=1.0.0,!=1.0.1")
False
>>> "1.3.0a1" in SpecifierSet(">=1.0.0,!=1.0.1")
False
>>> "1.3.0a1" in SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True)
True

**Param√®tres :**

- `item`

##### contains

Return whether or not the item is contained in this SpecifierSet.

:param item:
    The item to check for, which can be a version string or a
    :class:`Version` instance.
:param prereleases:
    Whether or not to match prereleases with this SpecifierSet. If set to
    ``None`` (the default), it uses :attr:`prereleases` to determine
    whether or not prereleases are allowed.

>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.2.3")
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains(Version("1.2.3"))
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.0.1")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.3.0a1")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True).contains("1.3.0a1")
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.3.0a1", prereleases=True)
True

**Param√®tres :**

- `item`
- `prereleases`
- `installed`

##### filter

Filter items in the given iterable, that match the specifiers in this set.

:param iterable:
    An iterable that can contain version strings and :class:`Version` instances.
    The items in the iterable will be filtered according to the specifier.
:param prereleases:
    Whether or not to allow prereleases in the returned iterator. If set to
    ``None`` (the default), it will be intelligently decide whether to allow
    prereleases or not (based on the :attr:`prereleases` attribute, and
    whether the only versions matching are prereleases).

This method is smarter than just ``filter(SpecifierSet(...).contains, [...])``
because it implements the rule from :pep:`440` that a prerelease item
SHOULD be accepted if no other versions match the given specifier.

>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.3", "1.5a1"]))
['1.3']
>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.3", Version("1.4")]))
['1.3', <Version('1.4')>]
>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.5a1"]))
[]
>>> list(SpecifierSet(">=1.2.3").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']
>>> list(SpecifierSet(">=1.2.3", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']

An "empty" SpecifierSet will filter items based on the presence of prerelease
versions in the set.

>>> list(SpecifierSet("").filter(["1.3", "1.5a1"]))
['1.3']
>>> list(SpecifierSet("").filter(["1.5a1"]))
['1.5a1']
>>> list(SpecifierSet("", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']
>>> list(SpecifierSet("").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']

**Param√®tres :**

- `iterable`
- `prereleases`

---

### tags

#### Classes

##### Tag

A representation of the tag triple for a wheel.

Instances are considered immutable and thus are hashable. Equality checking
is also supported.

**M√©thodes :**

- `__init__()`
- `interpreter()`
- `abi()`
- `platform()`
- `__eq__()`
- `__hash__()`
- `__str__()`
- `__repr__()`

#### Fonctions

##### parse_tag

Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.

Returning a set is required due to the possibility that the tag is a
compressed tag set.

**Param√®tres :**

- `tag`

##### _get_config_var

**Param√®tres :**

- `name`
- `warn`

##### _normalize_string

**Param√®tres :**

- `string`

##### _is_threaded_cpython

Determine if the ABI corresponds to a threaded (`--disable-gil`) build.

The threaded builds are indicated by a "t" in the abiflags.

**Param√®tres :**

- `abis`

##### _abi3_applies

Determine if the Python version supports abi3.

PEP 384 was first implemented in Python 3.2. The threaded (`--disable-gil`)
builds do not support abi3.

**Param√®tres :**

- `python_version`
- `threading`

##### _cpython_abis

**Param√®tres :**

- `py_version`
- `warn`

##### cpython_tags

Yields the tags for a CPython interpreter.

The tags consist of:
- cp<python_version>-<abi>-<platform>
- cp<python_version>-abi3-<platform>
- cp<python_version>-none-<platform>
- cp<less than python_version>-abi3-<platform>  # Older Python versions down to 3.2.

If python_version only specifies a major version then user-provided ABIs and
the 'none' ABItag will be used.

If 'abi3' or 'none' are specified in 'abis' then they will be yielded at
their normal position and not at the beginning.

**Param√®tres :**

- `python_version`
- `abis`
- `platforms`

##### _generic_abi

Return the ABI tag based on EXT_SUFFIX.

##### generic_tags

Yields the tags for a generic interpreter.

The tags consist of:
- <interpreter>-<abi>-<platform>

The "none" ABI will be added if it was not explicitly provided.

**Param√®tres :**

- `interpreter`
- `abis`
- `platforms`

##### _py_interpreter_range

Yields Python versions in descending order.

After the latest version, the major-only version will be yielded, and then
all previous versions of that major version.

**Param√®tres :**

- `py_version`

##### compatible_tags

Yields the sequence of tags that are compatible with a specific version of Python.

The tags consist of:
- py*-none-<platform>
- <interpreter>-none-any  # ... if `interpreter` is provided.
- py*-none-any

**Param√®tres :**

- `python_version`
- `interpreter`
- `platforms`

##### _mac_arch

**Param√®tres :**

- `arch`
- `is_32bit`

##### _mac_binary_formats

**Param√®tres :**

- `version`
- `cpu_arch`

##### mac_platforms

Yields the platform tags for a macOS system.

The `version` parameter is a two-item tuple specifying the macOS version to
generate platform tags for. The `arch` parameter is the CPU architecture to
generate platform tags for. Both parameters default to the appropriate value
for the current system.

**Param√®tres :**

- `version`
- `arch`

##### _linux_platforms

**Param√®tres :**

- `is_32bit`

##### _generic_platforms

##### platform_tags

Provides the platform tags for this installation.

##### interpreter_name

Returns the name of the running interpreter.

Some implementations have a reserved, two-letter abbreviation which will
be returned when appropriate.

##### interpreter_version

Returns the version of the running interpreter.

##### _version_nodot

**Param√®tres :**

- `version`

##### sys_tags

Returns the sequence of tag triples for the running interpreter.

The order of the sequence corresponds to priority order for the
interpreter, from most to least important.

##### __init__

**Param√®tres :**

- `interpreter`
- `abi`
- `platform`

##### interpreter

##### abi

##### platform

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __str__

##### __repr__

---

### utils

#### Classes

##### InvalidName

An invalid distribution name; users should refer to the packaging user guide.

##### InvalidWheelFilename

An invalid wheel filename was found, users should refer to PEP 427.

##### InvalidSdistFilename

An invalid sdist filename was found, users should refer to the packaging user guide.

#### Fonctions

##### canonicalize_name

**Param√®tres :**

- `name`

##### is_normalized_name

**Param√®tres :**

- `name`

##### canonicalize_version

This is very similar to Version.__str__, but has one subtle difference
with the way it handles the release segment.

**Param√®tres :**

- `version`

##### parse_wheel_filename

**Param√®tres :**

- `filename`

##### parse_sdist_filename

**Param√®tres :**

- `filename`

---

### version

.. testsetup::

    from packaging.version import parse, Version

#### Classes

##### _Version

##### InvalidVersion

Raised when a version string is not a valid version.

>>> Version("invalid")
Traceback (most recent call last):
    ...
packaging.version.InvalidVersion: Invalid version: 'invalid'

##### _BaseVersion

**M√©thodes :**

- `__hash__()`
- `__lt__()`
- `__le__()`
- `__eq__()`
- `__ge__()`
- `__gt__()`
- `__ne__()`

##### Version

This class abstracts handling of a project's versions.

A :class:`Version` instance is comparison aware and can be compared and
sorted using the standard Python interfaces.

>>> v1 = Version("1.0a5")
>>> v2 = Version("1.0")
>>> v1
<Version('1.0a5')>
>>> v2
<Version('1.0')>
>>> v1 < v2
True
>>> v1 == v2
False
>>> v1 > v2
False
>>> v1 >= v2
False
>>> v1 <= v2
True

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__str__()`
- `epoch()`
- `release()`
- `pre()`
- `post()`
- `dev()`
- `local()`
- `public()`
- `base_version()`
- `is_prerelease()`
- `is_postrelease()`
- `is_devrelease()`
- `major()`
- `minor()`
- `micro()`

#### Fonctions

##### parse

Parse the given version string.

>>> parse('1.0.dev1')
<Version('1.0.dev1')>

:param version: The version string to parse.
:raises InvalidVersion: When the version string is not a valid version.

**Param√®tres :**

- `version`

##### _parse_letter_version

**Param√®tres :**

- `letter`
- `number`

##### _parse_local_version

Takes a string like abc.1.twelve and turns it into ("abc", 1, "twelve").

**Param√®tres :**

- `local`

##### _cmpkey

**Param√®tres :**

- `epoch`
- `release`
- `pre`
- `post`
- `dev`
- `local`

##### __hash__

##### __lt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __init__

Initialize a Version object.

:param version:
    The string representation of a version which will be parsed and normalized
    before use.
:raises InvalidVersion:
    If the ``version`` does not conform to PEP 440 in any way then this
    exception will be raised.

**Param√®tres :**

- `version`

##### __repr__

A representation of the Version that shows all internal state.

>>> Version('1.0.0')
<Version('1.0.0')>

##### __str__

A string representation of the version that can be rounded-tripped.

>>> str(Version("1.0a5"))
'1.0a5'

##### epoch

The epoch of the version.

>>> Version("2.0.0").epoch
0
>>> Version("1!2.0.0").epoch
1

##### release

The components of the "release" segment of the version.

>>> Version("1.2.3").release
(1, 2, 3)
>>> Version("2.0.0").release
(2, 0, 0)
>>> Version("1!2.0.0.post0").release
(2, 0, 0)

Includes trailing zeroes but not the epoch or any pre-release / development /
post-release suffixes.

##### pre

The pre-release segment of the version.

>>> print(Version("1.2.3").pre)
None
>>> Version("1.2.3a1").pre
('a', 1)
>>> Version("1.2.3b1").pre
('b', 1)
>>> Version("1.2.3rc1").pre
('rc', 1)

##### post

The post-release number of the version.

>>> print(Version("1.2.3").post)
None
>>> Version("1.2.3.post1").post
1

##### dev

The development number of the version.

>>> print(Version("1.2.3").dev)
None
>>> Version("1.2.3.dev1").dev
1

##### local

The local version segment of the version.

>>> print(Version("1.2.3").local)
None
>>> Version("1.2.3+abc").local
'abc'

##### public

The public portion of the version.

>>> Version("1.2.3").public
'1.2.3'
>>> Version("1.2.3+abc").public
'1.2.3'
>>> Version("1.2.3+abc.dev1").public
'1.2.3'

##### base_version

The "base version" of the version.

>>> Version("1.2.3").base_version
'1.2.3'
>>> Version("1.2.3+abc").base_version
'1.2.3'
>>> Version("1!1.2.3+abc.dev1").base_version
'1!1.2.3'

The "base version" is the public version of the project without any pre or post
release markers.

##### is_prerelease

Whether this version is a pre-release.

>>> Version("1.2.3").is_prerelease
False
>>> Version("1.2.3a1").is_prerelease
True
>>> Version("1.2.3b1").is_prerelease
True
>>> Version("1.2.3rc1").is_prerelease
True
>>> Version("1.2.3dev1").is_prerelease
True

##### is_postrelease

Whether this version is a post-release.

>>> Version("1.2.3").is_postrelease
False
>>> Version("1.2.3.post1").is_postrelease
True

##### is_devrelease

Whether this version is a development release.

>>> Version("1.2.3").is_devrelease
False
>>> Version("1.2.3.dev1").is_devrelease
True

##### major

The first item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").major
1

##### minor

The second item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").minor
2
>>> Version("1").minor
0

##### micro

The third item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").micro
3
>>> Version("1").micro
0

---

### .!21138!api

---

### .!21148!unix

---

### .!21123!__init__

---

### .!21128!__main__

---

### .!21131!android

---

### .!21143!macos

---

### .!21153!version

---

### .!21156!windows

---

### .!21162!__init__

---

### .!21168!override

---

### .!21183!glob

---

### .!21171!__init__

---

### .!21176!_functools

---

### .!21192!overlay

---

### .!21197!py310

---

### .!21201!py313

---

### .!21206!__init__

---

### .!21223!zipp

---

### .!21218!appdirs

---

### .!21254!abc

---

### .!21227!__init__

---

### .!21232!_adapters

---

### .!21238!_common

---

### .!21241!_compat

---

### .!21248!_itertools

---

### .!21250!_legacy

---

### .!21260!readers

---

### .!21263!simple

---

### .!21276!context

---

### .!21279!functools

---

### .!21285!__init__

---

### .!21292!__init__

---

### .!21299!more

---

### .!21304!recipes

---

### .!21346!tags

---

### .!21309!__about__

---

### .!21316!__init__

---

### .!21319!_manylinux

---

### .!21323!_musllinux

---

### .!21330!_structures

---

### .!21332!markers

---

### .!21336!requirements

---

### .!21341!specifiers

---

### .!21351!utils

---

### .!21355!version

---

### .!21373!core

---

### .!21399!util

---

### .!21361!__init__

---

### .!21365!actions

---

### .!21370!common

---

### .!21378!exceptions

---

### .!21382!helpers

---

### .!21386!results

---

### .!21392!testing

---

### .!21395!unicode

---

### .!21404!__init__

---

### .!21409!__init__

---

### _pswindows

Windows platform implementation.

#### Classes

##### Priority

##### IOPriority

##### WindowsService

Represents an installed Windows service.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__eq__()`
- `__ne__()`
- `_query_config()`
- `_query_status()`
- `_wrap_exceptions()`
- `name()`
- `display_name()`
- `binpath()`
- `username()`
- `start_type()`
- `pid()`
- `status()`
- `description()`
- `as_dict()`

##### Process

Wrapper class around underlying C implementation.

**M√©thodes :**

- `__init__()`
- `oneshot_enter()`
- `oneshot_exit()`
- `_proc_info()`
- `name()`
- `exe()`
- `cmdline()`
- `environ()`
- `ppid()`
- `_get_raw_meminfo()`
- `memory_info()`
- `memory_full_info()`
- `memory_maps()`
- `kill()`
- `send_signal()`
- `wait()`
- `username()`
- `create_time()`
- `num_threads()`
- `threads()`
- `cpu_times()`
- `suspend()`
- `resume()`
- `cwd()`
- `open_files()`
- `net_connections()`
- `nice_get()`
- `nice_set()`
- `ionice_get()`
- `ionice_set()`
- `io_counters()`
- `status()`
- `cpu_affinity_get()`
- `cpu_affinity_set()`
- `num_handles()`
- `num_ctx_switches()`

#### Fonctions

##### convert_dos_path

Convert paths using native DOS format like:
    "\Device\HarddiskVolume1\Windows\systemew\file.txt"
into:
    "C:\Windows\systemew\file.txt".

**Param√®tres :**

- `s`

##### getpagesize

##### virtual_memory

System virtual memory as a namedtuple.

##### swap_memory

Swap system memory as a (total, used, free, sin, sout) tuple.

##### disk_usage

Return disk usage associated with path.

**Param√®tres :**

- `path`

##### disk_partitions

Return disk partitions.

**Param√®tres :**

- `all`

##### cpu_times

Return system CPU times as a named tuple.

##### per_cpu_times

Return system per-CPU times as a list of named tuples.

##### cpu_count_logical

Return the number of logical CPUs in the system.

##### cpu_count_cores

Return the number of CPU cores in the system.

##### cpu_stats

Return CPU statistics.

##### cpu_freq

Return CPU frequency.
On Windows per-cpu frequency is not supported.

##### getloadavg

Return the number of processes in the system run queue averaged
over the last 1, 5, and 15 minutes respectively as a tuple.

##### net_connections

Return socket connections.  If pid == -1 return system-wide
connections (as opposed to connections opened by one process only).

**Param√®tres :**

- `kind`
- `_pid`

##### net_if_stats

Get NIC stats (isup, duplex, speed, mtu).

##### net_io_counters

Return network I/O statistics for every network interface
installed on the system as a dict of raw tuples.

##### net_if_addrs

Return the addresses associated to each NIC.

##### sensors_battery

Return battery information.

##### boot_time

The system boot time expressed in seconds since the epoch.

##### users

Return currently connected users as a list of namedtuples.

##### win_service_iter

Yields a list of WindowsService instances.

##### win_service_get

Open a Windows service and return it as a WindowsService instance.

**Param√®tres :**

- `name`

##### is_permission_err

Return True if this is a permission error.

**Param√®tres :**

- `exc`

##### convert_oserror

Convert OSError into NoSuchProcess or AccessDenied.

**Param√®tres :**

- `exc`
- `pid`
- `name`

##### wrap_exceptions

Decorator which converts OSError into NoSuchProcess or AccessDenied.

**Param√®tres :**

- `fun`

##### retry_error_partial_copy

Workaround for https://github.com/giampaolo/psutil/issues/875.
See: https://stackoverflow.com/questions/4457745#4457745.

**Param√®tres :**

- `fun`

##### __init__

**Param√®tres :**

- `name`
- `display_name`

##### __str__

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### _query_config

##### _query_status

##### _wrap_exceptions

Ctx manager which translates bare OSError and WindowsError
exceptions into NoSuchProcess and AccessDenied.

##### name

The service name. This string is how a service is referenced
and can be passed to win_service_get() to get a new
WindowsService instance.

##### display_name

The service display name. The value is cached when this class
is instantiated.

##### binpath

The fully qualified path to the service binary/exe file as
a string, including command line arguments.

##### username

The name of the user that owns this service.

##### start_type

A string which can either be "automatic", "manual" or
"disabled".

##### pid

The process PID, if any, else None. This can be passed
to Process class to control the service's process.

##### status

Service status as a string.

##### description

Service long description.

##### as_dict

Utility method retrieving all the information above as a
dictionary.

##### wrapper

##### wrapper

##### __init__

**Param√®tres :**

- `pid`

##### oneshot_enter

##### oneshot_exit

##### _proc_info

Return multiple information about this process as a
raw tuple.

##### name

Return process name, which on Windows is always the final
part of the executable.

##### exe

##### cmdline

##### environ

##### ppid

##### _get_raw_meminfo

##### memory_info

##### memory_full_info

##### memory_maps

##### kill

##### send_signal

**Param√®tres :**

- `sig`

##### wait

**Param√®tres :**

- `timeout`

##### username

##### create_time

**Param√®tres :**

- `fast_only`

##### num_threads

##### threads

##### cpu_times

##### suspend

##### resume

##### cwd

##### open_files

##### net_connections

**Param√®tres :**

- `kind`

##### nice_get

##### nice_set

**Param√®tres :**

- `value`

##### ionice_get

##### ionice_set

**Param√®tres :**

- `ioclass`
- `value`

##### io_counters

##### status

##### cpu_affinity_get

##### cpu_affinity_set

**Param√®tres :**

- `value`

##### num_handles

##### num_ctx_switches

##### from_bitmask

**Param√®tres :**

- `x`

##### to_bitmask

**Param√®tres :**

- `ls`

---

### _common

Common objects shared by __init__.py and _ps*.py modules.

Note: this module is imported by setup.py, so it should not import
psutil or third-party modules.

#### Classes

##### NicDuplex

##### BatteryTime

##### Error

Base exception class. All other psutil exceptions inherit
from this one.

**M√©thodes :**

- `_infodict()`
- `__str__()`
- `__repr__()`

##### NoSuchProcess

Exception raised when a process with a certain PID doesn't
or no longer exists.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### ZombieProcess

Exception raised when querying a zombie process. This is
raised on macOS, BSD and Solaris only, and not always: depending
on the query the OS may be able to succeed anyway.
On Linux all zombie processes are querable (hence this is never
raised). Windows doesn't have zombie processes.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### AccessDenied

Exception raised when permission to perform an action is denied.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### TimeoutExpired

Raised on Process.wait(timeout) if timeout expires and process
is still alive.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### _WrapNumbers

Watches numbers so that they don't overflow and wrap
(reset to zero).

**M√©thodes :**

- `__init__()`
- `_add_dict()`
- `_remove_dead_reminders()`
- `run()`
- `cache_clear()`
- `cache_info()`

#### Fonctions

##### usage_percent

Calculate percentage usage of 'used' against 'total'.

**Param√®tres :**

- `used`
- `total`
- `round_`

##### memoize

A simple memoize decorator for functions supporting (hashable)
positional arguments.
It also provides a cache_clear() function for clearing the cache:

>>> @memoize
... def foo()
...     return 1
    ...
>>> foo()
1
>>> foo.cache_clear()
>>>

It supports:
 - functions
 - classes (acts as a @singleton)
 - staticmethods
 - classmethods

It does NOT support:
 - methods

**Param√®tres :**

- `fun`

##### memoize_when_activated

A memoize decorator which is disabled by default. It can be
activated and deactivated on request.
For efficiency reasons it can be used only against class methods
accepting no arguments.

>>> class Foo:
...     @memoize
...     def foo()
...         print(1)
...
>>> f = Foo()
>>> # deactivated (default)
>>> foo()
1
>>> foo()
1
>>>
>>> # activated
>>> foo.cache_activate(self)
>>> foo()
1
>>> foo()
>>> foo()
>>>

**Param√®tres :**

- `fun`

##### isfile_strict

Same as os.path.isfile() but does not swallow EACCES / EPERM
exceptions, see:
http://mail.python.org/pipermail/python-dev/2012-June/120787.html.

**Param√®tres :**

- `path`

##### path_exists_strict

Same as os.path.exists() but does not swallow EACCES / EPERM
exceptions. See:
http://mail.python.org/pipermail/python-dev/2012-June/120787.html.

**Param√®tres :**

- `path`

##### supports_ipv6

Return True if IPv6 is supported on this platform.

##### parse_environ_block

Parse a C environ block of environment variables into a dictionary.

**Param√®tres :**

- `data`

##### sockfam_to_enum

Convert a numeric socket family value to an IntEnum member.
If it's not a known member, return the numeric value itself.

**Param√®tres :**

- `num`

##### socktype_to_enum

Convert a numeric socket type value to an IntEnum member.
If it's not a known member, return the numeric value itself.

**Param√®tres :**

- `num`

##### conn_to_ntuple

Convert a raw connection tuple to a proper ntuple.

**Param√®tres :**

- `fd`
- `fam`
- `type_`
- `laddr`
- `raddr`
- `status`
- `status_map`
- `pid`

##### broadcast_addr

Given the address ntuple returned by ``net_if_addrs()``
calculates the broadcast address.

**Param√®tres :**

- `addr`

##### deprecated_method

A decorator which can be used to mark a method as deprecated
'replcement' is the method name which will be called instead.

**Param√®tres :**

- `replacement`

##### wrap_numbers

Given an `input_dict` and a function `name`, adjust the numbers
which "wrap" (restart from zero) across different calls by adding
"old value" to "new value" and return an updated dict.

**Param√®tres :**

- `input_dict`
- `name`

##### open_binary

**Param√®tres :**

- `fname`

##### open_text

Open a file in text mode by using the proper FS encoding and
en/decoding error handlers.

**Param√®tres :**

- `fname`

##### cat

Read entire file content and return it as a string. File is
opened in text mode. If specified, `fallback` is the value
returned in case of error, either if the file does not exist or
it can't be read().

**Param√®tres :**

- `fname`
- `fallback`
- `_open`

##### bcat

Same as above but opens file in binary mode.

**Param√®tres :**

- `fname`
- `fallback`

##### bytes2human

Used by various scripts. See: https://code.activestate.com/recipes/578019-bytes-to-human-human-to-bytes-converter/?in=user-4178764.

>>> bytes2human(10000)
'9.8K'
>>> bytes2human(100001221)
'95.4M'

**Param√®tres :**

- `n`
- `format`

##### get_procfs_path

Return updated psutil.PROCFS_PATH constant.

##### decode

**Param√®tres :**

- `s`

##### term_supports_colors

**Param√®tres :**

- `file`

##### hilite

Return an highlighted version of 'string'.

**Param√®tres :**

- `s`
- `color`
- `bold`

##### print_color

Print a colorized version of string.

**Param√®tres :**

- `s`
- `color`
- `bold`
- `file`

##### debug

If PSUTIL_DEBUG env var is set, print a debug message to stderr.

**Param√®tres :**

- `msg`

##### _infodict

**Param√®tres :**

- `attrs`

##### __str__

##### __repr__

##### __init__

**Param√®tres :**

- `pid`
- `name`
- `msg`

##### __reduce__

##### __init__

**Param√®tres :**

- `pid`
- `name`
- `ppid`
- `msg`

##### __reduce__

##### __init__

**Param√®tres :**

- `pid`
- `name`
- `msg`

##### __reduce__

##### __init__

**Param√®tres :**

- `seconds`
- `pid`
- `name`

##### __reduce__

##### wrapper

##### cache_clear

Clear cache.

##### wrapper

##### cache_activate

Activate cache. Expects a Process instance. Cache will be
stored as a "_cache" instance attribute.

**Param√®tres :**

- `proc`

##### cache_deactivate

Deactivate and clear cache.

**Param√®tres :**

- `proc`

##### outer

**Param√®tres :**

- `fun`

##### __init__

##### _add_dict

**Param√®tres :**

- `input_dict`
- `name`

##### _remove_dead_reminders

In case the number of keys changed between calls (e.g. a
disk disappears) this removes the entry from self.reminders.

**Param√®tres :**

- `input_dict`
- `name`

##### run

Cache dict and sum numbers which overflow and wrap.
Return an updated copy of `input_dict`.

**Param√®tres :**

- `input_dict`
- `name`

##### cache_clear

Clear the internal cache, optionally only for function 'name'.

**Param√®tres :**

- `name`

##### cache_info

Return internal cache dicts as a tuple of 3 elements.

##### inner

---

### _psosx

macOS platform implementation.

#### Classes

##### Process

Wrapper class around underlying C implementation.

**M√©thodes :**

- `__init__()`
- `_get_kinfo_proc()`
- `_get_pidtaskinfo()`
- `oneshot_enter()`
- `oneshot_exit()`
- `name()`
- `exe()`
- `cmdline()`
- `environ()`
- `ppid()`
- `cwd()`
- `uids()`
- `gids()`
- `terminal()`
- `memory_info()`
- `memory_full_info()`
- `cpu_times()`
- `create_time()`
- `num_ctx_switches()`
- `num_threads()`
- `open_files()`
- `net_connections()`
- `num_fds()`
- `wait()`
- `nice_get()`
- `nice_set()`
- `status()`
- `threads()`

#### Fonctions

##### virtual_memory

System virtual memory as a namedtuple.

##### swap_memory

Swap system memory as a (total, used, free, sin, sout) tuple.

##### cpu_times

Return system CPU times as a namedtuple.

##### per_cpu_times

Return system CPU times as a named tuple.

##### cpu_count_logical

Return the number of logical CPUs in the system.

##### cpu_count_cores

Return the number of CPU cores in the system.

##### cpu_stats

##### cpu_freq

Return CPU frequency.
On macOS per-cpu frequency is not supported.
Also, the returned frequency never changes, see:
https://arstechnica.com/civis/viewtopic.php?f=19&t=465002.

##### disk_partitions

Return mounted disk partitions as a list of namedtuples.

**Param√®tres :**

- `all`

##### sensors_battery

Return battery information.

##### net_connections

System-wide network connections.

**Param√®tres :**

- `kind`

##### net_if_stats

Get NIC stats (isup, duplex, speed, mtu).

##### boot_time

The system boot time expressed in seconds since the epoch.

##### users

Return currently connected users as a list of namedtuples.

##### pids

##### is_zombie

**Param√®tres :**

- `pid`

##### wrap_exceptions

Decorator which translates bare OSError exceptions into
NoSuchProcess and AccessDenied.

**Param√®tres :**

- `fun`

##### wrapper

##### __init__

**Param√®tres :**

- `pid`

##### _get_kinfo_proc

##### _get_pidtaskinfo

##### oneshot_enter

##### oneshot_exit

##### name

##### exe

##### cmdline

##### environ

##### ppid

##### cwd

##### uids

##### gids

##### terminal

##### memory_info

##### memory_full_info

##### cpu_times

##### create_time

##### num_ctx_switches

##### num_threads

##### open_files

##### net_connections

**Param√®tres :**

- `kind`

##### num_fds

##### wait

**Param√®tres :**

- `timeout`

##### nice_get

##### nice_set

**Param√®tres :**

- `value`

##### status

##### threads

---

### _psbsd

FreeBSD, OpenBSD and NetBSD platforms implementation.

#### Classes

##### Process

Wrapper class around underlying C implementation.

**M√©thodes :**

- `__init__()`
- `_assert_alive()`
- `oneshot()`
- `oneshot_enter()`
- `oneshot_exit()`
- `name()`
- `exe()`
- `cmdline()`
- `environ()`
- `terminal()`
- `ppid()`
- `uids()`
- `gids()`
- `cpu_times()`
- `memory_info()`
- `create_time()`
- `num_threads()`
- `num_ctx_switches()`
- `threads()`
- `net_connections()`
- `wait()`
- `nice_get()`
- `nice_set()`
- `status()`
- `io_counters()`
- `cwd()`
- `_not_implemented()`

#### Fonctions

##### virtual_memory

##### swap_memory

System swap memory as (total, used, free, sin, sout) namedtuple.

##### cpu_times

Return system per-CPU times as a namedtuple.

##### cpu_count_logical

Return the number of logical CPUs in the system.

##### cpu_stats

Return various CPU stats as a named tuple.

##### disk_partitions

Return mounted disk partitions as a list of namedtuples.
'all' argument is ignored, see:
https://github.com/giampaolo/psutil/issues/906.

**Param√®tres :**

- `all`

##### net_if_stats

Get NIC stats (isup, duplex, speed, mtu).

##### net_connections

System-wide network connections.

**Param√®tres :**

- `kind`

##### boot_time

The system boot time expressed in seconds since the epoch.

##### users

Return currently connected users as a list of namedtuples.

##### _pid_0_exists

##### pids

Returns a list of PIDs currently running on the system.

##### is_zombie

**Param√®tres :**

- `pid`

##### wrap_exceptions

Decorator which translates bare OSError exceptions into
NoSuchProcess and AccessDenied.

**Param√®tres :**

- `fun`

##### wrap_exceptions_procfs

Same as above, for routines relying on reading /proc fs.

**Param√®tres :**

- `inst`

##### per_cpu_times

Return system CPU times as a namedtuple.

##### per_cpu_times

Return system CPU times as a namedtuple.

##### cpu_count_cores

##### cpu_count_cores

Return the number of CPU cores in the system.

##### cpu_freq

Return frequency metrics for CPUs. As of Dec 2018 only
CPU 0 appears to be supported by FreeBSD and all other cores
match the frequency of CPU 0.

##### sensors_battery

Return battery info.

##### sensors_temperatures

Return CPU cores temperatures if available, else an empty dict.

##### pid_exists

**Param√®tres :**

- `pid`

##### wrapper

##### __init__

**Param√®tres :**

- `pid`

##### _assert_alive

Raise NSP if the process disappeared on us.

##### oneshot

Retrieves multiple process info in one shot as a raw tuple.

##### oneshot_enter

##### oneshot_exit

##### name

##### exe

##### cmdline

##### environ

##### terminal

##### ppid

##### uids

##### gids

##### cpu_times

##### memory_info

##### create_time

##### num_threads

##### num_ctx_switches

##### threads

##### net_connections

**Param√®tres :**

- `kind`

##### wait

**Param√®tres :**

- `timeout`

##### nice_get

##### nice_set

**Param√®tres :**

- `value`

##### status

##### io_counters

##### cwd

Return process current working directory.

##### _not_implemented

##### cpu_freq

##### pid_exists

**Param√®tres :**

- `pid`

##### cpu_num

##### open_files

Return files opened by process as a list of namedtuples.

##### num_fds

Return the number of file descriptors opened by this process.

##### cpu_affinity_get

##### cpu_affinity_set

**Param√®tres :**

- `cpus`

##### memory_maps

##### rlimit

**Param√®tres :**

- `resource`
- `limits`

---

### _psaix

AIX platform implementation.

#### Classes

##### Process

Wrapper class around underlying C implementation.

**M√©thodes :**

- `__init__()`
- `oneshot_enter()`
- `oneshot_exit()`
- `_proc_basic_info()`
- `_proc_cred()`
- `name()`
- `exe()`
- `cmdline()`
- `environ()`
- `create_time()`
- `num_threads()`
- `net_connections()`
- `nice_get()`
- `nice_set()`
- `ppid()`
- `uids()`
- `gids()`
- `cpu_times()`
- `terminal()`
- `cwd()`
- `memory_info()`
- `status()`
- `open_files()`
- `num_fds()`
- `num_ctx_switches()`
- `wait()`

#### Fonctions

##### virtual_memory

##### swap_memory

Swap system memory as a (total, used, free, sin, sout) tuple.

##### cpu_times

Return system-wide CPU times as a named tuple.

##### per_cpu_times

Return system per-CPU times as a list of named tuples.

##### cpu_count_logical

Return the number of logical CPUs in the system.

##### cpu_count_cores

##### cpu_stats

Return various CPU stats as a named tuple.

##### disk_partitions

Return system disk partitions.

**Param√®tres :**

- `all`

##### net_connections

Return socket connections.  If pid == -1 return system-wide
connections (as opposed to connections opened by one process only).

**Param√®tres :**

- `kind`
- `_pid`

##### net_if_stats

Get NIC stats (isup, duplex, speed, mtu).

##### boot_time

The system boot time expressed in seconds since the epoch.

##### users

Return currently connected users as a list of namedtuples.

##### pids

Returns a list of PIDs currently running on the system.

##### pid_exists

Check for the existence of a unix pid.

**Param√®tres :**

- `pid`

##### wrap_exceptions

Call callable into a try/except clause and translate ENOENT,
EACCES and EPERM in NoSuchProcess or AccessDenied exceptions.

**Param√®tres :**

- `fun`

##### wrapper

##### __init__

**Param√®tres :**

- `pid`

##### oneshot_enter

##### oneshot_exit

##### _proc_basic_info

##### _proc_cred

##### name

##### exe

##### cmdline

##### environ

##### create_time

##### num_threads

##### net_connections

**Param√®tres :**

- `kind`

##### nice_get

##### nice_set

**Param√®tres :**

- `value`

##### ppid

##### uids

##### gids

##### cpu_times

##### terminal

##### cwd

##### memory_info

##### status

##### open_files

##### num_fds

##### num_ctx_switches

##### wait

**Param√®tres :**

- `timeout`

##### threads

##### io_counters

---

### _pslinux

Linux platform implementation.

#### Classes

##### IOPriority

##### _Ipv6UnsupportedError

##### NetConnections

A wrapper on top of /proc/net/* files, retrieving per-process
and system-wide open connections (TCP, UDP, UNIX) similarly to
"netstat -an".

Note: in case of UNIX sockets we're only able to determine the
local endpoint/path, not the one it's connected to.
According to [1] it would be possible but not easily.

[1] http://serverfault.com/a/417946

**M√©thodes :**

- `__init__()`
- `get_proc_inodes()`
- `get_all_inodes()`
- `decode_address()`
- `process_inet()`
- `process_unix()`
- `retrieve()`

##### RootFsDeviceFinder

disk_partitions() may return partitions with device == "/dev/root"
or "rootfs". This container class uses different strategies to try to
obtain the real device path. Resources:
https://bootlin.com/blog/find-root-device/
https://www.systutorials.com/how-to-find-the-disk-where-root-is-on-in-bash-on-linux/.

**M√©thodes :**

- `__init__()`
- `ask_proc_partitions()`
- `ask_sys_dev_block()`
- `ask_sys_class_block()`
- `find()`

##### Process

Linux process implementation.

**M√©thodes :**

- `__init__()`
- `_is_zombie()`
- `_raise_if_zombie()`
- `_raise_if_not_alive()`
- `_parse_stat_file()`
- `_read_status_file()`
- `_read_smaps_file()`
- `oneshot_enter()`
- `oneshot_exit()`
- `name()`
- `exe()`
- `cmdline()`
- `environ()`
- `terminal()`
- `cpu_times()`
- `cpu_num()`
- `wait()`
- `create_time()`
- `memory_info()`
- `cwd()`
- `num_ctx_switches()`
- `num_threads()`
- `threads()`
- `nice_get()`
- `nice_set()`
- `status()`
- `open_files()`
- `net_connections()`
- `num_fds()`
- `ppid()`
- `uids()`
- `gids()`

#### Fonctions

##### readlink

Wrapper around os.readlink().

**Param√®tres :**

- `path`

##### file_flags_to_mode

Convert file's open() flags into a readable string.
Used by Process.open_files().

**Param√®tres :**

- `flags`

##### is_storage_device

Return True if the given name refers to a root device (e.g.
"sda", "nvme0n1") as opposed to a logical partition (e.g.  "sda1",
"nvme0n1p1"). If name is a virtual device (e.g. "loop1", "ram")
return True.

**Param√®tres :**

- `name`

##### set_scputimes_ntuple

Set a namedtuple of variable fields depending on the CPU times
available on this Linux kernel version which may be:
(user, nice, system, idle, iowait, irq, softirq, [steal, [guest,
 [guest_nice]]])
Used by cpu_times() function.

**Param√®tres :**

- `procfs_path`

##### calculate_avail_vmem

Fallback for kernels < 3.14 where /proc/meminfo does not provide
"MemAvailable", see:
https://blog.famzah.net/2014/09/24/.

This code reimplements the algorithm outlined here:
https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/
    commit/?id=34e431b0ae398fc54ea69ff85ec700722c9da773

We use this function also when "MemAvailable" returns 0 (possibly a
kernel bug, see: https://github.com/giampaolo/psutil/issues/1915).
In that case this routine matches "free" CLI tool result ("available"
column).

XXX: on recent kernels this calculation may differ by ~1.5% compared
to "MemAvailable:", as it's calculated slightly differently.
It is still way more realistic than doing (free + cached) though.
See:
* https://gitlab.com/procps-ng/procps/issues/42
* https://github.com/famzah/linux-memavailable-procfs/issues/2

**Param√®tres :**

- `mems`

##### virtual_memory

Report virtual memory stats.
This implementation mimics procps-ng-3.3.12, aka "free" CLI tool:
https://gitlab.com/procps-ng/procps/blob/
    24fd2605c51fccc375ab0287cec33aa767f06718/proc/sysinfo.c#L778-791
The returned values are supposed to match both "free" and "vmstat -s"
CLI tools.

##### swap_memory

Return swap memory metrics.

##### cpu_times

Return a named tuple representing the following system-wide
CPU times:
(user, nice, system, idle, iowait, irq, softirq [steal, [guest,
 [guest_nice]]])
Last 3 fields may not be available on all Linux kernel versions.

##### per_cpu_times

Return a list of namedtuple representing the CPU times
for every CPU available on the system.

##### cpu_count_logical

Return the number of logical CPUs in the system.

##### cpu_count_cores

Return the number of CPU cores in the system.

##### cpu_stats

Return various CPU stats as a named tuple.

##### _cpu_get_cpuinfo_freq

Return current CPU frequency from cpuinfo if available.

##### net_connections

Return system-wide open connections.

**Param√®tres :**

- `kind`

##### net_io_counters

Return network I/O statistics for every network interface
installed on the system as a dict of raw tuples.

##### net_if_stats

Get NIC stats (isup, duplex, speed, mtu).

##### disk_io_counters

Return disk I/O statistics for every disk installed on the
system as a dict of raw tuples.

**Param√®tres :**

- `perdisk`

##### disk_partitions

Return mounted disk partitions as a list of namedtuples.

**Param√®tres :**

- `all`

##### sensors_temperatures

Return hardware (CPU and others) temperatures as a dict
including hardware name, label, current, max and critical
temperatures.

Implementation notes:
- /sys/class/hwmon looks like the most recent interface to
  retrieve this info, and this implementation relies on it
  only (old distros will probably use something else)
- lm-sensors on Ubuntu 16.04 relies on /sys/class/hwmon
- /sys/class/thermal/thermal_zone* is another one but it's more
  difficult to parse

##### sensors_fans

Return hardware fans info (for CPU and other peripherals) as a
dict including hardware label and current speed.

Implementation notes:
- /sys/class/hwmon looks like the most recent interface to
  retrieve this info, and this implementation relies on it
  only (old distros will probably use something else)
- lm-sensors on Ubuntu 16.04 relies on /sys/class/hwmon

##### sensors_battery

Return battery information.
Implementation note: it appears /sys/class/power_supply/BAT0/
directory structure may vary and provide files with the same
meaning but under different names, see:
https://github.com/giampaolo/psutil/issues/966.

##### users

Return currently connected users as a list of namedtuples.

##### boot_time

Return the system boot time expressed in seconds since the epoch.

##### pids

Returns a list of PIDs currently running on the system.

##### pid_exists

Check for the existence of a unix PID. Linux TIDs are not
supported (always return False).

**Param√®tres :**

- `pid`

##### ppid_map

Obtain a {pid: ppid, ...} dict for all running processes in
one shot. Used to speed up Process.children().

##### wrap_exceptions

Decorator which translates bare OSError and OSError exceptions
into NoSuchProcess and AccessDenied.

**Param√®tres :**

- `fun`

##### cpu_freq

Return frequency metrics for all CPUs.
Contrarily to other OSes, Linux updates these values in
real-time.

##### cpu_freq

Alternate implementation using /proc/cpuinfo.
min and max frequencies are not available and are set to None.

##### __init__

##### get_proc_inodes

**Param√®tres :**

- `pid`

##### get_all_inodes

##### decode_address

Accept an "ip:port" address as displayed in /proc/net/*
and convert it into a human readable form, like:

"0500000A:0016" -> ("10.0.0.5", 22)
"0000000000000000FFFF00000100007F:9E49" -> ("::ffff:127.0.0.1", 40521)

The IP address portion is a little or big endian four-byte
hexadecimal number; that is, the least significant byte is listed
first, so we need to reverse the order of the bytes to convert it
to an IP address.
The port is represented as a two-byte hexadecimal number.

Reference:
http://linuxdevcenter.com/pub/a/linux/2000/11/16/LinuxAdmin.html

**Param√®tres :**

- `addr`
- `family`

##### process_inet

Parse /proc/net/tcp* and /proc/net/udp* files.

**Param√®tres :**

- `file`
- `family`
- `type_`
- `inodes`
- `filter_pid`

##### process_unix

Parse /proc/net/unix files.

**Param√®tres :**

- `file`
- `family`
- `inodes`
- `filter_pid`

##### retrieve

**Param√®tres :**

- `kind`
- `pid`

##### read_procfs

##### read_sysfs

##### __init__

##### ask_proc_partitions

##### ask_sys_dev_block

##### ask_sys_class_block

##### find

##### multi_bcat

Attempt to read the content of multiple files which may
not exist. If none of them exist return None.

##### wrapper

##### __init__

**Param√®tres :**

- `pid`

##### _is_zombie

##### _raise_if_zombie

##### _raise_if_not_alive

Raise NSP if the process disappeared on us.

##### _parse_stat_file

Parse /proc/{pid}/stat file and return a dict with various
process info.
Using "man proc" as a reference: where "man proc" refers to
position N always subtract 3 (e.g ppid position 4 in
'man proc' == position 1 in here).
The return value is cached in case oneshot() ctx manager is
in use.

##### _read_status_file

Read /proc/{pid}/stat file and return its content.
The return value is cached in case oneshot() ctx manager is
in use.

##### _read_smaps_file

##### oneshot_enter

##### oneshot_exit

##### name

##### exe

##### cmdline

##### environ

##### terminal

##### cpu_times

##### cpu_num

What CPU the process is on.

##### wait

**Param√®tres :**

- `timeout`

##### create_time

##### memory_info

##### cwd

##### num_ctx_switches

**Param√®tres :**

- `_ctxsw_re`

##### num_threads

**Param√®tres :**

- `_num_threads_re`

##### threads

##### nice_get

##### nice_set

**Param√®tres :**

- `value`

##### status

##### open_files

##### net_connections

**Param√®tres :**

- `kind`

##### num_fds

##### ppid

##### uids

**Param√®tres :**

- `_uids_re`

##### gids

**Param√®tres :**

- `_gids_re`

##### io_counters

##### _parse_smaps_rollup

##### _parse_smaps

**Param√®tres :**

- `_private_re`
- `_pss_re`
- `_swap_re`

##### memory_full_info

##### memory_maps

Return process's mapped memory regions as a list of named
tuples. Fields are explained in 'man proc'; here is an updated
(Apr 2012) version: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/filesystems/proc.txt?id=b76437579d1344b612cf1851ae610c636cec7db0.

/proc/{PID}/smaps does not exist on kernels < 2.6.14 or if
CONFIG_MMU kernel configuration option is not enabled.

##### cpu_affinity_get

##### _get_eligible_cpus

**Param√®tres :**

- `_re`

##### cpu_affinity_set

**Param√®tres :**

- `cpus`

##### ionice_get

##### ionice_set

**Param√®tres :**

- `ioclass`
- `value`

##### rlimit

**Param√®tres :**

- `resource_`
- `limits`

##### get_blocks

**Param√®tres :**

- `lines`
- `current_block`

---

### _psposix

Routines common to all posix systems.

#### Fonctions

##### pid_exists

Check whether pid exists in the current process table.

**Param√®tres :**

- `pid`

##### negsig_to_enum

Convert a negative signal value to an enum.

**Param√®tres :**

- `num`

##### wait_pid

Wait for a process PID to terminate.

If the process terminated normally by calling exit(3) or _exit(2),
or by returning from main(), the return value is the positive integer
passed to *exit().

If it was terminated by a signal it returns the negated value of the
signal which caused the termination (e.g. -SIGTERM).

If PID is not a children of os.getpid() (current process) just
wait until the process disappears and return None.

If PID does not exist at all return None immediately.

If *timeout* != None and process is still alive raise TimeoutExpired.
timeout=0 is also possible (either return immediately or raise).

**Param√®tres :**

- `pid`
- `timeout`
- `proc_name`
- `_waitpid`
- `_timer`
- `_min`
- `_sleep`
- `_pid_exists`

##### disk_usage

Return disk usage associated with path.
Note: UNIX usually reserves 5% disk space which is not accessible
by user. In this function "total" and "used" values reflect the
total and used disk space whereas "free" and "percent" represent
the "free" and "used percent" user disk space.

**Param√®tres :**

- `path`

##### get_terminal_map

Get a map of device-id -> path as a dict.
Used by Process.terminal().

##### sleep

**Param√®tres :**

- `interval`

---

### _pssunos

Sun OS Solaris platform implementation.

#### Classes

##### Process

Wrapper class around underlying C implementation.

**M√©thodes :**

- `__init__()`
- `_assert_alive()`
- `oneshot_enter()`
- `oneshot_exit()`
- `_proc_name_and_args()`
- `_proc_basic_info()`
- `_proc_cred()`
- `name()`
- `exe()`
- `cmdline()`
- `environ()`
- `create_time()`
- `num_threads()`
- `nice_get()`
- `nice_set()`
- `ppid()`
- `uids()`
- `gids()`
- `cpu_times()`
- `cpu_num()`
- `terminal()`
- `cwd()`
- `memory_info()`
- `status()`
- `threads()`
- `open_files()`
- `_get_unix_sockets()`
- `net_connections()`
- `memory_maps()`
- `num_fds()`
- `num_ctx_switches()`
- `wait()`

#### Fonctions

##### virtual_memory

Report virtual memory metrics.

##### swap_memory

Report swap memory metrics.

##### cpu_times

Return system-wide CPU times as a named tuple.

##### per_cpu_times

Return system per-CPU times as a list of named tuples.

##### cpu_count_logical

Return the number of logical CPUs in the system.

##### cpu_count_cores

Return the number of CPU cores in the system.

##### cpu_stats

Return various CPU stats as a named tuple.

##### disk_partitions

Return system disk partitions.

**Param√®tres :**

- `all`

##### net_connections

Return socket connections.  If pid == -1 return system-wide
connections (as opposed to connections opened by one process only).
Only INET sockets are returned (UNIX are not).

**Param√®tres :**

- `kind`
- `_pid`

##### net_if_stats

Get NIC stats (isup, duplex, speed, mtu).

##### boot_time

The system boot time expressed in seconds since the epoch.

##### users

Return currently connected users as a list of namedtuples.

##### pids

Returns a list of PIDs currently running on the system.

##### pid_exists

Check for the existence of a unix pid.

**Param√®tres :**

- `pid`

##### wrap_exceptions

Call callable into a try/except clause and translate ENOENT,
EACCES and EPERM in NoSuchProcess or AccessDenied exceptions.

**Param√®tres :**

- `fun`

##### wrapper

##### __init__

**Param√®tres :**

- `pid`

##### _assert_alive

Raise NSP if the process disappeared on us.

##### oneshot_enter

##### oneshot_exit

##### _proc_name_and_args

##### _proc_basic_info

##### _proc_cred

##### name

##### exe

##### cmdline

##### environ

##### create_time

##### num_threads

##### nice_get

##### nice_set

**Param√®tres :**

- `value`

##### ppid

##### uids

##### gids

##### cpu_times

##### cpu_num

##### terminal

##### cwd

##### memory_info

##### status

##### threads

##### open_files

##### _get_unix_sockets

Get UNIX sockets used by process by parsing 'pfiles' output.

**Param√®tres :**

- `pid`

##### net_connections

**Param√®tres :**

- `kind`

##### memory_maps

##### num_fds

##### num_ctx_switches

##### wait

**Param√®tres :**

- `timeout`

##### toaddr

**Param√®tres :**

- `start`
- `end`

---

### .!21416!_pswindows

---

### .!21422!_common

---

### .!21425!__init__

---

### .!21430!_psosx

---

### .!21435!_psbsd

---

### .!21440!_psaix

---

### .!21447!_pslinux

---

### .!21453!_psposix

---

### .!21455!_pssunos

---

### test_contracts

Contracts tests. These tests mainly check API sanity in terms of
returned types and APIs availability.
Some of these are duplicates of tests test_system.py and test_process.py.

#### Classes

##### TestAvailConstantsAPIs

**M√©thodes :**

- `test_PROCFS_PATH()`
- `test_win_priority()`
- `test_linux_ioprio_linux()`
- `test_linux_ioprio_windows()`
- `test_rlimit()`

##### TestAvailSystemAPIs

**M√©thodes :**

- `test_win_service_iter()`
- `test_win_service_get()`
- `test_cpu_freq()`
- `test_sensors_temperatures()`
- `test_sensors_fans()`
- `test_battery()`

##### TestAvailProcessAPIs

**M√©thodes :**

- `test_environ()`
- `test_uids()`
- `test_gids()`
- `test_terminal()`
- `test_ionice()`
- `test_rlimit()`
- `test_io_counters()`
- `test_num_fds()`
- `test_num_handles()`
- `test_cpu_affinity()`
- `test_cpu_num()`
- `test_memory_maps()`

##### TestSystemAPITypes

Check the return types of system related APIs.
https://github.com/giampaolo/psutil/issues/1039.

**M√©thodes :**

- `setUpClass()`
- `assert_ntuple_of_nums()`
- `test_cpu_times()`
- `test_cpu_percent()`
- `test_cpu_times_percent()`
- `test_cpu_count()`
- `test_cpu_freq()`
- `test_disk_io_counters()`
- `test_disk_partitions()`
- `test_net_connections()`
- `test_net_if_addrs()`
- `test_net_if_stats()`
- `test_net_io_counters()`
- `test_sensors_fans()`
- `test_sensors_temperatures()`
- `test_boot_time()`
- `test_users()`

##### TestProcessWaitType

**M√©thodes :**

- `test_negative_signal()`

#### Fonctions

##### test_PROCFS_PATH

##### test_win_priority

##### test_linux_ioprio_linux

##### test_linux_ioprio_windows

##### test_rlimit

##### test_win_service_iter

##### test_win_service_get

##### test_cpu_freq

##### test_sensors_temperatures

##### test_sensors_fans

##### test_battery

##### test_environ

##### test_uids

##### test_gids

##### test_terminal

##### test_ionice

##### test_rlimit

##### test_io_counters

##### test_num_fds

##### test_num_handles

##### test_cpu_affinity

##### test_cpu_num

##### test_memory_maps

##### setUpClass

**Param√®tres :**

- `cls`

##### assert_ntuple_of_nums

**Param√®tres :**

- `nt`
- `type_`
- `gezero`

##### test_cpu_times

##### test_cpu_percent

##### test_cpu_times_percent

##### test_cpu_count

##### test_cpu_freq

##### test_disk_io_counters

##### test_disk_partitions

##### test_net_connections

##### test_net_if_addrs

##### test_net_if_stats

##### test_net_io_counters

##### test_sensors_fans

##### test_sensors_temperatures

##### test_boot_time

##### test_users

##### test_negative_signal

---

### test_connections

Tests for psutil.net_connections() and Process.net_connections() APIs.

#### Classes

##### ConnectionTestCase

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `compare_procsys_connections()`

##### TestBasicOperations

**M√©thodes :**

- `test_system()`
- `test_process()`
- `test_invalid_kind()`

##### TestUnconnectedSockets

Tests sockets which are open but not connected to anything.

**M√©thodes :**

- `get_conn_from_sock()`
- `check_socket()`
- `test_tcp_v4()`
- `test_tcp_v6()`
- `test_udp_v4()`
- `test_udp_v6()`
- `test_unix_tcp()`
- `test_unix_udp()`

##### TestConnectedSocket

Test socket pairs which are actually connected to
each other.

**M√©thodes :**

- `test_tcp()`
- `test_unix()`

##### TestFilters

**M√©thodes :**

- `test_filters()`
- `test_combos()`
- `test_count()`

##### TestSystemWideConnections

Tests for net_connections().

**M√©thodes :**

- `test_it()`
- `test_multi_sockets_procs()`

##### TestMisc

**M√©thodes :**

- `test_net_connection_constants()`

#### Fonctions

##### this_proc_net_connections

**Param√®tres :**

- `kind`

##### setUp

##### tearDown

##### compare_procsys_connections

Given a process PID and its list of connections compare
those against system-wide connections retrieved via
psutil.net_connections.

**Param√®tres :**

- `pid`
- `proc_cons`
- `kind`

##### test_system

##### test_process

##### test_invalid_kind

##### get_conn_from_sock

**Param√®tres :**

- `sock`

##### check_socket

Given a socket, makes sure it matches the one obtained
via psutil. It assumes this process created one connection
only (the one supposed to be checked).

**Param√®tres :**

- `sock`

##### test_tcp_v4

##### test_tcp_v6

##### test_udp_v4

##### test_udp_v6

##### test_unix_tcp

##### test_unix_udp

##### test_tcp

##### test_unix

##### test_filters

##### test_combos

##### test_count

##### test_it

##### test_multi_sockets_procs

##### test_net_connection_constants

##### check

**Param√®tres :**

- `kind`
- `families`
- `types`

##### check_conn

**Param√®tres :**

- `proc`
- `conn`
- `family`
- `type`
- `laddr`
- `raddr`
- `status`
- `kinds`

##### check

**Param√®tres :**

- `cons`
- `families`
- `types_`

---

### test_unicode

Notes about unicode handling in psutil
======================================.

Starting from version 5.3.0 psutil adds unicode support, see:
https://github.com/giampaolo/psutil/issues/1040
The notes below apply to *any* API returning a string such as
process exe(), cwd() or username():

* all strings are encoded by using the OS filesystem encoding
  (sys.getfilesystemencoding()) which varies depending on the platform
  (e.g. "UTF-8" on macOS, "mbcs" on Win)
* no API call is supposed to crash with UnicodeDecodeError
* instead, in case of badly encoded data returned by the OS, the
  following error handlers are used to replace the corrupted characters in
  the string:
    * sys.getfilesystemencodeerrors() or "surrogatescape" on POSIX and
      "replace" on Windows.

For a detailed explanation of how psutil handles unicode see #1040.

Tests
=====

List of APIs returning or dealing with a string:
('not tested' means they are not tested to deal with non-ASCII strings):

* Process.cmdline()
* Process.cwd()
* Process.environ()
* Process.exe()
* Process.memory_maps()
* Process.name()
* Process.net_connections('unix')
* Process.open_files()
* Process.username()             (not tested)

* disk_io_counters()             (not tested)
* disk_partitions()              (not tested)
* disk_usage(str)
* net_connections('unix')
* net_if_addrs()                 (not tested)
* net_if_stats()                 (not tested)
* net_io_counters()              (not tested)
* sensors_fans()                 (not tested)
* sensors_temperatures()         (not tested)
* users()                        (not tested)

* WindowsService.binpath()       (not tested)
* WindowsService.description()   (not tested)
* WindowsService.display_name()  (not tested)
* WindowsService.name()          (not tested)
* WindowsService.status()        (not tested)
* WindowsService.username()      (not tested)

In here we create a unicode path with a funky non-ASCII name and (where
possible) make psutil return it back (e.g. on name(), exe(), open_files(),
etc.) and make sure that:

* psutil never crashes with UnicodeDecodeError
* the returned path matches

#### Classes

##### BaseUnicodeTest

**M√©thodes :**

- `setUpClass()`
- `setUp()`

##### TestFSAPIs

Test FS APIs with a funky, valid, UTF8 path name.

**M√©thodes :**

- `expect_exact_path_match()`
- `test_proc_exe()`
- `test_proc_name()`
- `test_proc_cmdline()`
- `test_proc_cwd()`
- `test_proc_open_files()`
- `test_proc_net_connections()`
- `test_net_connections()`
- `test_disk_usage()`
- `test_memory_maps()`

##### TestFSAPIsWithInvalidPath

Test FS APIs with a funky, invalid path name.

**M√©thodes :**

- `expect_exact_path_match()`

##### TestNonFSAPIS

Unicode tests for non fs-related APIs.

**M√©thodes :**

- `test_proc_environ()`

#### Fonctions

##### try_unicode

Return True if both the fs and the subprocess module can
deal with a unicode file name.

**Param√®tres :**

- `suffix`

##### setUpClass

**Param√®tres :**

- `cls`

##### setUp

##### expect_exact_path_match

##### test_proc_exe

##### test_proc_name

##### test_proc_cmdline

##### test_proc_cwd

##### test_proc_open_files

##### test_proc_net_connections

##### test_net_connections

##### test_disk_usage

##### test_memory_maps

##### expect_exact_path_match

##### test_proc_environ

##### find_sock

**Param√®tres :**

- `cons`

##### normpath

**Param√®tres :**

- `p`

---

### test_misc

Miscellaneous tests.

#### Classes

##### TestSpecialMethods

**M√©thodes :**

- `test_check_pid_range()`
- `test_process__repr__()`
- `test_process__str__()`
- `test_error__repr__()`
- `test_error__str__()`
- `test_no_such_process__repr__()`
- `test_no_such_process__str__()`
- `test_zombie_process__repr__()`
- `test_zombie_process__str__()`
- `test_access_denied__repr__()`
- `test_access_denied__str__()`
- `test_timeout_expired__repr__()`
- `test_timeout_expired__str__()`
- `test_process__eq__()`
- `test_process__hash__()`

##### TestMisc

**M√©thodes :**

- `test__all__()`
- `test_version()`
- `test_process_as_dict_no_new_names()`
- `test_serialization()`
- `test_ad_on_process_creation()`
- `test_sanity_version_check()`

##### TestMemoizeDecorator

**M√©thodes :**

- `setUp()`
- `run_against()`
- `test_function()`
- `test_class()`
- `test_class_singleton()`
- `test_staticmethod()`
- `test_classmethod()`
- `test_original()`

##### TestCommonModule

**M√©thodes :**

- `test_memoize_when_activated()`
- `test_parse_environ_block()`
- `test_supports_ipv6()`
- `test_isfile_strict()`
- `test_debug()`
- `test_cat_bcat()`

##### TestWrapNumbers

**M√©thodes :**

- `setUp()`
- `test_first_call()`
- `test_input_hasnt_changed()`
- `test_increase_but_no_wrap()`
- `test_wrap()`
- `test_changing_keys()`
- `test_changing_keys_w_wrap()`
- `test_real_data()`
- `test_cache_first_call()`
- `test_cache_call_twice()`
- `test_cache_wrap()`
- `test_cache_changing_keys()`
- `test_cache_clear()`
- `test_cache_clear_public_apis()`

##### Foo

My docstring.

**M√©thodes :**

- `__init__()`
- `bar()`

##### Bar

**M√©thodes :**

- `__init__()`

##### Foo

**M√©thodes :**

- `bar()`

##### Foo

**M√©thodes :**

- `bar()`

##### Foo

**M√©thodes :**

- `foo()`

#### Fonctions

##### test_check_pid_range

##### test_process__repr__

**Param√®tres :**

- `func`

##### test_process__str__

##### test_error__repr__

##### test_error__str__

##### test_no_such_process__repr__

##### test_no_such_process__str__

##### test_zombie_process__repr__

##### test_zombie_process__str__

##### test_access_denied__repr__

##### test_access_denied__str__

##### test_timeout_expired__repr__

##### test_timeout_expired__str__

##### test_process__eq__

##### test_process__hash__

##### test__all__

##### test_version

##### test_process_as_dict_no_new_names

##### test_serialization

##### test_ad_on_process_creation

##### test_sanity_version_check

##### setUp

##### run_against

**Param√®tres :**

- `obj`
- `expected_retval`

##### test_function

##### test_class

##### test_class_singleton

##### test_staticmethod

##### test_classmethod

##### test_original

##### test_memoize_when_activated

##### test_parse_environ_block

##### test_supports_ipv6

##### test_isfile_strict

##### test_debug

##### test_cat_bcat

##### setUp

##### test_first_call

##### test_input_hasnt_changed

##### test_increase_but_no_wrap

##### test_wrap

##### test_changing_keys

##### test_changing_keys_w_wrap

##### test_real_data

##### test_cache_first_call

##### test_cache_call_twice

##### test_cache_wrap

##### test_cache_changing_keys

##### test_cache_clear

##### test_cache_clear_public_apis

##### check

**Param√®tres :**

- `ret`

##### foo

My docstring.

##### foo

Foo docstring.

##### k

**Param√®tres :**

- `s`

##### check_cache_info

##### __init__

##### bar

##### __init__

##### bar

My docstring.

##### bar

My docstring.

**Param√®tres :**

- `cls`

##### foo

---

### test_posix

POSIX specific tests.

#### Classes

##### TestProcess

Compare psutil results against 'ps' command line utility (mainly).

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `test_ppid()`
- `test_uid()`
- `test_gid()`
- `test_username()`
- `test_username_no_resolution()`
- `test_rss_memory()`
- `test_vsz_memory()`
- `test_name()`
- `test_name_long()`
- `test_name_long_cmdline_ad_exc()`
- `test_name_long_cmdline_nsp_exc()`
- `test_create_time()`
- `test_exe()`
- `test_cmdline()`
- `test_nice()`

##### TestSystemAPIs

Test some system APIs.

**M√©thodes :**

- `test_pids()`
- `test_nic_names()`
- `test_users()`
- `test_users_started()`
- `test_pid_exists_let_raise()`
- `test_os_waitpid_let_raise()`
- `test_os_waitpid_eintr()`
- `test_os_waitpid_bad_ret_status()`
- `test_disk_usage()`

##### TestMisc

**M√©thodes :**

- `test_getpagesize()`

#### Fonctions

##### ps

Wrapper for calling the ps command with a little bit of cross-platform
support for a narrow range of features.

**Param√®tres :**

- `fmt`
- `pid`

##### ps_name

**Param√®tres :**

- `pid`

##### ps_args

**Param√®tres :**

- `pid`

##### ps_rss

**Param√®tres :**

- `pid`

##### ps_vsz

**Param√®tres :**

- `pid`

##### df

**Param√®tres :**

- `device`

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_ppid

##### test_uid

##### test_gid

##### test_username

##### test_username_no_resolution

##### test_rss_memory

##### test_vsz_memory

##### test_name

##### test_name_long

##### test_name_long_cmdline_ad_exc

##### test_name_long_cmdline_nsp_exc

##### test_create_time

##### test_exe

##### test_cmdline

##### test_nice

##### test_pids

##### test_nic_names

##### test_users

##### test_users_started

##### test_pid_exists_let_raise

##### test_os_waitpid_let_raise

##### test_os_waitpid_eintr

##### test_os_waitpid_bad_ret_status

##### test_disk_usage

##### test_getpagesize

---

### test_linux

Linux specific tests.

#### Classes

##### TestSystemVirtualMemoryAgainstFree

**M√©thodes :**

- `test_total()`
- `test_used()`
- `test_free()`
- `test_shared()`
- `test_available()`

##### TestSystemVirtualMemoryAgainstVmstat

**M√©thodes :**

- `test_total()`
- `test_used()`
- `test_free()`
- `test_buffers()`
- `test_active()`
- `test_inactive()`

##### TestSystemVirtualMemoryMocks

**M√©thodes :**

- `test_warnings_on_misses()`
- `test_avail_old_percent()`
- `test_avail_old_comes_from_kernel()`
- `test_avail_old_missing_fields()`
- `test_avail_old_missing_zoneinfo()`
- `test_virtual_memory_mocked()`

##### TestSystemSwapMemory

**M√©thodes :**

- `meminfo_has_swap_info()`
- `test_total()`
- `test_used()`
- `test_free()`
- `test_missing_sin_sout()`
- `test_no_vmstat_mocked()`
- `test_meminfo_against_sysinfo()`
- `test_emulate_meminfo_has_no_metrics()`

##### TestSystemCPUTimes

**M√©thodes :**

- `test_fields()`

##### TestSystemCPUCountLogical

**M√©thodes :**

- `test_against_sysdev_cpu_online()`
- `test_against_sysdev_cpu_num()`
- `test_against_nproc()`
- `test_against_lscpu()`
- `test_emulate_fallbacks()`

##### TestSystemCPUCountCores

**M√©thodes :**

- `test_against_lscpu()`
- `test_method_2()`
- `test_emulate_none()`

##### TestSystemCPUFrequency

**M√©thodes :**

- `test_emulate_use_second_file()`
- `test_emulate_use_cpuinfo()`
- `test_emulate_data()`
- `test_emulate_multi_cpu()`
- `test_emulate_no_scaling_cur_freq_file()`

##### TestSystemCPUStats

**M√©thodes :**

- `test_interrupts()`

##### TestLoadAvg

**M√©thodes :**

- `test_getloadavg()`

##### TestSystemNetIfAddrs

**M√©thodes :**

- `test_ips()`

##### TestSystemNetIfStats

**M√©thodes :**

- `test_against_ifconfig()`
- `test_mtu()`
- `test_flags()`

##### TestSystemNetIOCounters

**M√©thodes :**

- `test_against_ifconfig()`

##### TestSystemNetConnections

**M√©thodes :**

- `test_emulate_ipv6_unsupported()`
- `test_emulate_unix()`

##### TestSystemDiskPartitions

**M√©thodes :**

- `test_against_df()`
- `test_zfs_fs()`
- `test_emulate_realpath_fail()`

##### TestSystemDiskIoCounters

**M√©thodes :**

- `test_emulate_kernel_2_4()`
- `test_emulate_kernel_2_6_full()`
- `test_emulate_kernel_2_6_limited()`
- `test_emulate_include_partitions()`
- `test_emulate_exclude_partitions()`
- `test_emulate_use_sysfs()`
- `test_emulate_not_impl()`

##### TestRootFsDeviceFinder

**M√©thodes :**

- `setUp()`
- `test_call_methods()`
- `test_comparisons()`
- `test_against_findmnt()`
- `test_disk_partitions_mocked()`

##### TestMisc

**M√©thodes :**

- `test_boot_time()`
- `test_no_procfs_on_import()`
- `test_cpu_steal_decrease()`
- `test_boot_time_mocked()`
- `test_users()`
- `test_procfs_path()`
- `test_issue_687()`
- `test_pid_exists_no_proc_status()`

##### TestSensorsBattery

**M√©thodes :**

- `test_percent()`
- `test_emulate_power_plugged()`
- `test_emulate_power_plugged_2()`
- `test_emulate_power_not_plugged()`
- `test_emulate_power_not_plugged_2()`
- `test_emulate_power_undetermined()`
- `test_emulate_energy_full_0()`
- `test_emulate_energy_full_not_avail()`
- `test_emulate_no_power()`

##### TestSensorsBatteryEmulated

**M√©thodes :**

- `test_it()`

##### TestSensorsTemperatures

**M√©thodes :**

- `test_emulate_class_hwmon()`
- `test_emulate_class_thermal()`

##### TestSensorsFans

**M√©thodes :**

- `test_emulate_data()`

##### TestProcess

**M√©thodes :**

- `test_parse_smaps_vs_memory_maps()`
- `test_parse_smaps_mocked()`
- `test_open_files_mode()`
- `test_open_files_file_gone()`
- `test_open_files_fd_gone()`
- `test_open_files_enametoolong()`
- `test_terminal_mocked()`
- `test_cmdline_mocked()`
- `test_cmdline_spaces_mocked()`
- `test_cmdline_mixed_separators()`
- `test_readlink_path_deleted_mocked()`
- `test_threads_mocked()`
- `test_exe_mocked()`
- `test_issue_1014()`
- `test_issue_2418()`
- `test_rlimit_zombie()`
- `test_stat_file_parsing()`
- `test_status_file_parsing()`
- `test_net_connections_enametoolong()`

##### TestProcessAgainstStatus

/proc/pid/stat and /proc/pid/status have many values in common.
Whenever possible, psutil uses /proc/pid/stat (it's faster).
For all those cases we check that the value found in
/proc/pid/stat (by psutil) matches the one found in
/proc/pid/status.

**M√©thodes :**

- `setUpClass()`
- `read_status_file()`
- `test_name()`
- `test_status()`
- `test_ppid()`
- `test_num_threads()`
- `test_uids()`
- `test_gids()`
- `test_num_ctx_switches()`
- `test_cpu_affinity()`
- `test_cpu_affinity_eligible_cpus()`

##### TestUtils

**M√©thodes :**

- `test_readlink()`

#### Fonctions

##### get_ipv4_address

**Param√®tres :**

- `ifname`

##### get_ipv4_netmask

**Param√®tres :**

- `ifname`

##### get_ipv4_broadcast

**Param√®tres :**

- `ifname`

##### get_ipv6_addresses

**Param√®tres :**

- `ifname`

##### get_mac_address

**Param√®tres :**

- `ifname`

##### free_swap

Parse 'free' cmd and return swap memory's s total, used and free
values.

##### free_physmem

Parse 'free' cmd and return physical memory's total, used
and free values.

##### vmstat

**Param√®tres :**

- `stat`

##### get_free_version_info

##### mock_open_content

Mock open() builtin and forces it to return a certain content
for a given path. `pairs` is a {"path": "content", ...} dict.

**Param√®tres :**

- `pairs`

##### mock_open_exception

Mock open() builtin and raises `exc` if the path being opened
matches `for_path`.

**Param√®tres :**

- `for_path`
- `exc`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### test_total

##### test_used

##### test_free

##### test_shared

##### test_available

##### test_total

##### test_used

##### test_free

##### test_buffers

##### test_active

##### test_inactive

##### test_warnings_on_misses

##### test_avail_old_percent

##### test_avail_old_comes_from_kernel

##### test_avail_old_missing_fields

##### test_avail_old_missing_zoneinfo

##### test_virtual_memory_mocked

##### meminfo_has_swap_info

Return True if /proc/meminfo provides swap metrics.

##### test_total

##### test_used

##### test_free

##### test_missing_sin_sout

##### test_no_vmstat_mocked

##### test_meminfo_against_sysinfo

##### test_emulate_meminfo_has_no_metrics

##### test_fields

##### test_against_sysdev_cpu_online

##### test_against_sysdev_cpu_num

##### test_against_nproc

##### test_against_lscpu

##### test_emulate_fallbacks

##### test_against_lscpu

##### test_method_2

##### test_emulate_none

##### test_emulate_use_second_file

##### test_emulate_use_cpuinfo

##### test_emulate_data

##### test_emulate_multi_cpu

##### test_emulate_no_scaling_cur_freq_file

##### test_interrupts

##### test_getloadavg

##### test_ips

##### test_against_ifconfig

##### test_mtu

##### test_flags

##### test_against_ifconfig

##### test_emulate_ipv6_unsupported

**Param√®tres :**

- `supports_ipv6`
- `inet_ntop`

##### test_emulate_unix

##### test_against_df

##### test_zfs_fs

##### test_emulate_realpath_fail

##### test_emulate_kernel_2_4

##### test_emulate_kernel_2_6_full

##### test_emulate_kernel_2_6_limited

##### test_emulate_include_partitions

##### test_emulate_exclude_partitions

##### test_emulate_use_sysfs

##### test_emulate_not_impl

##### setUp

##### test_call_methods

##### test_comparisons

##### test_against_findmnt

##### test_disk_partitions_mocked

##### test_boot_time

##### test_no_procfs_on_import

##### test_cpu_steal_decrease

##### test_boot_time_mocked

##### test_users

##### test_procfs_path

##### test_issue_687

##### test_pid_exists_no_proc_status

##### test_percent

##### test_emulate_power_plugged

##### test_emulate_power_plugged_2

##### test_emulate_power_not_plugged

##### test_emulate_power_not_plugged_2

##### test_emulate_power_undetermined

##### test_emulate_energy_full_0

##### test_emulate_energy_full_not_avail

##### test_emulate_no_power

##### test_it

##### test_emulate_class_hwmon

##### test_emulate_class_thermal

##### test_emulate_data

##### test_parse_smaps_vs_memory_maps

##### test_parse_smaps_mocked

##### test_open_files_mode

##### test_open_files_file_gone

##### test_open_files_fd_gone

##### test_open_files_enametoolong

##### test_terminal_mocked

##### test_cmdline_mocked

##### test_cmdline_spaces_mocked

##### test_cmdline_mixed_separators

##### test_readlink_path_deleted_mocked

##### test_threads_mocked

##### test_exe_mocked

##### test_issue_1014

##### test_issue_2418

##### test_rlimit_zombie

##### test_stat_file_parsing

##### test_status_file_parsing

##### test_net_connections_enametoolong

##### setUpClass

**Param√®tres :**

- `cls`

##### read_status_file

**Param√®tres :**

- `linestart`

##### test_name

##### test_status

##### test_ppid

##### test_num_threads

##### test_uids

##### test_gids

##### test_num_ctx_switches

##### test_cpu_affinity

##### test_cpu_affinity_eligible_cpus

##### test_readlink

##### path_exists_mock

**Param√®tres :**

- `path`

##### path_exists_mock

**Param√®tres :**

- `path`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### ifconfig

**Param√®tres :**

- `nic`

##### df

**Param√®tres :**

- `path`

##### is_storage_device

**Param√®tres :**

- `name`

##### exists

**Param√®tres :**

- `path`

##### exists

**Param√®tres :**

- `path`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

##### glob_mock

**Param√®tres :**

- `path`

##### open_mock

**Param√®tres :**

- `name`

##### get_test_file

**Param√®tres :**

- `fname`

##### open_mock_1

**Param√®tres :**

- `name`

##### open_mock_2

**Param√®tres :**

- `name`

##### open_mock

**Param√®tres :**

- `name`

---

### test_sunos

Sun OS specific tests.

#### Classes

##### SunOSSpecificTestCase

**M√©thodes :**

- `test_swap_memory()`
- `test_cpu_count()`

#### Fonctions

##### test_swap_memory

##### test_cpu_count

---

### test_aix

AIX specific tests.

#### Classes

##### AIXSpecificTestCase

**M√©thodes :**

- `test_virtual_memory()`
- `test_swap_memory()`
- `test_cpu_stats()`
- `test_cpu_count_logical()`
- `test_net_if_addrs_names()`

#### Fonctions

##### test_virtual_memory

##### test_swap_memory

##### test_cpu_stats

##### test_cpu_count_logical

##### test_net_if_addrs_names

---

### test_process_all

Iterate over all process PIDs and for each one of them invoke and
test all psutil.Process() methods.

#### Classes

##### TestFetchAllProcesses

Test which iterates over all running processes and performs
some sanity checks against Process API's returned values.
Uses a process pool to get info about all processes.

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `iter_proc_info()`
- `test_all()`
- `cmdline()`
- `exe()`
- `pid()`
- `ppid()`
- `name()`
- `create_time()`
- `uids()`
- `gids()`
- `username()`
- `status()`
- `io_counters()`
- `ionice()`
- `num_threads()`
- `threads()`
- `cpu_times()`
- `cpu_percent()`
- `cpu_num()`
- `memory_info()`
- `memory_full_info()`
- `open_files()`
- `num_fds()`
- `net_connections()`
- `cwd()`
- `memory_percent()`
- `is_running()`
- `cpu_affinity()`
- `terminal()`
- `memory_maps()`
- `num_handles()`
- `nice()`
- `num_ctx_switches()`
- `rlimit()`
- `environ()`

##### TestPidsRange

Given pid_exists() return value for a range of PIDs which may or
may not exist, make sure that psutil.Process() and psutil.pids()
agree with pid_exists(). This guarantees that the 3 APIs are all
consistent with each other. See:
https://github.com/giampaolo/psutil/issues/2359

XXX - Note about Windows: it turns out there are some "hidden" PIDs
which are not returned by psutil.pids() and are also not revealed
by taskmgr.exe and ProcessHacker, still they can be instantiated by
psutil.Process() and queried. One of such PIDs is "conhost.exe".
Running as_dict() for it reveals that some Process() APIs
erroneously raise NoSuchProcess, so we know we have problem there.
Let's ignore this for now, since it's quite a corner case (who even
imagined hidden PIDs existed on Windows?).

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `test_it()`

#### Fonctions

##### proc_info

**Param√®tres :**

- `pid`

##### check_exception

**Param√®tres :**

- `exc`
- `proc`
- `name`
- `ppid`

##### do_wait

##### setUp

##### tearDown

##### iter_proc_info

##### test_all

##### cmdline

**Param√®tres :**

- `ret`
- `info`

##### exe

**Param√®tres :**

- `ret`
- `info`

##### pid

**Param√®tres :**

- `ret`
- `info`

##### ppid

**Param√®tres :**

- `ret`
- `info`

##### name

**Param√®tres :**

- `ret`
- `info`

##### create_time

**Param√®tres :**

- `ret`
- `info`

##### uids

**Param√®tres :**

- `ret`
- `info`

##### gids

**Param√®tres :**

- `ret`
- `info`

##### username

**Param√®tres :**

- `ret`
- `info`

##### status

**Param√®tres :**

- `ret`
- `info`

##### io_counters

**Param√®tres :**

- `ret`
- `info`

##### ionice

**Param√®tres :**

- `ret`
- `info`

##### num_threads

**Param√®tres :**

- `ret`
- `info`

##### threads

**Param√®tres :**

- `ret`
- `info`

##### cpu_times

**Param√®tres :**

- `ret`
- `info`

##### cpu_percent

**Param√®tres :**

- `ret`
- `info`

##### cpu_num

**Param√®tres :**

- `ret`
- `info`

##### memory_info

**Param√®tres :**

- `ret`
- `info`

##### memory_full_info

**Param√®tres :**

- `ret`
- `info`

##### open_files

**Param√®tres :**

- `ret`
- `info`

##### num_fds

**Param√®tres :**

- `ret`
- `info`

##### net_connections

**Param√®tres :**

- `ret`
- `info`

##### cwd

**Param√®tres :**

- `ret`
- `info`

##### memory_percent

**Param√®tres :**

- `ret`
- `info`

##### is_running

**Param√®tres :**

- `ret`
- `info`

##### cpu_affinity

**Param√®tres :**

- `ret`
- `info`

##### terminal

**Param√®tres :**

- `ret`
- `info`

##### memory_maps

**Param√®tres :**

- `ret`
- `info`

##### num_handles

**Param√®tres :**

- `ret`
- `info`

##### nice

**Param√®tres :**

- `ret`
- `info`

##### num_ctx_switches

**Param√®tres :**

- `ret`
- `info`

##### rlimit

**Param√®tres :**

- `ret`
- `info`

##### environ

**Param√®tres :**

- `ret`
- `info`

##### setUp

##### tearDown

##### test_it

##### is_linux_tid

**Param√®tres :**

- `pid`

##### check

**Param√®tres :**

- `pid`

---

### test_process

Tests for psutil.Process class.

#### Classes

##### TestProcess

Tests for psutil.Process class.

**M√©thodes :**

- `spawn_psproc()`
- `test_pid()`
- `test_kill()`
- `test_terminate()`
- `test_send_signal()`
- `test_send_signal_mocked()`
- `test_wait_exited()`
- `test_wait_stopped()`
- `test_wait_non_children()`
- `test_wait_timeout()`
- `test_wait_timeout_nonblocking()`
- `test_cpu_percent()`
- `test_cpu_percent_numcpus_none()`
- `test_cpu_times()`
- `test_cpu_times_2()`
- `test_cpu_num()`
- `test_create_time()`
- `test_terminal()`
- `test_io_counters()`
- `test_ionice_linux()`
- `test_ionice_win()`
- `test_rlimit_get()`
- `test_rlimit_set()`
- `test_rlimit()`
- `test_rlimit_infinity()`
- `test_rlimit_infinity_value()`
- `test_num_threads()`
- `test_num_handles()`
- `test_threads()`
- `test_threads_2()`
- `test_memory_info()`
- `test_memory_full_info()`
- `test_memory_maps()`
- `test_memory_maps_lists_lib()`
- `test_memory_percent()`
- `test_is_running()`
- `test_exe()`
- `test_cmdline()`
- `test_long_cmdline()`
- `test_name()`
- `test_long_name()`
- `test_uids()`
- `test_gids()`
- `test_nice()`
- `test_status()`
- `test_username()`
- `test_cwd()`
- `test_cwd_2()`
- `test_cpu_affinity()`
- `test_cpu_affinity_errs()`
- `test_cpu_affinity_all_combinations()`
- `test_open_files()`
- `test_open_files_2()`
- `test_num_fds()`
- `test_num_ctx_switches()`
- `test_ppid()`
- `test_parent()`
- `test_parent_multi()`
- `test_parents()`
- `test_children()`
- `test_children_recursive()`
- `test_children_duplicates()`
- `test_parents_and_children()`
- `test_suspend_resume()`
- `test_invalid_pid()`
- `test_as_dict()`
- `test_oneshot()`
- `test_oneshot_twice()`
- `test_oneshot_cache()`
- `test_halfway_terminated_process()`
- `test_zombie_process()`
- `test_zombie_process_is_running_w_exc()`
- `test_zombie_process_status_w_exc()`
- `test_reused_pid()`
- `test_pid_0()`
- `test_environ()`
- `test_weird_environ()`

##### TestPopen

Tests for psutil.Popen class.

**M√©thodes :**

- `tearDownClass()`
- `test_misc()`
- `test_ctx_manager()`
- `test_kill_terminate()`
- `test__getattribute__()`

#### Fonctions

##### spawn_psproc

##### test_pid

##### test_kill

##### test_terminate

##### test_send_signal

##### test_send_signal_mocked

##### test_wait_exited

##### test_wait_stopped

##### test_wait_non_children

##### test_wait_timeout

##### test_wait_timeout_nonblocking

##### test_cpu_percent

##### test_cpu_percent_numcpus_none

##### test_cpu_times

##### test_cpu_times_2

##### test_cpu_num

##### test_create_time

##### test_terminal

##### test_io_counters

##### test_ionice_linux

##### test_ionice_win

##### test_rlimit_get

##### test_rlimit_set

##### test_rlimit

##### test_rlimit_infinity

##### test_rlimit_infinity_value

##### test_num_threads

##### test_num_handles

##### test_threads

##### test_threads_2

##### test_memory_info

##### test_memory_full_info

##### test_memory_maps

##### test_memory_maps_lists_lib

##### test_memory_percent

##### test_is_running

##### test_exe

##### test_cmdline

##### test_long_cmdline

##### test_name

##### test_long_name

##### test_uids

##### test_gids

##### test_nice

##### test_status

##### test_username

##### test_cwd

##### test_cwd_2

##### test_cpu_affinity

##### test_cpu_affinity_errs

##### test_cpu_affinity_all_combinations

##### test_open_files

##### test_open_files_2

##### test_num_fds

##### test_num_ctx_switches

##### test_ppid

##### test_parent

##### test_parent_multi

##### test_parents

##### test_children

##### test_children_recursive

##### test_children_duplicates

##### test_parents_and_children

##### test_suspend_resume

##### test_invalid_pid

##### test_as_dict

##### test_oneshot

##### test_oneshot_twice

##### test_oneshot_cache

##### test_halfway_terminated_process

##### test_zombie_process

##### test_zombie_process_is_running_w_exc

##### test_zombie_process_status_w_exc

##### test_reused_pid

##### test_pid_0

##### test_environ

##### test_weird_environ

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_misc

##### test_ctx_manager

##### test_kill_terminate

##### test__getattribute__

##### waste_cpu

##### cleanup

**Param√®tres :**

- `init`

##### cleanup

**Param√®tres :**

- `init`

##### assert_raises_nsp

**Param√®tres :**

- `fun`
- `fun_name`

##### clean_dict

**Param√®tres :**

- `d`

##### normpath

**Param√®tres :**

- `p`

---

### test_bsd

Tests specific to all BSD platforms.

#### Classes

##### BSDTestCase

Generic tests common to all BSD variants.

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `test_process_create_time()`
- `test_disks()`
- `test_cpu_count_logical()`
- `test_virtual_memory_total()`
- `test_net_if_stats()`

##### FreeBSDPsutilTestCase

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `test_memory_maps()`
- `test_exe()`
- `test_cmdline()`
- `test_uids_gids()`
- `test_ctx_switches()`
- `test_cpu_times()`

##### FreeBSDSystemTestCase

**M√©thodes :**

- `parse_swapinfo()`
- `test_cpu_frequency_against_sysctl()`
- `test_vmem_active()`
- `test_vmem_inactive()`
- `test_vmem_wired()`
- `test_vmem_cached()`
- `test_vmem_free()`
- `test_vmem_buffers()`
- `test_muse_vmem_total()`
- `test_muse_vmem_active()`
- `test_muse_vmem_inactive()`
- `test_muse_vmem_wired()`
- `test_muse_vmem_cached()`
- `test_muse_vmem_free()`
- `test_muse_vmem_buffers()`
- `test_cpu_stats_ctx_switches()`
- `test_cpu_stats_interrupts()`
- `test_cpu_stats_soft_interrupts()`
- `test_cpu_stats_syscalls()`
- `test_swapmem_free()`
- `test_swapmem_used()`
- `test_swapmem_total()`
- `test_boot_time()`
- `test_sensors_battery()`
- `test_sensors_battery_against_sysctl()`
- `test_sensors_battery_no_battery()`
- `test_sensors_temperatures_against_sysctl()`

##### OpenBSDTestCase

**M√©thodes :**

- `test_boot_time()`

##### NetBSDTestCase

**M√©thodes :**

- `parse_meminfo()`
- `test_vmem_total()`
- `test_vmem_free()`
- `test_vmem_buffers()`
- `test_vmem_shared()`
- `test_vmem_cached()`
- `test_swapmem_total()`
- `test_swapmem_free()`
- `test_swapmem_used()`
- `test_cpu_stats_interrupts()`
- `test_cpu_stats_ctx_switches()`

#### Fonctions

##### sysctl

Expects a sysctl command with an argument and parse the result
returning only the value of interest.

**Param√®tres :**

- `cmdline`

##### muse

Thin wrapper around 'muse' cmdline utility.

**Param√®tres :**

- `field`

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_process_create_time

##### test_disks

##### test_cpu_count_logical

##### test_virtual_memory_total

##### test_net_if_stats

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_memory_maps

##### test_exe

##### test_cmdline

##### test_uids_gids

##### test_ctx_switches

##### test_cpu_times

##### parse_swapinfo

##### test_cpu_frequency_against_sysctl

##### test_vmem_active

##### test_vmem_inactive

##### test_vmem_wired

##### test_vmem_cached

##### test_vmem_free

##### test_vmem_buffers

##### test_muse_vmem_total

##### test_muse_vmem_active

##### test_muse_vmem_inactive

##### test_muse_vmem_wired

##### test_muse_vmem_cached

##### test_muse_vmem_free

##### test_muse_vmem_buffers

##### test_cpu_stats_ctx_switches

##### test_cpu_stats_interrupts

##### test_cpu_stats_soft_interrupts

##### test_cpu_stats_syscalls

##### test_swapmem_free

##### test_swapmem_used

##### test_swapmem_total

##### test_boot_time

##### test_sensors_battery

##### test_sensors_battery_against_sysctl

##### test_sensors_battery_no_battery

##### test_sensors_temperatures_against_sysctl

##### test_boot_time

##### parse_meminfo

**Param√®tres :**

- `look_for`

##### test_vmem_total

##### test_vmem_free

##### test_vmem_buffers

##### test_vmem_shared

##### test_vmem_cached

##### test_swapmem_total

##### test_swapmem_free

##### test_swapmem_used

##### test_cpu_stats_interrupts

##### test_cpu_stats_ctx_switches

##### df

**Param√®tres :**

- `path`

##### secs2hours

**Param√®tres :**

- `secs`

---

### test_system

Tests for system APIS.

#### Classes

##### TestProcessIter

**M√©thodes :**

- `test_pid_presence()`
- `test_no_duplicates()`
- `test_emulate_nsp()`
- `test_emulate_access_denied()`
- `test_attrs()`
- `test_cache_clear()`

##### TestProcessAPIs

**M√©thodes :**

- `test_wait_procs()`
- `test_wait_procs_no_timeout()`
- `test_pid_exists()`
- `test_pid_exists_2()`

##### TestMiscAPIs

**M√©thodes :**

- `test_boot_time()`
- `test_users()`
- `test_os_constants()`

##### TestMemoryAPIs

**M√©thodes :**

- `test_virtual_memory()`
- `test_swap_memory()`

##### TestCpuAPIs

**M√©thodes :**

- `test_cpu_count_logical()`
- `test_cpu_count_cores()`
- `test_cpu_count_none()`
- `test_cpu_times()`
- `test_cpu_times_time_increases()`
- `test_per_cpu_times()`
- `test_per_cpu_times_2()`
- `test_cpu_times_comparison()`
- `_test_cpu_percent()`
- `test_cpu_percent()`
- `test_per_cpu_percent()`
- `test_cpu_times_percent()`
- `test_per_cpu_times_percent()`
- `test_per_cpu_times_percent_negative()`
- `test_cpu_stats()`
- `test_cpu_freq()`
- `test_getloadavg()`

##### TestDiskAPIs

**M√©thodes :**

- `test_disk_usage()`
- `test_disk_usage_unicode()`
- `test_disk_usage_bytes()`
- `test_disk_partitions()`
- `test_disk_io_counters()`
- `test_disk_io_counters_no_disks()`

##### TestNetAPIs

**M√©thodes :**

- `test_net_io_counters()`
- `test_net_io_counters_no_nics()`
- `test_net_if_addrs()`
- `test_net_if_addrs_mac_null_bytes()`
- `test_net_if_stats()`
- `test_net_if_stats_enodev()`

##### TestSensorsAPIs

**M√©thodes :**

- `test_sensors_temperatures()`
- `test_sensors_temperatures_fahreneit()`
- `test_sensors_battery()`
- `test_sensors_fans()`

#### Fonctions

##### test_pid_presence

##### test_no_duplicates

##### test_emulate_nsp

##### test_emulate_access_denied

##### test_attrs

##### test_cache_clear

##### test_wait_procs

##### test_wait_procs_no_timeout

##### test_pid_exists

##### test_pid_exists_2

##### test_boot_time

##### test_users

##### test_os_constants

##### test_virtual_memory

##### test_swap_memory

##### test_cpu_count_logical

##### test_cpu_count_cores

##### test_cpu_count_none

##### test_cpu_times

##### test_cpu_times_time_increases

##### test_per_cpu_times

##### test_per_cpu_times_2

##### test_cpu_times_comparison

##### _test_cpu_percent

**Param√®tres :**

- `percent`
- `last_ret`
- `new_ret`

##### test_cpu_percent

##### test_per_cpu_percent

##### test_cpu_times_percent

##### test_per_cpu_times_percent

##### test_per_cpu_times_percent_negative

##### test_cpu_stats

##### test_cpu_freq

##### test_getloadavg

##### test_disk_usage

##### test_disk_usage_unicode

##### test_disk_usage_bytes

##### test_disk_partitions

##### test_disk_io_counters

##### test_disk_io_counters_no_disks

##### test_net_io_counters

##### test_net_io_counters_no_nics

##### test_net_if_addrs

##### test_net_if_addrs_mac_null_bytes

##### test_net_if_stats

##### test_net_if_stats_enodev

##### test_sensors_temperatures

##### test_sensors_temperatures_fahreneit

##### test_sensors_battery

##### test_sensors_fans

##### callback

**Param√®tres :**

- `p`

##### test_1

**Param√®tres :**

- `procs`
- `callback`

##### test_2

**Param√®tres :**

- `procs`
- `callback`

##### check_ls

**Param√®tres :**

- `ls`

##### check_ntuple

**Param√®tres :**

- `nt`

##### find_mount_point

**Param√®tres :**

- `path`

##### check_ntuple

**Param√®tres :**

- `nt`

##### check_ntuple

**Param√®tres :**

- `nt`

---

### test_osx

macOS specific tests.

#### Classes

##### TestProcess

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `test_process_create_time()`

##### TestSystemAPIs

**M√©thodes :**

- `test_disks()`
- `test_cpu_count_logical()`
- `test_cpu_count_cores()`
- `test_cpu_freq()`
- `test_vmem_total()`
- `test_vmem_free()`
- `test_vmem_active()`
- `test_vmem_inactive()`
- `test_vmem_wired()`
- `test_swapmem_sin()`
- `test_swapmem_sout()`
- `test_net_if_stats()`
- `test_sensors_battery()`

#### Fonctions

##### sysctl

Expects a sysctl command with an argument and parse the result
returning only the value of interest.

**Param√®tres :**

- `cmdline`

##### vm_stat

Wrapper around 'vm_stat' cmdline utility.

**Param√®tres :**

- `field`

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_process_create_time

##### test_disks

##### test_cpu_count_logical

##### test_cpu_count_cores

##### test_cpu_freq

##### test_vmem_total

##### test_vmem_free

##### test_vmem_active

##### test_vmem_inactive

##### test_vmem_wired

##### test_swapmem_sin

##### test_swapmem_sout

##### test_net_if_stats

##### test_sensors_battery

##### df

**Param√®tres :**

- `path`

---

### test_memleaks

Tests for detecting function memory leaks (typically the ones
implemented in C). It does so by calling a function many times and
checking whether process memory usage keeps increasing between
calls or over time.
Note that this may produce false positives (especially on Windows
for some reason).
PyPy appears to be completely unstable for this framework, probably
because of how its JIT handles memory, so tests are skipped.

#### Classes

##### TestProcessObjectLeaks

Test leaks of Process class methods.

**M√©thodes :**

- `test_coverage()`
- `test_name()`
- `test_cmdline()`
- `test_exe()`
- `test_ppid()`
- `test_uids()`
- `test_gids()`
- `test_status()`
- `test_nice()`
- `test_nice_set()`
- `test_ionice()`
- `test_ionice_set()`
- `test_io_counters()`
- `test_username()`
- `test_create_time()`
- `test_num_threads()`
- `test_num_handles()`
- `test_num_fds()`
- `test_num_ctx_switches()`
- `test_threads()`
- `test_cpu_times()`
- `test_cpu_num()`
- `test_memory_info()`
- `test_memory_full_info()`
- `test_terminal()`
- `test_resume()`
- `test_cwd()`
- `test_cpu_affinity()`
- `test_cpu_affinity_set()`
- `test_open_files()`
- `test_memory_maps()`
- `test_rlimit()`
- `test_rlimit_set()`
- `test_net_connections()`
- `test_environ()`
- `test_proc_info()`

##### TestTerminatedProcessLeaks

Repeat the tests above looking for leaks occurring when dealing
with terminated processes raising NoSuchProcess exception.
The C functions are still invoked but will follow different code
paths. We'll check those code paths.

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `call()`

##### TestProcessDualImplementation

**M√©thodes :**

- `test_cmdline_peb_true()`
- `test_cmdline_peb_false()`

##### TestModuleFunctionsLeaks

Test leaks of psutil module functions.

**M√©thodes :**

- `test_coverage()`
- `test_cpu_count()`
- `test_cpu_count_cores()`
- `test_cpu_times()`
- `test_per_cpu_times()`
- `test_cpu_stats()`
- `test_cpu_freq()`
- `test_getloadavg()`
- `test_virtual_memory()`
- `test_swap_memory()`
- `test_pid_exists()`
- `test_disk_usage()`
- `test_disk_partitions()`
- `test_disk_io_counters()`
- `test_pids()`
- `test_net_io_counters()`
- `test_net_connections()`
- `test_net_if_addrs()`
- `test_net_if_stats()`
- `test_sensors_battery()`
- `test_sensors_temperatures()`
- `test_sensors_fans()`
- `test_boot_time()`
- `test_users()`
- `test_set_debug()`

#### Fonctions

##### fewtimes_if_linux

Decorator for those Linux functions which are implemented in pure
Python, and which we want to run faster.

##### decorator

**Param√®tres :**

- `fun`

##### test_coverage

##### test_name

##### test_cmdline

##### test_exe

##### test_ppid

##### test_uids

##### test_gids

##### test_status

##### test_nice

##### test_nice_set

##### test_ionice

##### test_ionice_set

##### test_io_counters

##### test_username

##### test_create_time

##### test_num_threads

##### test_num_handles

##### test_num_fds

##### test_num_ctx_switches

##### test_threads

##### test_cpu_times

##### test_cpu_num

##### test_memory_info

##### test_memory_full_info

##### test_terminal

##### test_resume

##### test_cwd

##### test_cpu_affinity

##### test_cpu_affinity_set

##### test_open_files

##### test_memory_maps

##### test_rlimit

##### test_rlimit_set

##### test_net_connections

##### test_environ

##### test_proc_info

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### call

**Param√®tres :**

- `fun`

##### test_cmdline_peb_true

##### test_cmdline_peb_false

##### test_coverage

##### test_cpu_count

##### test_cpu_count_cores

##### test_cpu_times

##### test_per_cpu_times

##### test_cpu_stats

##### test_cpu_freq

##### test_getloadavg

##### test_virtual_memory

##### test_swap_memory

##### test_pid_exists

##### test_disk_usage

##### test_disk_partitions

##### test_disk_io_counters

##### test_pids

##### test_net_io_counters

##### test_net_connections

##### test_net_if_addrs

##### test_net_if_stats

##### test_sensors_battery

##### test_sensors_temperatures

##### test_sensors_fans

##### test_boot_time

##### test_users

##### test_set_debug

##### wrapper

##### test_kill

##### test_terminate

##### test_suspend

##### test_resume

##### test_wait

##### test_proc_info

##### test_win_service_iter

##### test_win_service_get

##### test_win_service_get_config

##### test_win_service_get_status

##### test_win_service_get_description

##### call

---

### test_windows

Windows specific tests.

#### Classes

##### WindowsTestCase

##### TestCpuAPIs

**M√©thodes :**

- `test_cpu_count_vs_NUMBER_OF_PROCESSORS()`
- `test_cpu_count_vs_GetSystemInfo()`
- `test_cpu_count_logical_vs_wmi()`
- `test_cpu_count_cores_vs_wmi()`
- `test_cpu_count_vs_cpu_times()`
- `test_cpu_freq()`

##### TestSystemAPIs

**M√©thodes :**

- `test_nic_names()`
- `test_total_phymem()`
- `test_free_phymem()`
- `test_total_swapmem()`
- `test_percent_swapmem()`
- `test_pids()`
- `test_disks()`
- `test_disk_usage()`
- `test_disk_partitions()`
- `test_net_if_stats()`
- `test_boot_time()`
- `test_boot_time_fluctuation()`

##### TestSensorsBattery

**M√©thodes :**

- `test_has_battery()`
- `test_percent()`
- `test_power_plugged()`
- `test_emulate_no_battery()`
- `test_emulate_power_connected()`
- `test_emulate_power_charging()`
- `test_emulate_secs_left_unknown()`

##### TestProcess

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `test_issue_24()`
- `test_special_pid()`
- `test_send_signal()`
- `test_num_handles_increment()`
- `test_ctrl_signals()`
- `test_username()`
- `test_cmdline()`
- `test_nice()`
- `test_memory_info()`
- `test_wait()`
- `test_cpu_affinity()`
- `test_io_counters()`
- `test_num_handles()`
- `test_error_partial_copy()`
- `test_exe()`

##### TestProcessWMI

Compare Process API results with WMI.

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `test_name()`
- `test_exe()`
- `test_cmdline()`
- `test_username()`
- `test_memory_rss()`
- `test_memory_vms()`
- `test_create_time()`

##### TestDualProcessImplementation

Certain APIs on Windows have 2 internal implementations, one
based on documented Windows APIs, another one based
NtQuerySystemInformation() which gets called as fallback in
case the first fails because of limited permission error.
Here we test that the two methods return the exact same value,
see:
https://github.com/giampaolo/psutil/issues/304.

**M√©thodes :**

- `setUpClass()`
- `tearDownClass()`
- `test_memory_info()`
- `test_create_time()`
- `test_cpu_times()`
- `test_io_counters()`
- `test_num_handles()`
- `test_cmdline()`

##### RemoteProcessTestCase

Certain functions require calling ReadProcessMemory.
This trivially works when called on the current process.
Check that this works on other processes, especially when they
have a different bitness.

**M√©thodes :**

- `find_other_interpreter()`
- `setUp()`
- `tearDown()`
- `test_cmdline_32()`
- `test_cmdline_64()`
- `test_cwd_32()`
- `test_cwd_64()`
- `test_environ_32()`
- `test_environ_64()`

##### TestServices

**M√©thodes :**

- `test_win_service_iter()`
- `test_win_service_get()`

#### Fonctions

##### powershell

Currently not used, but available just in case. Usage:

>>> powershell(
    "Get-CIMInstance Win32_PageFileUsage | Select AllocatedBaseSize")

**Param√®tres :**

- `cmd`

##### wmic

Currently not used, but available just in case. Usage:

>>> wmic("Win32_OperatingSystem", "FreePhysicalMemory")
2134124534

**Param√®tres :**

- `path`
- `what`
- `converter`

##### test_cpu_count_vs_NUMBER_OF_PROCESSORS

##### test_cpu_count_vs_GetSystemInfo

##### test_cpu_count_logical_vs_wmi

##### test_cpu_count_cores_vs_wmi

##### test_cpu_count_vs_cpu_times

##### test_cpu_freq

##### test_nic_names

##### test_total_phymem

##### test_free_phymem

##### test_total_swapmem

##### test_percent_swapmem

##### test_pids

##### test_disks

##### test_disk_usage

##### test_disk_partitions

##### test_net_if_stats

##### test_boot_time

##### test_boot_time_fluctuation

##### test_has_battery

##### test_percent

##### test_power_plugged

##### test_emulate_no_battery

##### test_emulate_power_connected

##### test_emulate_power_charging

##### test_emulate_secs_left_unknown

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_issue_24

##### test_special_pid

##### test_send_signal

##### test_num_handles_increment

##### test_ctrl_signals

##### test_username

##### test_cmdline

##### test_nice

##### test_memory_info

##### test_wait

##### test_cpu_affinity

##### test_io_counters

##### test_num_handles

##### test_error_partial_copy

##### test_exe

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_name

##### test_exe

##### test_cmdline

##### test_username

##### test_memory_rss

##### test_memory_vms

##### test_create_time

##### setUpClass

**Param√®tres :**

- `cls`

##### tearDownClass

**Param√®tres :**

- `cls`

##### test_memory_info

##### test_create_time

##### test_cpu_times

##### test_io_counters

##### test_num_handles

##### test_cmdline

##### find_other_interpreter

##### setUp

##### tearDown

##### test_cmdline_32

##### test_cmdline_64

##### test_cwd_32

##### test_cwd_64

##### test_environ_32

##### test_environ_64

##### test_win_service_iter

##### test_win_service_get

##### from_bitmask

**Param√®tres :**

- `x`

---

### test_scripts

Test various scripts.

#### Classes

##### TestExampleScripts

**M√©thodes :**

- `assert_stdout()`
- `assert_syntax()`
- `test_coverage()`
- `test_executable()`
- `test_disk_usage()`
- `test_free()`
- `test_meminfo()`
- `test_procinfo()`
- `test_who()`
- `test_ps()`
- `test_pstree()`
- `test_netstat()`
- `test_ifconfig()`
- `test_pmap()`
- `test_procsmem()`
- `test_killall()`
- `test_nettop()`
- `test_top()`
- `test_iotop()`
- `test_pidof()`
- `test_winservices()`
- `test_cpu_distribution()`
- `test_temperatures()`
- `test_fans()`
- `test_battery()`
- `test_sensors()`

##### TestInternalScripts

**M√©thodes :**

- `ls()`
- `test_syntax_all()`
- `test_import_all()`

##### TestSetupScript

**M√©thodes :**

- `test_invocation()`
- `test_python2()`

#### Fonctions

##### assert_stdout

**Param√®tres :**

- `exe`

##### assert_syntax

**Param√®tres :**

- `exe`

##### test_coverage

##### test_executable

##### test_disk_usage

##### test_free

##### test_meminfo

##### test_procinfo

##### test_who

##### test_ps

##### test_pstree

##### test_netstat

##### test_ifconfig

##### test_pmap

##### test_procsmem

##### test_killall

##### test_nettop

##### test_top

##### test_iotop

##### test_pidof

##### test_winservices

##### test_cpu_distribution

##### test_temperatures

##### test_fans

##### test_battery

##### test_sensors

##### ls

##### test_syntax_all

##### test_import_all

##### test_invocation

##### test_python2

---

### __main__

Run unit tests. This is invoked by:
$ python -m psutil.tests.

---

### test_testutils

Tests for testing utils (psutil.tests namespace).

#### Classes

##### TestRetryDecorator

**M√©thodes :**

- `test_retry_success()`
- `test_retry_failure()`
- `test_exception_arg()`
- `test_no_interval_arg()`
- `test_retries_arg()`
- `test_retries_and_timeout_args()`

##### TestSyncTestUtils

**M√©thodes :**

- `test_wait_for_pid()`
- `test_wait_for_file()`
- `test_wait_for_file_empty()`
- `test_wait_for_file_no_file()`
- `test_wait_for_file_no_delete()`
- `test_call_until()`

##### TestFSTestUtils

**M√©thodes :**

- `test_open_text()`
- `test_open_binary()`
- `test_safe_mkdir()`
- `test_safe_rmpath()`
- `test_chdir()`

##### TestProcessUtils

**M√©thodes :**

- `test_reap_children()`
- `test_spawn_children_pair()`
- `test_spawn_zombie()`
- `test_terminate()`

##### TestNetUtils

**M√©thodes :**

- `bind_socket()`
- `test_bind_unix_socket()`
- `test_tcp_socketpair()`
- `test_unix_socketpair()`
- `test_create_sockets()`

##### TestMemLeakClass

**M√©thodes :**

- `test_times()`
- `test_param_err()`
- `test_leak_mem()`
- `test_unclosed_files()`
- `test_tolerance()`
- `test_execute_w_exc()`

##### TestFakePytest

**M√©thodes :**

- `run_test_class()`
- `test_raises()`
- `test_mark()`
- `test_skipif()`
- `test_skip()`
- `test_main()`
- `test_warns()`

##### TestTestingUtils

**M√©thodes :**

- `test_process_namespace()`
- `test_system_namespace()`

##### TestOtherUtils

**M√©thodes :**

- `test_is_namedtuple()`

##### Foo

**M√©thodes :**

- `bar()`

##### TestCase

**M√©thodes :**

- `foo()`

##### TestCase

**M√©thodes :**

- `foo()`

##### TestCase

**M√©thodes :**

- `foo()`

#### Fonctions

##### test_retry_success

**Param√®tres :**

- `sleep`

##### test_retry_failure

**Param√®tres :**

- `sleep`

##### test_exception_arg

**Param√®tres :**

- `sleep`

##### test_no_interval_arg

**Param√®tres :**

- `sleep`

##### test_retries_arg

**Param√®tres :**

- `sleep`

##### test_retries_and_timeout_args

**Param√®tres :**

- `sleep`

##### test_wait_for_pid

##### test_wait_for_file

##### test_wait_for_file_empty

##### test_wait_for_file_no_file

##### test_wait_for_file_no_delete

##### test_call_until

##### test_open_text

##### test_open_binary

##### test_safe_mkdir

##### test_safe_rmpath

##### test_chdir

##### test_reap_children

##### test_spawn_children_pair

##### test_spawn_zombie

##### test_terminate

##### bind_socket

##### test_bind_unix_socket

##### test_tcp_socketpair

##### test_unix_socketpair

##### test_create_sockets

##### test_times

##### test_param_err

##### test_leak_mem

##### test_unclosed_files

##### test_tolerance

##### test_execute_w_exc

##### run_test_class

**Param√®tres :**

- `klass`

##### test_raises

##### test_mark

##### test_skipif

##### test_skip

##### test_main

##### test_warns

##### test_process_namespace

##### test_system_namespace

##### test_is_namedtuple

##### foo

##### foo

##### foo

##### foo

##### foo

##### fun

##### fun

**Param√®tres :**

- `ls`

##### fun

##### fun

##### fun_1

##### fun_2

##### foo

##### bar

##### foo

##### foo

##### foo

---

### .!21463!test_contracts

---

### .!21467!test_connections

---

### .!21473!test_unicode

---

### .!21478!test_misc

---

### .!21484!test_posix

---

### .!21488!test_linux

---

### .!21494!test_sunos

---

### .!21500!__init__

---

### .!21505!test_aix

---

### .!21509!test_process_all

---

### .!21515!test_process

---

### .!21520!test_bsd

---

### .!21526!test_system

---

### .!21532!test_osx

---

### .!21534!test_memleaks

---

### .!21542!test_windows

---

### .!21545!test_scripts

---

### .!21551!__main__

---

### .!21555!test_testutils

---

### .!21572!_imp

---

### .!21621!dist

---

### .!21638!glob

---

### .!21659!msvc

---

### .!21561!__init__

---

### .!21564!_deprecation_warning

---

### .!21569!_entry_points

---

### .!21577!_importlib

---

### .!21583!_itertools

---

### .!21587!_path

---

### .!21594!_reqs

---

### .!21599!archive_util

---

### .!21602!build_meta

---

### .!21608!dep_util

---

### .!21612!depends

---

### .!21615!discovery

---

### .!21624!extension

---

### .!21630!errors

---

### .!21633!installer

---

### .!21643!launch

---

### .!21645!logging

---

### .!21650!monkey

---

### .!21654!namespaces

---

### .!21666!package_index

---

### .!21671!py34compat

---

### .!21674!sandbox

---

### .!21679!unicode_utils

---

### .!21684!version

---

### .!21690!wheel

---

### .!21694!windows_support

---

### .!21736!cmd

---

### .!21745!core

---

### .!21770!dist

---

### .!21797!log

---

### .!21841!util

---

### .!21700!__init__

---

### .!21703!_collections

---

### .!21708!_functools

---

### .!21712!_macos_compat

---

### .!21718!_msvccompiler

---

### .!21721!archive_util

---

### .!21727!bcppcompiler

---

### .!21732!ccompiler

---

### .!21740!config

---

### .!21750!cygwinccompiler

---

### .!21755!debug

---

### .!21758!dep_util

---

### .!21765!dir_util

---

### .!21773!errors

---

### .!21777!extension

---

### .!21782!fancy_getopt

---

### .!21785!file_util

---

### .!21792!filelist

---

### .!21801!msvc9compiler

---

### .!21807!msvccompiler

---

### .!21813!py38compat

---

### .!21818!py39compat

---

### .!21823!spawn

---

### .!21828!sysconfig

---

### .!21834!text_file

---

### .!21836!unixccompiler

---

### .!21845!version

---

### .!21849!versionpredicate

---

### .!21854!__init__

---

### .!21857!_framework_compat

---

### .!21863!bdist

---

### .!21866!bdist_dumb

---

### .!21870!bdist_rpm

---

### .!21873!build

---

### .!21879!build_clib

---

### .!21884!build_ext

---

### .!21888!build_py

---

### .!21893!build_scripts

---

### .!21897!check

---

### .!21903!clean

---

### .!21908!config

---

### .!21911!install

---

### .!21917!install_data

---

### .!21923!install_egg_info

---

### .!21925!install_headers

---

### .!21930!install_lib

---

### .!21935!install_scripts

---

### .!21938!py37compat

---

### .!21943!register

---

### .!21948!sdist

---

### .!21952!upload

---

### .!21974!zipp

---

### .!21965!ordered_set

---

### .!21969!typing_extensions

---

### .!21980!__init__

---

### .!21984!_adapters

---

### .!21990!_collections

---

### .!21994!_compat

---

### .!21999!_functools

---

### .!22004!_itertools

---

### .!22008!_meta

---

### .!22012!_text

---

### .!22049!abc

---

### .!22017!__init__

---

### .!22022!_adapters

---

### .!22029!_common

---

### .!22034!_compat

---

### .!22039!_itertools

---

### .!22044!_legacy

---

### .!22053!readers

---

### .!22058!simple

---

### .!22068!context

---

### .!22072!functools

---

### .!22080!__init__

---

### .!22090!more

---

### .!22085!__init__

---

### .!22096!recipes

---

### .!22144!tags

---

### .!22104!__about__

---

### .!22109!__init__

---

### .!22115!_manylinux

---

### .!22120!_musllinux

---

### .!22126!_structures

---

### .!22129!markers

---

### .!22135!requirements

---

### .!22139!specifiers

---

### .!22148!utils

---

### .!22153!version

---

### .!22174!core

---

### .!22202!util

---

### .!22157!__init__

---

### .!22162!actions

---

### .!22167!common

---

### .!22178!exceptions

---

### .!22183!helpers

---

### .!22186!results

---

### .!22193!testing

---

### .!22197!unicode

---

### .!22207!__init__

---

### .!22224!_re

---

### .!22213!__init__

---

### .!22218!_parser

---

### .!22229!_types

---

### .!22347!test

---

### .!22232!__init__

---

### .!22240!alias

---

### .!22245!bdist_egg

---

### .!22249!bdist_rpm

---

### .!22254!build

---

### .!22259!build_clib

---

### .!22262!build_ext

---

### .!22268!build_py

---

### .!22273!develop

---

### .!22277!dist_info

---

### .!22285!easy_install

---

### .!22290!editable_wheel

---

### .!22292!egg_info

---

### .!22299!install

---

### .!22304!install_egg_info

---

### .!22309!install_lib

---

### .!22313!install_scripts

---

### .!22320!py36compat

---

### .!22324!register

---

### .!22330!rotate

---

### .!22333!saveopts

---

### .!22338!sdist

---

### .!22343!setopt

---

### .!22351!upload

---

### .!22356!upload_docs

---

### .!22360!__init__

---

### .!22365!_apply_pyprojecttoml

---

### .!22371!expand

---

### .!22373!pyprojecttoml

---

### .!22379!setupcfg

---

### .!22385!__init__

---

### .!22390!error_reporting

---

### .!22394!extra_validations

---

### .!22399!fastjsonschema_exceptions

---

### .!22404!fastjsonschema_validations

---

### .!22410!formats

---

### .!22413!__init__

---

### .!22420!__init__

---

### .!22427!__main__

---

### .!22431!cpuinfo

---

### __main__

---

### __pip-runner__

Execute exactly this copy of pip, within a different environment.

This file is named as it is, to ensure that this module can't be imported via
an import statement.

#### Classes

##### PipImportRedirectingFinder

**M√©thodes :**

- `find_spec()`

#### Fonctions

##### version_str

**Param√®tres :**

- `version`

##### find_spec

**Param√®tres :**

- `fullname`
- `path`
- `target`

---

### .!22436!__init__

---

### .!22444!__main__

---

### .!22448!__pip-runner__

---

### build_env

Build Environment used for isolation during sdist building

#### Classes

##### _Prefix

**M√©thodes :**

- `__init__()`

##### BuildEnvironment

Creates and manages an isolated environment to install build deps

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `check_requirements()`
- `install_requirements()`
- `_install_requirements()`

##### NoOpBuildEnvironment

A no-op drop-in replacement for BuildEnvironment

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `cleanup()`
- `install_requirements()`

#### Fonctions

##### _dedup

**Param√®tres :**

- `a`
- `b`

##### get_runnable_pip

Get a file to pass to a Python executable, to run the currently-running pip.

This is used to run a pip subprocess, for installing requirements into the build
environment.

##### _get_system_sitepackages

Get system site packages

Usually from site.getsitepackages,
but fallback on `get_purelib()/get_platlib()` if unavailable
(e.g. in a virtualenv created by virtualenv<20)

Returns normalized set of strings.

##### __init__

**Param√®tres :**

- `path`

##### __init__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### check_requirements

Return 2 sets:
- conflicting requirements: set of (installed, wanted) reqs tuples
- missing requirements: set of reqs

**Param√®tres :**

- `reqs`

##### install_requirements

**Param√®tres :**

- `finder`
- `requirements`
- `prefix_as_string`

##### _install_requirements

**Param√®tres :**

- `pip_runnable`
- `finder`
- `requirements`
- `prefix`

##### __init__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### cleanup

##### install_requirements

**Param√®tres :**

- `finder`
- `requirements`
- `prefix_as_string`

---

### cache

Cache Management

#### Classes

##### Cache

An abstract class - provides cache directories for data from links

:param cache_dir: The root of the cache.

**M√©thodes :**

- `__init__()`
- `_get_cache_path_parts()`
- `_get_candidates()`
- `get_path_for_link()`
- `get()`

##### SimpleWheelCache

A cache of wheels for future installs.

**M√©thodes :**

- `__init__()`
- `get_path_for_link()`
- `get()`

##### EphemWheelCache

A SimpleWheelCache that creates it's own temporary cache directory

**M√©thodes :**

- `__init__()`

##### CacheEntry

**M√©thodes :**

- `__init__()`

##### WheelCache

Wraps EphemWheelCache and SimpleWheelCache into a single Cache

This Cache allows for gracefully degradation, using the ephem wheel cache
when a certain link is not found in the simple wheel cache first.

**M√©thodes :**

- `__init__()`
- `get_path_for_link()`
- `get_ephem_path_for_link()`
- `get()`
- `get_cache_entry()`
- `record_download_origin()`

#### Fonctions

##### _hash_dict

Return a stable sha224 of a dictionary.

**Param√®tres :**

- `d`

##### __init__

**Param√®tres :**

- `cache_dir`

##### _get_cache_path_parts

Get parts of part that must be os.path.joined with cache_dir

**Param√®tres :**

- `link`

##### _get_candidates

**Param√®tres :**

- `link`
- `canonical_package_name`

##### get_path_for_link

Return a directory to store cached items in for link.

**Param√®tres :**

- `link`

##### get

Returns a link to a cached item if it exists, otherwise returns the
passed link.

**Param√®tres :**

- `link`
- `package_name`
- `supported_tags`

##### __init__

**Param√®tres :**

- `cache_dir`

##### get_path_for_link

Return a directory to store cached wheels for link

Because there are M wheels for any one sdist, we provide a directory
to cache them in, and then consult that directory when looking up
cache hits.

We only insert things into the cache if they have plausible version
numbers, so that we don't contaminate the cache with things that were
not unique. E.g. ./package might have dozens of installs done for it
and build a version of 0.0...and if we built and cached a wheel, we'd
end up using the same wheel even if the source has been edited.

:param link: The link of the sdist for which this will cache wheels.

**Param√®tres :**

- `link`

##### get

**Param√®tres :**

- `link`
- `package_name`
- `supported_tags`

##### __init__

##### __init__

**Param√®tres :**

- `link`
- `persistent`

##### __init__

**Param√®tres :**

- `cache_dir`

##### get_path_for_link

**Param√®tres :**

- `link`

##### get_ephem_path_for_link

**Param√®tres :**

- `link`

##### get

**Param√®tres :**

- `link`
- `package_name`
- `supported_tags`

##### get_cache_entry

Returns a CacheEntry with a link to a cached item if it exists or
None. The cache entry indicates if the item was found in the persistent
or ephemeral cache.

**Param√®tres :**

- `link`
- `package_name`
- `supported_tags`

##### record_download_origin

**Param√®tres :**

- `cache_dir`
- `download_info`

---

### .!22481!main

---

### configuration

Configuration management setup

Some terminology:
- name
  As written in config files.
- value
  Value associated with a name
- key
  Name combined with it's section (section.name)
- variant
  A single word describing where the configuration key-value pair came from

#### Classes

##### Configuration

Handles management of configuration.

Provides an interface to accessing and managing configuration files.

This class converts provides an API that takes "section.key-name" style
keys and stores the value associated with it as "key-name" under the
section "section".

This allows for a clean interface wherein the both the section and the
key-name are preserved in an easy to manage form in the configuration files
and the data stored is also nice.

**M√©thodes :**

- `__init__()`
- `load()`
- `get_file_to_edit()`
- `items()`
- `get_value()`
- `set_value()`
- `unset_value()`
- `save()`
- `_ensure_have_load_only()`
- `_dictionary()`
- `_load_config_files()`
- `_load_file()`
- `_construct_parser()`
- `_load_environment_vars()`
- `_normalized_keys()`
- `get_environ_vars()`
- `iter_config_files()`
- `get_values_in_config()`
- `_get_parser_to_modify()`
- `_mark_as_modified()`
- `__repr__()`

#### Fonctions

##### _normalize_name

Make a name consistent regardless of source (environment or file)

**Param√®tres :**

- `name`

##### _disassemble_key

**Param√®tres :**

- `name`

##### get_configuration_files

##### __init__

**Param√®tres :**

- `isolated`
- `load_only`

##### load

Loads configuration from configuration files and environment

##### get_file_to_edit

Returns the file with highest priority in configuration

##### items

Returns key-value pairs like dict.items() representing the loaded
configuration

##### get_value

Get a value from the configuration.

**Param√®tres :**

- `key`

##### set_value

Modify a value in the configuration.

**Param√®tres :**

- `key`
- `value`

##### unset_value

Unset a value in the configuration.

**Param√®tres :**

- `key`

##### save

Save the current in-memory state.

##### _ensure_have_load_only

##### _dictionary

A dictionary representing the loaded configuration.

##### _load_config_files

Loads configuration from configuration files

##### _load_file

**Param√®tres :**

- `variant`
- `fname`

##### _construct_parser

**Param√®tres :**

- `fname`

##### _load_environment_vars

Loads configuration from environment variables

##### _normalized_keys

Normalizes items to construct a dictionary with normalized keys.

This routine is where the names become keys and are made the same
regardless of source - configuration files or environment.

**Param√®tres :**

- `section`
- `items`

##### get_environ_vars

Returns a generator with all environmental vars with prefix PIP_

##### iter_config_files

Yields variant and configuration files associated with it.

This should be treated like items of a dictionary. The order
here doesn't affect what gets overridden. That is controlled
by OVERRIDE_ORDER. However this does control the order they are
displayed to the user. It's probably most ergonomic to display
things in the same order as OVERRIDE_ORDER

##### get_values_in_config

Get values present in a config file

**Param√®tres :**

- `variant`

##### _get_parser_to_modify

##### _mark_as_modified

**Param√®tres :**

- `fname`
- `parser`

##### __repr__

---

### exceptions

Exceptions used throughout package.

This module MUST NOT try to import from anything within `pip._internal` to
operate. This is expected to be importable from any/all files within the
subpackage and, thus, should not depend on them.

#### Classes

##### PipError

The base pip error.

##### DiagnosticPipError

An error, that presents diagnostic information to the user.

This contains a bunch of logic, to enable pretty presentation of our error
messages. Each error gets a unique reference. Each error can also include
additional context, a hint and/or a note -- which are presented with the
main error message in a consistent style.

This is adapted from the error output styling in `sphinx-theme-builder`.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__rich_console__()`

##### ConfigurationError

General exception in configuration

##### InstallationError

General exception during installation

##### MissingPyProjectBuildRequires

Raised when pyproject.toml has `build-system`, but no `build-system.requires`.

**M√©thodes :**

- `__init__()`

##### InvalidPyProjectBuildRequires

Raised when pyproject.toml an invalid `build-system.requires`.

**M√©thodes :**

- `__init__()`

##### NoneMetadataError

Raised when accessing a Distribution's "METADATA" or "PKG-INFO".

This signifies an inconsistency, when the Distribution claims to have
the metadata file (if not, raise ``FileNotFoundError`` instead), but is
not actually able to produce its content. This may be due to permission
errors.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### UserInstallationInvalid

A --user install is requested on an environment without user site.

**M√©thodes :**

- `__str__()`

##### InvalidSchemeCombination

**M√©thodes :**

- `__str__()`

##### DistributionNotFound

Raised when a distribution cannot be found to satisfy a requirement

##### RequirementsFileParseError

Raised when a general error occurs parsing a requirements file line.

##### BestVersionAlreadyInstalled

Raised when the most up-to-date version of a package is already
installed.

##### BadCommand

Raised when virtualenv or a command is not found

##### CommandError

Raised when there is an error in command-line arguments

##### PreviousBuildDirError

Raised when there's a previous conflicting build directory

##### NetworkConnectionError

HTTP connection error

**M√©thodes :**

- `__init__()`
- `__str__()`

##### InvalidWheelFilename

Invalid wheel filename.

##### UnsupportedWheel

Unsupported wheel.

##### InvalidWheel

Invalid (e.g. corrupt) wheel.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### MetadataInconsistent

Built metadata contains inconsistent information.

This is raised when the metadata contains values (e.g. name and version)
that do not match the information previously obtained from sdist filename,
user-supplied ``#egg=`` value, or an install requirement name.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### MetadataInvalid

Metadata is invalid.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### InstallationSubprocessError

A subprocess call failed.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### MetadataGenerationFailed

**M√©thodes :**

- `__init__()`
- `__str__()`

##### HashErrors

Multiple HashError instances rolled into one for reporting

**M√©thodes :**

- `__init__()`
- `append()`
- `__str__()`
- `__bool__()`

##### HashError

A failure to verify a package against known-good hashes

:cvar order: An int sorting hash exception classes by difficulty of
    recovery (lower being harder), so the user doesn't bother fretting
    about unpinned packages when he has deeper issues, like VCS
    dependencies, to deal with. Also keeps error reports in a
    deterministic order.
:cvar head: A section heading for display above potentially many
    exceptions of this kind
:ivar req: The InstallRequirement that triggered this error. This is
    pasted on after the exception is instantiated, because it's not
    typically available earlier.

**M√©thodes :**

- `body()`
- `__str__()`
- `_requirement_name()`

##### VcsHashUnsupported

A hash was provided for a version-control-system-based requirement, but
we don't have a method for hashing those.

##### DirectoryUrlHashUnsupported

A hash was provided for a version-control-system-based requirement, but
we don't have a method for hashing those.

##### HashMissing

A hash was needed for a requirement but is absent.

**M√©thodes :**

- `__init__()`
- `body()`

##### HashUnpinned

A requirement had a hash specified but was not pinned to a specific
version.

##### HashMismatch

Distribution file hash values don't match.

:ivar package_name: The name of the package that triggered the hash
    mismatch. Feel free to write to this after the exception is raise to
    improve its error message.

**M√©thodes :**

- `__init__()`
- `body()`
- `_hash_comparison()`

##### UnsupportedPythonVersion

Unsupported python version according to Requires-Python package
metadata.

##### ConfigurationFileCouldNotBeLoaded

When there are errors while loading a configuration file

**M√©thodes :**

- `__init__()`
- `__str__()`

##### ExternallyManagedEnvironment

The current environment is externally managed.

This is raised when the current environment is externally managed, as
defined by `PEP 668`_. The ``EXTERNALLY-MANAGED`` configuration is checked
and displayed when the error is bubbled up to the user.

:param error: The error message read from ``EXTERNALLY-MANAGED``.

**M√©thodes :**

- `__init__()`
- `_iter_externally_managed_error_keys()`
- `from_config()`

##### UninstallMissingRecord

**M√©thodes :**

- `__init__()`

##### LegacyDistutilsInstall

**M√©thodes :**

- `__init__()`

##### InvalidInstalledPackage

**M√©thodes :**

- `__init__()`

##### IncompleteDownloadError

Raised when the downloader receives fewer bytes than advertised
in the Content-Length header.

**M√©thodes :**

- `__init__()`

##### ResolutionTooDeepError

Raised when the dependency resolver exceeds the maximum recursion depth.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### _is_kebab_case

**Param√®tres :**

- `s`

##### _prefix_with_indent

**Param√®tres :**

- `s`
- `console`

##### __init__

##### __repr__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __init__

##### __init__

##### __init__

:param dist: A Distribution object.
:param metadata_name: The name of the metadata being accessed
    (can be "METADATA" or "PKG-INFO").

**Param√®tres :**

- `dist`
- `metadata_name`

##### __str__

##### __str__

##### __str__

##### __init__

Initialize NetworkConnectionError with  `request` and `response`
objects.

**Param√®tres :**

- `error_msg`
- `response`
- `request`

##### __str__

##### __init__

**Param√®tres :**

- `location`
- `name`

##### __str__

##### __init__

**Param√®tres :**

- `ireq`
- `field`
- `f_val`
- `m_val`

##### __str__

##### __init__

**Param√®tres :**

- `ireq`
- `error`

##### __str__

##### __init__

##### __str__

##### __init__

##### __str__

##### __init__

##### append

**Param√®tres :**

- `error`

##### __str__

##### __bool__

##### body

Return a summary of me for display under the heading.

This default implementation simply prints a description of the
triggering requirement.

:param req: The InstallRequirement that provoked this error, with
    its link already populated by the resolver's _populate_link().

##### __str__

##### _requirement_name

Return a description of the requirement that triggered me.

This default implementation returns long description of the req, with
line numbers

##### __init__

:param gotten_hash: The hash of the (possibly malicious) archive we
    just downloaded

**Param√®tres :**

- `gotten_hash`

##### body

##### __init__

:param allowed: A dict of algorithm names pointing to lists of allowed
    hex digests
:param gots: A dict of algorithm names pointing to hashes we
    actually got from the files under suspicion

**Param√®tres :**

- `allowed`
- `gots`

##### body

##### _hash_comparison

Return a comparison of actual and expected hash values.

Example::

       Expected sha256 abcdeabcdeabcdeabcdeabcdeabcdeabcdeabcdeabcde
                    or 123451234512345123451234512345123451234512345
            Got        bcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdef

##### __init__

**Param√®tres :**

- `reason`
- `fname`
- `error`

##### __str__

##### __init__

**Param√®tres :**

- `error`

##### _iter_externally_managed_error_keys

##### from_config

**Param√®tres :**

- `cls`
- `config`

##### __init__

##### __init__

##### __init__

##### __init__

**Param√®tres :**

- `link`
- `received`
- `expected`

##### __init__

##### hash_then_or

**Param√®tres :**

- `hash_name`

---

### main

#### Fonctions

##### main

This is preserved for old console scripts that may still be referencing
it.

For additional details, see https://github.com/pypa/pip/issues/7498.

**Param√®tres :**

- `args`

---

### pyproject

#### Fonctions

##### _is_list_of_str

**Param√®tres :**

- `obj`

##### make_pyproject_path

**Param√®tres :**

- `unpacked_source_directory`

##### load_pyproject_toml

Load the pyproject.toml file.

Parameters:
    use_pep517 - Has the user requested PEP 517 processing? None
                 means the user hasn't explicitly specified.
    pyproject_toml - Location of the project's pyproject.toml file
    setup_py - Location of the project's setup.py file
    req_name - The name of the requirement we're processing (for
               error reporting)

Returns:
    None if we should use the legacy code path, otherwise a tuple
    (
        requirements from pyproject.toml,
        name of PEP 517 backend,
        requirements we should check are installed after setting
            up the build environment
        directory paths to import the backend from (backend-path),
            relative to the project root.
    )

**Param√®tres :**

- `use_pep517`
- `pyproject_toml`
- `setup_py`
- `req_name`

---

### self_outdated_check

#### Classes

##### SelfCheckState

**M√©thodes :**

- `__init__()`
- `key()`
- `get()`
- `set()`

##### UpgradePrompt

**M√©thodes :**

- `__rich__()`

#### Fonctions

##### _get_statefile_name

**Param√®tres :**

- `key`

##### _convert_date

Convert an ISO format string to a date.

Handles the format 2020-01-22T14:24:01Z (trailing Z)
which is not supported by older versions of fromisoformat.

**Param√®tres :**

- `isodate`

##### was_installed_by_pip

Checks whether pkg was installed by pip

This is used not to display the upgrade message when pip is in fact
installed by system package manager, such as dnf on Fedora.

**Param√®tres :**

- `pkg`

##### _get_current_remote_pip_version

**Param√®tres :**

- `session`
- `options`

##### _self_version_check_logic

##### pip_self_version_check

Check for an update for pip.

Limit the frequency of checks to once per week. State is stored either in
the active virtualenv or in the user's USER_CACHE_DIR keyed off the prefix
of the pip script path.

**Param√®tres :**

- `session`
- `options`

##### __init__

**Param√®tres :**

- `cache_dir`

##### key

##### get

Check if we have a not-outdated version loaded already.

**Param√®tres :**

- `current_time`

##### set

**Param√®tres :**

- `pypi_version`
- `current_time`

##### __rich__

---

### wheel_builder

Orchestrator for building wheels from InstallRequirements.

#### Fonctions

##### _contains_egg_info

Determine whether the string looks like an egg_info.

:param s: The string to parse. E.g. foo-2.1

**Param√®tres :**

- `s`

##### _should_build

Return whether an InstallRequirement should be built into a wheel.

**Param√®tres :**

- `req`

##### should_build_for_install_command

**Param√®tres :**

- `req`

##### _should_cache

Return whether a built InstallRequirement can be stored in the persistent
wheel cache, assuming the wheel cache is available, and _should_build()
has determined a wheel needs to be built.

**Param√®tres :**

- `req`

##### _get_cache_dir

Return the persistent or temporary cache directory where the built
wheel need to be stored.

**Param√®tres :**

- `req`
- `wheel_cache`

##### _verify_one

**Param√®tres :**

- `req`
- `wheel_path`

##### _build_one

Build one wheel.

:return: The filename of the built wheel, or None if the build failed.

**Param√®tres :**

- `req`
- `output_dir`
- `verify`
- `build_options`
- `global_options`
- `editable`

##### _build_one_inside_env

**Param√®tres :**

- `req`
- `output_dir`
- `build_options`
- `global_options`
- `editable`

##### _clean_one_legacy

**Param√®tres :**

- `req`
- `global_options`

##### build

Build wheels.

:return: The list of InstallRequirement that succeeded to build and
    the list of InstallRequirement that failed to build.

**Param√®tres :**

- `requirements`
- `wheel_cache`
- `verify`
- `build_options`
- `global_options`

---

### .!22455!__init__

---

### .!22461!build_env

---

### .!22465!cache

---

### .!22473!configuration

---

### .!22477!exceptions

---

### .!22486!pyproject

---

### .!22493!self_outdated_check

---

### .!22498!wheel_builder

---

### autocompletion

Logic that powers autocompletion installed by ``pip completion``.

#### Fonctions

##### autocomplete

Entry Point for completion of main and subcommand options.

##### get_path_completion_type

Get the type of path completion (``file``, ``dir``, ``path`` or None)

:param cwords: same as the environmental variable ``COMP_WORDS``
:param cword: same as the environmental variable ``COMP_CWORD``
:param opts: The available options to check
:return: path completion type (``file``, ``dir``, ``path`` or None)

**Param√®tres :**

- `cwords`
- `cword`
- `opts`

##### auto_complete_paths

If ``completion_type`` is ``file`` or ``path``, list all regular files
and directories starting with ``current``; otherwise only list directories
starting with ``current``.

:param current: The word to be completed
:param completion_type: path completion type(``file``, ``path`` or ``dir``)
:return: A generator of regular files and/or directories

**Param√®tres :**

- `current`
- `completion_type`

---

### base_command

Base Command class, and related routines

#### Classes

##### Command

**M√©thodes :**

- `__init__()`
- `add_options()`
- `handle_pip_version_check()`
- `run()`
- `_run_wrapper()`
- `parse_args()`
- `main()`
- `_main()`

#### Fonctions

##### __init__

**Param√®tres :**

- `name`
- `summary`
- `isolated`

##### add_options

##### handle_pip_version_check

This is a no-op so that commands by default do not do the pip version
check.

**Param√®tres :**

- `options`

##### run

**Param√®tres :**

- `options`
- `args`

##### _run_wrapper

**Param√®tres :**

- `level_number`
- `options`
- `args`

##### parse_args

**Param√®tres :**

- `args`

##### main

**Param√®tres :**

- `args`

##### _main

**Param√®tres :**

- `args`

##### _inner_run

---

### cmdoptions

shared options and groups

The principle here is to define options once, but *not* instantiate them
globally. One reason being that options with action='append' can carry state
between parses. pip parses general options twice internally, and shouldn't
pass on state. To be consistent, all options will follow this design.

#### Classes

##### PipOption

#### Fonctions

##### raise_option_error

Raise an option parsing error using parser.error().

Args:
  parser: an OptionParser instance.
  option: an Option instance.
  msg: the error text.

**Param√®tres :**

- `parser`
- `option`
- `msg`

##### make_option_group

Return an OptionGroup object
group  -- assumed to be dict with 'name' and 'options' keys
parser -- an optparse Parser

**Param√®tres :**

- `group`
- `parser`

##### check_dist_restriction

Function for determining if custom platform options are allowed.

:param options: The OptionParser options.
:param check_target: Whether or not to check if --target is being used.

**Param√®tres :**

- `options`
- `check_target`

##### _path_option_check

**Param√®tres :**

- `option`
- `opt`
- `value`

##### _package_name_option_check

**Param√®tres :**

- `option`
- `opt`
- `value`

##### exists_action

##### extra_index_url

##### find_links

##### trusted_host

##### constraints

##### requirements

##### editable

##### _handle_src

**Param√®tres :**

- `option`
- `opt_str`
- `value`
- `parser`

##### _get_format_control

Get a format_control object.

**Param√®tres :**

- `values`
- `option`

##### _handle_no_binary

**Param√®tres :**

- `option`
- `opt_str`
- `value`
- `parser`

##### _handle_only_binary

**Param√®tres :**

- `option`
- `opt_str`
- `value`
- `parser`

##### no_binary

##### only_binary

##### _convert_python_version

Convert a version string like "3", "37", or "3.7.3" into a tuple of ints.

:return: A 2-tuple (version_info, error_msg), where `error_msg` is
    non-None if and only if there was a parsing error.

**Param√®tres :**

- `value`

##### _handle_python_version

Handle a provided --python-version value.

**Param√®tres :**

- `option`
- `opt_str`
- `value`
- `parser`

##### add_target_python_options

**Param√®tres :**

- `cmd_opts`

##### make_target_python

**Param√®tres :**

- `options`

##### prefer_binary

##### _handle_no_cache_dir

Process a value provided for the --no-cache-dir option.

This is an optparse.Option callback for the --no-cache-dir option.

**Param√®tres :**

- `option`
- `opt`
- `value`
- `parser`

##### _handle_dependency_group

Process a value provided for the --group option.

Splits on the rightmost ":", and validates that the path (if present) ends
in `pyproject.toml`. Defaults the path to `pyproject.toml` when one is not given.

`:` cannot appear in dependency group names, so this is a safe and simple parse.

This is an optparse.Option callback for the dependency_groups option.

**Param√®tres :**

- `option`
- `opt`
- `value`
- `parser`

##### _handle_no_use_pep517

Process a value provided for the --no-use-pep517 option.

This is an optparse.Option callback for the no_use_pep517 option.

**Param√®tres :**

- `option`
- `opt`
- `value`
- `parser`

##### _handle_config_settings

**Param√®tres :**

- `option`
- `opt_str`
- `value`
- `parser`

##### _handle_merge_hash

Given a value spelled "algo:digest", append the digest to a list
pointed to in a dict by the algo name.

**Param√®tres :**

- `option`
- `opt_str`
- `value`
- `parser`

##### check_list_path_option

**Param√®tres :**

- `options`

---

### .!22532!main

---

### command_context

#### Classes

##### CommandContextMixIn

**M√©thodes :**

- `__init__()`
- `main_context()`
- `enter_context()`

#### Fonctions

##### __init__

##### main_context

##### enter_context

**Param√®tres :**

- `context_provider`

---

### index_command

Contains command classes which may interact with an index / the network.

Unlike its sister module, req_command, this module still uses lazy imports
so commands which don't always hit the network (e.g. list w/o --outdated or
--uptodate) don't need waste time importing PipSession and friends.

#### Classes

##### SessionCommandMixin

A class mixin for command classes needing _build_session().

**M√©thodes :**

- `__init__()`
- `_get_index_urls()`
- `get_default_session()`
- `_build_session()`

##### IndexGroupCommand

Abstract base class for commands with the index_group options.

This also corresponds to the commands that permit the pip version check.

**M√©thodes :**

- `handle_pip_version_check()`

#### Fonctions

##### _create_truststore_ssl_context

##### _pip_self_version_check

**Param√®tres :**

- `session`
- `options`

##### __init__

##### _get_index_urls

Return a list of index urls from user-provided options.

**Param√®tres :**

- `cls`
- `options`

##### get_default_session

Get a default-managed session.

**Param√®tres :**

- `options`

##### _build_session

**Param√®tres :**

- `options`
- `retries`
- `timeout`

##### handle_pip_version_check

Do the pip version check if not disabled.

This overrides the default behavior of not doing the check.

**Param√®tres :**

- `options`

---

### main

Primary application entrypoint.

#### Fonctions

##### main

**Param√®tres :**

- `args`

---

### main_parser

A single place for constructing and exposing the main parser

#### Fonctions

##### create_main_parser

Creates and returns the main parser for pip's CLI

##### identify_python_interpreter

**Param√®tres :**

- `python`

##### parse_command

**Param√®tres :**

- `args`

---

### parser

Base option parser setup

#### Classes

##### PrettyHelpFormatter

A prettier/less verbose help formatter for optparse.

**M√©thodes :**

- `__init__()`
- `format_option_strings()`
- `_format_option_strings()`
- `format_heading()`
- `format_usage()`
- `format_description()`
- `format_epilog()`
- `indent_lines()`

##### UpdatingDefaultsHelpFormatter

Custom help formatter for use in ConfigOptionParser.

This is updates the defaults before expanding them, allowing
them to show up correctly in the help listing.

Also redact auth from url type options

**M√©thodes :**

- `expand_default()`

##### CustomOptionParser

**M√©thodes :**

- `insert_option_group()`
- `option_list_all()`

##### ConfigOptionParser

Custom option parser which updates its defaults by checking the
configuration files and environmental variables

**M√©thodes :**

- `__init__()`
- `check_default()`
- `_get_ordered_configuration_items()`
- `_update_defaults()`
- `get_default_values()`
- `error()`

#### Fonctions

##### __init__

##### format_option_strings

**Param√®tres :**

- `option`

##### _format_option_strings

Return a comma-separated list of option strings and metavars.

:param option:  tuple of (short opt, long opt), e.g: ('-f', '--format')
:param mvarfmt: metavar format string
:param optsep:  separator

**Param√®tres :**

- `option`
- `mvarfmt`
- `optsep`

##### format_heading

**Param√®tres :**

- `heading`

##### format_usage

Ensure there is only one newline between usage and the first heading
if there is no description.

**Param√®tres :**

- `usage`

##### format_description

**Param√®tres :**

- `description`

##### format_epilog

**Param√®tres :**

- `epilog`

##### indent_lines

**Param√®tres :**

- `text`
- `indent`

##### expand_default

**Param√®tres :**

- `option`

##### insert_option_group

Insert an OptionGroup at a given position.

**Param√®tres :**

- `idx`

##### option_list_all

Get a list of all options, including those in option groups.

##### __init__

##### check_default

**Param√®tres :**

- `option`
- `key`
- `val`

##### _get_ordered_configuration_items

##### _update_defaults

Updates the given defaults with values from the config files and
the environ. Does a little special handling for certain types of
options (lists).

**Param√®tres :**

- `defaults`

##### get_default_values

Overriding to make updating the defaults after instantiation of
the option parser possible, _update_defaults() does the dirty work.

##### error

**Param√®tres :**

- `msg`

---

### progress_bars

#### Fonctions

##### _rich_download_progress_bar

**Param√®tres :**

- `iterable`

##### _rich_install_progress_bar

**Param√®tres :**

- `iterable`

##### _raw_progress_bar

**Param√®tres :**

- `iterable`

##### get_download_progress_renderer

Get an object that can be used to render the download progress.

Returns a callable, that takes an iterable to "wrap".

##### get_install_progress_renderer

Get an object that can be used to render the install progress.
Returns a callable, that takes an iterable to "wrap".

##### write_progress

**Param√®tres :**

- `current`
- `total`

---

### req_command

Contains the RequirementCommand base class.

This class is in a separate module so the commands that do not always
need PackageFinder capability don't unnecessarily import the
PackageFinder machinery and all its vendored dependencies, etc.

#### Classes

##### RequirementCommand

**M√©thodes :**

- `__init__()`
- `determine_resolver_variant()`
- `make_requirement_preparer()`
- `make_resolver()`
- `get_requirements()`
- `trace_basic_info()`
- `_build_package_finder()`

#### Fonctions

##### with_cleanup

Decorator for common logic related to managing temporary
directories.

**Param√®tres :**

- `func`

##### configure_tempdir_registry

**Param√®tres :**

- `registry`

##### wrapper

**Param√®tres :**

- `options`
- `args`

##### __init__

##### determine_resolver_variant

Determines which resolver should be used, based on the given options.

**Param√®tres :**

- `options`

##### make_requirement_preparer

Create a RequirementPreparer instance for the given parameters.

**Param√®tres :**

- `cls`
- `temp_build_dir`
- `options`
- `build_tracker`
- `session`
- `finder`
- `use_user_site`
- `download_dir`
- `verbosity`

##### make_resolver

Create a Resolver instance for the given parameters.

**Param√®tres :**

- `cls`
- `preparer`
- `finder`
- `options`
- `wheel_cache`
- `use_user_site`
- `ignore_installed`
- `ignore_requires_python`
- `force_reinstall`
- `upgrade_strategy`
- `use_pep517`
- `py_version_info`

##### get_requirements

Parse command-line arguments into the corresponding requirements.

**Param√®tres :**

- `args`
- `options`
- `finder`
- `session`

##### trace_basic_info

Trace basic information about the provided objects.

**Param√®tres :**

- `finder`

##### _build_package_finder

Create a package finder appropriate to this requirement command.

:param ignore_requires_python: Whether to ignore incompatible
    "Requires-Python" values in links. Defaults to False.

**Param√®tres :**

- `options`
- `session`
- `target_python`
- `ignore_requires_python`

---

### spinners

#### Classes

##### SpinnerInterface

**M√©thodes :**

- `spin()`
- `finish()`

##### InteractiveSpinner

**M√©thodes :**

- `__init__()`
- `_write()`
- `spin()`
- `finish()`

##### NonInteractiveSpinner

**M√©thodes :**

- `__init__()`
- `_update()`
- `spin()`
- `finish()`

##### RateLimiter

**M√©thodes :**

- `__init__()`
- `ready()`
- `reset()`

#### Fonctions

##### open_spinner

**Param√®tres :**

- `message`

##### hidden_cursor

**Param√®tres :**

- `file`

##### spin

##### finish

**Param√®tres :**

- `final_status`

##### __init__

**Param√®tres :**

- `message`
- `file`
- `spin_chars`
- `min_update_interval_seconds`

##### _write

**Param√®tres :**

- `status`

##### spin

##### finish

**Param√®tres :**

- `final_status`

##### __init__

**Param√®tres :**

- `message`
- `min_update_interval_seconds`

##### _update

**Param√®tres :**

- `status`

##### spin

##### finish

**Param√®tres :**

- `final_status`

##### __init__

**Param√®tres :**

- `min_update_interval_seconds`

##### ready

##### reset

---

### status_codes

---

### .!22504!__init__

---

### .!22510!autocompletion

---

### .!22515!base_command

---

### .!22517!cmdoptions

---

### .!22523!command_context

---

### .!22526!index_command

---

### .!22536!main_parser

---

### .!22542!parser

---

### .!22546!progress_bars

---

### .!22551!req_command

---

### .!22556!spinners

---

### .!22560!status_codes

---

### cache

#### Classes

##### CacheCommand

Inspect and manage pip's wheel cache.

Subcommands:

- dir: Show the cache directory.
- info: Show information about the cache.
- list: List filenames of packages stored in the cache.
- remove: Remove one or more package from the cache.
- purge: Remove all items from the cache.

``<pattern>`` can be a glob expression or a package name.

**M√©thodes :**

- `add_options()`
- `run()`
- `get_cache_dir()`
- `get_cache_info()`
- `list_cache_items()`
- `format_for_human()`
- `format_for_abspath()`
- `remove_cache_items()`
- `purge_cache()`
- `_cache_dir()`
- `_find_http_files()`
- `_find_wheels()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

##### get_cache_dir

**Param√®tres :**

- `options`
- `args`

##### get_cache_info

**Param√®tres :**

- `options`
- `args`

##### list_cache_items

**Param√®tres :**

- `options`
- `args`

##### format_for_human

**Param√®tres :**

- `files`

##### format_for_abspath

**Param√®tres :**

- `files`

##### remove_cache_items

**Param√®tres :**

- `options`
- `args`

##### purge_cache

**Param√®tres :**

- `options`
- `args`

##### _cache_dir

**Param√®tres :**

- `options`
- `subdir`

##### _find_http_files

**Param√®tres :**

- `options`

##### _find_wheels

**Param√®tres :**

- `options`
- `pattern`

---

### check

#### Classes

##### CheckCommand

Verify installed packages have compatible dependencies.

**M√©thodes :**

- `run()`

#### Fonctions

##### run

**Param√®tres :**

- `options`
- `args`

---

### completion

#### Classes

##### CompletionCommand

A helper command to be used for command completion.

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### add_options

##### run

Prints the completion code of the given shell

**Param√®tres :**

- `options`
- `args`

---

### configuration

#### Classes

##### ConfigurationCommand

Manage local and global configuration.

Subcommands:

- list: List the active configuration (or from the file specified)
- edit: Edit the configuration file in an editor
- get: Get the value associated with command.option
- set: Set the command.option=value
- unset: Unset the value associated with command.option
- debug: List the configuration files and values defined under them

Configuration keys should be dot separated command and option name,
with the special prefix "global" affecting any command. For example,
"pip config set global.index-url https://example.org/" would configure
the index url for all commands, but "pip config set download.timeout 10"
would configure a 10 second timeout only for "pip download" commands.

If none of --user, --global and --site are passed, a virtual
environment configuration file is used if one is active and the file
exists. Otherwise, all modifications happen to the user file by
default.

**M√©thodes :**

- `add_options()`
- `run()`
- `_determine_file()`
- `list_values()`
- `get_name()`
- `set_name_value()`
- `unset_name()`
- `list_config_values()`
- `print_config_file_values()`
- `print_env_var_values()`
- `open_in_editor()`
- `_get_n_args()`
- `_save_configuration()`
- `_determine_editor()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

##### _determine_file

**Param√®tres :**

- `options`
- `need_value`

##### list_values

**Param√®tres :**

- `options`
- `args`

##### get_name

**Param√®tres :**

- `options`
- `args`

##### set_name_value

**Param√®tres :**

- `options`
- `args`

##### unset_name

**Param√®tres :**

- `options`
- `args`

##### list_config_values

List config key-value pairs across different config files

**Param√®tres :**

- `options`
- `args`

##### print_config_file_values

Get key-value pairs from the file of a variant

**Param√®tres :**

- `variant`

##### print_env_var_values

Get key-values pairs present as environment variables

##### open_in_editor

**Param√®tres :**

- `options`
- `args`

##### _get_n_args

Helper to make sure the command got the right number of arguments

**Param√®tres :**

- `args`
- `example`
- `n`

##### _save_configuration

##### _determine_editor

**Param√®tres :**

- `options`

---

### debug

#### Classes

##### DebugCommand

Display debug information.

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### show_value

**Param√®tres :**

- `name`
- `value`

##### show_sys_implementation

##### create_vendor_txt_map

##### get_module_from_module_name

**Param√®tres :**

- `module_name`

##### get_vendor_version_from_module

**Param√®tres :**

- `module_name`

##### show_actual_vendor_versions

Log the actual version and print extra info if there is
a conflict or if the actual version could not be imported.

**Param√®tres :**

- `vendor_txt_versions`

##### show_vendor_versions

##### show_tags

**Param√®tres :**

- `options`

##### ca_bundle_info

**Param√®tres :**

- `config`

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

---

### .!22608!hash

---

### download

#### Classes

##### DownloadCommand

Download packages from:

- PyPI (and other indexes) using requirement specifiers.
- VCS project urls.
- Local project directories.
- Local or remote source archives.

pip also supports downloading from "requirements files", which provide
an easy way to specify a whole environment to be downloaded.

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

---

### .!22614!help

---

### .!22630!list

---

### freeze

#### Classes

##### FreezeCommand

Output installed packages in requirements format.

packages are listed in a case-insensitive sorted order.

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### _should_suppress_build_backends

##### _dev_pkgs

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

---

### .!22635!lock

---

### .!22643!show

---

### hash

#### Classes

##### HashCommand

Compute a hash of a local package archive.

These can be used with --hash in a requirements file to do repeatable
installs.

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### _hash_of_file

Return the hash digest of a file.

**Param√®tres :**

- `path`
- `algorithm`

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

---

### help

#### Classes

##### HelpCommand

Show help for commands

**M√©thodes :**

- `run()`

#### Fonctions

##### run

**Param√®tres :**

- `options`
- `args`

---

### index

#### Classes

##### IndexCommand

Inspect information available from package indexes.

**M√©thodes :**

- `add_options()`
- `run()`
- `_build_package_finder()`
- `get_available_package_versions()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

##### _build_package_finder

Create a package finder appropriate to the index command.

**Param√®tres :**

- `options`
- `session`
- `target_python`
- `ignore_requires_python`

##### get_available_package_versions

**Param√®tres :**

- `options`
- `args`

---

### inspect

#### Classes

##### InspectCommand

Inspect the content of a Python environment and produce a report in JSON format.

**M√©thodes :**

- `add_options()`
- `run()`
- `_dist_to_dict()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

##### _dist_to_dict

**Param√®tres :**

- `dist`

---

### install

#### Classes

##### InstallCommand

Install packages from:

- PyPI (and other indexes) using requirement specifiers.
- VCS project urls.
- Local project directories.
- Local or remote source archives.

pip also supports installing from "requirements files", which provide
an easy way to specify a whole environment to be installed.

**M√©thodes :**

- `add_options()`
- `run()`
- `_handle_target_dir()`
- `_determine_conflicts()`
- `_warn_about_conflicts()`

#### Fonctions

##### get_lib_location_guesses

**Param√®tres :**

- `user`
- `home`
- `root`
- `isolated`
- `prefix`

##### site_packages_writable

**Param√®tres :**

- `root`
- `isolated`

##### decide_user_install

Determine whether to do a user install based on the input options.

If use_user_site is False, no additional checks are done.
If use_user_site is True, it is checked for compatibility with other
options.
If use_user_site is None, the default behaviour depends on the environment,
which is provided by the other arguments.

**Param√®tres :**

- `use_user_site`
- `prefix_path`
- `target_dir`
- `root_path`
- `isolated_mode`

##### create_os_error_message

Format an error message for an OSError

It may occur anytime during the execution of the install command.

**Param√®tres :**

- `error`
- `show_traceback`
- `using_user_site`

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

##### _handle_target_dir

**Param√®tres :**

- `target_dir`
- `target_temp_dir`
- `upgrade`

##### _determine_conflicts

**Param√®tres :**

- `to_install`

##### _warn_about_conflicts

**Param√®tres :**

- `conflict_details`
- `resolver_variant`

---

### list

#### Classes

##### ListCommand

List installed packages, including editables.

Packages are listed in a case-insensitive sorted order.

**M√©thodes :**

- `add_options()`
- `handle_pip_version_check()`
- `_build_package_finder()`
- `run()`
- `get_outdated()`
- `get_uptodate()`
- `get_not_required()`
- `iter_packages_latest_infos()`
- `output_package_listing()`
- `output_package_listing_columns()`

##### _DistWithLatestInfo

Give the distribution object a couple of extra fields.

These will be populated during ``get_outdated()``. This is dirty but
makes the rest of the code much cleaner.

#### Fonctions

##### format_for_columns

Convert the package data into something usable
by output_package_listing_columns.

**Param√®tres :**

- `pkgs`
- `options`

##### format_for_json

**Param√®tres :**

- `packages`
- `options`

##### add_options

##### handle_pip_version_check

**Param√®tres :**

- `options`

##### _build_package_finder

Create a package finder appropriate to this list command.

**Param√®tres :**

- `options`
- `session`

##### run

**Param√®tres :**

- `options`
- `args`

##### get_outdated

**Param√®tres :**

- `packages`
- `options`

##### get_uptodate

**Param√®tres :**

- `packages`
- `options`

##### get_not_required

**Param√®tres :**

- `packages`
- `options`

##### iter_packages_latest_infos

**Param√®tres :**

- `packages`
- `options`

##### output_package_listing

**Param√®tres :**

- `packages`
- `options`

##### output_package_listing_columns

**Param√®tres :**

- `data`
- `header`

##### wheel_build_tag

**Param√®tres :**

- `dist`

##### latest_info

**Param√®tres :**

- `dist`

---

### lock

#### Classes

##### LockCommand

EXPERIMENTAL - Lock packages and their dependencies from:

- PyPI (and other indexes) using requirement specifiers.
- VCS project urls.
- Local project directories.
- Local or remote source archives.

pip also supports locking from "requirements files", which provide an easy
way to specify a whole environment to be installed.

The generated lock file is only guaranteed to be valid for the current
python version and platform.

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

---

### search

#### Classes

##### TransformedHit

##### SearchCommand

Search for PyPI packages whose name or summary contains <query>.

**M√©thodes :**

- `add_options()`
- `run()`
- `search()`

#### Fonctions

##### transform_hits

The list from pypi is really a list of versions. We want a list of
packages with the list of versions stored inline. This converts the
list from pypi into one we can use.

**Param√®tres :**

- `hits`

##### print_dist_installation_info

**Param√®tres :**

- `latest`
- `dist`

##### get_installed_distribution

**Param√®tres :**

- `name`

##### print_results

**Param√®tres :**

- `hits`
- `name_column_width`
- `terminal_width`

##### highest_version

**Param√®tres :**

- `versions`

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

##### search

**Param√®tres :**

- `query`
- `options`

---

### show

#### Classes

##### ShowCommand

Show information about one or more installed packages.

The output is in RFC-compliant mail header format.

**M√©thodes :**

- `add_options()`
- `run()`

##### _PackageInfo

#### Fonctions

##### normalize_project_url_label

**Param√®tres :**

- `label`

##### search_packages_info

Gather details from installed distributions. Print distribution name,
version, location, and installed files. Installed files requires a
pip generated 'installed-files.txt' in the distributions '.egg-info'
directory.

**Param√®tres :**

- `query`

##### print_results

Print the information from installed distributions found.

**Param√®tres :**

- `distributions`
- `list_files`
- `verbose`

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

##### _get_requiring_packages

**Param√®tres :**

- `current_dist`

---

### uninstall

#### Classes

##### UninstallCommand

Uninstall packages.

pip is able to uninstall most installed packages. Known exceptions are:

- Pure distutils packages installed with ``python setup.py install``, which
  leave behind no metadata to determine what files were installed.
- Script wrappers installed by ``python setup.py develop``.

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

---

### wheel

#### Classes

##### WheelCommand

Build Wheel archives for your requirements and dependencies.

Wheel is a built-package format, and offers the advantage of not
recompiling your software during every install. For more details, see the
wheel docs: https://wheel.readthedocs.io/en/latest/

'pip wheel' uses the build system interface as described here:
https://pip.pypa.io/en/stable/reference/build-system/

**M√©thodes :**

- `add_options()`
- `run()`

#### Fonctions

##### add_options

##### run

**Param√®tres :**

- `options`
- `args`

---

### .!22565!__init__

---

### .!22572!cache

---

### .!22577!check

---

### .!22583!completion

---

### .!22588!configuration

---

### .!22593!debug

---

### .!22598!download

---

### .!22602!freeze

---

### .!22617!index

---

### .!22623!inspect

---

### .!22626!install

---

### .!22639!search

---

### .!22648!uninstall

---

### .!22651!wheel

---

### base

#### Classes

##### AbstractDistribution

A base class for handling installable artifacts.

The requirements for anything installable are as follows:

 - we must be able to determine the requirement name
   (or we can't correctly handle the non-upgrade case).

 - for packages with setup requirements, we must also be able
   to determine their requirements without installing additional
   packages (for the same reason as run-time dependencies)

 - we must be able to create a Distribution object exposing the
   above metadata.

 - if we need to do work in the build tracker, we must be able to generate a unique
   string to identify the requirement in the build tracker.

**M√©thodes :**

- `__init__()`
- `build_tracker_id()`
- `get_metadata_distribution()`
- `prepare_distribution_metadata()`

#### Fonctions

##### __init__

**Param√®tres :**

- `req`

##### build_tracker_id

A string that uniquely identifies this requirement to the build tracker.

If None, then this dist has no work to do in the build tracker, and
``.prepare_distribution_metadata()`` will not be called.

##### get_metadata_distribution

##### prepare_distribution_metadata

**Param√®tres :**

- `finder`
- `build_isolation`
- `check_build_deps`

---

### installed

#### Classes

##### InstalledDistribution

Represents an installed package.

This does not need any preparation as the required information has already
been computed.

**M√©thodes :**

- `build_tracker_id()`
- `get_metadata_distribution()`
- `prepare_distribution_metadata()`

#### Fonctions

##### build_tracker_id

##### get_metadata_distribution

##### prepare_distribution_metadata

**Param√®tres :**

- `finder`
- `build_isolation`
- `check_build_deps`

---

### .!22663!base

---

### sdist

#### Classes

##### SourceDistribution

Represents a source distribution.

The preparation step for these needs metadata for the packages to be
generated, either using PEP 517 or using the legacy `setup.py egg_info`.

**M√©thodes :**

- `build_tracker_id()`
- `get_metadata_distribution()`
- `prepare_distribution_metadata()`
- `_prepare_build_backend()`
- `_get_build_requires_wheel()`
- `_get_build_requires_editable()`
- `_install_build_reqs()`
- `_raise_conflicts()`
- `_raise_missing_reqs()`

#### Fonctions

##### build_tracker_id

Identify this requirement uniquely by its link.

##### get_metadata_distribution

##### prepare_distribution_metadata

**Param√®tres :**

- `finder`
- `build_isolation`
- `check_build_deps`

##### _prepare_build_backend

**Param√®tres :**

- `finder`

##### _get_build_requires_wheel

##### _get_build_requires_editable

##### _install_build_reqs

**Param√®tres :**

- `finder`

##### _raise_conflicts

**Param√®tres :**

- `conflicting_with`
- `conflicting_reqs`

##### _raise_missing_reqs

**Param√®tres :**

- `missing`

---

### wheel

#### Classes

##### WheelDistribution

Represents a wheel distribution.

This does not need any preparation as wheels can be directly unpacked.

**M√©thodes :**

- `build_tracker_id()`
- `get_metadata_distribution()`
- `prepare_distribution_metadata()`

#### Fonctions

##### build_tracker_id

##### get_metadata_distribution

Loads the metadata from the wheel file into memory and returns a
Distribution that uses it, not relying on the wheel file or
requirement.

##### prepare_distribution_metadata

**Param√®tres :**

- `finder`
- `build_isolation`
- `check_build_deps`

---

### .!22658!__init__

---

### .!22668!installed

---

### .!22673!sdist

---

### .!22679!wheel

---

### collector

The main purpose of this module is to expose LinkCollector.collect_sources().

#### Classes

##### _NotAPIContent

**M√©thodes :**

- `__init__()`

##### _NotHTTP

##### CacheablePageContent

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `__hash__()`

##### ParseLinks

**M√©thodes :**

- `__call__()`

##### IndexContent

Represents one response (or page), along with its URL.

:param encoding: the encoding to decode the given content.
:param url: the URL from which the HTML was downloaded.
:param cache_link_parsing: whether links parsed from this page's url
                           should be cached. PyPI index urls should
                           have this set to False, for example.

**M√©thodes :**

- `__str__()`

##### HTMLLinkParser

HTMLParser that keeps the first base HREF and a list of all anchor
elements' attributes.

**M√©thodes :**

- `__init__()`
- `handle_starttag()`
- `get_href()`

##### CollectedSources

##### LinkCollector

Responsible for collecting Link objects from all configured locations,
making network requests as needed.

The class's main method is its collect_sources() method.

**M√©thodes :**

- `__init__()`
- `create()`
- `find_links()`
- `fetch_response()`
- `collect_sources()`

#### Fonctions

##### _match_vcs_scheme

Look for VCS schemes in the URL.

Returns the matched VCS scheme, or None if there's no match.

**Param√®tres :**

- `url`

##### _ensure_api_header

Check the Content-Type header to ensure the response contains a Simple
API Response.

Raises `_NotAPIContent` if the content type is not a valid content-type.

**Param√®tres :**

- `response`

##### _ensure_api_response

Send a HEAD request to the URL, and ensure the response contains a simple
API Response.

Raises `_NotHTTP` if the URL is not available for a HEAD request, or
`_NotAPIContent` if the content type is not a valid content type.

**Param√®tres :**

- `url`
- `session`

##### _get_simple_response

Access an Simple API response with GET, and return the response.

This consists of three parts:

1. If the URL looks suspiciously like an archive, send a HEAD first to
   check the Content-Type is HTML or Simple API, to avoid downloading a
   large file. Raise `_NotHTTP` if the content type cannot be determined, or
   `_NotAPIContent` if it is not HTML or a Simple API.
2. Actually perform the request. Raise HTTP exceptions on network failures.
3. Check the Content-Type header to make sure we got a Simple API response,
   and raise `_NotAPIContent` otherwise.

**Param√®tres :**

- `url`
- `session`

##### _get_encoding_from_headers

Determine if we have any encoding information in our headers.

**Param√®tres :**

- `headers`

##### with_cached_index_content

Given a function that parses an Iterable[Link] from an IndexContent, cache the
function's result (keyed by CacheablePageContent), unless the IndexContent
`page` has `page.cache_link_parsing == False`.

**Param√®tres :**

- `fn`

##### parse_links

Parse a Simple API's Index Content, and yield its anchor elements as Link objects.

**Param√®tres :**

- `page`

##### _handle_get_simple_fail

**Param√®tres :**

- `link`
- `reason`
- `meth`

##### _make_index_content

**Param√®tres :**

- `response`
- `cache_link_parsing`

##### _get_index_content

**Param√®tres :**

- `link`

##### __init__

**Param√®tres :**

- `content_type`
- `request_desc`

##### __init__

**Param√®tres :**

- `page`

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __call__

**Param√®tres :**

- `page`

##### wrapper

**Param√®tres :**

- `cacheable_page`

##### wrapper_wrapper

**Param√®tres :**

- `page`

##### __str__

##### __init__

**Param√®tres :**

- `url`

##### handle_starttag

**Param√®tres :**

- `tag`
- `attrs`

##### get_href

**Param√®tres :**

- `attrs`

##### __init__

**Param√®tres :**

- `session`
- `search_scope`

##### create

:param session: The Session to use to make requests.
:param suppress_no_index: Whether to ignore the --no-index option
    when constructing the SearchScope object.

**Param√®tres :**

- `cls`
- `session`
- `options`
- `suppress_no_index`

##### find_links

##### fetch_response

Fetch an HTML page containing package links.

**Param√®tres :**

- `location`

##### collect_sources

**Param√®tres :**

- `project_name`
- `candidates_from_page`

---

### package_finder

Routines related to PyPI, indexes

#### Classes

##### LinkType

##### LinkEvaluator

Responsible for evaluating links for a particular project.

**M√©thodes :**

- `__init__()`
- `evaluate_link()`

##### CandidatePreferences

Encapsulates some of the preferences for filtering and sorting
InstallationCandidate objects.

##### BestCandidateResult

A collection of candidates, returned by `PackageFinder.find_best_candidate`.

This class is only intended to be instantiated by CandidateEvaluator's
`compute_best_candidate()` method.

:param all_candidates: A sequence of all available candidates found.
:param applicable_candidates: The applicable candidates.
:param best_candidate: The most preferred candidate found, or None
    if no applicable candidates were found.

**M√©thodes :**

- `__post_init__()`

##### CandidateEvaluator

Responsible for filtering and sorting candidates for installation based
on what tags are valid.

**M√©thodes :**

- `create()`
- `__init__()`
- `get_applicable_candidates()`
- `_sort_key()`
- `sort_best_candidate()`
- `compute_best_candidate()`

##### PackageFinder

This finds packages.

This is meant to match easy_install's technique for looking for
packages, by reading pages and looking for appropriate links.

**M√©thodes :**

- `__init__()`
- `create()`
- `target_python()`
- `search_scope()`
- `search_scope()`
- `find_links()`
- `index_urls()`
- `proxy()`
- `trusted_hosts()`
- `custom_cert()`
- `client_cert()`
- `allow_all_prereleases()`
- `set_allow_all_prereleases()`
- `prefer_binary()`
- `set_prefer_binary()`
- `requires_python_skipped_reasons()`
- `make_link_evaluator()`
- `_sort_links()`
- `_log_skipped_link()`
- `get_install_candidate()`
- `evaluate_links()`
- `process_project_url()`
- `find_all_candidates()`
- `make_candidate_evaluator()`
- `find_best_candidate()`
- `find_requirement()`

#### Fonctions

##### _check_link_requires_python

Return whether the given Python version is compatible with a link's
"Requires-Python" value.

:param version_info: A 3-tuple of ints representing the Python
    major-minor-micro version to check.
:param ignore_requires_python: Whether to ignore the "Requires-Python"
    value if the given Python version isn't compatible.

**Param√®tres :**

- `link`
- `version_info`
- `ignore_requires_python`

##### filter_unallowed_hashes

Filter out candidates whose hashes aren't allowed, and return a new
list of candidates.

If at least one candidate has an allowed hash, then all candidates with
either an allowed hash or no hash specified are returned.  Otherwise,
the given candidates are returned.

Including the candidates with no hash specified when there is a match
allows a warning to be logged if there is a more preferred candidate
with no hash specified.  Returning all candidates in the case of no
matches lets pip report the hash of the candidate that would otherwise
have been installed (e.g. permitting the user to more easily update
their requirements file with the desired hash).

**Param√®tres :**

- `candidates`
- `hashes`
- `project_name`

##### _find_name_version_sep

Find the separator's index based on the package's canonical name.

:param fragment: A <package>+<version> filename "fragment" (stem) or
    egg fragment.
:param canonical_name: The package's canonical name.

This function is needed since the canonicalized name does not necessarily
have the same length as the egg info's name part. An example::

>>> fragment = 'foo__bar-1.0'
>>> canonical_name = 'foo-bar'
>>> _find_name_version_sep(fragment, canonical_name)
8

**Param√®tres :**

- `fragment`
- `canonical_name`

##### _extract_version_from_fragment

Parse the version string from a <package>+<version> filename
"fragment" (stem) or egg fragment.

:param fragment: The string to parse. E.g. foo-2.1
:param canonical_name: The canonicalized name of the package this
    belongs to.

**Param√®tres :**

- `fragment`
- `canonical_name`

##### __init__

:param project_name: The user supplied package name.
:param canonical_name: The canonical package name.
:param formats: The formats allowed for this package. Should be a set
    with 'binary' or 'source' or both in it.
:param target_python: The target Python interpreter to use when
    evaluating link compatibility. This is used, for example, to
    check wheel compatibility, as well as when checking the Python
    version, e.g. the Python version embedded in a link filename
    (or egg fragment) and against an HTML link's optional PEP 503
    "data-requires-python" attribute.
:param allow_yanked: Whether files marked as yanked (in the sense
    of PEP 592) are permitted to be candidates for install.
:param ignore_requires_python: Whether to ignore incompatible
    PEP 503 "data-requires-python" values in HTML links. Defaults
    to False.

**Param√®tres :**

- `project_name`
- `canonical_name`
- `formats`
- `target_python`
- `allow_yanked`
- `ignore_requires_python`

##### evaluate_link

Determine whether a link is a candidate for installation.

:return: A tuple (result, detail), where *result* is an enum
    representing whether the evaluation found a candidate, or the reason
    why one is not found. If a candidate is found, *detail* will be the
    candidate's version string; if one is not found, it contains the
    reason the link fails to qualify.

**Param√®tres :**

- `link`

##### __post_init__

##### create

Create a CandidateEvaluator object.

:param target_python: The target Python interpreter to use when
    checking compatibility. If None (the default), a TargetPython
    object will be constructed from the running Python.
:param specifier: An optional object implementing `filter`
    (e.g. `packaging.specifiers.SpecifierSet`) to filter applicable
    versions.
:param hashes: An optional collection of allowed hashes.

**Param√®tres :**

- `cls`
- `project_name`
- `target_python`
- `prefer_binary`
- `allow_all_prereleases`
- `specifier`
- `hashes`

##### __init__

:param supported_tags: The PEP 425 tags supported by the target
    Python in order of preference (most preferred first).

**Param√®tres :**

- `project_name`
- `supported_tags`
- `specifier`
- `prefer_binary`
- `allow_all_prereleases`
- `hashes`

##### get_applicable_candidates

Return the applicable candidates from a list of candidates.

**Param√®tres :**

- `candidates`

##### _sort_key

Function to pass as the `key` argument to a call to sorted() to sort
InstallationCandidates by preference.

Returns a tuple such that tuples sorting as greater using Python's
default comparison operator are more preferred.

The preference is as follows:

First and foremost, candidates with allowed (matching) hashes are
always preferred over candidates without matching hashes. This is
because e.g. if the only candidate with an allowed hash is yanked,
we still want to use that candidate.

Second, excepting hash considerations, candidates that have been
yanked (in the sense of PEP 592) are always less preferred than
candidates that haven't been yanked. Then:

If not finding wheels, they are sorted by version only.
If finding wheels, then the sort order is by version, then:
  1. existing installs
  2. wheels ordered via Wheel.support_index_min(self._supported_tags)
  3. source archives
If prefer_binary was set, then all wheels are sorted above sources.

Note: it was considered to embed this logic into the Link
      comparison operators, but then different sdist links
      with the same version, would have to be considered equal

**Param√®tres :**

- `candidate`

##### sort_best_candidate

Return the best candidate per the instance's sort order, or None if
no candidate is acceptable.

**Param√®tres :**

- `candidates`

##### compute_best_candidate

Compute and return a `BestCandidateResult` instance.

**Param√®tres :**

- `candidates`

##### __init__

This constructor is primarily meant to be used by the create() class
method and from tests.

:param format_control: A FormatControl object, used to control
    the selection of source packages / binary packages when consulting
    the index and links.
:param candidate_prefs: Options to use when creating a
    CandidateEvaluator object.

**Param√®tres :**

- `link_collector`
- `target_python`
- `allow_yanked`
- `format_control`
- `candidate_prefs`
- `ignore_requires_python`

##### create

Create a PackageFinder.

:param selection_prefs: The candidate selection preferences, as a
    SelectionPreferences object.
:param target_python: The target Python interpreter to use when
    checking compatibility. If None (the default), a TargetPython
    object will be constructed from the running Python.

**Param√®tres :**

- `cls`
- `link_collector`
- `selection_prefs`
- `target_python`

##### target_python

##### search_scope

##### search_scope

**Param√®tres :**

- `search_scope`

##### find_links

##### index_urls

##### proxy

##### trusted_hosts

##### custom_cert

##### client_cert

##### allow_all_prereleases

##### set_allow_all_prereleases

##### prefer_binary

##### set_prefer_binary

##### requires_python_skipped_reasons

##### make_link_evaluator

**Param√®tres :**

- `project_name`

##### _sort_links

Returns elements of links in order, non-egg links first, egg links
second, while eliminating duplicates

**Param√®tres :**

- `links`

##### _log_skipped_link

**Param√®tres :**

- `link`
- `result`
- `detail`

##### get_install_candidate

If the link is a candidate for install, convert it to an
InstallationCandidate and return it. Otherwise, return None.

**Param√®tres :**

- `link_evaluator`
- `link`

##### evaluate_links

Convert links that are candidates to InstallationCandidate objects.

**Param√®tres :**

- `link_evaluator`
- `links`

##### process_project_url

**Param√®tres :**

- `project_url`
- `link_evaluator`

##### find_all_candidates

Find all available InstallationCandidate for project_name

This checks index_urls and find_links.
All versions found are returned as an InstallationCandidate list.

See LinkEvaluator.evaluate_link() for details on which files
are accepted.

**Param√®tres :**

- `project_name`

##### make_candidate_evaluator

Create a CandidateEvaluator object to use.

**Param√®tres :**

- `project_name`
- `specifier`
- `hashes`

##### find_best_candidate

Find matches for the given project and specifier.

:param specifier: An optional object implementing `filter`
    (e.g. `packaging.specifiers.SpecifierSet`) to filter applicable
    versions.

:return: A `BestCandidateResult` instance.

**Param√®tres :**

- `project_name`
- `specifier`
- `hashes`

##### find_requirement

Try to find a Link matching req

Expects req, an InstallRequirement and upgrade, a boolean
Returns a InstallationCandidate if found,
Raises DistributionNotFound or BestVersionAlreadyInstalled otherwise

**Param√®tres :**

- `req`
- `upgrade`

##### _format_versions

**Param√®tres :**

- `cand_iter`

##### _should_install_candidate

**Param√®tres :**

- `candidate`

---

### sources

#### Classes

##### LinkSource

**M√©thodes :**

- `link()`
- `page_candidates()`
- `file_links()`

##### _FlatDirectoryToUrls

Scans directory and caches results

**M√©thodes :**

- `__init__()`
- `_scan_directory()`
- `page_candidates()`
- `project_name_to_urls()`

##### _FlatDirectorySource

Link source specified by ``--find-links=<path-to-dir>``.

This looks the content of the directory, and returns:

* ``page_candidates``: Links listed on each HTML file in the directory.
* ``file_candidates``: Archives in the directory.

**M√©thodes :**

- `__init__()`
- `link()`
- `page_candidates()`
- `file_links()`

##### _LocalFileSource

``--find-links=<path-or-url>`` or ``--[extra-]index-url=<path-or-url>``.

If a URL is supplied, it must be a ``file:`` URL. If a path is supplied to
the option, it is converted to a URL first. This returns:

* ``page_candidates``: Links listed on an HTML file.
* ``file_candidates``: The non-HTML file.

**M√©thodes :**

- `__init__()`
- `link()`
- `page_candidates()`
- `file_links()`

##### _RemoteFileSource

``--find-links=<url>`` or ``--[extra-]index-url=<url>``.

This returns:

* ``page_candidates``: Links listed on an HTML file.
* ``file_candidates``: The non-HTML file.

**M√©thodes :**

- `__init__()`
- `link()`
- `page_candidates()`
- `file_links()`

##### _IndexDirectorySource

``--[extra-]index-url=<path-to-directory>``.

This is treated like a remote URL; ``candidates_from_page`` contains logic
for this by appending ``index.html`` to the link.

**M√©thodes :**

- `__init__()`
- `link()`
- `page_candidates()`
- `file_links()`

#### Fonctions

##### _is_html_file

**Param√®tres :**

- `file_url`

##### build_source

**Param√®tres :**

- `location`

##### link

Returns the underlying link, if there's one.

##### page_candidates

Candidates found by parsing an archive listing HTML file.

##### file_links

Links found by specifying archives directly.

##### __init__

**Param√®tres :**

- `path`

##### _scan_directory

Scans directory once and populates both page_candidates
and project_name_to_urls at the same time

##### page_candidates

##### project_name_to_urls

##### __init__

**Param√®tres :**

- `candidates_from_page`
- `path`
- `project_name`

##### link

##### page_candidates

##### file_links

##### __init__

**Param√®tres :**

- `candidates_from_page`
- `link`

##### link

##### page_candidates

##### file_links

##### __init__

**Param√®tres :**

- `candidates_from_page`
- `page_validator`
- `link`

##### link

##### page_candidates

##### file_links

##### __init__

**Param√®tres :**

- `candidates_from_page`
- `link`

##### link

##### page_candidates

##### file_links

---

### .!22687!__init__

---

### .!22691!collector

---

### .!22695!package_finder

---

### .!22700!sources

---

### _distutils

Locations where we look for configs, install stuff, etc

#### Fonctions

##### distutils_scheme

Return a distutils install scheme

**Param√®tres :**

- `dist_name`
- `user`
- `home`
- `root`
- `isolated`
- `prefix`

##### get_scheme

Get the "scheme" corresponding to the input parameters. The distutils
documentation provides the context for the available schemes:
https://docs.python.org/3/install/index.html#alternate-installation

:param dist_name: the name of the package to retrieve the scheme for, used
    in the headers scheme path
:param user: indicates to use the "user" scheme
:param home: indicates to use the "home" scheme and provides the base
    directory for the same
:param root: root under which other directories are re-based
:param isolated: equivalent to --no-user-cfg, i.e. do not consider
    ~/.pydistutils.cfg (posix) or ~/pydistutils.cfg (non-posix) for
    scheme paths
:param prefix: indicates to use the "prefix" scheme and provides the
    base directory for the same

**Param√®tres :**

- `dist_name`
- `user`
- `home`
- `root`
- `isolated`
- `prefix`

##### get_bin_prefix

##### get_purelib

##### get_platlib

---

### _sysconfig

#### Fonctions

##### _should_use_osx_framework_prefix

Check for Apple's ``osx_framework_library`` scheme.

Python distributed by Apple's Command Line Tools has this special scheme
that's used when:

* This is a framework build.
* We are installing into the system prefix.

This does not account for ``pip install --prefix`` (also means we're not
installing to the system prefix), which should use ``posix_prefix``, but
logic here means ``_infer_prefix()`` outputs ``osx_framework_library``. But
since ``prefix`` is not available for ``sysconfig.get_default_scheme()``,
which is the stdlib replacement for ``_infer_prefix()``, presumably Apple
wouldn't be able to magically switch between ``osx_framework_library`` and
``posix_prefix``. ``_infer_prefix()`` returning ``osx_framework_library``
means its behavior is consistent whether we use the stdlib implementation
or our own, and we deal with this special case in ``get_scheme()`` instead.

##### _infer_prefix

Try to find a prefix scheme for the current platform.

This tries:

* A special ``osx_framework_library`` for Python distributed by Apple's
  Command Line Tools, when not running in a virtual environment.
* Implementation + OS, used by PyPy on Windows (``pypy_nt``).
* Implementation without OS, used by PyPy on POSIX (``pypy``).
* OS + "prefix", used by CPython on POSIX (``posix_prefix``).
* Just the OS name, used by CPython on Windows (``nt``).

If none of the above works, fall back to ``posix_prefix``.

##### _infer_user

Try to find a user scheme for the current platform.

##### _infer_home

Try to find a home for the current platform.

##### get_scheme

Get the "scheme" corresponding to the input parameters.

:param dist_name: the name of the package to retrieve the scheme for, used
    in the headers scheme path
:param user: indicates to use the "user" scheme
:param home: indicates to use the "home" scheme
:param root: root under which other directories are re-based
:param isolated: ignored, but kept for distutils compatibility (where
    this controls whether the user-site pydistutils.cfg is honored)
:param prefix: indicates to use the "prefix" scheme and provides the
    base directory for the same

**Param√®tres :**

- `dist_name`
- `user`
- `home`
- `root`
- `isolated`
- `prefix`

##### get_bin_prefix

##### get_purelib

##### get_platlib

---

### .!22719!base

---

### base

#### Fonctions

##### get_major_minor_version

Return the major-minor version of the current Python as a string, e.g.
"3.7" or "3.10".

##### change_root

Return 'pathname' with 'new_root' prepended.

If 'pathname' is relative, this is equivalent to os.path.join(new_root, pathname).
Otherwise, it requires making 'pathname' relative and then joining the
two, which is tricky on DOS/Windows and Mac OS.

This is borrowed from Python's standard library's distutils module.

**Param√®tres :**

- `new_root`
- `pathname`

##### get_src_prefix

##### is_osx_framework

---

### .!22706!__init__

---

### .!22710!_distutils

---

### .!22716!_sysconfig

---

### _json

#### Fonctions

##### json_name

**Param√®tres :**

- `field`

##### msg_to_json

Convert a Message object into a JSON-compatible dictionary.

**Param√®tres :**

- `msg`

##### sanitise_header

**Param√®tres :**

- `h`

---

### base

#### Classes

##### BaseEntryPoint

**M√©thodes :**

- `name()`
- `value()`
- `group()`

##### RequiresEntry

##### BaseDistribution

**M√©thodes :**

- `from_directory()`
- `from_metadata_file_contents()`
- `from_wheel()`
- `__repr__()`
- `__str__()`
- `location()`
- `editable_project_location()`
- `installed_location()`
- `info_location()`
- `installed_by_distutils()`
- `installed_as_egg()`
- `installed_with_setuptools_egg_info()`
- `installed_with_dist_info()`
- `canonical_name()`
- `version()`
- `raw_version()`
- `setuptools_filename()`
- `direct_url()`
- `installer()`
- `requested()`
- `editable()`
- `local()`
- `in_usersite()`
- `in_site_packages()`
- `is_file()`
- `iter_distutils_script_names()`
- `read_text()`
- `iter_entry_points()`
- `_metadata_impl()`
- `metadata()`
- `metadata_dict()`
- `metadata_version()`
- `raw_name()`
- `requires_python()`
- `iter_dependencies()`
- `iter_raw_dependencies()`
- `iter_provided_extras()`
- `_iter_declared_entries_from_record()`
- `_iter_declared_entries_from_legacy()`
- `iter_declared_entries()`
- `_iter_requires_txt_entries()`
- `_iter_egg_info_extras()`
- `_iter_egg_info_dependencies()`
- `_add_egg_info_requires()`

##### BaseEnvironment

An environment containing distributions to introspect.

**M√©thodes :**

- `default()`
- `from_paths()`
- `get_distribution()`
- `_iter_distributions()`
- `iter_all_distributions()`
- `iter_installed_distributions()`

##### Wheel

**M√©thodes :**

- `as_zipfile()`

##### FilesystemWheel

**M√©thodes :**

- `__init__()`
- `as_zipfile()`

##### MemoryWheel

**M√©thodes :**

- `__init__()`
- `as_zipfile()`

#### Fonctions

##### _convert_installed_files_path

Convert a legacy installed-files.txt path into modern RECORD path.

The legacy format stores paths relative to the info directory, while the
modern format stores paths relative to the package root, e.g. the
site-packages directory.

:param entry: Path parts of the installed-files.txt entry.
:param info: Path parts of the egg-info directory relative to package root.
:returns: The converted entry.

For best compatibility with symlinks, this does not use ``abspath()`` or
``Path.resolve()``, but tries to work with path parts:

1. While ``entry`` starts with ``..``, remove the equal amounts of parts
   from ``info``; if ``info`` is empty, start appending ``..`` instead.
2. Join the two directly.

**Param√®tres :**

- `entry`
- `info`

##### name

##### value

##### group

##### from_directory

Load the distribution from a metadata directory.

:param directory: Path to a metadata directory, e.g. ``.dist-info``.

**Param√®tres :**

- `cls`
- `directory`

##### from_metadata_file_contents

Load the distribution from the contents of a METADATA file.

This is used to implement PEP 658 by generating a "shallow" dist object that can
be used for resolution without downloading or building the actual dist yet.

:param metadata_contents: The contents of a METADATA file.
:param filename: File name for the dist with this metadata.
:param project_name: Name of the project this dist represents.

**Param√®tres :**

- `cls`
- `metadata_contents`
- `filename`
- `project_name`

##### from_wheel

Load the distribution from a given wheel.

:param wheel: A concrete wheel definition.
:param name: File name of the wheel.

:raises InvalidWheel: Whenever loading of the wheel causes a
    :py:exc:`zipfile.BadZipFile` exception to be thrown.
:raises UnsupportedWheel: If the wheel is a valid zip, but malformed
    internally.

**Param√®tres :**

- `cls`
- `wheel`
- `name`

##### __repr__

##### __str__

##### location

Where the distribution is loaded from.

A string value is not necessarily a filesystem path, since distributions
can be loaded from other sources, e.g. arbitrary zip archives. ``None``
means the distribution is created in-memory.

Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
this is a symbolic link, we want to preserve the relative path between
it and files in the distribution.

##### editable_project_location

The project location for editable distributions.

This is the directory where pyproject.toml or setup.py is located.
None if the distribution is not installed in editable mode.

##### installed_location

The distribution's "installed" location.

This should generally be a ``site-packages`` directory. This is
usually ``dist.location``, except for legacy develop-installed packages,
where ``dist.location`` is the source code location, and this is where
the ``.egg-link`` file is.

The returned location is normalized (in particular, with symlinks removed).

##### info_location

Location of the .[egg|dist]-info directory or file.

Similarly to ``location``, a string value is not necessarily a
filesystem path. ``None`` means the distribution is created in-memory.

For a modern .dist-info installation on disk, this should be something
like ``{location}/{raw_name}-{version}.dist-info``.

Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
this is a symbolic link, we want to preserve the relative path between
it and other files in the distribution.

##### installed_by_distutils

Whether this distribution is installed with legacy distutils format.

A distribution installed with "raw" distutils not patched by setuptools
uses one single file at ``info_location`` to store metadata. We need to
treat this specially on uninstallation.

##### installed_as_egg

Whether this distribution is installed as an egg.

This usually indicates the distribution was installed by (older versions
of) easy_install.

##### installed_with_setuptools_egg_info

Whether this distribution is installed with the ``.egg-info`` format.

This usually indicates the distribution was installed with setuptools
with an old pip version or with ``single-version-externally-managed``.

Note that this ensure the metadata store is a directory. distutils can
also installs an ``.egg-info``, but as a file, not a directory. This
property is *False* for that case. Also see ``installed_by_distutils``.

##### installed_with_dist_info

Whether this distribution is installed with the "modern format".

This indicates a "modern" installation, e.g. storing metadata in the
``.dist-info`` directory. This applies to installations made by
setuptools (but through pip, not directly), or anything using the
standardized build backend interface (PEP 517).

##### canonical_name

##### version

##### raw_version

##### setuptools_filename

Convert a project name to its setuptools-compatible filename.

This is a copy of ``pkg_resources.to_filename()`` for compatibility.

##### direct_url

Obtain a DirectUrl from this distribution.

Returns None if the distribution has no `direct_url.json` metadata,
or if `direct_url.json` is invalid.

##### installer

##### requested

##### editable

##### local

If distribution is installed in the current virtual environment.

Always True if we're not in a virtualenv.

##### in_usersite

##### in_site_packages

##### is_file

Check whether an entry in the info directory is a file.

**Param√®tres :**

- `path`

##### iter_distutils_script_names

Find distutils 'scripts' entries metadata.

If 'scripts' is supplied in ``setup.py``, distutils records those in the
installed distribution's ``scripts`` directory, a file for each script.

##### read_text

Read a file in the info directory.

:raise FileNotFoundError: If ``path`` does not exist in the directory.
:raise NoneMetadataError: If ``path`` exists in the info directory, but
    cannot be read.

**Param√®tres :**

- `path`

##### iter_entry_points

##### _metadata_impl

##### metadata

Metadata of distribution parsed from e.g. METADATA or PKG-INFO.

This should return an empty message if the metadata file is unavailable.

:raises NoneMetadataError: If the metadata file is available, but does
    not contain valid metadata.

##### metadata_dict

PEP 566 compliant JSON-serializable representation of METADATA or PKG-INFO.

This should return an empty dict if the metadata file is unavailable.

:raises NoneMetadataError: If the metadata file is available, but does
    not contain valid metadata.

##### metadata_version

Value of "Metadata-Version:" in distribution metadata, if available.

##### raw_name

Value of "Name:" in distribution metadata.

##### requires_python

Value of "Requires-Python:" in distribution metadata.

If the key does not exist or contains an invalid value, an empty
SpecifierSet should be returned.

##### iter_dependencies

Dependencies of this distribution.

For modern .dist-info distributions, this is the collection of
"Requires-Dist:" entries in distribution metadata.

**Param√®tres :**

- `extras`

##### iter_raw_dependencies

Raw Requires-Dist metadata.

##### iter_provided_extras

Extras provided by this distribution.

For modern .dist-info distributions, this is the collection of
"Provides-Extra:" entries in distribution metadata.

The return value of this function is expected to be normalised names,
per PEP 685, with the returned value being handled appropriately by
`iter_dependencies`.

##### _iter_declared_entries_from_record

##### _iter_declared_entries_from_legacy

##### iter_declared_entries

Iterate through file entries declared in this distribution.

For modern .dist-info distributions, this is the files listed in the
``RECORD`` metadata file. For legacy setuptools distributions, this
comes from ``installed-files.txt``, with entries normalized to be
compatible with the format used by ``RECORD``.

:return: An iterator for listed entries, or None if the distribution
    contains neither ``RECORD`` nor ``installed-files.txt``.

##### _iter_requires_txt_entries

Parse a ``requires.txt`` in an egg-info directory.

This is an INI-ish format where an egg-info stores dependencies. A
section name describes extra other environment markers, while each entry
is an arbitrary string (not a key-value pair) representing a dependency
as a requirement string (no markers).

There is a construct in ``importlib.metadata`` called ``Sectioned`` that
does mostly the same, but the format is currently considered private.

##### _iter_egg_info_extras

Get extras from the egg-info directory.

##### _iter_egg_info_dependencies

Get distribution dependencies from the egg-info directory.

To ease parsing, this converts a legacy dependency entry into a PEP 508
requirement string. Like ``_iter_requires_txt_entries()``, there is code
in ``importlib.metadata`` that does mostly the same, but not do exactly
what we need.

Namely, ``importlib.metadata`` does not normalize the extra name before
putting it into the requirement string, which causes marker comparison
to fail because the dist-info format do normalize. This is consistent in
all currently available PEP 517 backends, although not standardized.

##### _add_egg_info_requires

Add egg-info requires.txt information to the metadata.

**Param√®tres :**

- `metadata`

##### default

**Param√®tres :**

- `cls`

##### from_paths

**Param√®tres :**

- `cls`
- `paths`

##### get_distribution

Given a requirement name, return the installed distributions.

The name may not be normalized. The implementation must canonicalize
it for lookup.

**Param√®tres :**

- `name`

##### _iter_distributions

Iterate through installed distributions.

This function should be implemented by subclass, but never called
directly. Use the public ``iter_distribution()`` instead, which
implements additional logic to make sure the distributions are valid.

##### iter_all_distributions

Iterate through all installed distributions without any filtering.

##### iter_installed_distributions

Return a list of installed distributions.

This is based on ``iter_all_distributions()`` with additional filtering
options. Note that ``iter_installed_distributions()`` without arguments
is *not* equal to ``iter_all_distributions()``, since some of the
configurations exclude packages by default.

:param local_only: If True (default), only return installations
local to the current virtualenv, if in a virtualenv.
:param skip: An iterable of canonicalized project names to ignore;
    defaults to ``stdlib_pkgs``.
:param include_editables: If False, don't report editables.
:param editables_only: If True, only report editables.
:param user_only: If True, only report installations in the user
site directory.

**Param√®tres :**

- `local_only`
- `skip`
- `include_editables`
- `editables_only`
- `user_only`

##### as_zipfile

##### __init__

**Param√®tres :**

- `location`

##### as_zipfile

##### __init__

**Param√®tres :**

- `location`
- `stream`

##### as_zipfile

---

### .!22733!base

---

### pkg_resources

#### Classes

##### EntryPoint

##### InMemoryMetadata

IMetadataProvider that reads metadata files from a dictionary.

This also maps metadata decoding exceptions to our internal exception type.

**M√©thodes :**

- `__init__()`
- `has_metadata()`
- `get_metadata()`
- `get_metadata_lines()`
- `metadata_isdir()`
- `metadata_listdir()`
- `run_script()`

##### Distribution

**M√©thodes :**

- `__init__()`
- `_extra_mapping()`
- `from_directory()`
- `from_metadata_file_contents()`
- `from_wheel()`
- `location()`
- `installed_location()`
- `info_location()`
- `installed_by_distutils()`
- `canonical_name()`
- `version()`
- `raw_version()`
- `is_file()`
- `iter_distutils_script_names()`
- `read_text()`
- `iter_entry_points()`
- `_metadata_impl()`
- `iter_dependencies()`
- `iter_provided_extras()`

##### Environment

**M√©thodes :**

- `__init__()`
- `default()`
- `from_paths()`
- `_iter_distributions()`
- `_search_distribution()`
- `get_distribution()`

#### Fonctions

##### __init__

**Param√®tres :**

- `metadata`
- `wheel_name`

##### has_metadata

**Param√®tres :**

- `name`

##### get_metadata

**Param√®tres :**

- `name`

##### get_metadata_lines

**Param√®tres :**

- `name`

##### metadata_isdir

**Param√®tres :**

- `name`

##### metadata_listdir

**Param√®tres :**

- `name`

##### run_script

**Param√®tres :**

- `script_name`
- `namespace`

##### __init__

**Param√®tres :**

- `dist`

##### _extra_mapping

##### from_directory

**Param√®tres :**

- `cls`
- `directory`

##### from_metadata_file_contents

**Param√®tres :**

- `cls`
- `metadata_contents`
- `filename`
- `project_name`

##### from_wheel

**Param√®tres :**

- `cls`
- `wheel`
- `name`

##### location

##### installed_location

##### info_location

##### installed_by_distutils

##### canonical_name

##### version

##### raw_version

##### is_file

**Param√®tres :**

- `path`

##### iter_distutils_script_names

##### read_text

**Param√®tres :**

- `path`

##### iter_entry_points

##### _metadata_impl

:raises NoneMetadataError: if the distribution reports `has_metadata()`
    True but `get_metadata()` returns None.

##### iter_dependencies

**Param√®tres :**

- `extras`

##### iter_provided_extras

##### __init__

**Param√®tres :**

- `ws`

##### default

**Param√®tres :**

- `cls`

##### from_paths

**Param√®tres :**

- `cls`
- `paths`

##### _iter_distributions

##### _search_distribution

Find a distribution matching the ``name`` in the environment.

This searches from *all* distributions available in the environment, to
match the behavior of ``pkg_resources.get_distribution()``.

**Param√®tres :**

- `name`

##### get_distribution

**Param√®tres :**

- `name`

---

### .!22724!__init__

---

### .!22730!_json

---

### .!22741!pkg_resources

---

### _compat

#### Classes

##### BadMetadata

**M√©thodes :**

- `__init__()`
- `__str__()`

##### BasePath

A protocol that various path objects conform.

This exists because importlib.metadata uses both ``pathlib.Path`` and
``zipfile.Path``, and we need a common base for type hints (Union does not
work well since ``zipfile.Path`` is too new for our linter setup).

This does not mean to be exhaustive, but only contains things that present
in both classes *that we need*.

**M√©thodes :**

- `name()`
- `parent()`

#### Fonctions

##### get_info_location

Find the path to the distribution's metadata directory.

HACK: This relies on importlib.metadata's private ``_path`` attribute. Not
all distributions exist on disk, so importlib.metadata is correct to not
expose the attribute as public. But pip's code base is old and not as clean,
so we do this to avoid having to rewrite too many things. Hopefully we can
eliminate this some day.

**Param√®tres :**

- `d`

##### parse_name_and_version_from_info_directory

Get a name and version from the metadata directory name.

This is much faster than reading distribution metadata.

**Param√®tres :**

- `dist`

##### get_dist_canonical_name

Get the distribution's normalized name.

The ``name`` attribute is only available in Python 3.10 or later. We are
targeting exactly that, but Mypy does not know this.

**Param√®tres :**

- `dist`

##### __init__

**Param√®tres :**

- `dist`

##### __str__

##### name

##### parent

---

### _dists

#### Classes

##### WheelDistribution

An ``importlib.metadata.Distribution`` read from a wheel.

Although ``importlib.metadata.PathDistribution`` accepts ``zipfile.Path``,
its implementation is too "lazy" for pip's needs (we can't keep the ZipFile
handle open for the entire lifetime of the distribution object).

This implementation eagerly reads the entire metadata directory into the
memory instead, and operates from that.

**M√©thodes :**

- `__init__()`
- `from_zipfile()`
- `iterdir()`
- `read_text()`
- `locate_file()`

##### Distribution

**M√©thodes :**

- `__init__()`
- `from_directory()`
- `from_metadata_file_contents()`
- `from_wheel()`
- `location()`
- `info_location()`
- `installed_location()`
- `canonical_name()`
- `version()`
- `raw_version()`
- `is_file()`
- `iter_distutils_script_names()`
- `read_text()`
- `iter_entry_points()`
- `_metadata_impl()`
- `iter_provided_extras()`
- `iter_dependencies()`

#### Fonctions

##### __init__

**Param√®tres :**

- `files`
- `info_location`

##### from_zipfile

**Param√®tres :**

- `cls`
- `zf`
- `name`
- `location`

##### iterdir

**Param√®tres :**

- `path`

##### read_text

**Param√®tres :**

- `filename`

##### locate_file

**Param√®tres :**

- `path`

##### __init__

**Param√®tres :**

- `dist`
- `info_location`
- `installed_location`

##### from_directory

**Param√®tres :**

- `cls`
- `directory`

##### from_metadata_file_contents

**Param√®tres :**

- `cls`
- `metadata_contents`
- `filename`
- `project_name`

##### from_wheel

**Param√®tres :**

- `cls`
- `wheel`
- `name`

##### location

##### info_location

##### installed_location

##### canonical_name

##### version

##### raw_version

##### is_file

**Param√®tres :**

- `path`

##### iter_distutils_script_names

##### read_text

**Param√®tres :**

- `path`

##### iter_entry_points

##### _metadata_impl

##### iter_provided_extras

##### iter_dependencies

**Param√®tres :**

- `extras`

---

### _envs

#### Classes

##### _DistributionFinder

Finder to locate distributions.

The main purpose of this class is to memoize found distributions' names, so
only one distribution is returned for each package name. At lot of pip code
assumes this (because it is setuptools's behavior), and not doing the same
can potentially cause a distribution in lower precedence path to override a
higher precedence one if the caller is not careful.

Eventually we probably want to make it possible to see lower precedence
installations as well. It's useful feature, after all.

**M√©thodes :**

- `__init__()`
- `_find_impl()`
- `find()`
- `find_legacy_editables()`

##### Environment

**M√©thodes :**

- `__init__()`
- `default()`
- `from_paths()`
- `_iter_distributions()`
- `get_distribution()`

#### Fonctions

##### _looks_like_wheel

**Param√®tres :**

- `location`

##### __init__

##### _find_impl

Find distributions in a location.

**Param√®tres :**

- `location`

##### find

Find distributions in a location.

The path can be either a directory, or a ZIP archive.

**Param√®tres :**

- `location`

##### find_legacy_editables

Read location in egg-link files and return distributions in there.

The path should be a directory; otherwise this returns nothing. This
follows how setuptools does this for compatibility. The first non-empty
line in the egg-link is read as a path (resolved against the egg-link's
containing directory if relative). Distributions found at that linked
location are returned.

**Param√®tres :**

- `location`

##### __init__

**Param√®tres :**

- `paths`

##### default

**Param√®tres :**

- `cls`

##### from_paths

**Param√®tres :**

- `cls`
- `paths`

##### _iter_distributions

##### get_distribution

**Param√®tres :**

- `name`

---

### .!22747!__init__

---

### .!22752!_compat

---

### .!22757!_dists

---

### .!22760!_envs

---

### candidate

#### Classes

##### InstallationCandidate

Represents a potential "candidate" for installation.

**M√©thodes :**

- `__init__()`
- `__str__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `name`
- `version`
- `link`

##### __str__

---

### direct_url

PEP 610

#### Classes

##### DirectUrlValidationError

##### VcsInfo

**M√©thodes :**

- `_from_dict()`
- `_to_dict()`

##### ArchiveInfo

**M√©thodes :**

- `__init__()`
- `hash()`
- `hash()`
- `_from_dict()`
- `_to_dict()`

##### DirInfo

**M√©thodes :**

- `_from_dict()`
- `_to_dict()`

##### DirectUrl

**M√©thodes :**

- `_remove_auth_from_netloc()`
- `redacted_url()`
- `validate()`
- `from_dict()`
- `to_dict()`
- `from_json()`
- `to_json()`
- `is_local_editable()`

#### Fonctions

##### _get

Get value from dictionary and verify expected type.

**Param√®tres :**

- `d`
- `expected_type`
- `key`
- `default`

##### _get_required

**Param√®tres :**

- `d`
- `expected_type`
- `key`
- `default`

##### _exactly_one_of

**Param√®tres :**

- `infos`

##### _filter_none

Make dict excluding None values.

##### _from_dict

**Param√®tres :**

- `cls`
- `d`

##### _to_dict

##### __init__

**Param√®tres :**

- `hash`
- `hashes`

##### hash

##### hash

**Param√®tres :**

- `value`

##### _from_dict

**Param√®tres :**

- `cls`
- `d`

##### _to_dict

##### _from_dict

**Param√®tres :**

- `cls`
- `d`

##### _to_dict

##### _remove_auth_from_netloc

**Param√®tres :**

- `netloc`

##### redacted_url

url with user:password part removed unless it is formed with
environment variables as specified in PEP 610, or it is ``git``
in the case of a git URL.

##### validate

##### from_dict

**Param√®tres :**

- `cls`
- `d`

##### to_dict

##### from_json

**Param√®tres :**

- `cls`
- `s`

##### to_json

##### is_local_editable

---

### .!22795!link

---

### format_control

#### Classes

##### FormatControl

Helper for managing formats from which a package can be installed.

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `__repr__()`
- `handle_mutual_excludes()`
- `get_allowed_formats()`
- `disallow_binaries()`

#### Fonctions

##### __init__

**Param√®tres :**

- `no_binary`
- `only_binary`

##### __eq__

**Param√®tres :**

- `other`

##### __repr__

##### handle_mutual_excludes

**Param√®tres :**

- `value`
- `target`
- `other`

##### get_allowed_formats

**Param√®tres :**

- `canonical_name`

##### disallow_binaries

---

### index

#### Classes

##### PackageIndex

Represents a Package Index and provides easier access to endpoints

**M√©thodes :**

- `__init__()`
- `_url_for_path()`

#### Fonctions

##### __init__

**Param√®tres :**

- `url`
- `file_storage_domain`

##### _url_for_path

**Param√®tres :**

- `path`

---

### installation_report

#### Classes

##### InstallationReport

**M√©thodes :**

- `__init__()`
- `_install_req_to_dict()`
- `to_dict()`

#### Fonctions

##### __init__

**Param√®tres :**

- `install_requirements`

##### _install_req_to_dict

**Param√®tres :**

- `cls`
- `ireq`

##### to_dict

---

### link

#### Classes

##### LinkHash

Links to content may have embedded hash values. This class parses those.

`name` must be any member of `_SUPPORTED_HASHES`.

This class can be converted to and from `ArchiveInfo`. While ArchiveInfo intends to
be JSON-serializable to conform to PEP 610, this class contains the logic for
parsing a hash name and value for correctness, and then checking whether that hash
conforms to a schema with `.is_hash_allowed()`.

**M√©thodes :**

- `__post_init__()`
- `find_hash_url_fragment()`
- `as_dict()`
- `as_hashes()`
- `is_hash_allowed()`

##### MetadataFile

Information about a core metadata file associated with a distribution.

**M√©thodes :**

- `__post_init__()`

##### Link

Represents a parsed link from a Package Index's simple URL

**M√©thodes :**

- `__init__()`
- `from_json()`
- `from_element()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `__lt__()`
- `url()`
- `redacted_url()`
- `filename()`
- `file_path()`
- `scheme()`
- `netloc()`
- `path()`
- `splitext()`
- `ext()`
- `url_without_fragment()`
- `_egg_fragment()`
- `subdirectory_fragment()`
- `metadata_link()`
- `as_hashes()`
- `hash()`
- `hash_name()`
- `show_url()`
- `is_file()`
- `is_existing_dir()`
- `is_wheel()`
- `is_vcs()`
- `is_yanked()`
- `has_hash()`
- `is_hash_allowed()`

##### _CleanResult

Convert link for equivalency check.

This is used in the resolver to check whether two URL-specified requirements
likely point to the same distribution and can be considered equivalent. This
equivalency logic avoids comparing URLs literally, which can be too strict
(e.g. "a=1&b=2" vs "b=2&a=1") and produce conflicts unexpecting to users.

Currently this does three things:

1. Drop the basic auth part. This is technically wrong since a server can
   serve different content based on auth, but if it does that, it is even
   impossible to guarantee two URLs without auth are equivalent, since
   the user can input different auth information when prompted. So the
   practical solution is to assume the auth doesn't affect the response.
2. Parse the query to avoid the ordering issue. Note that ordering under the
   same key in the query are NOT cleaned; i.e. "a=1&a=2" and "a=2&a=1" are
   still considered different.
3. Explicitly drop most of the fragment part, except ``subdirectory=`` and
   hash values, since it should have no impact the downloaded content. Note
   that this drops the "egg=" part historically used to denote the requested
   project (and extras), which is wrong in the strictest sense, but too many
   people are supplying it inconsistently to cause superfluous resolution
   conflicts, so we choose to also ignore them.

#### Fonctions

##### supported_hashes

**Param√®tres :**

- `hashes`

##### _clean_url_path_part

Clean a "part" of a URL path (i.e. after splitting on "@" characters).

**Param√®tres :**

- `part`

##### _clean_file_url_path

Clean the first part of a URL path that corresponds to a local
filesystem path (i.e. the first part after splitting on "@" characters).

**Param√®tres :**

- `part`

##### _clean_url_path

Clean the path portion of a URL.

**Param√®tres :**

- `path`
- `is_local_path`

##### _ensure_quoted_url

Make sure a link is fully quoted.
For example, if ' ' occurs in the URL, it will be replaced with "%20",
and without double-quoting other characters.

**Param√®tres :**

- `url`

##### _absolute_link_url

A faster implementation of urllib.parse.urljoin with a shortcut
for absolute http/https URLs.

**Param√®tres :**

- `base_url`
- `url`

##### _clean_link

**Param√®tres :**

- `link`

##### links_equivalent

**Param√®tres :**

- `link1`
- `link2`

##### __post_init__

##### find_hash_url_fragment

Search a string for a checksum algorithm name and encoded output value.

**Param√®tres :**

- `cls`
- `url`

##### as_dict

##### as_hashes

Return a Hashes instance which checks only for the current hash.

##### is_hash_allowed

Return True if the current hash is allowed by `hashes`.

**Param√®tres :**

- `hashes`

##### __post_init__

##### __init__

:param url: url of the resource pointed to (href of the link)
:param comes_from: instance of IndexContent where the link was found,
    or string.
:param requires_python: String containing the `Requires-Python`
    metadata field, specified in PEP 345. This may be specified by
    a data-requires-python attribute in the HTML link tag, as
    described in PEP 503.
:param yanked_reason: the reason the file has been yanked, if the
    file has been yanked, or None if the file hasn't been yanked.
    This is the value of the "data-yanked" attribute, if present, in
    a simple repository HTML link. If the file has been yanked but
    no reason was provided, this should be the empty string. See
    PEP 592 for more information and the specification.
:param metadata_file_data: the metadata attached to the file, or None if
    no such metadata is provided. This argument, if not None, indicates
    that a separate metadata file exists, and also optionally supplies
    hashes for that file.
:param cache_link_parsing: A flag that is used elsewhere to determine
    whether resources retrieved from this link should be cached. PyPI
    URLs should generally have this set to False, for example.
:param hashes: A mapping of hash names to digests to allow us to
    determine the validity of a download.

**Param√®tres :**

- `url`
- `comes_from`
- `requires_python`
- `yanked_reason`
- `metadata_file_data`
- `cache_link_parsing`
- `hashes`

##### from_json

Convert an pypi json document from a simple repository page into a Link.

**Param√®tres :**

- `cls`
- `file_data`
- `page_url`

##### from_element

Convert an anchor element's attributes in a simple repository page to a Link.

**Param√®tres :**

- `cls`
- `anchor_attribs`
- `page_url`
- `base_url`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __lt__

**Param√®tres :**

- `other`

##### url

##### redacted_url

##### filename

##### file_path

##### scheme

##### netloc

This can contain auth information.

##### path

##### splitext

##### ext

##### url_without_fragment

##### _egg_fragment

##### subdirectory_fragment

##### metadata_link

Return a link to the associated core metadata file (if any).

##### as_hashes

##### hash

##### hash_name

##### show_url

##### is_file

##### is_existing_dir

##### is_wheel

##### is_vcs

##### is_yanked

##### has_hash

##### is_hash_allowed

Return True if the link has a hash and it is allowed by `hashes`.

**Param√®tres :**

- `hashes`

---

### pylock

#### Classes

##### PackageVcs

##### PackageDirectory

##### PackageArchive

##### PackageSdist

##### PackageWheel

##### Package

**M√©thodes :**

- `from_install_requirement()`

##### Pylock

**M√©thodes :**

- `as_toml()`
- `from_install_requirements()`

#### Fonctions

##### is_valid_pylock_file_name

**Param√®tres :**

- `path`

##### _toml_dict_factory

**Param√®tres :**

- `data`

##### from_install_requirement

**Param√®tres :**

- `cls`
- `ireq`
- `base_dir`

##### as_toml

##### from_install_requirements

**Param√®tres :**

- `cls`
- `install_requirements`
- `base_dir`

---

### scheme

For types associated with installation schemes.

For a general overview of available schemes and their context, see
https://docs.python.org/3/install/index.html#alternate-installation.

#### Classes

##### Scheme

A Scheme holds paths which are used as the base directories for
artifacts associated with a Python package.

---

### search_scope

#### Classes

##### SearchScope

Encapsulates the locations that pip is configured to search.

**M√©thodes :**

- `create()`
- `get_formatted_locations()`
- `get_index_urls_locations()`

#### Fonctions

##### create

Create a SearchScope object after normalizing the `find_links`.

**Param√®tres :**

- `cls`
- `find_links`
- `index_urls`
- `no_index`

##### get_formatted_locations

##### get_index_urls_locations

Returns the locations found via self.index_urls

Checks the url_name on the main (first in the list) index and
use this url_name to produce all locations

**Param√®tres :**

- `project_name`

##### mkurl_pypi_url

**Param√®tres :**

- `url`

---

### selection_prefs

#### Classes

##### SelectionPreferences

Encapsulates the candidate selection preferences for downloading
and installing files.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

Create a SelectionPreferences object.

:param allow_yanked: Whether files marked as yanked (in the sense
    of PEP 592) are permitted to be candidates for install.
:param format_control: A FormatControl object or None. Used to control
    the selection of source packages / binary packages when consulting
    the index and links.
:param prefer_binary: Whether to prefer an old, but valid, binary
    dist over a new source dist.
:param ignore_requires_python: Whether to ignore incompatible
    "Requires-Python" values in links. Defaults to False.

**Param√®tres :**

- `allow_yanked`
- `allow_all_prereleases`
- `format_control`
- `prefer_binary`
- `ignore_requires_python`

---

### target_python

#### Classes

##### TargetPython

Encapsulates the properties of a Python interpreter one is targeting
for a package install, download, etc.

**M√©thodes :**

- `__init__()`
- `format_given()`
- `get_sorted_tags()`
- `get_unsorted_tags()`

#### Fonctions

##### __init__

:param platforms: A list of strings or None. If None, searches for
    packages that are supported by the current system. Otherwise, will
    find packages that can be built on the platforms passed in. These
    packages will only be downloaded for distribution: they will
    not be built locally.
:param py_version_info: An optional tuple of ints representing the
    Python version information to use (e.g. `sys.version_info[:3]`).
    This can have length 1, 2, or 3 when provided.
:param abis: A list of strings or None. This is passed to
    compatibility_tags.py's get_supported() function as is.
:param implementation: A string or None. This is passed to
    compatibility_tags.py's get_supported() function as is.

**Param√®tres :**

- `platforms`
- `py_version_info`
- `abis`
- `implementation`

##### format_given

Format the given, non-None attributes for display.

##### get_sorted_tags

Return the supported PEP 425 tags to check wheel candidates against.

The tags are returned in order of preference (most preferred first).

##### get_unsorted_tags

Exactly the same as get_sorted_tags, but returns a set.

This is important for performance.

---

### wheel

Represents a wheel file and provides access to the various parts of the
name that have meaning.

#### Classes

##### Wheel

A wheel file

**M√©thodes :**

- `__init__()`
- `build_tag()`
- `get_formatted_file_tags()`
- `support_index_min()`
- `find_most_preferred_tag()`
- `supported()`

#### Fonctions

##### __init__

**Param√®tres :**

- `filename`

##### build_tag

##### get_formatted_file_tags

Return the wheel's tags as a sorted list of strings.

##### support_index_min

Return the lowest index that one of the wheel's file_tag combinations
achieves in the given list of supported tags.

For example, if there are 8 supported tags and one of the file tags
is first in the list, then return 0.

:param tags: the PEP 425 tags to check the wheel against, in order
    with most preferred first.

:raises ValueError: If none of the wheel's file tags match one of
    the supported tags.

**Param√®tres :**

- `tags`

##### find_most_preferred_tag

Return the priority of the most preferred tag that one of the wheel's file
tag combinations achieves in the given list of supported tags using the given
tag_to_priority mapping, where lower priorities are more-preferred.

This is used in place of support_index_min in some cases in order to avoid
an expensive linear scan of a large list of tags.

:param tags: the PEP 425 tags to check the wheel against.
:param tag_to_priority: a mapping from tag to priority of that tag, where
    lower is more preferred.

:raises ValueError: If none of the wheel's file tags match one of
    the supported tags.

**Param√®tres :**

- `tags`
- `tag_to_priority`

##### supported

Return whether the wheel is compatible with one of the given tags.

:param tags: the PEP 425 tags to check the wheel against.

**Param√®tres :**

- `tags`

---

### .!22766!__init__

---

### .!22770!candidate

---

### .!22775!direct_url

---

### .!22780!format_control

---

### .!22785!index

---

### .!22788!installation_report

---

### .!22800!pylock

---

### .!22806!scheme

---

### .!22810!search_scope

---

### .!22814!selection_prefs

---

### .!22818!target_python

---

### .!22823!wheel

---

### auth

Network Authentication Helpers

Contains interface (MultiDomainBasicAuth) and associated glue code for
providing credentials in the context of network requests.

#### Classes

##### Credentials

##### KeyRingBaseProvider

Keyring base provider interface

**M√©thodes :**

- `get_auth_info()`
- `save_auth_info()`

##### KeyRingNullProvider

Keyring null provider

**M√©thodes :**

- `get_auth_info()`
- `save_auth_info()`

##### KeyRingPythonProvider

Keyring interface which uses locally imported `keyring`

**M√©thodes :**

- `__init__()`
- `get_auth_info()`
- `save_auth_info()`

##### KeyRingCliProvider

Provider which uses `keyring` cli

Instead of calling the keyring package installed alongside pip
we call keyring on the command line which will enable pip to
use which ever installation of keyring is available first in
PATH.

**M√©thodes :**

- `__init__()`
- `get_auth_info()`
- `save_auth_info()`
- `_get_password()`
- `_set_password()`

##### MultiDomainBasicAuth

**M√©thodes :**

- `__init__()`
- `keyring_provider()`
- `keyring_provider()`
- `use_keyring()`
- `_get_keyring_auth()`
- `_get_index_url()`
- `_get_new_credentials()`
- `_get_url_and_credentials()`
- `__call__()`
- `_prompt_for_password()`
- `_should_save_password_to_keyring()`
- `handle_401()`
- `warn_on_401()`
- `save_credentials()`

#### Fonctions

##### get_keyring_provider

**Param√®tres :**

- `provider`

##### get_auth_info

**Param√®tres :**

- `url`
- `username`

##### save_auth_info

**Param√®tres :**

- `url`
- `username`
- `password`

##### get_auth_info

**Param√®tres :**

- `url`
- `username`

##### save_auth_info

**Param√®tres :**

- `url`
- `username`
- `password`

##### __init__

##### get_auth_info

**Param√®tres :**

- `url`
- `username`

##### save_auth_info

**Param√®tres :**

- `url`
- `username`
- `password`

##### __init__

**Param√®tres :**

- `cmd`

##### get_auth_info

**Param√®tres :**

- `url`
- `username`

##### save_auth_info

**Param√®tres :**

- `url`
- `username`
- `password`

##### _get_password

Mirror the implementation of keyring.get_password using cli

**Param√®tres :**

- `service_name`
- `username`

##### _set_password

Mirror the implementation of keyring.set_password using cli

**Param√®tres :**

- `service_name`
- `username`
- `password`

##### __init__

**Param√®tres :**

- `prompting`
- `index_urls`
- `keyring_provider`

##### keyring_provider

##### keyring_provider

**Param√®tres :**

- `provider`

##### use_keyring

##### _get_keyring_auth

Return the tuple auth for a given url from keyring.

**Param√®tres :**

- `url`
- `username`

##### _get_index_url

Return the original index URL matching the requested URL.

Cached or dynamically generated credentials may work against
the original index URL rather than just the netloc.

The provided url should have had its username and password
removed already. If the original index url had credentials then
they will be included in the return value.

Returns None if no matching index was found, or if --no-index
was specified by the user.

**Param√®tres :**

- `url`

##### _get_new_credentials

Find and return credentials for the specified URL.

**Param√®tres :**

- `original_url`

##### _get_url_and_credentials

Return the credentials to use for the provided URL.

If allowed, netrc and keyring may be used to obtain the
correct credentials.

Returns (url_without_credentials, username, password). Note
that even if the original URL contains credentials, this
function may return a different username and password.

**Param√®tres :**

- `original_url`

##### __call__

**Param√®tres :**

- `req`

##### _prompt_for_password

**Param√®tres :**

- `netloc`

##### _should_save_password_to_keyring

##### handle_401

**Param√®tres :**

- `resp`

##### warn_on_401

Response callback to warn about incorrect credentials.

**Param√®tres :**

- `resp`

##### save_credentials

Response callback to save credentials on success.

**Param√®tres :**

- `resp`

##### PATH_as_shutil_which_determines_it

---

### cache

HTTP cache implementation.

#### Classes

##### SafeFileCache

A file based cache which is safe to use even when the target directory may
not be accessible or writable.

There is a race condition when two processes try to write and/or read the
same entry at the same time, since each entry consists of two separate
files (https://github.com/psf/cachecontrol/issues/324).  We therefore have
additional logic that makes sure that both files to be present before
returning an entry; this fixes the read side of the race condition.

For the write side, we assume that the server will only ever return the
same data for the same URL, which ought to be the case for files pip is
downloading.  PyPI does not have a mechanism to swap out a wheel for
another wheel, for example.  If this assumption is not true, the
CacheControl issue will need to be fixed.

**M√©thodes :**

- `__init__()`
- `_get_cache_path()`
- `get()`
- `_write()`
- `set()`
- `delete()`
- `get_body()`
- `set_body()`

#### Fonctions

##### is_from_cache

**Param√®tres :**

- `response`

##### suppressed_cache_errors

If we can't access the cache then we can just skip caching and process
requests as if caching wasn't enabled.

##### __init__

**Param√®tres :**

- `directory`

##### _get_cache_path

**Param√®tres :**

- `name`

##### get

**Param√®tres :**

- `key`

##### _write

**Param√®tres :**

- `path`
- `data`

##### set

**Param√®tres :**

- `key`
- `value`
- `expires`

##### delete

**Param√®tres :**

- `key`

##### get_body

**Param√®tres :**

- `key`

##### set_body

**Param√®tres :**

- `key`
- `body`

---

### .!22835!auth

---

### download

Download files with progress indicators.

#### Classes

##### Downloader

**M√©thodes :**

- `__init__()`
- `__call__()`
- `_process_response()`
- `_write_chunks_to_file()`
- `_attempt_resume()`
- `_reset_download_state()`

##### BatchDownloader

**M√©thodes :**

- `__init__()`
- `__call__()`

#### Fonctions

##### _get_http_response_size

**Param√®tres :**

- `resp`

##### _get_http_response_etag_or_last_modified

Return either the ETag or Last-Modified header (or None if neither exists).
The return value can be used in an If-Range header.

**Param√®tres :**

- `resp`

##### _prepare_download

**Param√®tres :**

- `resp`
- `link`
- `progress_bar`
- `total_length`
- `range_start`

##### sanitize_content_filename

Sanitize the "filename" value from a Content-Disposition header.

**Param√®tres :**

- `filename`

##### parse_content_disposition

Parse the "filename" value from a Content-Disposition header, and
return the default filename if the result is empty.

**Param√®tres :**

- `content_disposition`
- `default_filename`

##### _get_http_response_filename

Get an ideal filename from the given HTTP response, falling back to
the link filename if not provided.

**Param√®tres :**

- `resp`
- `link`

##### _http_get_download

**Param√®tres :**

- `session`
- `link`
- `range_start`
- `if_range`

##### __init__

**Param√®tres :**

- `session`
- `progress_bar`
- `resume_retries`

##### __call__

Download the file given by link into location.

**Param√®tres :**

- `link`
- `location`

##### _process_response

Process the response and write the chunks to the file.

**Param√®tres :**

- `resp`
- `link`
- `content_file`
- `bytes_received`
- `total_length`

##### _write_chunks_to_file

Write the chunks to the file and return the number of bytes received.

**Param√®tres :**

- `chunks`
- `content_file`

##### _attempt_resume

Attempt to resume the download if connection was dropped.

**Param√®tres :**

- `resp`
- `link`
- `content_file`
- `total_length`
- `bytes_received`

##### _reset_download_state

Reset the download state to restart downloading from the beginning.

**Param√®tres :**

- `resp`
- `content_file`

##### __init__

**Param√®tres :**

- `session`
- `progress_bar`
- `resume_retries`

##### __call__

Download the files given by links into location.

**Param√®tres :**

- `links`
- `location`

---

### lazy_wheel

Lazy ZIP over HTTP

#### Classes

##### HTTPRangeRequestUnsupported

##### LazyZipOverHTTP

File-like object mapped to a ZIP file over HTTP.

This uses HTTP range requests to lazily fetch the file's content,
which is supposed to be fed to ZipFile.  If such requests are not
supported by the server, raise HTTPRangeRequestUnsupported
during initialization.

**M√©thodes :**

- `__init__()`
- `mode()`
- `name()`
- `seekable()`
- `close()`
- `closed()`
- `read()`
- `readable()`
- `seek()`
- `tell()`
- `truncate()`
- `writable()`
- `__enter__()`
- `__exit__()`
- `_stay()`
- `_check_zip()`
- `_stream_response()`
- `_merge()`
- `_download()`

#### Fonctions

##### dist_from_wheel_url

Return a distribution object from the given wheel URL.

This uses HTTP range requests to only fetch the portion of the wheel
containing metadata, just enough for the object to be constructed.
If such requests are not supported, HTTPRangeRequestUnsupported
is raised.

**Param√®tres :**

- `name`
- `url`
- `session`

##### __init__

**Param√®tres :**

- `url`
- `session`
- `chunk_size`

##### mode

Opening mode, which is always rb.

##### name

Path to the underlying file.

##### seekable

Return whether random access is supported, which is True.

##### close

Close the file.

##### closed

Whether the file is closed.

##### read

Read up to size bytes from the object and return them.

As a convenience, if size is unspecified or -1,
all bytes until EOF are returned.  Fewer than
size bytes may be returned if EOF is reached.

**Param√®tres :**

- `size`

##### readable

Return whether the file is readable, which is True.

##### seek

Change stream position and return the new absolute position.

Seek to offset relative position indicated by whence:
* 0: Start of stream (the default).  pos should be >= 0;
* 1: Current position - pos may be negative;
* 2: End of stream - pos usually negative.

**Param√®tres :**

- `offset`
- `whence`

##### tell

Return the current position.

##### truncate

Resize the stream to the given size in bytes.

If size is unspecified resize to the current position.
The current stream position isn't changed.

Return the new file size.

**Param√®tres :**

- `size`

##### writable

Return False.

##### __enter__

##### __exit__

##### _stay

Return a context manager keeping the position.

At the end of the block, seek back to original position.

##### _check_zip

Check and download until the file is a valid ZIP.

##### _stream_response

Return HTTP response to a range request from start to end.

**Param√®tres :**

- `start`
- `end`
- `base_headers`

##### _merge

Return a generator of intervals to be fetched.

Args:
    start (int): Start of needed interval
    end (int): End of needed interval
    left (int): Index of first overlapping downloaded data
    right (int): Index after last overlapping downloaded data

**Param√®tres :**

- `start`
- `end`
- `left`
- `right`

##### _download

Download bytes from start to end inclusively.

**Param√®tres :**

- `start`
- `end`

---

### session

PipSession and supporting code, containing all pip-specific
network request configuration and behavior.

#### Classes

##### LocalFSAdapter

**M√©thodes :**

- `send()`
- `close()`

##### _SSLContextAdapterMixin

Mixin to add the ``ssl_context`` constructor argument to HTTP adapters.

The additional argument is forwarded directly to the pool manager. This allows us
to dynamically decide what SSL store to use at runtime, which is used to implement
the optional ``truststore`` backend.

**M√©thodes :**

- `__init__()`
- `init_poolmanager()`

##### HTTPAdapter

##### CacheControlAdapter

##### InsecureHTTPAdapter

**M√©thodes :**

- `cert_verify()`

##### InsecureCacheControlAdapter

**M√©thodes :**

- `cert_verify()`

##### PipSession

**M√©thodes :**

- `__init__()`
- `update_index_urls()`
- `add_trusted_host()`
- `iter_secure_origins()`
- `is_secure_origin()`
- `request()`

#### Fonctions

##### looks_like_ci

Return whether it looks like pip is running under CI.

##### user_agent

Return a string representing the user agent.

##### send

**Param√®tres :**

- `request`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`

##### close

##### __init__

##### init_poolmanager

**Param√®tres :**

- `connections`
- `maxsize`
- `block`

##### cert_verify

**Param√®tres :**

- `conn`
- `url`
- `verify`
- `cert`

##### cert_verify

**Param√®tres :**

- `conn`
- `url`
- `verify`
- `cert`

##### __init__

:param trusted_hosts: Domains not to emit warnings for when not using
    HTTPS.

##### update_index_urls

:param new_index_urls: New index urls to update the authentication
    handler with.

**Param√®tres :**

- `new_index_urls`

##### add_trusted_host

:param host: It is okay to provide a host that has previously been
    added.
:param source: An optional source string, for logging where the host
    string came from.

**Param√®tres :**

- `host`
- `source`
- `suppress_logging`

##### iter_secure_origins

##### is_secure_origin

**Param√®tres :**

- `location`

##### request

**Param√®tres :**

- `method`
- `url`

---

### utils

#### Fonctions

##### raise_for_status

**Param√®tres :**

- `resp`

##### response_chunks

Given a requests Response, provide the data chunks.

**Param√®tres :**

- `response`
- `chunk_size`

---

### xmlrpc

xmlrpclib.Transport implementation

#### Classes

##### PipXmlrpcTransport

Provide a `xmlrpclib.Transport` implementation via a `PipSession`
object.

**M√©thodes :**

- `__init__()`
- `request()`

#### Fonctions

##### __init__

**Param√®tres :**

- `index_url`
- `session`
- `use_datetime`

##### request

**Param√®tres :**

- `host`
- `handler`
- `request_body`
- `verbose`

---

### .!22827!__init__

---

### .!22839!cache

---

### .!22844!download

---

### .!22851!lazy_wheel

---

### .!22855!session

---

### .!22860!utils

---

### .!22865!xmlrpc

---

### check

Validation of dependencies of packages

#### Classes

##### PackageDetails

#### Fonctions

##### create_package_set_from_installed

Converts a list of distributions into a PackageSet.

##### check_package_set

Check if a package set is consistent

If should_ignore is passed, it should be a callable that takes a
package name and returns a boolean.

**Param√®tres :**

- `package_set`
- `should_ignore`

##### check_install_conflicts

For checking if the dependency graph would be consistent after     installing given requirements
    

**Param√®tres :**

- `to_install`

##### check_unsupported

**Param√®tres :**

- `packages`
- `supported_tags`

##### _simulate_installation_of

Computes the version of packages after installing to_install.

**Param√®tres :**

- `to_install`
- `package_set`

##### _create_whitelist

**Param√®tres :**

- `would_be_installed`
- `package_set`

---

### freeze

#### Classes

##### _EditableInfo

##### FrozenRequirement

**M√©thodes :**

- `canonical_name()`
- `from_dist()`
- `__str__()`

#### Fonctions

##### freeze

**Param√®tres :**

- `requirement`
- `local_only`
- `user_only`
- `paths`
- `isolated`
- `exclude_editable`
- `skip`

##### _format_as_name_version

**Param√®tres :**

- `dist`

##### _get_editable_info

Compute and return values (req, comments) for use in
FrozenRequirement.from_dist().

**Param√®tres :**

- `dist`

##### canonical_name

##### from_dist

**Param√®tres :**

- `cls`
- `dist`

##### __str__

---

### prepare

Prepares a distribution for installation

#### Classes

##### File

**M√©thodes :**

- `__post_init__()`

##### RequirementPreparer

Prepares a Requirement

**M√©thodes :**

- `__init__()`
- `_log_preparing_link()`
- `_ensure_link_req_src_dir()`
- `_get_linked_req_hashes()`
- `_fetch_metadata_only()`
- `_fetch_metadata_using_link_data_attr()`
- `_fetch_metadata_using_lazy_wheel()`
- `_complete_partial_requirements()`
- `prepare_linked_requirement()`
- `prepare_linked_requirements_more()`
- `_prepare_linked_requirement()`
- `save_linked_requirement()`
- `prepare_editable_requirement()`
- `prepare_installed_requirement()`

#### Fonctions

##### _get_prepared_distribution

Prepare a distribution for installation.

**Param√®tres :**

- `req`
- `build_tracker`
- `finder`
- `build_isolation`
- `check_build_deps`

##### unpack_vcs_link

**Param√®tres :**

- `link`
- `location`
- `verbosity`

##### get_http_url

**Param√®tres :**

- `link`
- `download`
- `download_dir`
- `hashes`

##### get_file_url

Get file and optionally check its hash.

**Param√®tres :**

- `link`
- `download_dir`
- `hashes`

##### unpack_url

Unpack link into location, downloading if required.

:param hashes: A Hashes object, one of whose embedded hashes must match,
    or HashMismatch will be raised. If the Hashes is empty, no matches are
    required, and unhashable types of requirements (like VCS ones, which
    would ordinarily raise HashUnsupported) are allowed.

**Param√®tres :**

- `link`
- `location`
- `download`
- `verbosity`
- `download_dir`
- `hashes`

##### _check_download_dir

Check download_dir for previously downloaded file with correct hash
If a correct file is found return its path else None

**Param√®tres :**

- `link`
- `download_dir`
- `hashes`
- `warn_on_hash_mismatch`

##### __post_init__

##### __init__

**Param√®tres :**

- `build_dir`
- `download_dir`
- `src_dir`
- `build_isolation`
- `check_build_deps`
- `build_tracker`
- `session`
- `progress_bar`
- `finder`
- `require_hashes`
- `use_user_site`
- `lazy_wheel`
- `verbosity`
- `legacy_resolver`
- `resume_retries`

##### _log_preparing_link

Provide context for the requirement being prepared.

**Param√®tres :**

- `req`

##### _ensure_link_req_src_dir

Ensure source_dir of a linked InstallRequirement.

**Param√®tres :**

- `req`
- `parallel_builds`

##### _get_linked_req_hashes

**Param√®tres :**

- `req`

##### _fetch_metadata_only

**Param√®tres :**

- `req`

##### _fetch_metadata_using_link_data_attr

Fetch metadata from the data-dist-info-metadata attribute, if possible.

**Param√®tres :**

- `req`

##### _fetch_metadata_using_lazy_wheel

Fetch metadata using lazy wheel, if possible.

**Param√®tres :**

- `link`

##### _complete_partial_requirements

Download any requirements which were only fetched by metadata.

**Param√®tres :**

- `partially_downloaded_reqs`
- `parallel_builds`

##### prepare_linked_requirement

Prepare a requirement to be obtained from req.link.

**Param√®tres :**

- `req`
- `parallel_builds`

##### prepare_linked_requirements_more

Prepare linked requirements more, if needed.

**Param√®tres :**

- `reqs`
- `parallel_builds`

##### _prepare_linked_requirement

**Param√®tres :**

- `req`
- `parallel_builds`

##### save_linked_requirement

**Param√®tres :**

- `req`

##### prepare_editable_requirement

Prepare an editable requirement.

**Param√®tres :**

- `req`

##### prepare_installed_requirement

Prepare an already-installed requirement.

**Param√®tres :**

- `req`
- `skip_reason`

---

### .!22879!check

---

### .!22884!freeze

---

### .!22891!prepare

---

### build_tracker

#### Classes

##### TrackerId

Uniquely identifying string provided to the build tracker.

##### BuildTracker

Ensure that an sdist cannot request itself as a setup requirement.

When an sdist is prepared, it identifies its setup requirements in the
context of ``BuildTracker.track()``. If a requirement shows up recursively, this
raises an exception.

This stops fork bombs embedded in malicious packages.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `_entry_path()`
- `add()`
- `remove()`
- `cleanup()`
- `track()`

#### Fonctions

##### update_env_context_manager

##### get_build_tracker

##### __init__

**Param√®tres :**

- `root`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### _entry_path

**Param√®tres :**

- `key`

##### add

Add an InstallRequirement to build tracking.

**Param√®tres :**

- `req`
- `key`

##### remove

Remove an InstallRequirement from build tracking.

**Param√®tres :**

- `req`
- `key`

##### cleanup

##### track

Ensure that `key` cannot install itself as a setup requirement.

:raises LookupError: If `key` was already provided in a parent invocation of
                     the context introduced by this method.

**Param√®tres :**

- `req`
- `key`

---

### metadata

Metadata generation logic for source distributions.

#### Fonctions

##### generate_metadata

Generate metadata using mechanisms described in PEP 517.

Returns the generated metadata directory.

**Param√®tres :**

- `build_env`
- `backend`
- `details`

---

### metadata_editable

Metadata generation logic for source distributions.

#### Fonctions

##### generate_editable_metadata

Generate metadata using mechanisms described in PEP 660.

Returns the generated metadata directory.

**Param√®tres :**

- `build_env`
- `backend`
- `details`

---

### metadata_legacy

Metadata generation logic for legacy source distributions.

#### Fonctions

##### _find_egg_info

Find an .egg-info subdirectory in `directory`.

**Param√®tres :**

- `directory`

##### generate_metadata

Generate metadata using setup.py-based defacto mechanisms.

Returns the generated metadata directory.

**Param√®tres :**

- `build_env`
- `setup_py_path`
- `source_dir`
- `isolated`
- `details`

---

### wheel

#### Fonctions

##### build_wheel_pep517

Build one InstallRequirement using the PEP 517 build process.

Returns path to wheel if successfully built. Otherwise, returns None.

**Param√®tres :**

- `name`
- `backend`
- `metadata_directory`
- `tempd`

---

### wheel_editable

#### Fonctions

##### build_wheel_editable

Build one InstallRequirement using the PEP 660 build process.

Returns path to wheel if successfully built. Otherwise, returns None.

**Param√®tres :**

- `name`
- `backend`
- `metadata_directory`
- `tempd`

---

### wheel_legacy

#### Fonctions

##### format_command_result

Format command information for logging.

**Param√®tres :**

- `command_args`
- `command_output`

##### get_legacy_build_wheel_path

Return the path to the wheel in the temporary build directory.

**Param√®tres :**

- `names`
- `temp_dir`
- `name`
- `command_args`
- `command_output`

##### build_wheel_legacy

Build one unpacked package using the "legacy" build process.

Returns path to wheel if successfully built. Otherwise, returns None.

**Param√®tres :**

- `name`
- `setup_py_path`
- `source_dir`
- `global_options`
- `build_options`
- `tempd`

---

### .!22902!build_tracker

---

### .!22908!metadata

---

### .!22911!metadata_editable

---

### .!22917!metadata_legacy

---

### .!22922!wheel

---

### .!22927!wheel_editable

---

### .!22931!wheel_legacy

---

### editable_legacy

Legacy editable installation process, i.e. `setup.py develop`.

#### Fonctions

##### install_editable

Install a package in editable mode. Most arguments are pass-through
to setuptools.

---

### wheel

Support for installing and building the "wheel" binary package format.

#### Classes

##### File

**M√©thodes :**

- `save()`

##### ZipBackedFile

**M√©thodes :**

- `__init__()`
- `_getinfo()`
- `save()`

##### ScriptFile

**M√©thodes :**

- `__init__()`
- `save()`

##### MissingCallableSuffix

**M√©thodes :**

- `__init__()`

##### PipScriptMaker

**M√©thodes :**

- `make()`

#### Fonctions

##### rehash

Return (encoded_digest, length) for path using hashlib.sha256()

**Param√®tres :**

- `path`
- `blocksize`

##### csv_io_kwargs

Return keyword arguments to properly open a CSV file
in the given mode.

**Param√®tres :**

- `mode`

##### fix_script

Replace #!python with #!/path/to/python
Return True if file was changed.

**Param√®tres :**

- `path`

##### wheel_root_is_purelib

**Param√®tres :**

- `metadata`

##### get_entrypoints

**Param√®tres :**

- `dist`

##### message_about_scripts_not_on_PATH

Determine if any scripts are not on PATH and format a warning.
Returns a warning message if one or more scripts are not on PATH,
otherwise None.

**Param√®tres :**

- `scripts`

##### _normalized_outrows

Normalize the given rows of a RECORD file.

Items in each row are converted into str. Rows are then sorted to make
the value more predictable for tests.

Each row is a 3-tuple (path, hash, size) and corresponds to a record of
a RECORD file (see PEP 376 and PEP 427 for details).  For the rows
passed to this function, the size can be an integer as an int or string,
or the empty string.

**Param√®tres :**

- `outrows`

##### _record_to_fs_path

**Param√®tres :**

- `record_path`
- `lib_dir`

##### _fs_to_record_path

**Param√®tres :**

- `path`
- `lib_dir`

##### get_csv_rows_for_installed

:param installed: A map from archive RECORD path to installation RECORD
    path.

**Param√®tres :**

- `old_csv_rows`
- `installed`
- `changed`
- `generated`
- `lib_dir`

##### get_console_script_specs

Given the mapping from entrypoint name to callable, return the relevant
console script specs.

**Param√®tres :**

- `console`

##### _raise_for_invalid_entrypoint

**Param√®tres :**

- `specification`

##### _install_wheel

Install a wheel.

:param name: Name of the project to install
:param wheel_zip: open ZipFile for wheel being installed
:param scheme: Distutils scheme dictating the install directories
:param req_description: String used in place of the requirement, for
    logging
:param pycompile: Whether to byte-compile installed Python files
:param warn_script_location: Whether to check that scripts are installed
    into a directory on PATH
:raises UnsupportedWheel:
    * when the directory holds an unpacked wheel with incompatible
      Wheel-Version
    * when the .dist-info dir does not match the wheel

**Param√®tres :**

- `name`
- `wheel_zip`
- `wheel_path`
- `scheme`
- `pycompile`
- `warn_script_location`
- `direct_url`
- `requested`

##### req_error_context

**Param√®tres :**

- `req_description`

##### install_wheel

**Param√®tres :**

- `name`
- `wheel_path`
- `scheme`
- `req_description`
- `pycompile`
- `warn_script_location`
- `direct_url`
- `requested`

##### save

##### __init__

**Param√®tres :**

- `src_record_path`
- `dest_path`
- `zip_file`

##### _getinfo

##### save

##### __init__

**Param√®tres :**

- `file`

##### save

##### __init__

**Param√®tres :**

- `entry_point`

##### make

**Param√®tres :**

- `specification`
- `options`

##### record_installed

Map archive RECORD paths to installation RECORD paths.

**Param√®tres :**

- `srcfile`
- `destfile`
- `modified`

##### is_dir_path

**Param√®tres :**

- `path`

##### assert_no_path_traversal

**Param√®tres :**

- `dest_dir_path`
- `target_path`

##### root_scheme_file_maker

**Param√®tres :**

- `zip_file`
- `dest`

##### data_scheme_file_maker

**Param√®tres :**

- `zip_file`
- `scheme`

##### is_data_scheme_path

**Param√®tres :**

- `path`

##### is_script_scheme_path

**Param√®tres :**

- `path`

##### is_entrypoint_wrapper

**Param√®tres :**

- `file`

##### pyc_source_file_paths

##### pyc_output_path

Return the path the pyc file would have been written to.

**Param√®tres :**

- `path`

##### _generate_file

**Param√®tres :**

- `path`

##### make_root_scheme_file

**Param√®tres :**

- `record_path`

##### make_data_scheme_file

**Param√®tres :**

- `record_path`

---

### .!22938!__init__

---

### .!22943!editable_legacy

---

### .!22947!wheel

---

### constructors

Backing implementation for InstallRequirement's various constructors

The idea here is that these formed a major chunk of InstallRequirement's size
so, moving them and support code dedicated to them outside of that class
helps creates for better understandability for the rest of the code.

These are meant to be used elsewhere within pip to create instances of
InstallRequirement.

#### Classes

##### RequirementParts

#### Fonctions

##### _strip_extras

**Param√®tres :**

- `path`

##### convert_extras

**Param√®tres :**

- `extras`

##### _set_requirement_extras

Returns a new requirement based on the given one, with the supplied extras. If the
given requirement already has extras those are replaced (or dropped if no new extras
are given).

**Param√®tres :**

- `req`
- `new_extras`

##### parse_editable

Parses an editable requirement into:
    - a requirement name
    - an URL
    - extras
    - editable options
Accepted requirements:
    svn+http://blahblah@rev#egg=Foobar[baz]&subdirectory=version_subdir
    .[some_extra]

**Param√®tres :**

- `editable_req`

##### check_first_requirement_in_file

Check if file is parsable as a requirements file.

This is heavily based on ``pkg_resources.parse_requirements``, but
simplified to just check the first meaningful line.

:raises InvalidRequirement: If the first meaningful line cannot be parsed
    as an requirement.

**Param√®tres :**

- `filename`

##### deduce_helpful_msg

Returns helpful msg in case requirements file does not exist,
or cannot be parsed.

:params req: Requirements file path

**Param√®tres :**

- `req`

##### parse_req_from_editable

**Param√®tres :**

- `editable_req`

##### install_req_from_editable

**Param√®tres :**

- `editable_req`
- `comes_from`

##### _looks_like_path

Checks whether the string "looks like" a path on the filesystem.

This does not check whether the target actually exists, only judge from the
appearance.

Returns true if any of the following conditions is true:
* a path separator is found (either os.path.sep or os.path.altsep);
* a dot is found (which represents the current directory).

**Param√®tres :**

- `name`

##### _get_url_from_path

First, it checks whether a provided path is an installable directory. If it
is, returns the path.

If false, check if the path is an archive file (such as a .whl).
The function checks if the path is a file. If false, if the path has
an @, it will treat it as a PEP 440 URL requirement and return the path.

**Param√®tres :**

- `path`
- `name`

##### parse_req_from_line

**Param√®tres :**

- `name`
- `line_source`

##### install_req_from_line

Creates an InstallRequirement from a name, which might be a
requirement, directory containing 'setup.py', filename, or URL.

:param line_source: An optional string describing where the line is from,
    for logging purposes in case of an error.

**Param√®tres :**

- `name`
- `comes_from`

##### install_req_from_req_string

**Param√®tres :**

- `req_string`
- `comes_from`
- `isolated`
- `use_pep517`
- `user_supplied`

##### install_req_from_parsed_requirement

**Param√®tres :**

- `parsed_req`
- `isolated`
- `use_pep517`
- `user_supplied`
- `config_settings`

##### install_req_from_link_and_ireq

**Param√®tres :**

- `link`
- `ireq`

##### install_req_drop_extras

Creates a new InstallationRequirement using the given template but without
any extras. Sets the original requirement as the new one's parent
(comes_from).

**Param√®tres :**

- `ireq`

##### install_req_extend_extras

Returns a copy of an installation requirement with some additional extras.
Makes a shallow copy of the ireq object.

**Param√®tres :**

- `ireq`
- `extras`

##### with_source

**Param√®tres :**

- `text`

##### _parse_req_string

**Param√®tres :**

- `req_as_string`

---

### req_dependency_group

#### Fonctions

##### parse_dependency_groups

Parse dependency groups data as provided via the CLI, in a `[path:]group` syntax.

Raises InstallationErrors if anything goes wrong.

**Param√®tres :**

- `groups`

##### _resolve_all_groups

Run all resolution, converting any error from `DependencyGroupResolver` into
an InstallationError.

**Param√®tres :**

- `resolvers`
- `groups`

##### _build_resolvers

**Param√®tres :**

- `paths`

##### _load_pyproject

This helper loads a pyproject.toml as TOML.

It raises an InstallationError if the operation fails.

**Param√®tres :**

- `path`

---

### req_file

Requirements file parsing

#### Classes

##### ParsedRequirement

##### ParsedLine

**M√©thodes :**

- `is_editable()`
- `requirement()`

##### RequirementsFileParser

**M√©thodes :**

- `__init__()`
- `parse()`
- `_parse_and_recurse()`
- `_parse_file()`

##### OptionParsingError

**M√©thodes :**

- `__init__()`

#### Fonctions

##### parse_requirements

Parse a requirements file and yield ParsedRequirement instances.

:param filename:    Path or url of requirements file.
:param session:     PipSession instance.
:param finder:      Instance of pip.index.PackageFinder.
:param options:     cli options.
:param constraint:  If true, parsing a constraint file rather than
    requirements file.

**Param√®tres :**

- `filename`
- `session`
- `finder`
- `options`
- `constraint`

##### preprocess

Split, filter, and join lines, and return a line iterator

:param content: the content of the requirements file

**Param√®tres :**

- `content`

##### handle_requirement_line

**Param√®tres :**

- `line`
- `options`

##### handle_option_line

**Param√®tres :**

- `opts`
- `filename`
- `lineno`
- `finder`
- `options`
- `session`

##### handle_line

Handle a single parsed requirements line; This can result in
creating/yielding requirements, or updating the finder.

:param line:        The parsed line to be processed.
:param options:     CLI options.
:param finder:      The finder - updated by non-requirement lines.
:param session:     The session - updated by non-requirement lines.

Returns a ParsedRequirement object if the line is a requirement line,
otherwise returns None.

For lines that contain requirements, the only options that have an effect
are from SUPPORTED_OPTIONS_REQ, and they are scoped to the
requirement. Other options from SUPPORTED_OPTIONS may be present, but are
ignored.

For lines that do not contain requirements, the only options that have an
effect are from SUPPORTED_OPTIONS. Options from SUPPORTED_OPTIONS_REQ may
be present, but are ignored. These lines may contain multiple options
(although our docs imply only one is supported), and all our parsed and
affect the finder.

**Param√®tres :**

- `line`
- `options`
- `finder`
- `session`

##### get_line_parser

**Param√®tres :**

- `finder`

##### break_args_options

Break up the line into an args and options string.  We only want to shlex
(and then optparse) the options, not the args.  args can contain markers
which are corrupted by shlex.

**Param√®tres :**

- `line`

##### build_parser

Return a parser for parsing requirement lines

##### join_lines

Joins a line ending in '' with the previous line (except when following
comments).  The joined line takes on the index of the first line.

**Param√®tres :**

- `lines_enum`

##### ignore_comments

Strips comments and filter empty lines.

**Param√®tres :**

- `lines_enum`

##### expand_env_variables

Replace all environment variables that can be retrieved via `os.getenv`.

The only allowed format for environment variables defined in the
requirement file is `${MY_VARIABLE_1}` to ensure two things:

1. Strings that contain a `$` aren't accidentally (partially) expanded.
2. Ensure consistency across platforms for requirement files.

These points are the result of a discussion on the `github pull
request #3514 <https://github.com/pypa/pip/pull/3514>`_.

Valid characters in variable names follow the `POSIX standard
<http://pubs.opengroup.org/onlinepubs/9699919799/>`_ and are limited
to uppercase letter, digits and the `_` (underscore).

**Param√®tres :**

- `lines_enum`

##### get_file_content

Gets the content of a file; it may be a filename, file: URL, or
http: URL.  Returns (location, content).  Content is unicode.
Respects # -*- coding: declarations on the retrieved files.

:param url:         File path or url.
:param session:     PipSession instance.

**Param√®tres :**

- `url`
- `session`

##### _decode_req_file

**Param√®tres :**

- `data`
- `url`

##### is_editable

##### requirement

##### __init__

**Param√®tres :**

- `session`
- `line_parser`

##### parse

Parse a given file, yielding parsed lines.

**Param√®tres :**

- `filename`
- `constraint`

##### _parse_and_recurse

**Param√®tres :**

- `filename`
- `constraint`
- `parsed_files_stack`

##### _parse_file

**Param√®tres :**

- `filename`
- `constraint`

##### parse_line

**Param√®tres :**

- `line`

##### __init__

**Param√®tres :**

- `msg`

##### parser_exit

**Param√®tres :**

- `msg`

---

### req_install

#### Classes

##### InstallRequirement

Represents something that may be installed later on, may have information
about where to fetch the relevant requirement and also contains logic for
installing the said requirement.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `format_debug()`
- `name()`
- `supports_pyproject_editable()`
- `specifier()`
- `is_direct()`
- `is_pinned()`
- `match_markers()`
- `has_hash_options()`
- `hashes()`
- `from_path()`
- `ensure_build_location()`
- `_set_requirement()`
- `warn_on_mismatching_name()`
- `check_if_exists()`
- `is_wheel()`
- `is_wheel_from_cache()`
- `unpacked_source_directory()`
- `setup_py_path()`
- `setup_cfg_path()`
- `pyproject_toml_path()`
- `load_pyproject_toml()`
- `isolated_editable_sanity_check()`
- `prepare_metadata()`
- `metadata()`
- `get_dist()`
- `assert_source_matches_version()`
- `ensure_has_source_dir()`
- `needs_unpacked_archive()`
- `ensure_pristine_source_checkout()`
- `update_editable()`
- `uninstall()`
- `_get_archive_name()`
- `archive()`
- `install()`

#### Fonctions

##### check_invalid_constraint_type

**Param√®tres :**

- `req`

##### _has_option

**Param√®tres :**

- `options`
- `reqs`
- `option`

##### check_legacy_setup_py_options

**Param√®tres :**

- `options`
- `reqs`

##### __init__

**Param√®tres :**

- `req`
- `comes_from`
- `editable`
- `link`
- `markers`
- `use_pep517`
- `isolated`

##### __str__

##### __repr__

##### format_debug

An un-tested helper for getting state, for debugging.

##### name

##### supports_pyproject_editable

##### specifier

##### is_direct

Whether this requirement was specified as a direct URL.

##### is_pinned

Return whether I am pinned to an exact version.

For example, some-package==1.2 is pinned; some-package>1.2 is not.

##### match_markers

**Param√®tres :**

- `extras_requested`

##### has_hash_options

Return whether any known-good hashes are specified as options.

These activate --require-hashes mode; hashes specified as part of a
URL do not.

##### hashes

Return a hash-comparer that considers my option- and URL-based
hashes to be known-good.

Hashes in URLs--ones embedded in the requirements file, not ones
downloaded from an index server--are almost peers with ones from
flags. They satisfy --require-hashes (whether it was implicitly or
explicitly activated) but do not activate it. md5 and sha224 are not
allowed in flags, which should nudge people toward good algos. We
always OR all hashes together, even ones from URLs.

:param trust_internet: Whether to trust URL-based (#md5=...) hashes
    downloaded from the internet, as by populate_link()

**Param√®tres :**

- `trust_internet`

##### from_path

Format a nice indicator to show where this "comes from" 

##### ensure_build_location

**Param√®tres :**

- `build_dir`
- `autodelete`
- `parallel_builds`

##### _set_requirement

Set requirement after generating metadata.

##### warn_on_mismatching_name

##### check_if_exists

Find an installed distribution that satisfies or conflicts
with this requirement, and set self.satisfied_by or
self.should_reinstall appropriately.

**Param√®tres :**

- `use_user_site`

##### is_wheel

##### is_wheel_from_cache

##### unpacked_source_directory

##### setup_py_path

##### setup_cfg_path

##### pyproject_toml_path

##### load_pyproject_toml

Load the pyproject.toml file.

After calling this routine, all of the attributes related to PEP 517
processing for this requirement have been set. In particular, the
use_pep517 attribute can be used to determine whether we should
follow the PEP 517 or legacy (setup.py) code path.

##### isolated_editable_sanity_check

Check that an editable requirement if valid for use with PEP 517/518.

This verifies that an editable that has a pyproject.toml either supports PEP 660
or as a setup.py or a setup.cfg

##### prepare_metadata

Ensure that project metadata is available.

Under PEP 517 and PEP 660, call the backend hook to prepare the metadata.
Under legacy processing, call setup.py egg-info.

##### metadata

##### get_dist

##### assert_source_matches_version

##### ensure_has_source_dir

Ensure that a source_dir is set.

This will create a temporary build dir if the name of the requirement
isn't known yet.

:param parent_dir: The ideal pip parent_dir for the source_dir.
    Generally src_dir for editables and build_dir for sdists.
:return: self.source_dir

**Param√®tres :**

- `parent_dir`
- `autodelete`
- `parallel_builds`

##### needs_unpacked_archive

**Param√®tres :**

- `archive_source`

##### ensure_pristine_source_checkout

Ensure the source directory has not yet been built in.

##### update_editable

##### uninstall

Uninstall the distribution currently satisfying this requirement.

Prompts before removing or modifying files unless
``auto_confirm`` is True.

Refuses to delete or modify files outside of ``sys.prefix`` -
thus uninstallation within a virtual environment can only
modify that virtual environment, even if the virtualenv is
linked to global site-packages.

**Param√®tres :**

- `auto_confirm`
- `verbose`

##### _get_archive_name

**Param√®tres :**

- `path`
- `parentdir`
- `rootdir`

##### archive

Saves archive to provided build_dir.

Used for saving downloaded VCS requirements as part of `pip download`.

**Param√®tres :**

- `build_dir`

##### install

**Param√®tres :**

- `global_options`
- `root`
- `home`
- `prefix`
- `warn_script_location`
- `use_user_site`
- `pycompile`

##### _clean_zip_name

**Param√®tres :**

- `name`
- `prefix`

---

### req_set

#### Classes

##### RequirementSet

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `add_unnamed_requirement()`
- `add_named_requirement()`
- `has_requirement()`
- `get_requirement()`
- `all_requirements()`
- `requirements_to_install()`

#### Fonctions

##### __init__

Create a RequirementSet.

**Param√®tres :**

- `check_supported_wheels`

##### __str__

##### __repr__

##### add_unnamed_requirement

**Param√®tres :**

- `install_req`

##### add_named_requirement

**Param√®tres :**

- `install_req`

##### has_requirement

**Param√®tres :**

- `name`

##### get_requirement

**Param√®tres :**

- `name`

##### all_requirements

##### requirements_to_install

Return the list of requirements that need to be installed.

TODO remove this property together with the legacy resolver, since the new
     resolver only returns requirements that need to be installed.

---

### req_uninstall

#### Classes

##### StashedUninstallPathSet

A set of file rename operations to stash files while
tentatively uninstalling them.

**M√©thodes :**

- `__init__()`
- `_get_directory_stash()`
- `_get_file_stash()`
- `stash()`
- `commit()`
- `rollback()`
- `can_rollback()`

##### UninstallPathSet

A set of file paths to be removed in the uninstallation of a
requirement.

**M√©thodes :**

- `__init__()`
- `_permitted()`
- `add()`
- `add_pth()`
- `remove()`
- `_allowed_to_proceed()`
- `rollback()`
- `commit()`
- `from_dist()`

##### UninstallPthEntries

**M√©thodes :**

- `__init__()`
- `add()`
- `remove()`
- `rollback()`

#### Fonctions

##### _script_names

Create the fully qualified name of the files created by
{console,gui}_scripts for the given ``dist``.
Returns the list of file names

**Param√®tres :**

- `bin_dir`
- `script_name`
- `is_gui`

##### _unique

**Param√®tres :**

- `fn`

##### uninstallation_paths

Yield all the uninstallation paths for dist based on RECORD-without-.py[co]

Yield paths to all the files in RECORD. For each .py file in RECORD, add
the .pyc and .pyo in the same directory.

UninstallPathSet.add() takes care of the __pycache__ .py[co].

If RECORD is not found, raises an error,
with possible information from the INSTALLER file.

https://packaging.python.org/specifications/recording-installed-packages/

**Param√®tres :**

- `dist`

##### compact

Compact a path set to contain the minimal number of paths
necessary to contain all paths in the set. If /a/path/ and
/a/path/to/a/file.txt are both in the set, leave only the
shorter path.

**Param√®tres :**

- `paths`

##### compress_for_rename

Returns a set containing the paths that need to be renamed.

This set may include directories when the original sequence of paths
included every file on disk.

**Param√®tres :**

- `paths`

##### compress_for_output_listing

Returns a tuple of 2 sets of which paths to display to user

The first set contains paths that would be deleted. Files of a package
are not added and the top-level directory of the package has a '*' added
at the end - to signify that all it's contents are removed.

The second set contains files that would have been skipped in the above
folders.

**Param√®tres :**

- `paths`

##### unique

##### norm_join

##### __init__

##### _get_directory_stash

Stashes a directory.

Directories are stashed adjacent to their original location if
possible, or else moved/copied into the user's temp dir.

**Param√®tres :**

- `path`

##### _get_file_stash

Stashes a file.

If no root has been provided, one will be created for the directory
in the user's temp directory.

**Param√®tres :**

- `path`

##### stash

Stashes the directory or file and returns its new location.
Handle symlinks as files to avoid modifying the symlink targets.

**Param√®tres :**

- `path`

##### commit

Commits the uninstall by removing stashed files.

##### rollback

Undoes the uninstall by moving stashed files back.

##### can_rollback

##### __init__

**Param√®tres :**

- `dist`

##### _permitted

Return True if the given path is one we are permitted to
remove/modify, False otherwise.

**Param√®tres :**

- `path`

##### add

**Param√®tres :**

- `path`

##### add_pth

**Param√®tres :**

- `pth_file`
- `entry`

##### remove

Remove paths in ``self._paths`` with confirmation (unless
``auto_confirm`` is True).

**Param√®tres :**

- `auto_confirm`
- `verbose`

##### _allowed_to_proceed

Display which files would be deleted and prompt for confirmation

**Param√®tres :**

- `verbose`

##### rollback

Rollback the changes previously made by remove().

##### commit

Remove temporary save dir: rollback will no longer be possible.

##### from_dist

**Param√®tres :**

- `cls`
- `dist`

##### __init__

**Param√®tres :**

- `pth_file`

##### add

**Param√®tres :**

- `entry`

##### remove

##### rollback

##### _display

**Param√®tres :**

- `msg`
- `paths`

##### iter_scripts_to_remove

**Param√®tres :**

- `dist`
- `bin_dir`

---

### .!22952!__init__

---

### .!22956!constructors

---

### .!22961!req_dependency_group

---

### .!22964!req_file

---

### .!22970!req_install

---

### .!22973!req_set

---

### .!22979!req_uninstall

---

### base

#### Classes

##### BaseResolver

**M√©thodes :**

- `resolve()`
- `get_installation_order()`

#### Fonctions

##### resolve

**Param√®tres :**

- `root_reqs`
- `check_supported_wheels`

##### get_installation_order

**Param√®tres :**

- `req_set`

---

### .!22990!base

---

### resolver

Dependency Resolution

The dependency resolution in pip is performed as follows:

for top-level requirements:
    a. only one spec allowed per project, regardless of conflicts or not.
       otherwise a "double requirement" exception is raised
    b. they override sub-dependency requirements.
for sub-dependencies
    a. "first found, wins" (where the order is breadth first)

#### Classes

##### Resolver

Resolves which packages need to be installed/uninstalled to perform     the requested operation without breaking the requirements of any package.
    

**M√©thodes :**

- `__init__()`
- `resolve()`
- `_add_requirement_to_set()`
- `_is_upgrade_allowed()`
- `_set_req_to_reinstall()`
- `_check_skip_installed()`
- `_find_requirement_link()`
- `_populate_link()`
- `_get_dist_for()`
- `_resolve_one()`
- `get_installation_order()`

#### Fonctions

##### _check_dist_requires_python

Check whether the given Python version is compatible with a distribution's
"Requires-Python" value.

:param version_info: A 3-tuple of ints representing the Python
    major-minor-micro version to check.
:param ignore_requires_python: Whether to ignore the "Requires-Python"
    value if the given Python version isn't compatible.

:raises UnsupportedPythonVersion: When the given Python version isn't
    compatible.

**Param√®tres :**

- `dist`
- `version_info`
- `ignore_requires_python`

##### __init__

**Param√®tres :**

- `preparer`
- `finder`
- `wheel_cache`
- `make_install_req`
- `use_user_site`
- `ignore_dependencies`
- `ignore_installed`
- `ignore_requires_python`
- `force_reinstall`
- `upgrade_strategy`
- `py_version_info`

##### resolve

Resolve what operations need to be done

As a side-effect of this method, the packages (and their dependencies)
are downloaded, unpacked and prepared for installation. This
preparation is done by ``pip.operations.prepare``.

Once PyPI has static dependency metadata available, it would be
possible to move the preparation to become a step separated from
dependency resolution.

**Param√®tres :**

- `root_reqs`
- `check_supported_wheels`

##### _add_requirement_to_set

Add install_req as a requirement to install.

:param parent_req_name: The name of the requirement that needed this
    added. The name is used because when multiple unnamed requirements
    resolve to the same name, we could otherwise end up with dependency
    links that point outside the Requirements set. parent_req must
    already be added. Note that None implies that this is a user
    supplied requirement, vs an inferred one.
:param extras_requested: an iterable of extras used to evaluate the
    environment markers.
:return: Additional requirements to scan. That is either [] if
    the requirement is not applicable, or [install_req] if the
    requirement is applicable and has just been added.

**Param√®tres :**

- `requirement_set`
- `install_req`
- `parent_req_name`
- `extras_requested`

##### _is_upgrade_allowed

**Param√®tres :**

- `req`

##### _set_req_to_reinstall

Set a requirement to be installed.

**Param√®tres :**

- `req`

##### _check_skip_installed

Check if req_to_install should be skipped.

This will check if the req is installed, and whether we should upgrade
or reinstall it, taking into account all the relevant user options.

After calling this req_to_install will only have satisfied_by set to
None if the req_to_install is to be upgraded/reinstalled etc. Any
other value will be a dist recording the current thing installed that
satisfies the requirement.

Note that for vcs urls and the like we can't assess skipping in this
routine - we simply identify that we need to pull the thing down,
then later on it is pulled down and introspected to assess upgrade/
reinstalls etc.

:return: A text reason for why it was skipped, or None.

**Param√®tres :**

- `req_to_install`

##### _find_requirement_link

**Param√®tres :**

- `req`

##### _populate_link

Ensure that if a link can be found for this, that it is found.

Note that req.link may still be None - if the requirement is already
installed and not needed to be upgraded based on the return value of
_is_upgrade_allowed().

If preparer.require_hashes is True, don't use the wheel cache, because
cached wheels, always built locally, have different hashes than the
files downloaded from the index server and thus throw false hash
mismatches. Furthermore, cached wheels at present have undeterministic
contents due to file modification times.

**Param√®tres :**

- `req`

##### _get_dist_for

Takes a InstallRequirement and returns a single AbstractDist         representing a prepared variant of the same.
        

**Param√®tres :**

- `req`

##### _resolve_one

Prepare a single requirements file.

:return: A list of additional InstallRequirements to also install.

**Param√®tres :**

- `requirement_set`
- `req_to_install`

##### get_installation_order

Create the installation order.

The installation order is topological - requirements are installed
before the requiring thing. We break cycles at an arbitrary point,
and make no other guarantees.

**Param√®tres :**

- `req_set`

##### add_req

**Param√®tres :**

- `subreq`
- `extras_requested`

##### schedule

**Param√®tres :**

- `req`

---

### .!23002!resolver

---

### base

#### Classes

##### Constraint

**M√©thodes :**

- `empty()`
- `from_ireq()`
- `__bool__()`
- `__and__()`
- `is_satisfied_by()`

##### Requirement

**M√©thodes :**

- `project_name()`
- `name()`
- `is_satisfied_by()`
- `get_candidate_lookup()`
- `format_for_error()`

##### Candidate

**M√©thodes :**

- `project_name()`
- `name()`
- `version()`
- `is_installed()`
- `is_editable()`
- `source_link()`
- `iter_dependencies()`
- `get_install_requirement()`
- `format_for_error()`

#### Fonctions

##### format_name

**Param√®tres :**

- `project`
- `extras`

##### _match_link

**Param√®tres :**

- `link`
- `candidate`

##### empty

**Param√®tres :**

- `cls`

##### from_ireq

**Param√®tres :**

- `cls`
- `ireq`

##### __bool__

##### __and__

**Param√®tres :**

- `other`

##### is_satisfied_by

**Param√®tres :**

- `candidate`

##### project_name

The "project name" of a requirement.

This is different from ``name`` if this requirement contains extras,
in which case ``name`` would contain the ``[...]`` part, while this
refers to the name of the project.

##### name

The name identifying this requirement in the resolver.

This is different from ``project_name`` if this requirement contains
extras, where ``project_name`` would not contain the ``[...]`` part.

##### is_satisfied_by

**Param√®tres :**

- `candidate`

##### get_candidate_lookup

##### format_for_error

##### project_name

The "project name" of the candidate.

This is different from ``name`` if this candidate contains extras,
in which case ``name`` would contain the ``[...]`` part, while this
refers to the name of the project.

##### name

The name identifying this candidate in the resolver.

This is different from ``project_name`` if this candidate contains
extras, where ``project_name`` would not contain the ``[...]`` part.

##### version

##### is_installed

##### is_editable

##### source_link

##### iter_dependencies

**Param√®tres :**

- `with_requires`

##### get_install_requirement

##### format_for_error

---

### candidates

#### Classes

##### _InstallRequirementBackedCandidate

A candidate backed by an ``InstallRequirement``.

This represents a package request with the target not being already
in the environment, and needs to be fetched and installed. The backing
``InstallRequirement`` is responsible for most of the leg work; this
class exposes appropriate information to the resolver.

:param link: The link passed to the ``InstallRequirement``. The backing
    ``InstallRequirement`` will use this link to fetch the distribution.
:param source_link: The link this candidate "originates" from. This is
    different from ``link`` when the link is found in the wheel cache.
    ``link`` would point to the wheel cache, while this points to the
    found remote link (e.g. from pypi.org).

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `source_link()`
- `project_name()`
- `name()`
- `version()`
- `format_for_error()`
- `_prepare_distribution()`
- `_check_metadata_consistency()`
- `_prepare()`
- `iter_dependencies()`
- `get_install_requirement()`

##### LinkCandidate

**M√©thodes :**

- `__init__()`
- `_prepare_distribution()`

##### EditableCandidate

**M√©thodes :**

- `__init__()`
- `_prepare_distribution()`

##### AlreadyInstalledCandidate

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__eq__()`
- `__hash__()`
- `project_name()`
- `name()`
- `version()`
- `is_editable()`
- `format_for_error()`
- `iter_dependencies()`
- `get_install_requirement()`

##### ExtrasCandidate

A candidate that has 'extras', indicating additional dependencies.

Requirements can be for a project with dependencies, something like
foo[extra].  The extras don't affect the project/version being installed
directly, but indicate that we need additional dependencies. We model that
by having an artificial ExtrasCandidate that wraps the "base" candidate.

The ExtrasCandidate differs from the base in the following ways:

1. It has a unique name, of the form foo[extra]. This causes the resolver
   to treat it as a separate node in the dependency graph.
2. When we're getting the candidate's dependencies,
   a) We specify that we want the extra dependencies as well.
   b) We add a dependency on the base candidate.
      See below for why this is needed.
3. We return None for the underlying InstallRequirement, as the base
   candidate will provide it, and we don't want to end up with duplicates.

The dependency on the base candidate is needed so that the resolver can't
decide that it should recommend foo[extra1] version 1.0 and foo[extra2]
version 2.0. Having those candidates depend on foo=1.0 and foo=2.0
respectively forces the resolver to recognise that this is a conflict.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `project_name()`
- `name()`
- `version()`
- `format_for_error()`
- `is_installed()`
- `is_editable()`
- `source_link()`
- `iter_dependencies()`
- `get_install_requirement()`

##### RequiresPythonCandidate

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `project_name()`
- `name()`
- `version()`
- `format_for_error()`
- `iter_dependencies()`
- `get_install_requirement()`

#### Fonctions

##### as_base_candidate

The runtime version of BaseCandidate.

**Param√®tres :**

- `candidate`

##### make_install_req_from_link

**Param√®tres :**

- `link`
- `template`

##### make_install_req_from_editable

**Param√®tres :**

- `link`
- `template`

##### _make_install_req_from_dist

**Param√®tres :**

- `dist`
- `template`

##### __init__

**Param√®tres :**

- `link`
- `source_link`
- `ireq`
- `factory`
- `name`
- `version`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### source_link

##### project_name

The normalised name of the project the candidate refers to

##### name

##### version

##### format_for_error

##### _prepare_distribution

##### _check_metadata_consistency

Check for consistency of project name and version of dist.

**Param√®tres :**

- `dist`

##### _prepare

##### iter_dependencies

**Param√®tres :**

- `with_requires`

##### get_install_requirement

##### __init__

**Param√®tres :**

- `link`
- `template`
- `factory`
- `name`
- `version`

##### _prepare_distribution

##### __init__

**Param√®tres :**

- `link`
- `template`
- `factory`
- `name`
- `version`

##### _prepare_distribution

##### __init__

**Param√®tres :**

- `dist`
- `template`
- `factory`

##### __str__

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### project_name

##### name

##### version

##### is_editable

##### format_for_error

##### iter_dependencies

**Param√®tres :**

- `with_requires`

##### get_install_requirement

##### __init__

:param comes_from: the InstallRequirement that led to this candidate if it
    differs from the base's InstallRequirement. This will often be the
    case in the sense that this candidate's requirement has the extras
    while the base's does not. Unlike the InstallRequirement backed
    candidates, this requirement is used solely for reporting purposes,
    it does not do any leg work.

**Param√®tres :**

- `base`
- `extras`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### project_name

##### name

The normalised name of the project the candidate refers to

##### version

##### format_for_error

##### is_installed

##### is_editable

##### source_link

##### iter_dependencies

**Param√®tres :**

- `with_requires`

##### get_install_requirement

##### __init__

**Param√®tres :**

- `py_version_info`

##### __str__

##### __repr__

##### project_name

##### name

##### version

##### format_for_error

##### iter_dependencies

**Param√®tres :**

- `with_requires`

##### get_install_requirement

---

### factory

#### Classes

##### CollectedRootRequirements

##### Factory

**M√©thodes :**

- `__init__()`
- `force_reinstall()`
- `_fail_if_link_is_unsupported_wheel()`
- `_make_extras_candidate()`
- `_make_candidate_from_dist()`
- `_make_candidate_from_link()`
- `_make_base_candidate_from_link()`
- `_iter_found_candidates()`
- `_iter_explicit_candidates_from_base()`
- `_iter_candidates_from_constraints()`
- `find_candidates()`
- `_make_requirements_from_install_req()`
- `collect_root_requirements()`
- `make_requirement_from_candidate()`
- `make_requirements_from_spec()`
- `make_requires_python_requirement()`
- `get_wheel_cache_entry()`
- `get_dist_to_uninstall()`
- `_report_requires_python_error()`
- `_report_single_requirement_conflict()`
- `get_installation_error()`

##### ConflictCause

#### Fonctions

##### __init__

**Param√®tres :**

- `finder`
- `preparer`
- `make_install_req`
- `wheel_cache`
- `use_user_site`
- `force_reinstall`
- `ignore_installed`
- `ignore_requires_python`
- `py_version_info`

##### force_reinstall

##### _fail_if_link_is_unsupported_wheel

**Param√®tres :**

- `link`

##### _make_extras_candidate

**Param√®tres :**

- `base`
- `extras`

##### _make_candidate_from_dist

**Param√®tres :**

- `dist`
- `extras`
- `template`

##### _make_candidate_from_link

**Param√®tres :**

- `link`
- `extras`
- `template`
- `name`
- `version`

##### _make_base_candidate_from_link

**Param√®tres :**

- `link`
- `template`
- `name`
- `version`

##### _iter_found_candidates

**Param√®tres :**

- `ireqs`
- `specifier`
- `hashes`
- `prefers_installed`
- `incompatible_ids`

##### _iter_explicit_candidates_from_base

Produce explicit candidates from the base given an extra-ed package.

:param base_requirements: Requirements known to the resolver. The
    requirements are guaranteed to not have extras.
:param extras: The extras to inject into the explicit requirements'
    candidates.

**Param√®tres :**

- `base_requirements`
- `extras`

##### _iter_candidates_from_constraints

Produce explicit candidates from constraints.

This creates "fake" InstallRequirement objects that are basically clones
of what "should" be the template, but with original_link set to link.

**Param√®tres :**

- `identifier`
- `constraint`
- `template`

##### find_candidates

**Param√®tres :**

- `identifier`
- `requirements`
- `incompatibilities`
- `constraint`
- `prefers_installed`
- `is_satisfied_by`

##### _make_requirements_from_install_req

Returns requirement objects associated with the given InstallRequirement. In
most cases this will be a single object but the following special cases exist:
    - the InstallRequirement has markers that do not apply -> result is empty
    - the InstallRequirement has both a constraint (or link) and extras
        -> result is split in two requirement objects: one with the constraint
        (or link) and one with the extra. This allows centralized constraint
        handling for the base, resulting in fewer candidate rejections.

**Param√®tres :**

- `ireq`
- `requested_extras`

##### collect_root_requirements

**Param√®tres :**

- `root_ireqs`

##### make_requirement_from_candidate

**Param√®tres :**

- `candidate`

##### make_requirements_from_spec

Returns requirement objects associated with the given specifier. In most cases
this will be a single object but the following special cases exist:
    - the specifier has markers that do not apply -> result is empty
    - the specifier has both a constraint and extras -> result is split
        in two requirement objects: one with the constraint and one with the
        extra. This allows centralized constraint handling for the base,
        resulting in fewer candidate rejections.

**Param√®tres :**

- `specifier`
- `comes_from`
- `requested_extras`

##### make_requires_python_requirement

**Param√®tres :**

- `specifier`

##### get_wheel_cache_entry

Look up the link in the wheel cache.

If ``preparer.require_hashes`` is True, don't use the wheel cache,
because cached wheels, always built locally, have different hashes
than the files downloaded from the index server and thus throw false
hash mismatches. Furthermore, cached wheels at present have
nondeterministic contents due to file modification times.

**Param√®tres :**

- `link`
- `name`

##### get_dist_to_uninstall

**Param√®tres :**

- `candidate`

##### _report_requires_python_error

**Param√®tres :**

- `causes`

##### _report_single_requirement_conflict

**Param√®tres :**

- `req`
- `parent`

##### get_installation_error

**Param√®tres :**

- `e`
- `constraints`

##### _get_installed_candidate

Get the candidate for the currently-installed version.

##### iter_index_candidate_infos

##### text_join

**Param√®tres :**

- `parts`

##### describe_trigger

**Param√®tres :**

- `parent`

##### is_pinned

**Param√®tres :**

- `specifier`

---

### .!23011!base

---

### found_candidates

Utilities to lazily create and visit candidates found.

Creating and visiting a candidate is a *very* costly operation. It involves
fetching, extracting, potentially building modules from source, and verifying
distribution metadata. It is therefore crucial for performance to keep
everything here lazy all the way down, so we only touch candidates that we
absolutely need, and not "download the world" when we only need one version of
something.

#### Classes

##### FoundCandidates

A lazy sequence to provide candidates to the resolver.

The intended usage is to return this from `find_matches()` so the resolver
can iterate through the sequence multiple times, but only access the index
page when remote packages are actually needed. This improve performances
when suitable candidates are already installed on disk.

**M√©thodes :**

- `__init__()`
- `__getitem__()`
- `__iter__()`
- `__len__()`
- `__bool__()`

#### Fonctions

##### _iter_built

Iterator for ``FoundCandidates``.

This iterator is used when the package is not already installed. Candidates
from index come later in their normal ordering.

**Param√®tres :**

- `infos`

##### _iter_built_with_prepended

Iterator for ``FoundCandidates``.

This iterator is used when the resolver prefers the already-installed
candidate and NOT to upgrade. The installed candidate is therefore
always yielded first, and candidates from index come later in their
normal ordering, except skipped when the version is already installed.

**Param√®tres :**

- `installed`
- `infos`

##### _iter_built_with_inserted

Iterator for ``FoundCandidates``.

This iterator is used when the resolver prefers to upgrade an
already-installed package. Candidates from index are returned in their
normal ordering, except replaced when the version is already installed.

The implementation iterates through and yields other candidates, inserting
the installed candidate exactly once before we start yielding older or
equivalent candidates, or after all other candidates if they are all newer.

**Param√®tres :**

- `installed`
- `infos`

##### __init__

**Param√®tres :**

- `get_infos`
- `installed`
- `prefers_installed`
- `incompatible_ids`

##### __getitem__

**Param√®tres :**

- `index`

##### __iter__

##### __len__

##### __bool__

---

### provider

#### Classes

##### PipProvider

Pip's provider implementation for resolvelib.

:params constraints: A mapping of constraints specified by the user. Keys
    are canonicalized project names.
:params ignore_dependencies: Whether the user specified ``--no-deps``.
:params upgrade_strategy: The user-specified upgrade strategy.
:params user_requested: A set of canonicalized package names that the user
    supplied for pip to install/upgrade.

**M√©thodes :**

- `__init__()`
- `identify()`
- `narrow_requirement_selection()`
- `get_preference()`
- `find_matches()`
- `is_satisfied_by()`
- `get_dependencies()`

#### Fonctions

##### _get_with_identifier

Get item from a package name lookup mapping with a resolver identifier.

This extra logic is needed when the target mapping is keyed by package
name, which cannot be directly looked up with an identifier (which may
contain requested extras). Additional logic is added to also look up a value
by "cleaning up" the extras from the identifier.

**Param√®tres :**

- `mapping`
- `identifier`
- `default`

##### __init__

**Param√®tres :**

- `factory`
- `constraints`
- `ignore_dependencies`
- `upgrade_strategy`
- `user_requested`

##### identify

**Param√®tres :**

- `requirement_or_candidate`

##### narrow_requirement_selection

Produce a subset of identifiers that should be considered before others.

Currently pip narrows the following selection:
    * Requires-Python, if present is always returned by itself
    * Backtrack causes are considered next because they can be identified
      in linear time here, whereas because get_preference() is called
      for each identifier, it would be quadratic to check for them there.
      Further, the current backtrack causes likely need to be resolved
      before other requirements as a resolution can't be found while
      there is a conflict.

**Param√®tres :**

- `identifiers`
- `resolutions`
- `candidates`
- `information`
- `backtrack_causes`

##### get_preference

Produce a sort key for given requirement based on preference.

The lower the return value is, the more preferred this group of
arguments is.

Currently pip considers the following in order:

* Any requirement that is "direct", e.g., points to an explicit URL.
* Any requirement that is "pinned", i.e., contains the operator ``===``
  or ``==`` without a wildcard.
* Any requirement that imposes an upper version limit, i.e., contains the
  operator ``<``, ``<=``, ``~=``, or ``==`` with a wildcard. Because
  pip prioritizes the latest version, preferring explicit upper bounds
  can rule out infeasible candidates sooner. This does not imply that
  upper bounds are good practice; they can make dependency management
  and resolution harder.
* Order user-specified requirements as they are specified, placing
  other requirements afterward.
* Any "non-free" requirement, i.e., one that contains at least one
  operator, such as ``>=`` or ``!=``.
* Alphabetical order for consistency (aids debuggability).

**Param√®tres :**

- `identifier`
- `resolutions`
- `candidates`
- `information`
- `backtrack_causes`

##### find_matches

**Param√®tres :**

- `identifier`
- `requirements`
- `incompatibilities`

##### is_satisfied_by

**Param√®tres :**

- `requirement`
- `candidate`

##### get_dependencies

**Param√®tres :**

- `candidate`

##### _eligible_for_upgrade

Are upgrades allowed for this project?

This checks the upgrade strategy, and whether the project was one
that the user specified in the command line, in order to decide
whether we should upgrade if there's a newer version available.

(Note that we don't need access to the `--upgrade` flag, because
an upgrade strategy of "to-satisfy-only" means that `--upgrade`
was not specified).

**Param√®tres :**

- `identifier`

---

### reporter

#### Classes

##### PipReporter

**M√©thodes :**

- `__init__()`
- `rejecting_candidate()`

##### PipDebuggingReporter

A reporter that does an info log for every event it sees.

**M√©thodes :**

- `starting()`
- `starting_round()`
- `ending_round()`
- `ending()`
- `adding_requirement()`
- `rejecting_candidate()`
- `pinning()`

#### Fonctions

##### __init__

##### rejecting_candidate

**Param√®tres :**

- `criterion`
- `candidate`

##### starting

##### starting_round

**Param√®tres :**

- `index`

##### ending_round

**Param√®tres :**

- `index`
- `state`

##### ending

**Param√®tres :**

- `state`

##### adding_requirement

**Param√®tres :**

- `requirement`
- `parent`

##### rejecting_candidate

**Param√®tres :**

- `criterion`
- `candidate`

##### pinning

**Param√®tres :**

- `candidate`

---

### requirements

#### Classes

##### ExplicitRequirement

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `project_name()`
- `name()`
- `format_for_error()`
- `get_candidate_lookup()`
- `is_satisfied_by()`

##### SpecifierRequirement

**M√©thodes :**

- `__init__()`
- `_equal()`
- `__str__()`
- `__repr__()`
- `__eq__()`
- `__hash__()`
- `project_name()`
- `name()`
- `format_for_error()`
- `get_candidate_lookup()`
- `is_satisfied_by()`

##### SpecifierWithoutExtrasRequirement

Requirement backed by an install requirement on a base package.
Trims extras from its install requirement if there are any.

**M√©thodes :**

- `__init__()`
- `_equal()`
- `__eq__()`
- `__hash__()`

##### RequiresPythonRequirement

A requirement representing Requires-Python metadata.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `project_name()`
- `name()`
- `format_for_error()`
- `get_candidate_lookup()`
- `is_satisfied_by()`

##### UnsatisfiableRequirement

A requirement that cannot be satisfied.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__eq__()`
- `__hash__()`
- `project_name()`
- `name()`
- `format_for_error()`
- `get_candidate_lookup()`
- `is_satisfied_by()`

#### Fonctions

##### __init__

**Param√®tres :**

- `candidate`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### project_name

##### name

##### format_for_error

##### get_candidate_lookup

##### is_satisfied_by

**Param√®tres :**

- `candidate`

##### __init__

**Param√®tres :**

- `ireq`

##### _equal

##### __str__

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### project_name

##### name

##### format_for_error

##### get_candidate_lookup

##### is_satisfied_by

**Param√®tres :**

- `candidate`

##### __init__

**Param√®tres :**

- `ireq`

##### _equal

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __init__

**Param√®tres :**

- `specifier`
- `match`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### project_name

##### name

##### format_for_error

##### get_candidate_lookup

##### is_satisfied_by

**Param√®tres :**

- `candidate`

##### __init__

**Param√®tres :**

- `name`

##### __str__

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### project_name

##### name

##### format_for_error

##### get_candidate_lookup

##### is_satisfied_by

**Param√®tres :**

- `candidate`

---

### resolver

#### Classes

##### Resolver

**M√©thodes :**

- `__init__()`
- `resolve()`
- `get_installation_order()`

#### Fonctions

##### get_topological_weights

Assign weights to each node based on how "deep" they are.

This implementation may change at any point in the future without prior
notice.

We first simplify the dependency graph by pruning any leaves and giving them
the highest weight: a package without any dependencies should be installed
first. This is done again and again in the same way, giving ever less weight
to the newly found leaves. The loop stops when no leaves are left: all
remaining packages have at least one dependency left in the graph.

Then we continue with the remaining graph, by taking the length for the
longest path to any node from root, ignoring any paths that contain a single
node twice (i.e. cycles). This is done through a depth-first search through
the graph, while keeping track of the path to the node.

Cycles in the graph result would result in node being revisited while also
being on its own path. In this case, take no action. This helps ensure we
don't get stuck in a cycle.

When assigning weight, the longer path (i.e. larger length) is preferred.

We are only interested in the weights of packages that are in the
requirement_keys.

**Param√®tres :**

- `graph`
- `requirement_keys`

##### _req_set_item_sorter

Key function used to sort install requirements for installation.

Based on the "weight" mapping calculated in ``get_installation_order()``.
The canonical package name is returned as the second member as a tie-
breaker to ensure the result is predictable, which is useful in tests.

**Param√®tres :**

- `item`
- `weights`

##### __init__

**Param√®tres :**

- `preparer`
- `finder`
- `wheel_cache`
- `make_install_req`
- `use_user_site`
- `ignore_dependencies`
- `ignore_installed`
- `ignore_requires_python`
- `force_reinstall`
- `upgrade_strategy`
- `py_version_info`

##### resolve

**Param√®tres :**

- `root_reqs`
- `check_supported_wheels`

##### get_installation_order

Get order for installation of requirements in RequirementSet.

The returned list contains a requirement before another that depends on
it. This helps ensure that the environment is kept consistent as they
get installed one-by-one.

The current implementation creates a topological ordering of the
dependency graph, giving more weight to packages with less
or no dependencies, while breaking any cycles in the graph at
arbitrary points. We make no guarantees about where the cycle
would be broken, other than it *would* be broken.

**Param√®tres :**

- `req_set`

##### visit

**Param√®tres :**

- `node`

---

### .!23019!candidates

---

### .!23024!factory

---

### .!23031!found_candidates

---

### .!23036!provider

---

### .!23040!reporter

---

### .!23045!requirements

---

### .!23049!resolver

---

### _jaraco_text

Functions brought over from jaraco.text.

These functions are not supposed to be used within `pip._internal`. These are
helper functions brought over from `jaraco.text` to enable vendoring newer
copies of `pkg_resources` without having to vendor `jaraco.text` and its entire
dependency cone; something that our vendoring setup is not currently capable of
handling.

License reproduced from original source below:

Copyright Jason R. Coombs

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to
deal in the Software without restriction, including without limitation the
rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
sell copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
IN THE SOFTWARE.

#### Fonctions

##### _nonblank

**Param√®tres :**

- `str`

##### yield_lines

Yield valid lines of a string or iterable.

>>> list(yield_lines(''))
[]
>>> list(yield_lines(['foo', 'bar']))
['foo', 'bar']
>>> list(yield_lines('foo\nbar'))
['foo', 'bar']
>>> list(yield_lines('\nfoo\n#bar\nbaz #comment'))
['foo', 'baz #comment']
>>> list(yield_lines(['foo\nbar', 'baz', 'bing\n\n\n']))
['foo', 'bar', 'baz', 'bing']

**Param√®tres :**

- `iterable`

##### _

**Param√®tres :**

- `text`

##### drop_comment

Drop comments.

>>> drop_comment('foo # bar')
'foo'

A hash without a space may be in a URL.

>>> drop_comment('http://example.com/foo#bar')
'http://example.com/foo#bar'

**Param√®tres :**

- `line`

##### join_continuation

Join lines continued by a trailing backslash.

>>> list(join_continuation(['foo \\', 'bar', 'baz']))
['foobar', 'baz']
>>> list(join_continuation(['foo \\', 'bar', 'baz']))
['foobar', 'baz']
>>> list(join_continuation(['foo \\', 'bar \\', 'baz']))
['foobarbaz']

Not sure why, but...
The character preceding the backslash is also elided.

>>> list(join_continuation(['goo\\', 'dly']))
['godly']

A terrible idea, but...
If no line is available to continue, suppress the lines.

>>> list(join_continuation(['foo', 'bar\\', 'baz\\']))
['foo']

**Param√®tres :**

- `lines`

---

### _log

Customize logging

Defines custom logger class for the `logger.verbose(...)` method.

init_logging() must be called before any other modules that call logging.getLogger.

#### Classes

##### VerboseLogger

Custom Logger, defining a verbose log-level

VERBOSE is between INFO and DEBUG.

**M√©thodes :**

- `verbose()`

#### Fonctions

##### getLogger

logging.getLogger, but ensures our VerboseLogger class is returned

**Param√®tres :**

- `name`

##### init_logging

Register our VerboseLogger and VERBOSE log level.

Should be called before any calls to getLogger(),
i.e. in pip._internal.__init__

##### verbose

**Param√®tres :**

- `msg`

---

### appdirs

This code wraps the vendored appdirs module to so the return values are
compatible for the current pip code base.

The intention is to rewrite current usages gradually, keeping the tests pass,
and eventually drop this after all usages are changed.

#### Fonctions

##### user_cache_dir

**Param√®tres :**

- `appname`

##### _macos_user_config_dir

**Param√®tres :**

- `appname`
- `roaming`

##### user_config_dir

**Param√®tres :**

- `appname`
- `roaming`

##### site_config_dirs

**Param√®tres :**

- `appname`

---

### compat

Stuff that differs in different Python versions and platform
distributions.

#### Fonctions

##### has_tls

##### get_path_uid

Return path's uid.

Does not follow symlinks:
    https://github.com/pypa/pip/pull/935#discussion_r5307003

Placed this function in compat due to differences on AIX and
Jython, that should eventually go away.

:raises OSError: When path is a symlink or can't be read.

**Param√®tres :**

- `path`

##### open_text_resource

**Param√®tres :**

- `package`
- `resource`
- `encoding`
- `errors`

---

### compatibility_tags

Generate and work with PEP 425 Compatibility Tags.

#### Fonctions

##### version_info_to_nodot

**Param√®tres :**

- `version_info`

##### _mac_platforms

**Param√®tres :**

- `arch`

##### _ios_platforms

**Param√®tres :**

- `arch`

##### _android_platforms

**Param√®tres :**

- `arch`

##### _custom_manylinux_platforms

**Param√®tres :**

- `arch`

##### _get_custom_platforms

**Param√®tres :**

- `arch`

##### _expand_allowed_platforms

**Param√®tres :**

- `platforms`

##### _get_python_version

**Param√®tres :**

- `version`

##### _get_custom_interpreter

**Param√®tres :**

- `implementation`
- `version`

##### get_supported

Return a list of supported tags for each version specified in
`versions`.

:param version: a string version, of the form "33" or "32",
    or None. The version will be assumed to support our ABI.
:param platform: specify a list of platforms you want valid
    tags for, or None. If None, use the local system platform.
:param impl: specify the exact implementation you want valid
    tags for, or None. If None, use the local interpreter impl.
:param abis: specify a list of abis you want valid
    tags for, or None. If None, use the local interpreter abi.

**Param√®tres :**

- `version`
- `platforms`
- `impl`
- `abis`

---

### datetime

For when pip wants to check the date or time.

#### Fonctions

##### today_is_later_than

**Param√®tres :**

- `year`
- `month`
- `day`

---

### deprecation

A module that implements tooling to enable easy warnings about deprecations.

#### Classes

##### PipDeprecationWarning

#### Fonctions

##### _showwarning

**Param√®tres :**

- `message`
- `category`
- `filename`
- `lineno`
- `file`
- `line`

##### install_warning_logger

##### deprecated

Helper to deprecate existing functionality.

reason:
    Textual reason shown to the user about why this functionality has
    been deprecated. Should be a complete sentence.
replacement:
    Textual suggestion shown to the user about what alternative
    functionality they can use.
gone_in:
    The version of pip does this functionality should get removed in.
    Raises an error if pip's current version is greater than or equal to
    this.
feature_flag:
    Command-line flag of the form --use-feature={feature_flag} for testing
    upcoming functionality.
issue:
    Issue number on the tracker that would serve as a useful place for
    users to find related discussion and provide feedback.

---

### direct_url_helpers

#### Fonctions

##### direct_url_as_pep440_direct_reference

Convert a DirectUrl to a pip requirement string.

**Param√®tres :**

- `direct_url`
- `name`

##### direct_url_for_editable

**Param√®tres :**

- `source_dir`

##### direct_url_from_link

**Param√®tres :**

- `link`
- `source_dir`
- `link_is_in_wheel_cache`

---

### egg_link

#### Fonctions

##### _egg_link_names

Convert a Name metadata value to a .egg-link name, by applying
the same substitution as pkg_resources's safe_name function.
Note: we cannot use canonicalize_name because it has a different logic.

We also look for the raw name (without normalization) as setuptools 69 changed
the way it names .egg-link files (https://github.com/pypa/setuptools/issues/4167).

**Param√®tres :**

- `raw_name`

##### egg_link_path_from_sys_path

Look for a .egg-link file for project name, by walking sys.path.

**Param√®tres :**

- `raw_name`

##### egg_link_path_from_location

Return the path for the .egg-link file if it exists, otherwise, None.

There's 3 scenarios:
1) not in a virtualenv
   try to find in site.USER_SITE, then site_packages
2) in a no-global virtualenv
   try to find in site_packages
3) in a yes-global virtualenv
   try to find in site_packages, then site.USER_SITE
   (don't look in global location)

For #1 and #3, there could be odd cases, where there's an egg-link in 2
locations.

This method will just return the first one found.

**Param√®tres :**

- `raw_name`

---

### .!23064!_log

---

### entrypoints

#### Fonctions

##### _wrapper

Central wrapper for all old entrypoints.

Historically pip has had several entrypoints defined. Because of issues
arising from PATH, sys.path, multiple Pythons, their interactions, and most
of them having a pip installed, users suffer every time an entrypoint gets
moved.

To alleviate this pain, and provide a mechanism for warning users and
directing them to an appropriate place for help, we now define all of
our old entrypoints as wrappers for the current one.

**Param√®tres :**

- `args`

##### get_best_invocation_for_this_pip

Try to figure out the best way to invoke pip in the current environment.

##### get_best_invocation_for_this_python

Try to figure out the best way to invoke the current Python.

---

### .!23130!misc

---

### filesystem

#### Fonctions

##### check_path_owner

**Param√®tres :**

- `path`

##### adjacent_tmp_file

Return a file-like object pointing to a tmp file next to path.

The file is created securely and is ensured to be written to disk
after the context reaches its end.

kwargs will be passed to tempfile.NamedTemporaryFile to control
the way the temporary file will be opened.

**Param√®tres :**

- `path`

##### test_writable_dir

Check if a directory is writable.

Uses os.access() on POSIX, tries creating files on Windows.

**Param√®tres :**

- `path`

##### _test_writable_dir_win

**Param√®tres :**

- `path`

##### find_files

Returns a list of absolute paths of files beneath path, recursively,
with filenames which match the UNIX-style shell glob pattern.

**Param√®tres :**

- `path`
- `pattern`

##### file_size

**Param√®tres :**

- `path`

##### format_file_size

**Param√®tres :**

- `path`

##### directory_size

**Param√®tres :**

- `path`

##### format_directory_size

**Param√®tres :**

- `path`

---

### .!23167!urls

---

### filetypes

Filetype information.

#### Fonctions

##### is_archive_file

Return True if `name` is a considered as an archive file.

**Param√®tres :**

- `name`

---

### glibc

#### Fonctions

##### glibc_version_string

Returns glibc version string, or None if not using glibc.

##### glibc_version_string_confstr

Primary implementation of glibc_version_string using os.confstr.

##### glibc_version_string_ctypes

Fallback implementation of glibc_version_string using ctypes.

##### libc_ver

Try to determine the glibc version

Returns a tuple of strings (lib, version) which default to empty strings
in case the lookup fails.

---

### hashes

#### Classes

##### Hashes

A wrapper that builds multiple hashes at once and checks them against
known-good values

**M√©thodes :**

- `__init__()`
- `__and__()`
- `digest_count()`
- `is_hash_allowed()`
- `check_against_chunks()`
- `_raise()`
- `check_against_file()`
- `check_against_path()`
- `has_one_of()`
- `__bool__()`
- `__eq__()`
- `__hash__()`

##### MissingHashes

A workalike for Hashes used when we're missing a hash for a requirement

It computes the actual hash of the requirement and raises a HashMissing
exception showing it to the user.

**M√©thodes :**

- `__init__()`
- `_raise()`

#### Fonctions

##### __init__

:param hashes: A dict of algorithm names pointing to lists of allowed
    hex digests

**Param√®tres :**

- `hashes`

##### __and__

**Param√®tres :**

- `other`

##### digest_count

##### is_hash_allowed

Return whether the given hex digest is allowed.

**Param√®tres :**

- `hash_name`
- `hex_digest`

##### check_against_chunks

Check good hashes against ones built from iterable of chunks of
data.

Raise HashMismatch if none match.

**Param√®tres :**

- `chunks`

##### _raise

**Param√®tres :**

- `gots`

##### check_against_file

Check good hashes against a file-like object

Raise HashMismatch if none match.

**Param√®tres :**

- `file`

##### check_against_path

**Param√®tres :**

- `path`

##### has_one_of

Return whether any of the given hashes are allowed.

**Param√®tres :**

- `hashes`

##### __bool__

Return whether I know any known-good hashes.

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __init__

Don't offer the ``hashes`` kwarg.

##### _raise

**Param√®tres :**

- `gots`

---

### logging

#### Classes

##### BrokenStdoutLoggingError

Raised if BrokenPipeError occurs for the stdout stream while logging.

##### IndentingFormatter

**M√©thodes :**

- `__init__()`
- `get_message_start()`
- `format()`

##### IndentedRenderable

**M√©thodes :**

- `__rich_console__()`

##### PipConsole

**M√©thodes :**

- `on_broken_pipe()`

##### RichPipStreamHandler

**M√©thodes :**

- `__init__()`
- `emit()`
- `handleError()`

##### BetterRotatingFileHandler

**M√©thodes :**

- `_open()`

##### MaxLevelFilter

**M√©thodes :**

- `__init__()`
- `filter()`

##### ExcludeLoggerFilter

A logging Filter that excludes records from a logger (or its children).

**M√©thodes :**

- `filter()`

#### Fonctions

##### _is_broken_pipe_error

**Param√®tres :**

- `exc_class`
- `exc`

##### indent_log

A context manager which will cause the log output to be indented for any
log messages emitted inside it.

**Param√®tres :**

- `num`

##### get_indentation

##### get_console

##### setup_logging

Configures and sets up all of the logging

Returns the requested logging level, as its integer value.

**Param√®tres :**

- `verbosity`
- `no_color`
- `user_log_file`

##### __init__

A logging.Formatter that obeys the indent_log() context manager.

:param add_timestamp: A bool indicating output lines should be prefixed
    with their record's timestamp.

##### get_message_start

Return the start of the formatted log message (not counting the
prefix to add to each line).

**Param√®tres :**

- `formatted`
- `levelno`

##### format

Calls the standard formatter, but will indent all of the log message
lines by our current indentation level.

**Param√®tres :**

- `record`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### on_broken_pipe

##### __init__

**Param√®tres :**

- `console`

##### emit

**Param√®tres :**

- `record`

##### handleError

Called when logging is unable to log some output.

**Param√®tres :**

- `record`

##### _open

##### __init__

**Param√®tres :**

- `level`

##### filter

**Param√®tres :**

- `record`

##### filter

**Param√®tres :**

- `record`

---

### misc

#### Classes

##### StreamWrapper

**M√©thodes :**

- `from_stream()`
- `encoding()`

##### HiddenText

**M√©thodes :**

- `__repr__()`
- `__str__()`
- `__eq__()`

##### ConfiguredBuildBackendHookCaller

**M√©thodes :**

- `__init__()`
- `build_wheel()`
- `build_sdist()`
- `build_editable()`
- `get_requires_for_build_wheel()`
- `get_requires_for_build_sdist()`
- `get_requires_for_build_editable()`
- `prepare_metadata_for_build_wheel()`
- `prepare_metadata_for_build_editable()`

#### Fonctions

##### get_pip_version

##### normalize_version_info

Convert a tuple of ints representing a Python version to one of length
three.

:param py_version_info: a tuple of ints representing a Python version,
    or None to specify no version. The tuple can have any length.

:return: a tuple of length three if `py_version_info` is non-None.
    Otherwise, return `py_version_info` unchanged (i.e. None).

**Param√®tres :**

- `py_version_info`

##### ensure_dir

os.path.makedirs without EEXIST.

**Param√®tres :**

- `path`

##### get_prog

##### rmtree

**Param√®tres :**

- `dir`
- `ignore_errors`
- `onexc`

##### _onerror_ignore

##### _onerror_reraise

##### rmtree_errorhandler

`rmtree` error handler to 'force' a file remove (i.e. like `rm -f`).

* If a file is readonly then it's write flag is set and operation is
  retried.

* `onerror` is the original callback from `rmtree(... onerror=onerror)`
  that is chained at the end if the "rm -f" still fails.

**Param√®tres :**

- `func`
- `path`
- `exc_info`

##### display_path

Gives the display value for a given path, making it relative to cwd
if possible.

**Param√®tres :**

- `path`

##### backup_dir

Figure out the name of a directory to back up the given dir to
(adding .bak, .bak2, etc)

**Param√®tres :**

- `dir`
- `ext`

##### ask_path_exists

**Param√®tres :**

- `message`
- `options`

##### _check_no_input

Raise an error if no input is allowed.

**Param√®tres :**

- `message`

##### ask

Ask the message interactively, with the given possible responses

**Param√®tres :**

- `message`
- `options`

##### ask_input

Ask for input interactively.

**Param√®tres :**

- `message`

##### ask_password

Ask for a password interactively.

**Param√®tres :**

- `message`

##### strtobool

Convert a string representation of truth to true (1) or false (0).

True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
'val' is anything else.

**Param√®tres :**

- `val`

##### format_size

**Param√®tres :**

- `bytes`

##### tabulate

Return a list of formatted rows and a list of column sizes.

For example::

>>> tabulate([['foobar', 2000], [0xdeadbeef]])
(['foobar     2000', '3735928559'], [10, 4])

**Param√®tres :**

- `rows`

##### is_installable_dir

Is path is a directory containing pyproject.toml or setup.py?

If pyproject.toml exists, this is a PEP 517 project. Otherwise we look for
a legacy setuptools layout by identifying setup.py. We don't check for the
setup.cfg because using it without setup.py is only available for PEP 517
projects, which are already covered by the pyproject.toml check.

**Param√®tres :**

- `path`

##### read_chunks

Yield pieces of data from a file-like object until EOF.

**Param√®tres :**

- `file`
- `size`

##### normalize_path

Convert a path to its canonical, case-normalized, absolute version.

**Param√®tres :**

- `path`
- `resolve_symlinks`

##### splitext

Like os.path.splitext, but take off .tar too

**Param√®tres :**

- `path`

##### renames

Like os.renames(), but handles renaming across devices.

**Param√®tres :**

- `old`
- `new`

##### is_local

Return True if path is within sys.prefix, if we're running in a virtualenv.

If we're not in a virtualenv, all paths are considered "local."

Caution: this function assumes the head of path has been normalized
with normalize_path.

**Param√®tres :**

- `path`

##### write_output

**Param√®tres :**

- `msg`

##### enum

##### build_netloc

Build a netloc from a host-port pair

**Param√®tres :**

- `host`
- `port`

##### build_url_from_netloc

Build a full URL from a netloc.

**Param√®tres :**

- `netloc`
- `scheme`

##### parse_netloc

Return the host-port pair from a netloc.

**Param√®tres :**

- `netloc`

##### split_auth_from_netloc

Parse out and remove the auth information from a netloc.

Returns: (netloc, (username, password)).

**Param√®tres :**

- `netloc`

##### redact_netloc

Replace the sensitive data in a netloc with "****", if it exists.

For example:
    - "user:pass@example.com" returns "user:****@example.com"
    - "accesstoken@example.com" returns "****@example.com"

**Param√®tres :**

- `netloc`

##### _transform_url

Transform and replace netloc in a url.

transform_netloc is a function taking the netloc and returning a
tuple. The first element of this tuple is the new netloc. The
entire tuple is returned.

Returns a tuple containing the transformed url as item 0 and the
original tuple returned by transform_netloc as item 1.

**Param√®tres :**

- `url`
- `transform_netloc`

##### _get_netloc

**Param√®tres :**

- `netloc`

##### _redact_netloc

**Param√®tres :**

- `netloc`

##### split_auth_netloc_from_url

Parse a url into separate netloc, auth, and url with no auth.

Returns: (url_without_auth, netloc, (username, password))

**Param√®tres :**

- `url`

##### remove_auth_from_url

Return a copy of url with 'username:password@' removed.

**Param√®tres :**

- `url`

##### redact_auth_from_url

Replace the password in a given url with ****.

**Param√®tres :**

- `url`

##### redact_auth_from_requirement

Replace the password in a given requirement url with ****.

**Param√®tres :**

- `req`

##### hide_value

**Param√®tres :**

- `value`

##### hide_url

**Param√®tres :**

- `url`

##### protect_pip_from_modification_on_windows

Protection of pip.exe from modification on Windows

On Windows, any operation modifying pip should be run as:
    python -m pip ...

**Param√®tres :**

- `modifying_pip`

##### check_externally_managed

Check whether the current environment is externally managed.

If the ``EXTERNALLY-MANAGED`` config file is found, the current environment
is considered externally managed, and an ExternallyManagedEnvironment is
raised.

##### is_console_interactive

Is this console interactive?

##### hash_file

Return (hash, length) for path using hashlib.sha256()

**Param√®tres :**

- `path`
- `blocksize`

##### pairwise

Return paired elements.

For example:
    s -> (s0, s1), (s2, s3), (s4, s5), ...

**Param√®tres :**

- `iterable`

##### partition

Use a predicate to partition entries into false entries and true entries,
like

    partition(is_odd, range(10)) --> 0 2 4 6 8   and  1 3 5 7 9

**Param√®tres :**

- `pred`
- `iterable`

##### warn_if_run_as_root

Output a warning for sudo users on Unix.

In a virtual environment, sudo pip still writes to virtualenv.
On Windows, users may run pip as Administrator without issues.
This warning only applies to Unix root users outside of virtualenv.

##### from_stream

**Param√®tres :**

- `cls`
- `orig_stream`

##### encoding

##### __repr__

##### __str__

##### __eq__

**Param√®tres :**

- `other`

##### __init__

**Param√®tres :**

- `config_holder`
- `source_dir`
- `build_backend`
- `backend_path`
- `runner`
- `python_executable`

##### build_wheel

**Param√®tres :**

- `wheel_directory`
- `config_settings`
- `metadata_directory`

##### build_sdist

**Param√®tres :**

- `sdist_directory`
- `config_settings`

##### build_editable

**Param√®tres :**

- `wheel_directory`
- `config_settings`
- `metadata_directory`

##### get_requires_for_build_wheel

**Param√®tres :**

- `config_settings`

##### get_requires_for_build_sdist

**Param√®tres :**

- `config_settings`

##### get_requires_for_build_editable

**Param√®tres :**

- `config_settings`

##### prepare_metadata_for_build_wheel

**Param√®tres :**

- `metadata_directory`
- `config_settings`
- `_allow_fallback`

##### prepare_metadata_for_build_editable

**Param√®tres :**

- `metadata_directory`
- `config_settings`
- `_allow_fallback`

---

### packaging

#### Fonctions

##### check_requires_python

Check if the given Python version matches a "Requires-Python" specifier.

:param version_info: A 3-tuple of ints representing a Python
    major-minor-micro version to check (e.g. `sys.version_info[:3]`).

:return: `True` if the given Python version satisfies the requirement.
    Otherwise, return `False`.

:raises InvalidSpecifier: If `requires_python` has an invalid format.

**Param√®tres :**

- `requires_python`
- `version_info`

##### get_requirement

Construct a packaging.Requirement object with caching

**Param√®tres :**

- `req_string`

---

### retry

#### Fonctions

##### retry

Decorator to automatically retry a function on error.

If the function raises, the function is recalled with the same arguments
until it returns or the time limit is reached. When the time limit is
surpassed, the last exception raised is reraised.

:param wait: The time to wait after an error before retrying, in seconds.
:param stop_after_delay: The time limit after which retries will cease,
    in seconds.

**Param√®tres :**

- `wait`
- `stop_after_delay`

##### wrapper

**Param√®tres :**

- `func`

##### retry_wrapped

---

### setuptools_build

#### Fonctions

##### make_setuptools_shim_args

Get setuptools command arguments with shim wrapped setup file invocation.

:param setup_py_path: The path to setup.py to be wrapped.
:param global_options: Additional global options.
:param no_user_config: If True, disables personal user configuration.
:param unbuffered_output: If True, adds the unbuffered switch to the
 argument list.

**Param√®tres :**

- `setup_py_path`
- `global_options`
- `no_user_config`
- `unbuffered_output`

##### make_setuptools_bdist_wheel_args

**Param√®tres :**

- `setup_py_path`
- `global_options`
- `build_options`
- `destination_dir`

##### make_setuptools_clean_args

**Param√®tres :**

- `setup_py_path`
- `global_options`

##### make_setuptools_develop_args

**Param√®tres :**

- `setup_py_path`

##### make_setuptools_egg_info_args

**Param√®tres :**

- `setup_py_path`
- `egg_info_dir`
- `no_user_config`

---

### subprocess

#### Fonctions

##### make_command

Create a CommandArgs object.

##### format_command_args

Format command arguments for display.

**Param√®tres :**

- `args`

##### reveal_command_args

Return the arguments in their raw, unredacted form.

**Param√®tres :**

- `args`

##### call_subprocess

Args:
  show_stdout: if true, use INFO to log the subprocess's stderr and
    stdout streams.  Otherwise, use DEBUG.  Defaults to False.
  extra_ok_returncodes: an iterable of integer return codes that are
    acceptable, in addition to 0. Defaults to None, which means [].
  unset_environ: an iterable of environment variable names to unset
    prior to calling subprocess.Popen().
  log_failed_cmd: if false, failed commands are not logged, only raised.
  stdout_only: if true, return only stdout, else return both. When true,
    logging of both stdout and stderr occurs when the subprocess has
    terminated, else logging occurs as subprocess output is produced.

**Param√®tres :**

- `cmd`
- `show_stdout`
- `cwd`
- `on_returncode`
- `extra_ok_returncodes`
- `extra_environ`
- `unset_environ`
- `spinner`
- `log_failed_cmd`
- `stdout_only`

##### runner_with_spinner_message

Provide a subprocess_runner that shows a spinner message.

Intended for use with for BuildBackendHookCaller. Thus, the runner has
an API that matches what's expected by BuildBackendHookCaller.subprocess_runner.

**Param√®tres :**

- `message`

##### runner

**Param√®tres :**

- `cmd`
- `cwd`
- `extra_environ`

---

### temp_dir

#### Classes

##### TempDirectoryTypeRegistry

Manages temp directory behavior

**M√©thodes :**

- `__init__()`
- `set_delete()`
- `get_delete()`

##### _Default

##### TempDirectory

Helper class that owns and cleans up a temporary directory.

This class can be used as a context manager or as an OO representation of a
temporary directory.

Attributes:
    path
        Location to the created temporary directory
    delete
        Whether the directory should be deleted when exiting
        (when used as a contextmanager)

Methods:
    cleanup()
        Deletes the temporary directory

When used as a context manager, if the delete attribute is True, on
exiting the context the temporary directory is deleted.

**M√©thodes :**

- `__init__()`
- `path()`
- `__repr__()`
- `__enter__()`
- `__exit__()`
- `_create()`
- `cleanup()`

##### AdjacentTempDirectory

Helper class that creates a temporary directory adjacent to a real one.

Attributes:
    original
        The original directory to create a temp directory for.
    path
        After calling create() or entering, contains the full
        path to the temporary directory.
    delete
        Whether the directory should be deleted when exiting
        (when used as a contextmanager)

**M√©thodes :**

- `__init__()`
- `_generate_names()`
- `_create()`

#### Fonctions

##### global_tempdir_manager

##### tempdir_registry

Provides a scoped global tempdir registry that can be used to dictate
whether directories should be deleted.

##### __init__

##### set_delete

Indicate whether a TempDirectory of the given kind should be
auto-deleted.

**Param√®tres :**

- `kind`
- `value`

##### get_delete

Get configured auto-delete flag for a given TempDirectory type,
default True.

**Param√®tres :**

- `kind`

##### __init__

**Param√®tres :**

- `path`
- `delete`
- `kind`
- `globally_managed`
- `ignore_cleanup_errors`

##### path

##### __repr__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc`
- `value`
- `tb`

##### _create

Create a temporary directory and store its path in self.path

**Param√®tres :**

- `kind`

##### cleanup

Remove the temporary directory created and reset state

##### __init__

**Param√®tres :**

- `original`
- `delete`

##### _generate_names

Generates a series of temporary names.

The algorithm replaces the leading characters in the name
with ones that are valid filesystem characters, but are not
valid package names (for both Python and pip definitions of
package).

**Param√®tres :**

- `cls`
- `name`

##### _create

**Param√®tres :**

- `kind`

##### onerror

Log a warning for a `rmtree` error and continue

**Param√®tres :**

- `func`
- `path`
- `exc_val`

---

### unpacking

Utilities related archives.

#### Fonctions

##### current_umask

Get the current umask which involves having to set it temporarily.

##### split_leading_dir

**Param√®tres :**

- `path`

##### has_leading_dir

Returns true if all the paths have the same leading path name
(i.e., everything is in one subdirectory in an archive)

**Param√®tres :**

- `paths`

##### is_within_directory

Return true if the absolute path of target is within the directory

**Param√®tres :**

- `directory`
- `target`

##### _get_default_mode_plus_executable

##### set_extracted_file_to_default_mode_plus_executable

Make file present at path have execute for user/group/world
(chmod +x) is no-op on windows per python docs

**Param√®tres :**

- `path`

##### zip_item_is_executable

**Param√®tres :**

- `info`

##### unzip_file

Unzip the file (with path `filename`) to the destination `location`.  All
files are written based on system defaults and umask (i.e. permissions are
not preserved), except that regular file members with any execute
permissions (user, group, or world) have "chmod +x" applied after being
written. Note that for windows, any execute changes using os.chmod are
no-ops per the python docs.

**Param√®tres :**

- `filename`
- `location`
- `flatten`

##### untar_file

Untar the file (with path `filename`) to the destination `location`.
All files are written based on system defaults and umask (i.e. permissions
are not preserved), except that regular file members with any execute
permissions (user, group, or world) have "chmod +x" applied on top of the
default.  Note that for windows, any execute changes using os.chmod are
no-ops per the python docs.

**Param√®tres :**

- `filename`
- `location`

##### _untar_without_filter

Fallback for Python without tarfile.data_filter

**Param√®tres :**

- `filename`
- `location`
- `tar`
- `leading`

##### unpack_file

**Param√®tres :**

- `filename`
- `location`
- `content_type`

##### pip_filter

**Param√®tres :**

- `member`
- `path`

---

### urls

#### Fonctions

##### path_to_url

Convert a path to a file: URL.  The path will be made absolute and have
quoted path parts.

**Param√®tres :**

- `path`

##### url_to_path

Convert a file: URL to a path.

**Param√®tres :**

- `url`

---

### virtualenv

#### Fonctions

##### _running_under_venv

Checks if sys.base_prefix and sys.prefix match.

This handles PEP 405 compliant virtual environments.

##### _running_under_legacy_virtualenv

Checks if sys.real_prefix is set.

This handles virtual environments created with pypa's virtualenv.

##### running_under_virtualenv

True if we're running inside a virtual environment, False otherwise.

##### _get_pyvenv_cfg_lines

Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines

Returns None, if it could not read/access the file.

##### _no_global_under_venv

Check `{sys.prefix}/pyvenv.cfg` for system site-packages inclusion

PEP 405 specifies that when system site-packages are not supposed to be
visible from a virtual environment, `pyvenv.cfg` must contain the following
line:

    include-system-site-packages = false

Additionally, log a warning if accessing the file fails.

##### _no_global_under_legacy_virtualenv

Check if "no-global-site-packages.txt" exists beside site.py

This mirrors logic in pypa/virtualenv for determining whether system
site-packages are visible in the virtual environment.

##### virtualenv_no_global

Returns a boolean, whether running in venv with no system site-packages.

---

### wheel

Support functions for working with wheel files.

#### Fonctions

##### parse_wheel

Extract information from the provided wheel, ensuring it meets basic
standards.

Returns the name of the .dist-info directory and the parsed WHEEL metadata.

**Param√®tres :**

- `wheel_zip`
- `name`

##### wheel_dist_info_dir

Returns the name of the contained .dist-info directory.

Raises AssertionError or UnsupportedWheel if not found, >1 found, or
it doesn't match the provided name.

**Param√®tres :**

- `source`
- `name`

##### read_wheel_metadata_file

**Param√®tres :**

- `source`
- `path`

##### wheel_metadata

Return the WHEEL metadata of an extracted wheel, if possible.
Otherwise, raise UnsupportedWheel.

**Param√®tres :**

- `source`
- `dist_info_dir`

##### wheel_version

Given WHEEL metadata, return the parsed Wheel-Version.
Otherwise, raise UnsupportedWheel.

**Param√®tres :**

- `wheel_data`

##### check_compatibility

Raises errors or warns if called with an incompatible Wheel-Version.

pip should refuse to install a Wheel-Version that's a major series
ahead of what it's compatible with (e.g 2.0 > 1.1); and warn when
installing a version only minor version ahead (e.g 1.2 > 1.1).

version: a 2-tuple representing a Wheel-Version (Major, Minor)
name: name of wheel or package to raise exception about

:raises UnsupportedWheel: when an incompatible Wheel-Version is given

**Param√®tres :**

- `version`
- `name`

---

### .!23059!_jaraco_text

---

### .!23069!appdirs

---

### .!23074!compat

---

### .!23078!compatibility_tags

---

### .!23083!datetime

---

### .!23087!deprecation

---

### .!23093!direct_url_helpers

---

### .!23098!egg_link

---

### .!23103!entrypoints

---

### .!23108!filesystem

---

### .!23112!filetypes

---

### .!23117!glibc

---

### .!23121!hashes

---

### .!23124!logging

---

### .!23136!packaging

---

### .!23141!retry

---

### .!23146!setuptools_build

---

### .!23150!subprocess

---

### .!23155!temp_dir

---

### .!23161!unpacking

---

### .!23170!virtualenv

---

### .!23175!wheel

---

### bazaar

#### Classes

##### Bazaar

**M√©thodes :**

- `get_base_rev_args()`
- `fetch_new()`
- `switch()`
- `update()`
- `get_url_rev_and_auth()`
- `get_remote_url()`
- `get_revision()`
- `is_commit_id_equal()`

#### Fonctions

##### get_base_rev_args

**Param√®tres :**

- `rev`

##### fetch_new

**Param√®tres :**

- `dest`
- `url`
- `rev_options`
- `verbosity`

##### switch

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### update

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### get_url_rev_and_auth

**Param√®tres :**

- `cls`
- `url`

##### get_remote_url

**Param√®tres :**

- `cls`
- `location`

##### get_revision

**Param√®tres :**

- `cls`
- `location`

##### is_commit_id_equal

Always assume the versions don't match

**Param√®tres :**

- `cls`
- `dest`
- `name`

---

### git

#### Classes

##### Git

**M√©thodes :**

- `get_base_rev_args()`
- `run_command()`
- `is_immutable_rev_checkout()`
- `get_git_version()`
- `get_current_branch()`
- `get_revision_sha()`
- `_should_fetch()`
- `resolve_revision()`
- `is_commit_id_equal()`
- `fetch_new()`
- `switch()`
- `update()`
- `get_remote_url()`
- `_git_remote_to_pip_url()`
- `has_commit()`
- `get_revision()`
- `get_subdirectory()`
- `get_url_rev_and_auth()`
- `update_submodules()`
- `get_repository_root()`
- `should_add_vcs_url_prefix()`

#### Fonctions

##### looks_like_hash

**Param√®tres :**

- `sha`

##### get_base_rev_args

**Param√®tres :**

- `rev`

##### run_command

**Param√®tres :**

- `cls`

##### is_immutable_rev_checkout

**Param√®tres :**

- `url`
- `dest`

##### get_git_version

##### get_current_branch

Return the current branch, or None if HEAD isn't at a branch
(e.g. detached HEAD).

**Param√®tres :**

- `cls`
- `location`

##### get_revision_sha

Return (sha_or_none, is_branch), where sha_or_none is a commit hash
if the revision names a remote branch or tag, otherwise None.

Args:
  dest: the repository directory.
  rev: the revision name.

**Param√®tres :**

- `cls`
- `dest`
- `rev`

##### _should_fetch

Return true if rev is a ref or is a commit that we don't have locally.

Branches and tags are not considered in this method because they are
assumed to be always available locally (which is a normal outcome of
``git clone`` and ``git fetch --tags``).

**Param√®tres :**

- `cls`
- `dest`
- `rev`

##### resolve_revision

Resolve a revision to a new RevOptions object with the SHA1 of the
branch, tag, or ref if found.

Args:
  rev_options: a RevOptions object.

**Param√®tres :**

- `cls`
- `dest`
- `url`
- `rev_options`

##### is_commit_id_equal

Return whether the current commit hash equals the given name.

Args:
  dest: the repository directory.
  name: a string name.

**Param√®tres :**

- `cls`
- `dest`
- `name`

##### fetch_new

**Param√®tres :**

- `dest`
- `url`
- `rev_options`
- `verbosity`

##### switch

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### update

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### get_remote_url

Return URL of the first remote encountered.

Raises RemoteNotFoundError if the repository does not have a remote
url configured.

**Param√®tres :**

- `cls`
- `location`

##### _git_remote_to_pip_url

Convert a remote url from what git uses to what pip accepts.

There are 3 legal forms **url** may take:

    1. A fully qualified url: ssh://git@example.com/foo/bar.git
    2. A local project.git folder: /path/to/bare/repository.git
    3. SCP shorthand for form 1: git@example.com:foo/bar.git

Form 1 is output as-is. Form 2 must be converted to URI and form 3 must
be converted to form 1.

See the corresponding test test_git_remote_url_to_pip() for examples of
sample inputs/outputs.

**Param√®tres :**

- `url`

##### has_commit

Check if rev is a commit that is available in the local repository.

**Param√®tres :**

- `cls`
- `location`
- `rev`

##### get_revision

**Param√®tres :**

- `cls`
- `location`
- `rev`

##### get_subdirectory

Return the path to Python project root, relative to the repo root.
Return None if the project root is in the repo root.

**Param√®tres :**

- `cls`
- `location`

##### get_url_rev_and_auth

Prefixes stub URLs like 'user@hostname:user/repo.git' with 'ssh://'.
That's required because although they use SSH they sometimes don't
work with a ssh:// scheme (e.g. GitHub). But we need a scheme for
parsing. Hence we remove it again afterwards and return it as a stub.

**Param√®tres :**

- `cls`
- `url`

##### update_submodules

**Param√®tres :**

- `cls`
- `location`

##### get_repository_root

**Param√®tres :**

- `cls`
- `location`

##### should_add_vcs_url_prefix

In either https or ssh form, requirements must be prefixed with git+.

**Param√®tres :**

- `repo_url`

---

### .!23190!git

---

### mercurial

#### Classes

##### Mercurial

**M√©thodes :**

- `get_base_rev_args()`
- `fetch_new()`
- `switch()`
- `update()`
- `get_remote_url()`
- `get_revision()`
- `get_requirement_revision()`
- `is_commit_id_equal()`
- `get_subdirectory()`
- `get_repository_root()`

#### Fonctions

##### get_base_rev_args

**Param√®tres :**

- `rev`

##### fetch_new

**Param√®tres :**

- `dest`
- `url`
- `rev_options`
- `verbosity`

##### switch

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### update

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### get_remote_url

**Param√®tres :**

- `cls`
- `location`

##### get_revision

Return the repository-local changeset revision number, as an integer.

**Param√®tres :**

- `cls`
- `location`

##### get_requirement_revision

Return the changeset identification hash, as a 40-character
hexadecimal string

**Param√®tres :**

- `cls`
- `location`

##### is_commit_id_equal

Always assume the versions don't match

**Param√®tres :**

- `cls`
- `dest`
- `name`

##### get_subdirectory

Return the path to Python project root, relative to the repo root.
Return None if the project root is in the repo root.

**Param√®tres :**

- `cls`
- `location`

##### get_repository_root

**Param√®tres :**

- `cls`
- `location`

---

### subversion

#### Classes

##### Subversion

**M√©thodes :**

- `should_add_vcs_url_prefix()`
- `get_base_rev_args()`
- `get_revision()`
- `get_netloc_and_auth()`
- `get_url_rev_and_auth()`
- `make_rev_args()`
- `get_remote_url()`
- `_get_svn_url_rev()`
- `is_commit_id_equal()`
- `__init__()`
- `call_vcs_version()`
- `get_vcs_version()`
- `get_remote_call_options()`
- `fetch_new()`
- `switch()`
- `update()`

#### Fonctions

##### should_add_vcs_url_prefix

**Param√®tres :**

- `cls`
- `remote_url`

##### get_base_rev_args

**Param√®tres :**

- `rev`

##### get_revision

Return the maximum revision for all files under a given location

**Param√®tres :**

- `cls`
- `location`

##### get_netloc_and_auth

This override allows the auth information to be passed to svn via the
--username and --password options instead of via the URL.

**Param√®tres :**

- `cls`
- `netloc`
- `scheme`

##### get_url_rev_and_auth

**Param√®tres :**

- `cls`
- `url`

##### make_rev_args

**Param√®tres :**

- `username`
- `password`

##### get_remote_url

**Param√®tres :**

- `cls`
- `location`

##### _get_svn_url_rev

**Param√®tres :**

- `cls`
- `location`

##### is_commit_id_equal

Always assume the versions don't match

**Param√®tres :**

- `cls`
- `dest`
- `name`

##### __init__

**Param√®tres :**

- `use_interactive`

##### call_vcs_version

Query the version of the currently installed Subversion client.

:return: A tuple containing the parts of the version information or
    ``()`` if the version returned from ``svn`` could not be parsed.
:raises: BadCommand: If ``svn`` is not installed.

##### get_vcs_version

Return the version of the currently installed Subversion client.

If the version of the Subversion client has already been queried,
a cached value will be used.

:return: A tuple containing the parts of the version information or
    ``()`` if the version returned from ``svn`` could not be parsed.
:raises: BadCommand: If ``svn`` is not installed.

##### get_remote_call_options

Return options to be used on calls to Subversion that contact the server.

These options are applicable for the following ``svn`` subcommands used
in this class.

    - checkout
    - switch
    - update

:return: A list of command line arguments to pass to ``svn``.

##### fetch_new

**Param√®tres :**

- `dest`
- `url`
- `rev_options`
- `verbosity`

##### switch

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### update

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

---

### versioncontrol

Handles all VCS (version control) support

#### Classes

##### RemoteNotFoundError

##### RemoteNotValidError

**M√©thodes :**

- `__init__()`

##### RevOptions

Encapsulates a VCS-specific revision to install, along with any VCS
install options.

Args:
    vc_class: a VersionControl subclass.
    rev: the name of the revision to install.
    extra_args: a list of extra options.

**M√©thodes :**

- `__repr__()`
- `arg_rev()`
- `to_args()`
- `to_display()`
- `make_new()`

##### VcsSupport

**M√©thodes :**

- `__init__()`
- `__iter__()`
- `backends()`
- `dirnames()`
- `all_schemes()`
- `register()`
- `unregister()`
- `get_backend_for_dir()`
- `get_backend_for_scheme()`
- `get_backend()`

##### VersionControl

**M√©thodes :**

- `should_add_vcs_url_prefix()`
- `get_subdirectory()`
- `get_requirement_revision()`
- `get_src_requirement()`
- `get_base_rev_args()`
- `is_immutable_rev_checkout()`
- `make_rev_options()`
- `_is_local_repository()`
- `get_netloc_and_auth()`
- `get_url_rev_and_auth()`
- `make_rev_args()`
- `get_url_rev_options()`
- `normalize_url()`
- `compare_urls()`
- `fetch_new()`
- `switch()`
- `update()`
- `is_commit_id_equal()`
- `obtain()`
- `unpack()`
- `get_remote_url()`
- `get_revision()`
- `run_command()`
- `is_repository_directory()`
- `get_repository_root()`

#### Fonctions

##### is_url

Return true if the name looks like a URL.

**Param√®tres :**

- `name`

##### make_vcs_requirement_url

Return the URL for a VCS requirement.

Args:
  repo_url: the remote VCS url, with any needed VCS prefix (e.g. "git+").
  project_name: the (unescaped) project name.

**Param√®tres :**

- `repo_url`
- `rev`
- `project_name`
- `subdir`

##### find_path_to_project_root_from_repo_root

Find the the Python project's root by searching up the filesystem from
`location`. Return the path to project root relative to `repo_root`.
Return None if the project root is `repo_root`, or cannot be found.

**Param√®tres :**

- `location`
- `repo_root`

##### __init__

**Param√®tres :**

- `url`

##### __repr__

##### arg_rev

##### to_args

Return the VCS-specific command arguments.

##### to_display

##### make_new

Make a copy of the current instance, but with a new rev.

Args:
  rev: the name of the revision for the new object.

**Param√®tres :**

- `rev`

##### __init__

##### __iter__

##### backends

##### dirnames

##### all_schemes

##### register

**Param√®tres :**

- `cls`

##### unregister

**Param√®tres :**

- `name`

##### get_backend_for_dir

Return a VersionControl object if a repository of that type is found
at the given directory.

**Param√®tres :**

- `location`

##### get_backend_for_scheme

Return a VersionControl object or None.

**Param√®tres :**

- `scheme`

##### get_backend

Return a VersionControl object or None.

**Param√®tres :**

- `name`

##### should_add_vcs_url_prefix

Return whether the vcs prefix (e.g. "git+") should be added to a
repository's remote url when used in a requirement.

**Param√®tres :**

- `cls`
- `remote_url`

##### get_subdirectory

Return the path to Python project root, relative to the repo root.
Return None if the project root is in the repo root.

**Param√®tres :**

- `cls`
- `location`

##### get_requirement_revision

Return the revision string that should be used in a requirement.

**Param√®tres :**

- `cls`
- `repo_dir`

##### get_src_requirement

Return the requirement string to use to redownload the files
currently at the given repository directory.

Args:
  project_name: the (unescaped) project name.

The return value has a form similar to the following:

    {repository_url}@{revision}#egg={project_name}

**Param√®tres :**

- `cls`
- `repo_dir`
- `project_name`

##### get_base_rev_args

Return the base revision arguments for a vcs command.

Args:
  rev: the name of a revision to install.  Cannot be None.

**Param√®tres :**

- `rev`

##### is_immutable_rev_checkout

Return true if the commit hash checked out at dest matches
the revision in url.

Always return False, if the VCS does not support immutable commit
hashes.

This method does not check if there are local uncommitted changes
in dest after checkout, as pip currently has no use case for that.

**Param√®tres :**

- `url`
- `dest`

##### make_rev_options

Return a RevOptions object.

Args:
  rev: the name of a revision to install.
  extra_args: a list of extra options.

**Param√®tres :**

- `cls`
- `rev`
- `extra_args`

##### _is_local_repository

posix absolute paths start with os.path.sep,
win32 ones start with drive (like c:\folder)

**Param√®tres :**

- `cls`
- `repo`

##### get_netloc_and_auth

Parse the repository URL's netloc, and return the new netloc to use
along with auth information.

Args:
  netloc: the original repository URL netloc.
  scheme: the repository URL's scheme without the vcs prefix.

This is mainly for the Subversion class to override, so that auth
information can be provided via the --username and --password options
instead of through the URL.  For other subclasses like Git without
such an option, auth information must stay in the URL.

Returns: (netloc, (username, password)).

**Param√®tres :**

- `cls`
- `netloc`
- `scheme`

##### get_url_rev_and_auth

Parse the repository URL to use, and return the URL, revision,
and auth info to use.

Returns: (url, rev, (username, password)).

**Param√®tres :**

- `cls`
- `url`

##### make_rev_args

Return the RevOptions "extra arguments" to use in obtain().

**Param√®tres :**

- `username`
- `password`

##### get_url_rev_options

Return the URL and RevOptions object to use in obtain(),
as a tuple (url, rev_options).

**Param√®tres :**

- `url`

##### normalize_url

Normalize a URL for comparison by unquoting it and removing any
trailing slash.

**Param√®tres :**

- `url`

##### compare_urls

Compare two repo URLs for identity, ignoring incidental differences.

**Param√®tres :**

- `cls`
- `url1`
- `url2`

##### fetch_new

Fetch a revision from a repository, in the case that this is the
first fetch from the repository.

Args:
  dest: the directory to fetch the repository to.
  rev_options: a RevOptions object.
  verbosity: verbosity level.

**Param√®tres :**

- `dest`
- `url`
- `rev_options`
- `verbosity`

##### switch

Switch the repo at ``dest`` to point to ``URL``.

Args:
  rev_options: a RevOptions object.

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### update

Update an already-existing repo to the given ``rev_options``.

Args:
  rev_options: a RevOptions object.

**Param√®tres :**

- `dest`
- `url`
- `rev_options`

##### is_commit_id_equal

Return whether the id of the current commit equals the given name.

Args:
  dest: the repository directory.
  name: a string name.

**Param√®tres :**

- `cls`
- `dest`
- `name`

##### obtain

Install or update in editable mode the package represented by this
VersionControl object.

:param dest: the repository directory in which to install or update.
:param url: the repository URL starting with a vcs prefix.
:param verbosity: verbosity level.

**Param√®tres :**

- `dest`
- `url`
- `verbosity`

##### unpack

Clean up current location and download the url repository
(and vcs infos) into location

:param url: the repository URL starting with a vcs prefix.
:param verbosity: verbosity level.

**Param√®tres :**

- `location`
- `url`
- `verbosity`

##### get_remote_url

Return the url used at location

Raises RemoteNotFoundError if the repository does not have a remote
url configured.

**Param√®tres :**

- `cls`
- `location`

##### get_revision

Return the current commit id of the files at the given location.

**Param√®tres :**

- `cls`
- `location`

##### run_command

Run a VCS subcommand
This is simply a wrapper around call_subprocess that adds the VCS
command name, and checks that the VCS is available

**Param√®tres :**

- `cls`
- `cmd`
- `show_stdout`
- `cwd`
- `on_returncode`
- `extra_ok_returncodes`
- `command_desc`
- `extra_environ`
- `spinner`
- `log_failed_cmd`
- `stdout_only`

##### is_repository_directory

Return whether a directory path is a repository directory.

**Param√®tres :**

- `cls`
- `path`

##### get_repository_root

Return the "root" (top-level) directory controlled by the vcs,
or `None` if the directory is not in any.

It is meant to be overridden to implement smarter detection
mechanisms for specific vcs.

This can do more than is_repository_directory() alone. For
example, the Git override checks that Git is actually available.

**Param√®tres :**

- `cls`
- `location`

---

### .!23181!__init__

---

### .!23185!bazaar

---

### .!23195!mercurial

---

### .!23198!subversion

---

### .!23203!versioncontrol

---

### typing_extensions

#### Classes

##### _Sentinel

**M√©thodes :**

- `__repr__()`

##### _ExtensionsSpecialForm

**M√©thodes :**

- `__repr__()`

##### _DefaultMixin

Mixin for TypeVarLike defaults.

##### _TypeVarLikeMeta

**M√©thodes :**

- `__instancecheck__()`

##### _EllipsisDummy

##### _SpecialForm

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `__mro_entries__()`
- `__repr__()`
- `__reduce__()`
- `__call__()`
- `__or__()`
- `__ror__()`
- `__instancecheck__()`
- `__subclasscheck__()`
- `__getitem__()`

##### Format

##### _AnyMeta

**M√©thodes :**

- `__instancecheck__()`
- `__repr__()`

##### Any

Special type indicating an unconstrained type.
- Any is compatible with every type.
- Any assumed to have all methods.
- All values assumed to be instances of Any.
Note that all the above statements are true from the point of view of
static type checkers. At runtime, Any should not be used with instance
checks.

**M√©thodes :**

- `__new__()`

##### _LiteralGenericAlias

**M√©thodes :**

- `__eq__()`
- `__hash__()`

##### _LiteralForm

**M√©thodes :**

- `__init__()`
- `__getitem__()`

##### _SpecialGenericAlias

**M√©thodes :**

- `__init__()`
- `__setattr__()`
- `__getitem__()`

##### _ProtocolMeta

**M√©thodes :**

- `__new__()`
- `__init__()`
- `__subclasscheck__()`
- `__instancecheck__()`
- `__eq__()`
- `__hash__()`

##### Protocol

**M√©thodes :**

- `__init_subclass__()`

##### SupportsInt

An ABC with one abstract method __int__.

**M√©thodes :**

- `__int__()`

##### SupportsFloat

An ABC with one abstract method __float__.

**M√©thodes :**

- `__float__()`

##### SupportsComplex

An ABC with one abstract method __complex__.

**M√©thodes :**

- `__complex__()`

##### SupportsBytes

An ABC with one abstract method __bytes__.

**M√©thodes :**

- `__bytes__()`

##### SupportsIndex

**M√©thodes :**

- `__index__()`

##### SupportsAbs

An ABC with one abstract method __abs__ that is covariant in its return type.

**M√©thodes :**

- `__abs__()`

##### SupportsRound

An ABC with one abstract method __round__ that is covariant in its return type.

**M√©thodes :**

- `__round__()`

##### SingletonMeta

**M√©thodes :**

- `__setattr__()`

##### NoDefaultType

The type of the NoDefault singleton.

**M√©thodes :**

- `__new__()`
- `__repr__()`
- `__reduce__()`

##### NoExtraItemsType

The type of the NoExtraItems singleton.

**M√©thodes :**

- `__new__()`
- `__repr__()`
- `__reduce__()`

##### _TypedDictMeta

**M√©thodes :**

- `__new__()`
- `__subclasscheck__()`

##### _AnnotatedAlias

Runtime representation of an annotated type.

At its core 'Annotated[t, dec1, dec2, ...]' is an alias for the type 't'
with extra annotations. The alias behaves like a normal typing alias,
instantiating is the same as instantiating the underlying type, binding
it to types is also the same.

**M√©thodes :**

- `__init__()`
- `copy_with()`
- `__repr__()`
- `__reduce__()`
- `__eq__()`
- `__hash__()`

##### Annotated

Add context specific metadata to a type.

Example: Annotated[int, runtime_check.Unsigned] indicates to the
hypothetical runtime_check module that this type is an unsigned int.
Every other consumer of this type can ignore this metadata and treat
this type as int.

The first argument to Annotated must be a valid type (and will be in
the __origin__ field), the remaining arguments are kept as a tuple in
the __extra__ field.

Details:

- It's an error to call `Annotated` with less than two arguments.
- Nested Annotated are flattened::

    Annotated[Annotated[T, Ann1, Ann2], Ann3] == Annotated[T, Ann1, Ann2, Ann3]

- Instantiating an annotated type is equivalent to instantiating the
underlying type::

    Annotated[C, Ann1](5) == C(5)

- Annotated can be used as a generic type alias::

    Optimized = Annotated[T, runtime.Optimize()]
    Optimized[int] == Annotated[int, runtime.Optimize()]

    OptimizedList = Annotated[List[T], runtime.Optimize()]
    OptimizedList[int] == Annotated[List[int], runtime.Optimize()]

**M√©thodes :**

- `__new__()`
- `__class_getitem__()`
- `__init_subclass__()`

##### TypeVar

Type variable.

**M√©thodes :**

- `__new__()`
- `__init_subclass__()`

##### _Immutable

Mixin to indicate that object should not be copied.

**M√©thodes :**

- `__copy__()`
- `__deepcopy__()`

##### ParamSpecArgs

The args for a ParamSpec object.

Given a ParamSpec object P, P.args is an instance of ParamSpecArgs.

ParamSpecArgs objects have a reference back to their ParamSpec:

P.args.__origin__ is P

This type is meant for runtime introspection and has no special meaning to
static type checkers.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__eq__()`

##### ParamSpecKwargs

The kwargs for a ParamSpec object.

Given a ParamSpec object P, P.kwargs is an instance of ParamSpecKwargs.

ParamSpecKwargs objects have a reference back to their ParamSpec:

P.kwargs.__origin__ is P

This type is meant for runtime introspection and has no special meaning to
static type checkers.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__eq__()`

##### _ConcatenateGenericAlias

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__hash__()`
- `__call__()`
- `__parameters__()`
- `copy_with()`
- `__getitem__()`

##### deprecated

Indicate that a class, function or overload is deprecated.

When this decorator is applied to an object, the type checker
will generate a diagnostic on usage of the deprecated object.

Usage:

    @deprecated("Use B instead")
    class A:
        pass

    @deprecated("Use g instead")
    def f():
        pass

    @overload
    @deprecated("int support is deprecated")
    def g(x: int) -> int: ...
    @overload
    def g(x: str) -> int: ...

The warning specified by *category* will be emitted at runtime
on use of deprecated objects. For functions, that happens on calls;
for classes, on instantiation and on creation of subclasses.
If the *category* is ``None``, no warning is emitted at runtime.
The *stacklevel* determines where the
warning is emitted. If it is ``1`` (the default), the warning
is emitted at the direct caller of the deprecated object; if it
is higher, it is emitted further up the stack.
Static type checker behavior is not affected by the *category*
and *stacklevel* arguments.

The deprecation message passed to the decorator is saved in the
``__deprecated__`` attribute on the decorated object.
If applied to an overload, the decorator
must be after the ``@overload`` decorator for the attribute to
exist on the overload as returned by ``get_overloads()``.

See PEP 702 for details.

**M√©thodes :**

- `__init__()`
- `__call__()`

##### _NamedTupleMeta

**M√©thodes :**

- `__new__()`

##### Buffer

Base class for classes that implement the buffer protocol.

The buffer protocol allows Python objects to expose a low-level
memory buffer interface. Before Python 3.12, it is not possible
to implement the buffer protocol in pure Python code, or even
to check whether a class implements the buffer protocol. In
Python 3.12 and higher, the ``__buffer__`` method allows access
to the buffer protocol from Python code, and the
``collections.abc.Buffer`` ABC allows checking whether a class
implements the buffer protocol.

To indicate support for the buffer protocol in earlier versions,
inherit from this ABC, either in a stub file or at runtime,
or use ABC registration. This ABC provides no methods, because
there is no Python-accessible methods shared by pre-3.12 buffer
classes. It is useful primarily for static checks.

##### NewType

NewType creates simple unique types with almost zero
runtime overhead. NewType(name, tp) is considered a subtype of tp
by static type checkers. At runtime, NewType(name, tp) returns
a dummy callable that simply returns its argument. Usage::
    UserId = NewType('UserId', int)
    def name_by_id(user_id: UserId) -> str:
        ...
    UserId('user')          # Fails type check
    name_by_id(42)          # Fails type check
    name_by_id(UserId(42))  # OK
    num = UserId(5) + 1     # type: int

**M√©thodes :**

- `__call__()`
- `__init__()`
- `__mro_entries__()`
- `__repr__()`
- `__reduce__()`

##### TypeAliasType

Create named, parameterized type aliases.

This provides a backport of the new `type` statement in Python 3.12:

    type ListOrSet[T] = list[T] | set[T]

is equivalent to:

    T = TypeVar("T")
    ListOrSet = TypeAliasType("ListOrSet", list[T] | set[T], type_params=(T,))

The name ListOrSet can then be used as an alias for the type it refers to.

The type_params argument should contain all the type parameters used
in the value of the type alias. If the alias is not generic, this
argument is omitted.

Static type checkers should only support type aliases declared using
TypeAliasType that follow these rules:

- The first argument (the name) must be a string literal.
- The TypeAliasType instance must be immediately assigned to a variable
  of the same name. (For example, 'X = TypeAliasType("Y", int)' is invalid,
  as is 'X, Y = TypeAliasType("X", int), TypeAliasType("Y", int)').

**M√©thodes :**

- `__init__()`
- `__setattr__()`
- `__delattr__()`
- `_raise_attribute_error()`
- `__repr__()`
- `_check_parameters()`
- `__getitem__()`
- `__reduce__()`
- `__init_subclass__()`
- `__call__()`

##### Doc

Define the documentation of a type annotation using ``Annotated``, to be
 used in class attributes, function and method parameters, return values,
 and variables.

The value should be a positional-only string literal to allow static tools
like editors and documentation generators to use it.

This complements docstrings.

The string value passed is available in the attribute ``documentation``.

Example::

    >>> from typing_extensions import Annotated, Doc
    >>> def hi(to: Annotated[str, Doc("Who to say hi to")]) -> None: ...

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`

##### ParamSpec

Parameter specification.

**M√©thodes :**

- `__new__()`
- `__init_subclass__()`

##### ParamSpec

Parameter specification variable.

Usage::

   P = ParamSpec('P')

Parameter specification variables exist primarily for the benefit of static
type checkers.  They are used to forward the parameter types of one
callable to another callable, a pattern commonly found in higher order
functions and decorators.  They are only valid when used in ``Concatenate``,
or s the first argument to ``Callable``. In Python 3.10 and higher,
they are also supported in user-defined Generics at runtime.
See class Generic for more information on generic types.  An
example for annotating a decorator::

   T = TypeVar('T')
   P = ParamSpec('P')

   def add_logging(f: Callable[P, T]) -> Callable[P, T]:
       '''A type-safe decorator to add logging to a function.'''
       def inner(*args: P.args, **kwargs: P.kwargs) -> T:
           logging.info(f'{f.__name__} was called')
           return f(*args, **kwargs)
       return inner

   @add_logging
   def add_two(x: float, y: float) -> float:
       '''Add two numbers together.'''
       return x + y

Parameter specification variables defined with covariant=True or
contravariant=True can be used to declare covariant or contravariant
generic types.  These keyword arguments are valid, but their actual semantics
are yet to be decided.  See PEP 612 for details.

Parameter specification variables can be introspected. e.g.:

   P.__name__ == 'T'
   P.__bound__ == None
   P.__covariant__ == False
   P.__contravariant__ == False

Note that only parameter specification variables defined in global scope can
be pickled.

**M√©thodes :**

- `args()`
- `kwargs()`
- `__init__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `__reduce__()`
- `__call__()`

##### _ConcatenateGenericAlias

**M√©thodes :**

- `copy_with()`
- `__getitem__()`

##### _ConcatenateForm

**M√©thodes :**

- `__getitem__()`

##### _TypeGuardForm

**M√©thodes :**

- `__getitem__()`

##### _TypeIsForm

**M√©thodes :**

- `__getitem__()`

##### _TypeFormForm

**M√©thodes :**

- `__call__()`

##### _TypeFormForm

**M√©thodes :**

- `__getitem__()`
- `__call__()`

##### _RequiredForm

**M√©thodes :**

- `__getitem__()`

##### _ReadOnlyForm

**M√©thodes :**

- `__getitem__()`

##### _UnpackSpecialForm

**M√©thodes :**

- `__init__()`

##### _UnpackAlias

**M√©thodes :**

- `__typing_unpacked_tuple_args__()`
- `__typing_is_unpacked_typevartuple__()`
- `__getitem__()`

##### _UnpackAlias

**M√©thodes :**

- `__typing_unpacked_tuple_args__()`
- `__typing_is_unpacked_typevartuple__()`
- `__getitem__()`

##### _UnpackForm

**M√©thodes :**

- `__getitem__()`

##### TypeVarTuple

Type variable tuple.

**M√©thodes :**

- `__new__()`
- `__init_subclass__()`

##### TypeVarTuple

Type variable tuple.

Usage::

    Ts = TypeVarTuple('Ts')

In the same way that a normal type variable is a stand-in for a single
type such as ``int``, a type variable *tuple* is a stand-in for a *tuple*
type such as ``Tuple[int, str]``.

Type variable tuples can be used in ``Generic`` declarations.
Consider the following example::

    class Array(Generic[*Ts]): ...

The ``Ts`` type variable tuple here behaves like ``tuple[T1, T2]``,
where ``T1`` and ``T2`` are type variables. To use these type variables
as type parameters of ``Array``, we must *unpack* the type variable tuple using
the star operator: ``*Ts``. The signature of ``Array`` then behaves
as if we had simply written ``class Array(Generic[T1, T2]): ...``.
In contrast to ``Generic[T1, T2]``, however, ``Generic[*Shape]`` allows
us to parameterise the class with an *arbitrary* number of type parameters.

Type variable tuples can be used anywhere a normal ``TypeVar`` can.
This includes class definitions, as shown above, as well as function
signatures and variable annotations::

    class Array(Generic[*Ts]):

        def __init__(self, shape: Tuple[*Ts]):
            self._shape: Tuple[*Ts] = shape

        def get_shape(self) -> Tuple[*Ts]:
            return self._shape

    shape = (Height(480), Width(640))
    x: Array[Height, Width] = Array(shape)
    y = abs(x)  # Inferred type is Array[Height, Width]
    z = x + x   #        ...    is Array[Height, Width]
    x.get_shape()  #     ...    is tuple[Height, Width]

**M√©thodes :**

- `__iter__()`
- `__init__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `__reduce__()`
- `__init_subclass__()`

##### _TypeAliasGenericAlias

**M√©thodes :**

- `__getattr__()`

##### Dummy

**M√©thodes :**

- `__init_subclass__()`

#### Fonctions

##### IntVar

**Param√®tres :**

- `name`

##### _get_protocol_attrs

**Param√®tres :**

- `cls`

##### _caller

**Param√®tres :**

- `depth`

##### _ensure_subclassable

**Param√®tres :**

- `mro_entries`

##### _set_default

**Param√®tres :**

- `type_param`
- `default`

##### _set_module

**Param√®tres :**

- `typevarlike`

##### _create_concatenate_alias

**Param√®tres :**

- `origin`
- `parameters`

##### _concatenate_getitem

**Param√®tres :**

- `parameters`

##### _unpack_args

##### _has_generic_or_protocol_as_origin

##### _is_unpacked_typevartuple

**Param√®tres :**

- `x`

##### __repr__

##### _should_collect_from_parameters

**Param√®tres :**

- `t`

##### __repr__

##### final

This decorator can be used to indicate to type checkers that
the decorated method cannot be overridden, and decorated class
cannot be subclassed. For example:

    class Base:
        @final
        def done(self) -> None:
            ...
    class Sub(Base):
        def done(self) -> None:  # Error reported by type checker
            ...
    @final
    class Leaf:
        ...
    class Other(Leaf):  # Error reported by type checker
        ...

There is no runtime checking of these properties. The decorator
sets the ``__final__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

**Param√®tres :**

- `f`

##### _flatten_literal_params

An internal helper for Literal creation: flatten Literals among parameters

**Param√®tres :**

- `parameters`

##### _value_and_type_iter

**Param√®tres :**

- `params`

##### overload

Decorator for overloaded functions/methods.

In a stub file, place two or more stub definitions for the same
function in a row, each decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...

In a non-stub file (i.e. a regular .py file), do the same but
follow it with an implementation.  The implementation should *not*
be decorated with @overload.  For example:

@overload
def utf8(value: None) -> None: ...
@overload
def utf8(value: bytes) -> bytes: ...
@overload
def utf8(value: str) -> bytes: ...
def utf8(value):
    # implementation goes here

The overloads for a function can be retrieved at runtime using the
get_overloads() function.

**Param√®tres :**

- `func`

##### get_overloads

Return all defined overloads for *func* as a sequence.

**Param√®tres :**

- `func`

##### clear_overloads

Clear all overloads in the registry.

##### _is_dunder

**Param√®tres :**

- `attr`

##### _allow_reckless_class_checks

Allow instance and class checks for special stdlib modules.
The abc and functools modules indiscriminately call isinstance() and
issubclass() on the whole MRO of a user class, which may contain protocols.

**Param√®tres :**

- `depth`

##### _no_init

##### _type_check_issubclass_arg_1

Raise TypeError if `arg` is not an instance of `type`
in `issubclass(arg, <protocol>)`.

In most cases, this is verified by type.__subclasscheck__.
Checking it again unnecessarily would slow down issubclass() checks,
so, we don't perform this check unless we absolutely have to.

For various error paths, however,
we want to ensure that *this* error message is shown to the user
where relevant, rather than a typing.py-specific error message.

**Param√®tres :**

- `arg`

##### _proto_hook

**Param√®tres :**

- `cls`
- `other`

##### runtime_checkable

Mark a protocol class as a runtime protocol.

Such protocol can be used with isinstance() and issubclass().
Raise TypeError if applied to a non-protocol class.
This allows a simple-minded structural check very similar to
one trick ponies in collections.abc such as Iterable.

For example::

    @runtime_checkable
    class Closable(Protocol):
        def close(self): ...

    assert isinstance(open('/some/file'), Closable)

Warning: this will check only the presence of the required methods,
not their type signatures!

**Param√®tres :**

- `cls`

##### inner

**Param√®tres :**

- `func`

##### _get_typeddict_qualifiers

**Param√®tres :**

- `annotation_type`

##### TypedDict

A simple typed namespace. At runtime it is equivalent to a plain dict.

TypedDict creates a dictionary type such that a type checker will expect all
instances to have a certain set of keys, where each key is
associated with a value of a consistent type. This expectation
is not checked at runtime.

Usage::

    class Point2D(TypedDict):
        x: int
        y: int
        label: str

    a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
    b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check

    assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')

The type info can be accessed via the Point2D.__annotations__ dict, and
the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
TypedDict supports an additional equivalent form::

    Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})

By default, all keys must be present in a TypedDict. It is possible
to override this by specifying totality::

    class Point2D(TypedDict, total=False):
        x: int
        y: int

This means that a Point2D TypedDict can have any of the keys omitted. A type
checker is only expected to support a literal False or True as the value of
the total argument. True is the default, and makes all items defined in the
class body be required.

The Required and NotRequired special forms can also be used to mark
individual keys as being required or not required::

    class Point2D(TypedDict):
        x: int  # the "x" key must always be present (Required is the default)
        y: NotRequired[int]  # the "y" key can be omitted

See PEP 655 for more details on Required and NotRequired.

##### is_typeddict

Check if an annotation is a TypedDict class

For example::
    class Film(TypedDict):
        title: str
        year: int

    is_typeddict(Film)  # => True
    is_typeddict(Union[list, str])  # => False

**Param√®tres :**

- `tp`

##### assert_type

Assert (to the type checker) that the value is of the given type.

When the type checker encounters a call to assert_type(), it
emits an error if the value is not of the specified type::

    def greet(name: str) -> None:
        assert_type(name, str)  # ok
        assert_type(name, int)  # type checker error

At runtime this returns the first argument unchanged and otherwise
does nothing.

##### _strip_extras

Strips Annotated, Required and NotRequired from a given type.

**Param√®tres :**

- `t`

##### get_type_hints

Return type hints for an object.

This is often the same as obj.__annotations__, but it handles
forward references encoded as string literals, adds Optional[t] if a
default value equal to None is set and recursively replaces all
'Annotated[T, ...]', 'Required[T]' or 'NotRequired[T]' with 'T'
(unless 'include_extras=True').

The argument may be a module, class, method, or function. The annotations
are returned as a dictionary. For classes, annotations include also
inherited members.

TypeError is raised if the argument is not of a type that can contain
annotations, and an empty dictionary is returned if no annotations are
present.

BEWARE -- the behavior of globalns and localns is counterintuitive
(unless you are familiar with how eval() and exec() work).  The
search order is locals first, then globals.

- If no dict arguments are passed, an attempt is made to use the
  globals from obj (or the respective module's globals for classes),
  and these are also used as the locals.  If the object does not appear
  to have globals, an empty dictionary is used.

- If one dict argument is passed, it is used for both globals and
  locals.

- If two dict arguments are passed, they specify globals and
  locals, respectively.

**Param√®tres :**

- `obj`
- `globalns`
- `localns`
- `include_extras`

##### _could_be_inserted_optional

detects Union[..., None] pattern

**Param√®tres :**

- `t`

##### _clean_optional

**Param√®tres :**

- `obj`
- `hints`
- `globalns`
- `localns`

##### get_origin

Get the unsubscripted version of a type.

This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
and Annotated. Return None for unsupported types. Examples::

    get_origin(Literal[42]) is Literal
    get_origin(int) is None
    get_origin(ClassVar[int]) is ClassVar
    get_origin(Generic) is Generic
    get_origin(Generic[T]) is Generic
    get_origin(Union[T, int]) is Union
    get_origin(List[Tuple[T, T]][int]) == list
    get_origin(P.args) is P

**Param√®tres :**

- `tp`

##### get_args

Get type arguments with all substitutions performed.

For unions, basic simplifications used by Union constructor are performed.
Examples::
    get_args(Dict[str, int]) == (str, int)
    get_args(int) == ()
    get_args(Union[int, Union[T, int], str][int]) == (int, str)
    get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
    get_args(Callable[[], T][int]) == ([], int)

**Param√®tres :**

- `tp`

##### __instancecheck__

**Param√®tres :**

- `cls`
- `__instance`

##### __init__

**Param√®tres :**

- `getitem`

##### __getattr__

**Param√®tres :**

- `item`

##### __mro_entries__

**Param√®tres :**

- `bases`

##### __repr__

##### __reduce__

##### __call__

##### __or__

**Param√®tres :**

- `other`

##### __ror__

**Param√®tres :**

- `other`

##### __instancecheck__

**Param√®tres :**

- `obj`

##### __subclasscheck__

**Param√®tres :**

- `cls`

##### __getitem__

**Param√®tres :**

- `parameters`

##### LiteralString

Represents an arbitrary literal string.

Example::

  from pip._vendor.typing_extensions import LiteralString

  def query(sql: LiteralString) -> ...:
      ...

  query("SELECT * FROM table")  # ok
  query(f"SELECT * FROM {input()}")  # not ok

See PEP 675 for details.

**Param√®tres :**

- `params`

##### Self

Used to spell the type of "self" in classes.

Example::

  from typing import Self

  class ReturnsSelf:
      def parse(self, data: bytes) -> Self:
          ...
          return self

**Param√®tres :**

- `params`

##### Never

The bottom type, a type that has no members.

This can be used to define a function that should never be
called, or a function that never returns::

    from pip._vendor.typing_extensions import Never

    def never_call_me(arg: Never) -> None:
        pass

    def int_or_str(arg: int | str) -> None:
        never_call_me(arg)  # type checker error
        match arg:
            case int():
                print("It's an int")
            case str():
                print("It's a str")
            case _:
                never_call_me(arg)  # ok, arg is of type Never

**Param√®tres :**

- `params`

##### _is_unpack

**Param√®tres :**

- `obj`

##### reveal_type

Reveal the inferred type of a variable.

When a static type checker encounters a call to ``reveal_type()``,
it will emit the inferred type of the argument::

    x: int = 1
    reveal_type(x)

Running a static type checker (e.g., ``mypy``) on this example
will produce output similar to 'Revealed type is "builtins.int"'.

At runtime, the function prints the runtime type of the
argument and returns it unchanged.

##### assert_never

Assert to the type checker that a line of code is unreachable.

Example::

    def int_or_str(arg: int | str) -> None:
        match arg:
            case int():
                print("It's an int")
            case str():
                print("It's a str")
            case _:
                assert_never(arg)

If a type checker finds that a call to assert_never() is
reachable, it will emit an error.

At runtime, this throws an exception when called.

##### dataclass_transform

Decorator that marks a function, class, or metaclass as providing
dataclass-like behavior.

Example:

    from pip._vendor.typing_extensions import dataclass_transform

    _T = TypeVar("_T")

    # Used on a decorator function
    @dataclass_transform()
    def create_model(cls: type[_T]) -> type[_T]:
        ...
        return cls

    @create_model
    class CustomerModel:
        id: int
        name: str

    # Used on a base class
    @dataclass_transform()
    class ModelBase: ...

    class CustomerModel(ModelBase):
        id: int
        name: str

    # Used on a metaclass
    @dataclass_transform()
    class ModelMeta(type): ...

    class ModelBase(metaclass=ModelMeta): ...

    class CustomerModel(ModelBase):
        id: int
        name: str

Each of the ``CustomerModel`` classes defined in this example will now
behave similarly to a dataclass created with the ``@dataclasses.dataclass``
decorator. For example, the type checker will synthesize an ``__init__``
method.

The arguments to this decorator can be used to customize this behavior:
- ``eq_default`` indicates whether the ``eq`` parameter is assumed to be
  True or False if it is omitted by the caller.
- ``order_default`` indicates whether the ``order`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``kw_only_default`` indicates whether the ``kw_only`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``frozen_default`` indicates whether the ``frozen`` parameter is
  assumed to be True or False if it is omitted by the caller.
- ``field_specifiers`` specifies a static list of supported classes
  or functions that describe fields, similar to ``dataclasses.field()``.

At runtime, this decorator records its arguments in the
``__dataclass_transform__`` attribute on the decorated object.

See PEP 681 for details.

##### override

Indicate that a method is intended to override a method in a base class.

Usage:

    class Base:
        def method(self) -> None:
            pass

    class Child(Base):
        @override
        def method(self) -> None:
            super().method()

When this decorator is applied to a method, the type checker will
validate that it overrides a method with the same name on a base class.
This helps prevent bugs that may occur when a base class is changed
without an equivalent change to a child class.

There is no runtime checking of these properties. The decorator
sets the ``__override__`` attribute to ``True`` on the decorated object
to allow runtime introspection.

See PEP 698 for details.

##### _is_param_expr

**Param√®tres :**

- `arg`

##### _is_param_expr

**Param√®tres :**

- `arg`

##### _check_generic

Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Param√®tres :**

- `cls`
- `parameters`
- `elen`

##### _check_generic

Check correct count for parameters of a generic cls (internal helper).

This gives a nice error message in case of count mismatch.

**Param√®tres :**

- `cls`
- `parameters`
- `elen`

##### _collect_type_vars

Collect all type variable contained in types in order of
first appearance (lexicographic order). For example::

    _collect_type_vars((T, List[S, T])) == (T, S)

**Param√®tres :**

- `types`
- `typevar_types`

##### _collect_parameters

Collect all type variables and parameter specifications in args
in order of first appearance (lexicographic order).

For example::

    assert _collect_parameters((T, Callable[P, T])) == (T, P)

**Param√®tres :**

- `args`

##### _make_nmtuple

**Param√®tres :**

- `name`
- `types`
- `module`
- `defaults`

##### _namedtuple_mro_entries

**Param√®tres :**

- `bases`

##### NamedTuple

Typed version of namedtuple.

Usage::

    class Employee(NamedTuple):
        name: str
        id: int

This is equivalent to::

    Employee = collections.namedtuple('Employee', ['name', 'id'])

The resulting class has an extra __annotations__ attribute, giving a
dict that maps field names to types.  (The field names are also in
the _fields attribute, which is part of the namedtuple API.)
An alternative equivalent functional syntax is also accepted::

    Employee = NamedTuple('Employee', [('name', str), ('id', int)])

##### get_original_bases

Return the class's "original" bases prior to modification by `__mro_entries__`.

Examples::

    from typing import TypeVar, Generic
    from pip._vendor.typing_extensions import NamedTuple, TypedDict

    T = TypeVar("T")
    class Foo(Generic[T]): ...
    class Bar(Foo[int], float): ...
    class Baz(list[str]): ...
    Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])
    Spam = TypedDict("Spam", {"a": int, "b": str})

    assert get_original_bases(Bar) == (Foo[int], float)
    assert get_original_bases(Baz) == (list[str],)
    assert get_original_bases(Eggs) == (NamedTuple,)
    assert get_original_bases(Spam) == (TypedDict,)
    assert get_original_bases(int) == (object,)

##### is_protocol

Return True if the given type is a Protocol.

Example::

    >>> from typing_extensions import Protocol, is_protocol
    >>> class P(Protocol):
    ...     def a(self) -> str: ...
    ...     b: int
    >>> is_protocol(P)
    True
    >>> is_protocol(int)
    False

##### get_protocol_members

Return the set of members defined in a Protocol.

Example::

    >>> from typing_extensions import Protocol, get_protocol_members
    >>> class P(Protocol):
    ...     def a(self) -> str: ...
    ...     b: int
    >>> get_protocol_members(P)
    frozenset({'a', 'b'})

Raise a TypeError for arguments that are not Protocols.

##### get_annotations

Compute the annotations dict for an object.

obj may be a callable, class, or module.
Passing in an object of any other type raises TypeError.

Returns a dict.  get_annotations() returns a new dict every time
it's called; calling it twice on the same object will return two
different but equivalent dicts.

This is a backport of `inspect.get_annotations`, which has been
in the standard library since Python 3.10. See the standard library
documentation for more:

    https://docs.python.org/3/library/inspect.html#inspect.get_annotations

This backport adds the *format* argument introduced by PEP 649. The
three formats supported are:
* VALUE: the annotations are returned as-is. This is the default and
  it is compatible with the behavior on previous Python versions.
* FORWARDREF: return annotations as-is if possible, but replace any
  undefined names with ForwardRef objects. The implementation proposed by
  PEP 649 relies on language changes that cannot be backported; the
  typing-extensions implementation simply returns the same result as VALUE.
* STRING: return annotations as strings, in a format close to the original
  source. Again, this behavior cannot be replicated directly in a backport.
  As an approximation, typing-extensions retrieves the annotations under
  VALUE semantics and then stringifies them.

The purpose of this backport is to allow users who would like to use
FORWARDREF or STRING semantics once PEP 649 is implemented, but who also
want to support earlier Python versions, to simply write:

    typing_extensions.get_annotations(obj, format=Format.FORWARDREF)

**Param√®tres :**

- `obj`

##### _eval_with_owner

**Param√®tres :**

- `forward_ref`

##### _lax_type_check

A lax Python 3.11+ like version of typing._type_check

**Param√®tres :**

- `value`
- `msg`
- `is_argument`

##### evaluate_forward_ref

Evaluate a forward reference as a type hint.

This is similar to calling the ForwardRef.evaluate() method,
but unlike that method, evaluate_forward_ref() also:

* Recursively evaluates forward references nested within the type hint.
* Rejects certain objects that are not valid type hints.
* Replaces type hints that evaluate to None with types.NoneType.
* Supports the *FORWARDREF* and *STRING* formats.

*forward_ref* must be an instance of ForwardRef. *owner*, if given,
should be the object that holds the annotations that the forward reference
derived from, such as a module, class object, or function. It is used to
infer the namespaces to use for looking up names. *globals* and *locals*
can also be explicitly given to provide the global and local namespaces.
*type_params* is a tuple of type parameters that are in scope when
evaluating the forward reference. This parameter must be provided (though
it may be an empty tuple) if *owner* is not given and the forward reference
does not already have an owner set. *format* specifies the format of the
annotation and is a member of the annotationlib.Format enum.

**Param√®tres :**

- `forward_ref`

##### _should_collect_from_parameters

**Param√®tres :**

- `t`

##### _should_collect_from_parameters

**Param√®tres :**

- `t`

##### __instancecheck__

**Param√®tres :**

- `obj`

##### __repr__

##### __new__

**Param√®tres :**

- `cls`

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __init__

**Param√®tres :**

- `doc`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __init__

**Param√®tres :**

- `origin`
- `nparams`

##### __setattr__

**Param√®tres :**

- `attr`
- `val`

##### __getitem__

**Param√®tres :**

- `params`

##### __new__

**Param√®tres :**

- `mcls`
- `name`
- `bases`
- `namespace`

##### __init__

**Param√®tres :**

- `cls`

##### __subclasscheck__

**Param√®tres :**

- `cls`
- `other`

##### __instancecheck__

**Param√®tres :**

- `cls`
- `instance`

##### __eq__

**Param√®tres :**

- `cls`
- `other`

##### __hash__

**Param√®tres :**

- `cls`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __int__

##### __float__

##### __complex__

##### __bytes__

##### __index__

##### __abs__

##### __round__

**Param√®tres :**

- `ndigits`

##### __setattr__

**Param√®tres :**

- `cls`
- `attr`
- `value`

##### __new__

**Param√®tres :**

- `cls`

##### __repr__

##### __reduce__

##### __new__

**Param√®tres :**

- `cls`

##### __repr__

##### __reduce__

##### __new__

Create new typed dict class object.

This method is called when TypedDict is subclassed,
or when TypedDict is instantiated. This way
TypedDict supports all three syntax forms described in its docstring.
Subclasses and instances of TypedDict return actual dictionaries.

**Param√®tres :**

- `cls`
- `name`
- `bases`
- `ns`

##### __subclasscheck__

**Param√®tres :**

- `cls`
- `other`

##### __init__

**Param√®tres :**

- `origin`
- `metadata`

##### copy_with

**Param√®tres :**

- `params`

##### __repr__

##### __reduce__

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __new__

**Param√®tres :**

- `cls`

##### __class_getitem__

**Param√®tres :**

- `cls`
- `params`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### TypeAlias

Special marker indicating that an assignment should
be recognized as a proper type alias definition by type
checkers.

For example::

    Predicate: TypeAlias = Callable[..., bool]

It's invalid when used anywhere except as in the example above.

**Param√®tres :**

- `parameters`

##### __new__

**Param√®tres :**

- `cls`
- `name`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __copy__

##### __deepcopy__

**Param√®tres :**

- `memo`

##### __init__

**Param√®tres :**

- `origin`

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __init__

**Param√®tres :**

- `origin`

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### _type_convert

For converting None to type(None), and strings to ForwardRef.

**Param√®tres :**

- `arg`
- `module`

##### __init__

**Param√®tres :**

- `origin`
- `args`

##### __repr__

##### __hash__

##### __call__

##### __parameters__

##### copy_with

**Param√®tres :**

- `params`

##### __getitem__

**Param√®tres :**

- `args`

##### Concatenate

Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
higher order function which adds, removes or transforms parameters of a
callable.

For example::

   Callable[Concatenate[int, P], int]

See PEP 612 for detailed information.

**Param√®tres :**

- `parameters`

##### TypeGuard

Special typing form used to annotate the return type of a user-defined
type guard function.  ``TypeGuard`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeGuard[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeGuard`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the type inside ``TypeGuard``.

For example::

    def is_str(val: Union[str, float]):
        # "isinstance" type guard
        if isinstance(val, str):
            # Type of ``val`` is narrowed to ``str``
            ...
        else:
            # Else, type of ``val`` is narrowed to ``float``.
            ...

Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
form of ``TypeA`` (it can even be a wider form) and this may lead to
type-unsafe results.  The main reason is to allow for things like
narrowing ``List[object]`` to ``List[str]`` even though the latter is not
a subtype of the former, since ``List`` is invariant.  The responsibility of
writing type-safe type guards is left to the user.

``TypeGuard`` also works with type variables.  For more information, see
PEP 647 (User-Defined Type Guards).

**Param√®tres :**

- `parameters`

##### TypeIs

Special typing form used to annotate the return type of a user-defined
type narrower function.  ``TypeIs`` only accepts a single type argument.
At runtime, functions marked this way should return a boolean.

``TypeIs`` aims to benefit *type narrowing* -- a technique used by static
type checkers to determine a more precise type of an expression within a
program's code flow.  Usually type narrowing is done by analyzing
conditional code flow and applying the narrowing to a block of code.  The
conditional expression here is sometimes referred to as a "type guard".

Sometimes it would be convenient to use a user-defined boolean function
as a type guard.  Such a function should use ``TypeIs[...]`` as its
return type to alert static type checkers to this intention.

Using  ``-> TypeIs`` tells the static type checker that for a given
function:

1. The return value is a boolean.
2. If the return value is ``True``, the type of its argument
is the intersection of the type inside ``TypeIs`` and the argument's
previously known type.

For example::

    def is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
        return hasattr(val, '__await__')

    def f(val: Union[int, Awaitable[int]]) -> int:
        if is_awaitable(val):
            assert_type(val, Awaitable[int])
        else:
            assert_type(val, int)

``TypeIs`` also works with type variables.  For more information, see
PEP 742 (Narrowing types with TypeIs).

**Param√®tres :**

- `parameters`

##### TypeForm

A special form representing the value that results from the evaluation
of a type expression. This value encodes the information supplied in the
type expression, and it represents the type described by that type expression.

When used in a type expression, TypeForm describes a set of type form objects.
It accepts a single type argument, which must be a valid type expression.
``TypeForm[T]`` describes the set of all type form objects that represent
the type T or types that are assignable to T.

Usage:

    def cast[T](typ: TypeForm[T], value: Any) -> T: ...

    reveal_type(cast(int, "x"))  # int

See PEP 747 for more information.

**Param√®tres :**

- `parameters`

##### Required

A special typing construct to mark a key of a total=False TypedDict
as required. For example:

    class Movie(TypedDict, total=False):
        title: Required[str]
        year: int

    m = Movie(
        title='The Matrix',  # typechecker error if key is omitted
        year=1999,
    )

There is no runtime checking that a required key is actually provided
when instantiating a related TypedDict.

**Param√®tres :**

- `parameters`

##### NotRequired

A special typing construct to mark a key of a TypedDict as
potentially missing. For example:

    class Movie(TypedDict):
        title: str
        year: NotRequired[int]

    m = Movie(
        title='The Matrix',  # typechecker error if key is omitted
        year=1999,
    )

**Param√®tres :**

- `parameters`

##### ReadOnly

A special typing construct to mark an item of a TypedDict as read-only.

For example:

    class Movie(TypedDict):
        title: ReadOnly[str]
        year: int

    def mutate_movie(m: Movie) -> None:
        m["year"] = 1992  # allowed
        m["title"] = "The Matrix"  # typechecker error

There is no runtime checking for this property.

**Param√®tres :**

- `parameters`

##### Unpack

**Param√®tres :**

- `parameters`

##### _is_unpack

**Param√®tres :**

- `obj`

##### _is_unpack

**Param√®tres :**

- `obj`

##### decorator

**Param√®tres :**

- `cls_or_fn`

##### __init__

##### __call__

##### __new__

**Param√®tres :**

- `cls`
- `typename`
- `bases`
- `ns`

##### __call__

##### __init__

**Param√®tres :**

- `name`
- `tp`

##### __mro_entries__

**Param√®tres :**

- `bases`

##### __repr__

##### __reduce__

##### _is_unionable

Corresponds to is_unionable() in unionobject.c in CPython.

**Param√®tres :**

- `obj`

##### _is_unionable

Corresponds to is_unionable() in unionobject.c in CPython.

**Param√®tres :**

- `obj`

##### __init__

**Param√®tres :**

- `name`
- `value`

##### __setattr__

##### __delattr__

##### _raise_attribute_error

**Param√®tres :**

- `name`

##### __repr__

##### _check_parameters

**Param√®tres :**

- `parameters`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __reduce__

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __call__

##### __init__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### _tvar_prepare_subst

**Param√®tres :**

- `alias`
- `args`

##### __new__

**Param√®tres :**

- `cls`
- `name`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### args

##### kwargs

##### __init__

**Param√®tres :**

- `name`

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __reduce__

##### __call__

##### copy_with

**Param√®tres :**

- `params`

##### __getitem__

**Param√®tres :**

- `args`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __call__

##### __getitem__

**Param√®tres :**

- `parameters`

##### __call__

##### __getitem__

**Param√®tres :**

- `parameters`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __init__

**Param√®tres :**

- `getitem`

##### __typing_unpacked_tuple_args__

##### __typing_is_unpacked_typevartuple__

##### __getitem__

**Param√®tres :**

- `args`

##### __typing_unpacked_tuple_args__

##### __typing_is_unpacked_typevartuple__

##### __getitem__

**Param√®tres :**

- `args`

##### __getitem__

**Param√®tres :**

- `parameters`

##### __new__

**Param√®tres :**

- `cls`
- `name`

##### __init_subclass__

##### __iter__

##### __init__

**Param√®tres :**

- `name`

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __reduce__

##### __init_subclass__

##### __or__

**Param√®tres :**

- `other`

##### __ror__

**Param√®tres :**

- `other`

##### __getattr__

**Param√®tres :**

- `attr`

##### _check_single_param

**Param√®tres :**

- `param`
- `recursion`

##### __or__

**Param√®tres :**

- `right`

##### __ror__

**Param√®tres :**

- `left`

##### _paramspec_prepare_subst

**Param√®tres :**

- `alias`
- `args`

##### _typevartuple_prepare_subst

**Param√®tres :**

- `alias`
- `args`

##### __init_subclass__

**Param√®tres :**

- `cls`

##### __getitem__

**Param√®tres :**

- `item`

##### __new__

##### __init_subclass__

##### __init_subclass__

##### wrapper

---

### .!23210!__init__

---

### .!23213!typing_extensions

---

### _cmd

#### Fonctions

##### setup_logging

##### get_session

##### get_args

##### main

---

### adapter

#### Classes

##### CacheControlAdapter

**M√©thodes :**

- `__init__()`
- `send()`
- `build_response()`
- `close()`

#### Fonctions

##### __init__

**Param√®tres :**

- `cache`
- `cache_etags`
- `controller_class`
- `serializer`
- `heuristic`
- `cacheable_methods`

##### send

Send a request. Use the request information to see if it
exists in the cache and cache the response if we need to and can.

**Param√®tres :**

- `request`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`
- `cacheable_methods`

##### build_response

Build a response by making a request or using the cache.

This will end up calling send and returning a potentially
cached response

**Param√®tres :**

- `request`
- `response`
- `from_cache`
- `cacheable_methods`

##### close

##### _update_chunk_length

**Param√®tres :**

- `weak_self`

---

### .!23222!_cmd

---

### cache

The cache object API for implementing caches. The default is a thread
safe in-memory dictionary.

#### Classes

##### BaseCache

**M√©thodes :**

- `get()`
- `set()`
- `delete()`
- `close()`

##### DictCache

**M√©thodes :**

- `__init__()`
- `get()`
- `set()`
- `delete()`

##### SeparateBodyBaseCache

In this variant, the body is not stored mixed in with the metadata, but is
passed in (as a bytes-like object) in a separate call to ``set_body()``.

That is, the expected interaction pattern is::

    cache.set(key, serialized_metadata)
    cache.set_body(key)

Similarly, the body should be loaded separately via ``get_body()``.

**M√©thodes :**

- `set_body()`
- `get_body()`

#### Fonctions

##### get

**Param√®tres :**

- `key`

##### set

**Param√®tres :**

- `key`
- `value`
- `expires`

##### delete

**Param√®tres :**

- `key`

##### close

##### __init__

**Param√®tres :**

- `init_dict`

##### get

**Param√®tres :**

- `key`

##### set

**Param√®tres :**

- `key`
- `value`
- `expires`

##### delete

**Param√®tres :**

- `key`

##### set_body

**Param√®tres :**

- `key`
- `body`

##### get_body

Return the body as file-like object.

**Param√®tres :**

- `key`

---

### controller

The httplib2 algorithms ported for use with requests.

#### Classes

##### CacheController

An interface to see if request should cached or not.

**M√©thodes :**

- `__init__()`
- `_urlnorm()`
- `cache_url()`
- `parse_cache_control()`
- `_load_from_cache()`
- `cached_request()`
- `conditional_headers()`
- `_cache_set()`
- `cache_response()`
- `update_cached_response()`

#### Fonctions

##### parse_uri

Parses a URI using the regex given in Appendix B of RFC 3986.

(scheme, authority, path, query, fragment) = parse_uri(uri)

**Param√®tres :**

- `uri`

##### __init__

**Param√®tres :**

- `cache`
- `cache_etags`
- `serializer`
- `status_codes`

##### _urlnorm

Normalize the URL to create a safe key for the cache

**Param√®tres :**

- `cls`
- `uri`

##### cache_url

**Param√®tres :**

- `cls`
- `uri`

##### parse_cache_control

**Param√®tres :**

- `headers`

##### _load_from_cache

Load a cached response, or return None if it's not available.

**Param√®tres :**

- `request`

##### cached_request

Return a cached response if it exists in the cache, otherwise
return False.

**Param√®tres :**

- `request`

##### conditional_headers

**Param√®tres :**

- `request`

##### _cache_set

Store the data in the cache.

**Param√®tres :**

- `cache_url`
- `request`
- `response`
- `body`
- `expires_time`

##### cache_response

Algorithm for caching requests.

This assumes a requests Response object.

**Param√®tres :**

- `request`
- `response_or_ref`
- `body`
- `status_codes`

##### update_cached_response

On a 304 we will get a new set of headers that we want to
update our cached value with, assuming we have one.

This should only ever be called when we've sent an ETag and
gotten a 304 as the response.

**Param√®tres :**

- `request`
- `response`

---

### filewrapper

#### Classes

##### CallbackFileWrapper

Small wrapper around a fp object which will tee everything read into a
buffer, and when that file is closed it will execute a callback with the
contents of that buffer.

All attributes are proxied to the underlying file object.

This class uses members with a double underscore (__) leading prefix so as
not to accidentally shadow an attribute.

The data is stored in a temporary file until it is all available.  As long
as the temporary files directory is disk-based (sometimes it's a
memory-backed-``tmpfs`` on Linux), data will be unloaded to disk if memory
pressure is high.  For small files the disk usually won't be used at all,
it'll all be in the filesystem memory cache, so there should be no
performance impact.

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `__is_fp_closed()`
- `_close()`
- `read()`
- `_safe_read()`

#### Fonctions

##### __init__

**Param√®tres :**

- `fp`
- `callback`

##### __getattr__

**Param√®tres :**

- `name`

##### __is_fp_closed

##### _close

##### read

**Param√®tres :**

- `amt`

##### _safe_read

**Param√®tres :**

- `amt`

---

### heuristics

#### Classes

##### BaseHeuristic

**M√©thodes :**

- `warning()`
- `update_headers()`
- `apply()`

##### OneDayCache

Cache the response by providing an expires 1 day in the
future.

**M√©thodes :**

- `update_headers()`

##### ExpiresAfter

Cache **all** requests for a defined time period.

**M√©thodes :**

- `__init__()`
- `update_headers()`
- `warning()`

##### LastModified

If there is no Expires header already, fall back on Last-Modified
using the heuristic from
http://tools.ietf.org/html/rfc7234#section-4.2.2
to calculate a reasonable value.

Firefox also does something like this per
https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching_FAQ
http://lxr.mozilla.org/mozilla-release/source/netwerk/protocol/http/nsHttpResponseHead.cpp#397
Unlike mozilla we limit this to 24-hr.

**M√©thodes :**

- `update_headers()`
- `warning()`

#### Fonctions

##### expire_after

**Param√®tres :**

- `delta`
- `date`

##### datetime_to_header

**Param√®tres :**

- `dt`

##### warning

Return a valid 1xx warning header value describing the cache
adjustments.

The response is provided too allow warnings like 113
http://tools.ietf.org/html/rfc7234#section-5.5.4 where we need
to explicitly say response is over 24 hours old.

**Param√®tres :**

- `response`

##### update_headers

Update the response headers with any new headers.

NOTE: This SHOULD always include some Warning header to
      signify that the response was cached by the client, not
      by way of the provided headers.

**Param√®tres :**

- `response`

##### apply

**Param√®tres :**

- `response`

##### update_headers

**Param√®tres :**

- `response`

##### __init__

##### update_headers

**Param√®tres :**

- `response`

##### warning

**Param√®tres :**

- `response`

##### update_headers

**Param√®tres :**

- `resp`

##### warning

**Param√®tres :**

- `resp`

---

### serialize

#### Classes

##### Serializer

**M√©thodes :**

- `dumps()`
- `serialize()`
- `loads()`
- `prepare_response()`
- `_loads_v4()`

#### Fonctions

##### dumps

**Param√®tres :**

- `request`
- `response`
- `body`

##### serialize

**Param√®tres :**

- `data`

##### loads

**Param√®tres :**

- `request`
- `data`
- `body_file`

##### prepare_response

Verify our vary headers match and construct a real urllib3
HTTPResponse object.

**Param√®tres :**

- `request`
- `cached`
- `body_file`

##### _loads_v4

**Param√®tres :**

- `request`
- `data`
- `body_file`

---

### wrapper

#### Fonctions

##### CacheControl

**Param√®tres :**

- `sess`
- `cache`
- `cache_etags`
- `serializer`
- `heuristic`
- `controller_class`
- `adapter_class`
- `cacheable_methods`

---

### .!23220!__init__

---

### .!23227!adapter

---

### .!23233!cache

---

### .!23237!controller

---

### .!23243!filewrapper

---

### .!23247!heuristics

---

### .!23252!serialize

---

### .!23256!wrapper

---

### file_cache

#### Classes

##### _FileCacheMixin

Shared implementation for both FileCache variants.

**M√©thodes :**

- `__init__()`
- `encode()`
- `_fn()`
- `get()`
- `set()`
- `_write()`
- `_delete()`

##### FileCache

Traditional FileCache: body is stored in memory, so not suitable for large
downloads.

**M√©thodes :**

- `delete()`

##### SeparateBodyFileCache

Memory-efficient FileCache: body is stored in a separate file, reducing
peak memory usage.

**M√©thodes :**

- `get_body()`
- `set_body()`
- `delete()`

#### Fonctions

##### url_to_file_path

Return the file cache path based on the URL.

This does not ensure the file exists!

**Param√®tres :**

- `url`
- `filecache`

##### __init__

**Param√®tres :**

- `directory`
- `forever`
- `filemode`
- `dirmode`
- `lock_class`

##### encode

**Param√®tres :**

- `x`

##### _fn

**Param√®tres :**

- `name`

##### get

**Param√®tres :**

- `key`

##### set

**Param√®tres :**

- `key`
- `value`
- `expires`

##### _write

Safely write the data to the given path.

**Param√®tres :**

- `path`
- `data`

##### _delete

**Param√®tres :**

- `key`
- `suffix`

##### delete

**Param√®tres :**

- `key`

##### get_body

**Param√®tres :**

- `key`

##### set_body

**Param√®tres :**

- `key`
- `body`

##### delete

**Param√®tres :**

- `key`

---

### redis_cache

#### Classes

##### RedisCache

**M√©thodes :**

- `__init__()`
- `get()`
- `set()`
- `delete()`
- `clear()`
- `close()`

#### Fonctions

##### __init__

**Param√®tres :**

- `conn`

##### get

**Param√®tres :**

- `key`

##### set

**Param√®tres :**

- `key`
- `value`
- `expires`

##### delete

**Param√®tres :**

- `key`

##### clear

Helper for clearing all the keys in a database. Use with
caution!

##### close

Redis uses connection pooling, no need to close the connection.

---

### .!23263!__init__

---

### .!23269!file_cache

---

### .!23274!redis_cache

---

### __main__

---

### .!23289!core

---

### core

certifi.py
~~~~~~~~~~

This module returns the installation location of cacert.pem or its contents.

#### Fonctions

##### exit_cacert_ctx

##### where

##### contents

##### where

##### contents

##### read_text

**Param√®tres :**

- `package`
- `resource`
- `encoding`
- `errors`

##### where

##### contents

---

### .!23279!__init__

---

### .!23283!__main__

---

### __main__

#### Fonctions

##### main

---

### _implementation

#### Classes

##### DependencyGroupInclude

##### CyclicDependencyError

An error representing the detection of a cycle.

**M√©thodes :**

- `__init__()`

##### DependencyGroupResolver

A resolver for Dependency Group data.

This class handles caching, name normalization, cycle detection, and other
parsing requirements. There are only two public methods for exploring the data:
``lookup()`` and ``resolve()``.

:param dependency_groups: A mapping, as provided via pyproject
    ``[dependency-groups]``.

**M√©thodes :**

- `__init__()`
- `lookup()`
- `resolve()`
- `_parse_group()`
- `_resolve()`

#### Fonctions

##### _normalize_name

**Param√®tres :**

- `name`

##### _normalize_group_names

**Param√®tres :**

- `dependency_groups`

##### resolve

Resolve a dependency group to a tuple of requirements, as strings.

:param dependency_groups: the parsed contents of the ``[dependency-groups]`` table
    from ``pyproject.toml``
:param groups: the name of the group(s) to resolve

:raises TypeError: if the inputs appear to be the wrong types
:raises ValueError: if the data does not appear to be valid dependency group data
:raises LookupError: if group name is absent
:raises packaging.requirements.InvalidRequirement: if a specifier is not valid

##### __init__

**Param√®tres :**

- `requested_group`
- `group`
- `include_group`

##### __init__

**Param√®tres :**

- `dependency_groups`

##### lookup

Lookup a group name, returning the parsed dependency data for that group.
This will not resolve includes.

:param group: the name of the group to lookup

:raises ValueError: if the data does not appear to be valid dependency group
    data
:raises TypeError: if the data is not a string
:raises LookupError: if group name is absent
:raises packaging.requirements.InvalidRequirement: if a specifier is not valid

**Param√®tres :**

- `group`

##### resolve

Resolve a dependency group to a list of requirements.

:param group: the name of the group to resolve

:raises TypeError: if the inputs appear to be the wrong types
:raises ValueError: if the data does not appear to be valid dependency group
    data
:raises LookupError: if group name is absent
:raises packaging.requirements.InvalidRequirement: if a specifier is not valid

**Param√®tres :**

- `group`

##### _parse_group

**Param√®tres :**

- `group`

##### _resolve

This is a helper for cached resolution to strings.

:param group: The name of the group to resolve.
:param requested_group: The group which was used in the original, user-facing
    request.

**Param√®tres :**

- `group`
- `requested_group`

---

### _lint_dependency_groups

#### Fonctions

##### main

---

### _pip_wrapper

#### Fonctions

##### _invoke_pip

**Param√®tres :**

- `deps`

##### main

---

### _toml_compat

---

### .!23294!__init__

---

### .!23299!__main__

---

### .!23304!_implementation

---

### .!23309!_lint_dependency_groups

---

### .!23315!_pip_wrapper

---

### .!23319!_toml_compat

---

### compat

#### Classes

##### ZipExtFile

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### ZipFile

**M√©thodes :**

- `__enter__()`
- `__exit__()`
- `open()`

##### CertificateError

##### Container

A generic container for when multiple values need to be returned

**M√©thodes :**

- `__init__()`

##### ChainMap

A ChainMap groups multiple dicts (or other mappings) together
to create a single, updateable view.

The underlying mappings are stored in a list.  That list is public and can
accessed or updated using the *maps* attribute.  There is no other state.

Lookups search the underlying mappings successively until a key is found.
In contrast, writes, updates, and deletions only operate on the first
mapping.

**M√©thodes :**

- `__init__()`
- `__missing__()`
- `__getitem__()`
- `get()`
- `__len__()`
- `__iter__()`
- `__contains__()`
- `__bool__()`
- `__repr__()`
- `fromkeys()`
- `copy()`
- `new_child()`
- `parents()`
- `__setitem__()`
- `__delitem__()`
- `popitem()`
- `pop()`
- `clear()`

##### OrderedDict

Dictionary that remembers insertion order

**M√©thodes :**

- `__init__()`
- `__setitem__()`
- `__delitem__()`
- `__iter__()`
- `__reversed__()`
- `clear()`
- `popitem()`
- `keys()`
- `values()`
- `items()`
- `iterkeys()`
- `itervalues()`
- `iteritems()`
- `update()`
- `pop()`
- `setdefault()`
- `__repr__()`
- `__reduce__()`
- `copy()`
- `fromkeys()`
- `__eq__()`
- `__ne__()`
- `viewkeys()`
- `viewvalues()`
- `viewitems()`

##### ConvertingDict

A converting dictionary wrapper.

**M√©thodes :**

- `__getitem__()`
- `get()`

##### ConvertingList

A converting list wrapper.

**M√©thodes :**

- `__getitem__()`
- `pop()`

##### ConvertingTuple

A converting tuple wrapper.

**M√©thodes :**

- `__getitem__()`

##### BaseConfigurator

The configurator base class which defines some useful defaults.

**M√©thodes :**

- `__init__()`
- `resolve()`
- `ext_convert()`
- `cfg_convert()`
- `convert()`
- `configure_custom()`
- `as_tuple()`

#### Fonctions

##### quote

**Param√®tres :**

- `s`

##### _dnsname_match

Matching according to RFC 6125, section 6.4.3

http://tools.ietf.org/html/rfc6125#section-6.4.3

**Param√®tres :**

- `dn`
- `hostname`
- `max_wildcards`

##### match_hostname

Verify that *cert* (in decoded format as returned by
SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
rules are followed, but IP addresses are not accepted for *hostname*.

CertificateError is raised on failure. On success, the function
returns nothing.

**Param√®tres :**

- `cert`
- `hostname`

##### which

Given a command, mode, and a PATH string, return the path which
conforms to the given mode on the PATH, or None if there is no such
file.

`mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result
of os.environ.get("PATH"), or can be overridden with a custom search
path.

**Param√®tres :**

- `cmd`
- `mode`
- `path`

##### __init__

**Param√®tres :**

- `base`

##### __enter__

##### __exit__

##### __enter__

##### __exit__

##### open

##### python_implementation

Return a string identifying the Python implementation.

##### callable

**Param√®tres :**

- `obj`

##### fsencode

**Param√®tres :**

- `filename`

##### fsdecode

**Param√®tres :**

- `filename`

##### _get_normal_name

Imitates get_normal_name in tokenizer.c.

**Param√®tres :**

- `orig_enc`

##### detect_encoding

The detect_encoding() function is used to detect the encoding that should
be used to decode a Python source file.  It requires one argument, readline,
in the same way as the tokenize() generator.

It will call readline a maximum of twice, and return the encoding used
(as a string) and a list of any lines (left as bytes) it has read in.

It detects the encoding from the presence of a utf-8 bom or an encoding
cookie as specified in pep-0263.  If both a bom and a cookie are present,
but disagree, a SyntaxError will be raised.  If the encoding cookie is an
invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
'utf-8-sig' is returned.

If no encoding is specified, then the default of 'utf-8' will be returned.

**Param√®tres :**

- `readline`

##### cache_from_source

**Param√®tres :**

- `path`
- `debug_override`

##### valid_ident

**Param√®tres :**

- `s`

##### pop

**Param√®tres :**

- `key`
- `default`

##### __init__

##### _access_check

**Param√®tres :**

- `fn`
- `mode`

##### read_or_stop

##### find_cookie

**Param√®tres :**

- `line`

##### __init__

Initialize a ChainMap by setting *maps* to the given mappings.
If no mappings are provided, a single empty dictionary is used.

##### __missing__

**Param√®tres :**

- `key`

##### __getitem__

**Param√®tres :**

- `key`

##### get

**Param√®tres :**

- `key`
- `default`

##### __len__

##### __iter__

##### __contains__

**Param√®tres :**

- `key`

##### __bool__

##### __repr__

##### fromkeys

Create a ChainMap with a single dict created from the iterable.

**Param√®tres :**

- `cls`
- `iterable`

##### copy

New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]

##### new_child

New ChainMap with a new dict followed by all previous maps.

##### parents

New ChainMap from maps[1:].

##### __setitem__

**Param√®tres :**

- `key`
- `value`

##### __delitem__

**Param√®tres :**

- `key`

##### popitem

Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.

##### pop

Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].

**Param√®tres :**

- `key`

##### clear

Clear maps[0], leaving maps[1:] intact.

##### __init__

Initialize an ordered dictionary.  Signature is the same as for
regular dictionaries, but keyword arguments are not recommended
because their insertion order is arbitrary.

##### __setitem__

od.__setitem__(i, y) <==> od[i]=y

**Param√®tres :**

- `key`
- `value`
- `dict_setitem`

##### __delitem__

od.__delitem__(y) <==> del od[y]

**Param√®tres :**

- `key`
- `dict_delitem`

##### __iter__

od.__iter__() <==> iter(od)

##### __reversed__

od.__reversed__() <==> reversed(od)

##### clear

od.clear() -> None.  Remove all items from od.

##### popitem

od.popitem() -> (k, v), return and remove a (key, value) pair.
Pairs are returned in LIFO order if last is true or FIFO order if false.

**Param√®tres :**

- `last`

##### keys

od.keys() -> list of keys in od

##### values

od.values() -> list of values in od

##### items

od.items() -> list of (key, value) pairs in od

##### iterkeys

od.iterkeys() -> an iterator over the keys in od

##### itervalues

od.itervalues -> an iterator over the values in od

##### iteritems

od.iteritems -> an iterator over the (key, value) items in od

##### update

od.update(E, **F) -> None.  Update od from dict/iterable E and F.

If E is a dict instance, does:           for k in E: od[k] = E[k]
If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
Or if E is an iterable of items, does:   for k, v in E: od[k] = v
In either case, this is followed by:     for k, v in F.items(): od[k] = v

##### pop

od.pop(k[,d]) -> v, remove specified key and return the corresponding value.
If key is not found, d is returned if given, otherwise KeyError is raised.

**Param√®tres :**

- `key`
- `default`

##### setdefault

od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od

**Param√®tres :**

- `key`
- `default`

##### __repr__

od.__repr__() <==> repr(od)

**Param√®tres :**

- `_repr_running`

##### __reduce__

Return state information for pickling

##### copy

od.copy() -> a shallow copy of od

##### fromkeys

OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
and values equal to v (which defaults to None).

**Param√®tres :**

- `cls`
- `iterable`
- `value`

##### __eq__

od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
while comparison to a regular mapping is order-insensitive.

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### viewkeys

od.viewkeys() -> a set-like object providing a view on od's keys

##### viewvalues

od.viewvalues() -> an object providing a view on od's values

##### viewitems

od.viewitems() -> a set-like object providing a view on od's items

##### __getitem__

**Param√®tres :**

- `key`

##### get

**Param√®tres :**

- `key`
- `default`

##### __getitem__

**Param√®tres :**

- `key`

##### pop

**Param√®tres :**

- `idx`

##### __getitem__

**Param√®tres :**

- `key`

##### __init__

**Param√®tres :**

- `config`

##### resolve

Resolve strings to objects using standard import and attribute
syntax.

**Param√®tres :**

- `s`

##### ext_convert

Default converter for the ext:// protocol.

**Param√®tres :**

- `value`

##### cfg_convert

Default converter for the cfg:// protocol.

**Param√®tres :**

- `value`

##### convert

Convert values to an appropriate type. dicts, lists and tuples are
replaced by their converting alternatives. Strings are checked to
see if they have a conversion format and are converted if they do.

**Param√®tres :**

- `value`

##### configure_custom

Configure an object with a user-supplied factory.

**Param√®tres :**

- `config`

##### as_tuple

Utility function which converts lists to tuples.

**Param√®tres :**

- `value`

##### _recursive_repr

Decorator to make a repr function return fillvalue for a recursive
call

**Param√®tres :**

- `fillvalue`

##### decorating_function

**Param√®tres :**

- `user_function`

##### wrapper

---

### database

PEP 376 implementation.

#### Classes

##### _Cache

A simple cache mapping names and .dist-info paths to distributions

**M√©thodes :**

- `__init__()`
- `clear()`
- `add()`

##### DistributionPath

Represents a set of distributions installed on a path (typically sys.path).

**M√©thodes :**

- `__init__()`
- `_get_cache_enabled()`
- `_set_cache_enabled()`
- `clear_cache()`
- `_yield_distributions()`
- `_generate_cache()`
- `distinfo_dirname()`
- `get_distributions()`
- `get_distribution()`
- `provides_distribution()`
- `get_file_path()`
- `get_exported_entries()`

##### Distribution

A base class for distributions, whether installed or from indexes.
Either way, it must have some metadata, so that's all that's needed
for construction.

**M√©thodes :**

- `__init__()`
- `source_url()`
- `name_and_version()`
- `provides()`
- `_get_requirements()`
- `run_requires()`
- `meta_requires()`
- `build_requires()`
- `test_requires()`
- `dev_requires()`
- `matches_requirement()`
- `__repr__()`
- `__eq__()`
- `__hash__()`

##### BaseInstalledDistribution

This is the base class for installed distributions (whether PEP 376 or
legacy).

**M√©thodes :**

- `__init__()`
- `get_hash()`

##### InstalledDistribution

Created with the *path* of the ``.dist-info`` directory provided to the
constructor. It reads the metadata contained in ``pydist.json`` when it is
instantiated., or uses a passed in Metadata instance (useful for when
dry-run mode is being used).

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__str__()`
- `_get_records()`
- `exports()`
- `read_exports()`
- `write_exports()`
- `get_resource_path()`
- `list_installed_files()`
- `write_installed_files()`
- `check_installed_files()`
- `shared_locations()`
- `write_shared_locations()`
- `get_distinfo_resource()`
- `get_distinfo_file()`
- `list_distinfo_files()`
- `__eq__()`

##### EggInfoDistribution

Created with the *path* of the ``.egg-info`` directory or file provided
to the constructor. It reads the metadata contained in the file itself, or
if the given path happens to be a directory, the metadata is read from the
file ``PKG-INFO`` under that directory.

**M√©thodes :**

- `__init__()`
- `_get_metadata()`
- `__repr__()`
- `__str__()`
- `check_installed_files()`
- `list_installed_files()`
- `list_distinfo_files()`
- `__eq__()`

##### DependencyGraph

Represents a dependency graph between distributions.

The dependency relationships are stored in an ``adjacency_list`` that maps
distributions to a list of ``(other, label)`` tuples where  ``other``
is a distribution and the edge is labeled with ``label`` (i.e. the version
specifier, if such was provided). Also, for more efficient traversal, for
every distribution ``x``, a list of predecessors is kept in
``reverse_list[x]``. An edge from distribution ``a`` to
distribution ``b`` means that ``a`` depends on ``b``. If any missing
dependencies are found, they are stored in ``missing``, which is a
dictionary that maps distributions to a list of requirements that were not
provided by any other distributions.

**M√©thodes :**

- `__init__()`
- `add_distribution()`
- `add_edge()`
- `add_missing()`
- `_repr_dist()`
- `repr_node()`
- `to_dot()`
- `topological_sort()`
- `__repr__()`

#### Fonctions

##### make_graph

Makes a dependency graph from the given distributions.

:parameter dists: a list of distributions
:type dists: list of :class:`distutils2.database.InstalledDistribution` and
             :class:`distutils2.database.EggInfoDistribution` instances
:rtype: a :class:`DependencyGraph` instance

**Param√®tres :**

- `dists`
- `scheme`

##### get_dependent_dists

Recursively generate a list of distributions from *dists* that are
dependent on *dist*.

:param dists: a list of distributions
:param dist: a distribution, member of *dists* for which we are interested

**Param√®tres :**

- `dists`
- `dist`

##### get_required_dists

Recursively generate a list of distributions from *dists* that are
required by *dist*.

:param dists: a list of distributions
:param dist: a distribution, member of *dists* for which we are interested
             in finding the dependencies.

**Param√®tres :**

- `dists`
- `dist`

##### make_dist

A convenience method for making a dist given just a name and version.

**Param√®tres :**

- `name`
- `version`

##### __init__

Initialise an instance. There is normally one for each DistributionPath.

##### clear

Clear the cache, setting it to its initial state.

##### add

Add a distribution to the cache.
:param dist: The distribution to add.

**Param√®tres :**

- `dist`

##### __init__

Create an instance from a path, optionally including legacy (distutils/
setuptools/distribute) distributions.
:param path: The path to use, as a list of directories. If not specified,
             sys.path is used.
:param include_egg: If True, this instance will look for and return legacy
                    distributions as well as those based on PEP 376.

**Param√®tres :**

- `path`
- `include_egg`

##### _get_cache_enabled

##### _set_cache_enabled

**Param√®tres :**

- `value`

##### clear_cache

Clears the internal cache.

##### _yield_distributions

Yield .dist-info and/or .egg(-info) distributions.

##### _generate_cache

Scan the path for distributions and populate the cache with
those that are found.

##### distinfo_dirname

The *name* and *version* parameters are converted into their
filename-escaped form, i.e. any ``'-'`` characters are replaced
with ``'_'`` other than the one in ``'dist-info'`` and the one
separating the name from the version number.

:parameter name: is converted to a standard distribution name by replacing
                 any runs of non- alphanumeric characters with a single
                 ``'-'``.
:type name: string
:parameter version: is converted to a standard version string. Spaces
                    become dots, and all other non-alphanumeric characters
                    (except dots) become dashes, with runs of multiple
                    dashes condensed to a single dash.
:type version: string
:returns: directory name
:rtype: string

**Param√®tres :**

- `cls`
- `name`
- `version`

##### get_distributions

Provides an iterator that looks for distributions and returns
:class:`InstalledDistribution` or
:class:`EggInfoDistribution` instances for each one of them.

:rtype: iterator of :class:`InstalledDistribution` and
        :class:`EggInfoDistribution` instances

##### get_distribution

Looks for a named distribution on the path.

This function only returns the first result found, as no more than one
value is expected. If nothing is found, ``None`` is returned.

:rtype: :class:`InstalledDistribution`, :class:`EggInfoDistribution`
        or ``None``

**Param√®tres :**

- `name`

##### provides_distribution

Iterates over all distributions to find which distributions provide *name*.
If a *version* is provided, it will be used to filter the results.

This function only returns the first result found, since no more than
one values are expected. If the directory is not found, returns ``None``.

:parameter version: a version specifier that indicates the version
                    required, conforming to the format in ``PEP-345``

:type name: string
:type version: string

**Param√®tres :**

- `name`
- `version`

##### get_file_path

Return the path to a resource file.

**Param√®tres :**

- `name`
- `relative_path`

##### get_exported_entries

Return all of the exported entries in a particular category.

:param category: The category to search for entries.
:param name: If specified, only entries with that name are returned.

**Param√®tres :**

- `category`
- `name`

##### __init__

Initialise an instance.
:param metadata: The instance of :class:`Metadata` describing this
distribution.

**Param√®tres :**

- `metadata`

##### source_url

The source archive download URL for this distribution.

##### name_and_version

A utility property which displays the name and version in parentheses.

##### provides

A set of distribution names and versions provided by this distribution.
:return: A set of "name (version)" strings.

##### _get_requirements

**Param√®tres :**

- `req_attr`

##### run_requires

##### meta_requires

##### build_requires

##### test_requires

##### dev_requires

##### matches_requirement

Say if this instance matches (fulfills) a requirement.
:param req: The requirement to match.
:rtype req: str
:return: True if it matches, else False.

**Param√®tres :**

- `req`

##### __repr__

Return a textual representation of this instance,

##### __eq__

See if this distribution is the same as another.
:param other: The distribution to compare with. To be equal to one
              another. distributions must have the same type, name,
              version and source_url.
:return: True if it is the same, else False.

**Param√®tres :**

- `other`

##### __hash__

Compute hash in a way which matches the equality test.

##### __init__

Initialise an instance.
:param metadata: An instance of :class:`Metadata` which describes the
                 distribution. This will normally have been initialised
                 from a metadata file in the ``path``.
:param path:     The path of the ``.dist-info`` or ``.egg-info``
                 directory for the distribution.
:param env:      This is normally the :class:`DistributionPath`
                 instance where this distribution was found.

**Param√®tres :**

- `metadata`
- `path`
- `env`

##### get_hash

Get the hash of some data, using a particular hash algorithm, if
specified.

:param data: The data to be hashed.
:type data: bytes
:param hasher: The name of a hash implementation, supported by hashlib,
               or ``None``. Examples of valid values are ``'sha1'``,
               ``'sha224'``, ``'sha384'``, '``sha256'``, ``'md5'`` and
               ``'sha512'``. If no hasher is specified, the ``hasher``
               attribute of the :class:`InstalledDistribution` instance
               is used. If the hasher is determined to be ``None``, MD5
               is used as the hashing algorithm.
:returns: The hash of the data. If a hasher was explicitly specified,
          the returned hash will be prefixed with the specified hasher
          followed by '='.
:rtype: str

**Param√®tres :**

- `data`
- `hasher`

##### __init__

**Param√®tres :**

- `path`
- `metadata`
- `env`

##### __repr__

##### __str__

##### _get_records

Get the list of installed files for the distribution
:return: A list of tuples of path, hash and size. Note that hash and
         size might be ``None`` for some entries. The path is exactly
         as stored in the file (which is as in PEP 376).

##### exports

Return the information exported by this distribution.
:return: A dictionary of exports, mapping an export category to a dict
         of :class:`ExportEntry` instances describing the individual
         export entries, and keyed by name.

##### read_exports

Read exports data from a file in .ini format.

:return: A dictionary of exports, mapping an export category to a list
         of :class:`ExportEntry` instances describing the individual
         export entries.

##### write_exports

Write a dictionary of exports to a file in .ini format.
:param exports: A dictionary of exports, mapping an export category to
                a list of :class:`ExportEntry` instances describing the
                individual export entries.

**Param√®tres :**

- `exports`

##### get_resource_path

NOTE: This API may change in the future.

Return the absolute path to a resource file with the given relative
path.

:param relative_path: The path, relative to .dist-info, of the resource
                      of interest.
:return: The absolute path where the resource is to be found.

**Param√®tres :**

- `relative_path`

##### list_installed_files

Iterates over the ``RECORD`` entries and returns a tuple
``(path, hash, size)`` for each line.

:returns: iterator of (path, hash, size)

##### write_installed_files

Writes the ``RECORD`` file, using the ``paths`` iterable passed in. Any
existing ``RECORD`` file is silently overwritten.

prefix is used to determine when to write absolute paths.

**Param√®tres :**

- `paths`
- `prefix`
- `dry_run`

##### check_installed_files

Checks that the hashes and sizes of the files in ``RECORD`` are
matched by the files themselves. Returns a (possibly empty) list of
mismatches. Each entry in the mismatch list will be a tuple consisting
of the path, 'exists', 'size' or 'hash' according to what didn't match
(existence is checked first, then size, then hash), the expected
value and the actual value.

##### shared_locations

A dictionary of shared locations whose keys are in the set 'prefix',
'purelib', 'platlib', 'scripts', 'headers', 'data' and 'namespace'.
The corresponding value is the absolute path of that category for
this distribution, and takes into account any paths selected by the
user at installation time (e.g. via command-line arguments). In the
case of the 'namespace' key, this would be a list of absolute paths
for the roots of namespace packages in this distribution.

The first time this property is accessed, the relevant information is
read from the SHARED file in the .dist-info directory.

##### write_shared_locations

Write shared location information to the SHARED file in .dist-info.
:param paths: A dictionary as described in the documentation for
:meth:`shared_locations`.
:param dry_run: If True, the action is logged but no file is actually
                written.
:return: The path of the file written to.

**Param√®tres :**

- `paths`
- `dry_run`

##### get_distinfo_resource

**Param√®tres :**

- `path`

##### get_distinfo_file

Returns a path located under the ``.dist-info`` directory. Returns a
string representing the path.

:parameter path: a ``'/'``-separated path relative to the
                 ``.dist-info`` directory or an absolute path;
                 If *path* is an absolute path and doesn't start
                 with the ``.dist-info`` directory path,
                 a :class:`DistlibException` is raised
:type path: str
:rtype: str

**Param√®tres :**

- `path`

##### list_distinfo_files

Iterates over the ``RECORD`` entries and returns paths for each line if
the path is pointing to a file located in the ``.dist-info`` directory
or one of its subdirectories.

:returns: iterator of paths

##### __eq__

**Param√®tres :**

- `other`

##### __init__

**Param√®tres :**

- `path`
- `env`

##### _get_metadata

**Param√®tres :**

- `path`

##### __repr__

##### __str__

##### check_installed_files

Checks that the hashes and sizes of the files in ``RECORD`` are
matched by the files themselves. Returns a (possibly empty) list of
mismatches. Each entry in the mismatch list will be a tuple consisting
of the path, 'exists', 'size' or 'hash' according to what didn't match
(existence is checked first, then size, then hash), the expected
value and the actual value.

##### list_installed_files

Iterates over the ``installed-files.txt`` entries and returns a tuple
``(path, hash, size)`` for each line.

:returns: a list of (path, hash, size)

##### list_distinfo_files

Iterates over the ``installed-files.txt`` entries and returns paths for
each line if the path is pointing to a file located in the
``.egg-info`` directory or one of its subdirectories.

:parameter absolute: If *absolute* is ``True``, each returned path is
                  transformed into a local absolute path. Otherwise the
                  raw value from ``installed-files.txt`` is returned.
:type absolute: boolean
:returns: iterator of paths

**Param√®tres :**

- `absolute`

##### __eq__

**Param√®tres :**

- `other`

##### __init__

##### add_distribution

Add the *distribution* to the graph.

:type distribution: :class:`distutils2.database.InstalledDistribution`
                    or :class:`distutils2.database.EggInfoDistribution`

**Param√®tres :**

- `distribution`

##### add_edge

Add an edge from distribution *x* to distribution *y* with the given
*label*.

:type x: :class:`distutils2.database.InstalledDistribution` or
         :class:`distutils2.database.EggInfoDistribution`
:type y: :class:`distutils2.database.InstalledDistribution` or
         :class:`distutils2.database.EggInfoDistribution`
:type label: ``str`` or ``None``

**Param√®tres :**

- `x`
- `y`
- `label`

##### add_missing

Add a missing *requirement* for the given *distribution*.

:type distribution: :class:`distutils2.database.InstalledDistribution`
                    or :class:`distutils2.database.EggInfoDistribution`
:type requirement: ``str``

**Param√®tres :**

- `distribution`
- `requirement`

##### _repr_dist

**Param√®tres :**

- `dist`

##### repr_node

Prints only a subgraph

**Param√®tres :**

- `dist`
- `level`

##### to_dot

Writes a DOT output for the graph to the provided file *f*.

If *skip_disconnected* is set to ``True``, then all distributions
that are not dependent on any other distribution are skipped.

:type f: has to support ``file``-like operations
:type skip_disconnected: ``bool``

**Param√®tres :**

- `f`
- `skip_disconnected`

##### topological_sort

Perform a topological sort of the graph.
:return: A tuple, the first element of which is a topologically sorted
         list of distributions, and the second element of which is a
         list of distributions that cannot be sorted because they have
         circular dependencies and so form a cycle.

##### __repr__

Representation of the graph

##### set_name_and_version

**Param√®tres :**

- `s`
- `n`
- `v`

##### parse_requires_data

Create a list of dependencies from a requires.txt file.

*data*: the contents of a setuptools-produced requires.txt file.

**Param√®tres :**

- `data`

##### parse_requires_path

Create a list of dependencies from a requires.txt file.

*req_path*: the path to a setuptools-produced requires.txt file.

**Param√®tres :**

- `req_path`

##### _md5

**Param√®tres :**

- `path`

##### _size

**Param√®tres :**

- `path`

---

### .!23370!util

---

### index

#### Classes

##### PackageIndex

This class represents a package index compatible with PyPI, the Python
Package Index.

**M√©thodes :**

- `__init__()`
- `_get_pypirc_command()`
- `read_configuration()`
- `save_configuration()`
- `check_credentials()`
- `register()`
- `_reader()`
- `get_sign_command()`
- `run_command()`
- `sign_file()`
- `upload_file()`
- `upload_documentation()`
- `get_verify_command()`
- `verify_signature()`
- `download_file()`
- `send_request()`
- `encode_request()`
- `search()`

#### Fonctions

##### __init__

Initialise an instance.

:param url: The URL of the index. If not specified, the URL for PyPI is
            used.

**Param√®tres :**

- `url`

##### _get_pypirc_command

Get the distutils command for interacting with PyPI configurations.
:return: the command.

##### read_configuration

Read the PyPI access configuration as supported by distutils. This populates
``username``, ``password``, ``realm`` and ``url`` attributes from the
configuration.

##### save_configuration

Save the PyPI access configuration. You must have set ``username`` and
``password`` attributes before calling this method.

##### check_credentials

Check that ``username`` and ``password`` have been set, and raise an
exception if not.

##### register

Register a distribution on PyPI, using the provided metadata.

:param metadata: A :class:`Metadata` instance defining at least a name
                 and version number for the distribution to be
                 registered.
:return: The HTTP response received from PyPI upon submission of the
        request.

**Param√®tres :**

- `metadata`

##### _reader

Thread runner for reading lines of from a subprocess into a buffer.

:param name: The logical name of the stream (used for logging only).
:param stream: The stream to read from. This will typically a pipe
               connected to the output stream of a subprocess.
:param outbuf: The list to append the read lines to.

**Param√®tres :**

- `name`
- `stream`
- `outbuf`

##### get_sign_command

Return a suitable command for signing a file.

:param filename: The pathname to the file to be signed.
:param signer: The identifier of the signer of the file.
:param sign_password: The passphrase for the signer's
                      private key used for signing.
:param keystore: The path to a directory which contains the keys
                 used in verification. If not specified, the
                 instance's ``gpg_home`` attribute is used instead.
:return: The signing command as a list suitable to be
         passed to :class:`subprocess.Popen`.

**Param√®tres :**

- `filename`
- `signer`
- `sign_password`
- `keystore`

##### run_command

Run a command in a child process , passing it any input data specified.

:param cmd: The command to run.
:param input_data: If specified, this must be a byte string containing
                   data to be sent to the child process.
:return: A tuple consisting of the subprocess' exit code, a list of
         lines read from the subprocess' ``stdout``, and a list of
         lines read from the subprocess' ``stderr``.

**Param√®tres :**

- `cmd`
- `input_data`

##### sign_file

Sign a file.

:param filename: The pathname to the file to be signed.
:param signer: The identifier of the signer of the file.
:param sign_password: The passphrase for the signer's
                      private key used for signing.
:param keystore: The path to a directory which contains the keys
                 used in signing. If not specified, the instance's
                 ``gpg_home`` attribute is used instead.
:return: The absolute pathname of the file where the signature is
         stored.

**Param√®tres :**

- `filename`
- `signer`
- `sign_password`
- `keystore`

##### upload_file

Upload a release file to the index.

:param metadata: A :class:`Metadata` instance defining at least a name
                 and version number for the file to be uploaded.
:param filename: The pathname of the file to be uploaded.
:param signer: The identifier of the signer of the file.
:param sign_password: The passphrase for the signer's
                      private key used for signing.
:param filetype: The type of the file being uploaded. This is the
                distutils command which produced that file, e.g.
                ``sdist`` or ``bdist_wheel``.
:param pyversion: The version of Python which the release relates
                  to. For code compatible with any Python, this would
                  be ``source``, otherwise it would be e.g. ``3.2``.
:param keystore: The path to a directory which contains the keys
                 used in signing. If not specified, the instance's
                 ``gpg_home`` attribute is used instead.
:return: The HTTP response received from PyPI upon submission of the
        request.

**Param√®tres :**

- `metadata`
- `filename`
- `signer`
- `sign_password`
- `filetype`
- `pyversion`
- `keystore`

##### upload_documentation

Upload documentation to the index.

:param metadata: A :class:`Metadata` instance defining at least a name
                 and version number for the documentation to be
                 uploaded.
:param doc_dir: The pathname of the directory which contains the
                documentation. This should be the directory that
                contains the ``index.html`` for the documentation.
:return: The HTTP response received from PyPI upon submission of the
        request.

**Param√®tres :**

- `metadata`
- `doc_dir`

##### get_verify_command

Return a suitable command for verifying a file.

:param signature_filename: The pathname to the file containing the
                           signature.
:param data_filename: The pathname to the file containing the
                      signed data.
:param keystore: The path to a directory which contains the keys
                 used in verification. If not specified, the
                 instance's ``gpg_home`` attribute is used instead.
:return: The verifying command as a list suitable to be
         passed to :class:`subprocess.Popen`.

**Param√®tres :**

- `signature_filename`
- `data_filename`
- `keystore`

##### verify_signature

Verify a signature for a file.

:param signature_filename: The pathname to the file containing the
                           signature.
:param data_filename: The pathname to the file containing the
                      signed data.
:param keystore: The path to a directory which contains the keys
                 used in verification. If not specified, the
                 instance's ``gpg_home`` attribute is used instead.
:return: True if the signature was verified, else False.

**Param√®tres :**

- `signature_filename`
- `data_filename`
- `keystore`

##### download_file

This is a convenience method for downloading a file from an URL.
Normally, this will be a file from the index, though currently
no check is made for this (i.e. a file can be downloaded from
anywhere).

The method is just like the :func:`urlretrieve` function in the
standard library, except that it allows digest computation to be
done during download and checking that the downloaded data
matched any expected value.

:param url: The URL of the file to be downloaded (assumed to be
            available via an HTTP GET request).
:param destfile: The pathname where the downloaded file is to be
                 saved.
:param digest: If specified, this must be a (hasher, value)
               tuple, where hasher is the algorithm used (e.g.
               ``'md5'``) and ``value`` is the expected value.
:param reporthook: The same as for :func:`urlretrieve` in the
                   standard library.

**Param√®tres :**

- `url`
- `destfile`
- `digest`
- `reporthook`

##### send_request

Send a standard library :class:`Request` to PyPI and return its
response.

:param req: The request to send.
:return: The HTTP response from PyPI (a standard library HTTPResponse).

**Param√®tres :**

- `req`

##### encode_request

Encode fields and files for posting to an HTTP server.

:param fields: The fields to send as a list of (fieldname, value)
               tuples.
:param files: The files to send as a list of (fieldname, filename,
              file_bytes) tuple.

**Param√®tres :**

- `fields`
- `files`

##### search

**Param√®tres :**

- `terms`
- `operator`

---

### locators

#### Classes

##### RedirectHandler

A class to work around a bug in some Python 3.2.x releases.

**M√©thodes :**

- `http_error_302()`

##### Locator

A base class for locators - things that locate distributions.

**M√©thodes :**

- `__init__()`
- `get_errors()`
- `clear_errors()`
- `clear_cache()`
- `_get_scheme()`
- `_set_scheme()`
- `_get_project()`
- `get_distribution_names()`
- `get_project()`
- `score_url()`
- `prefer_url()`
- `split_filename()`
- `convert_url_to_download_info()`
- `_get_digest()`
- `_update_version_data()`
- `locate()`

##### PyPIRPCLocator

This locator uses XML-RPC to locate distributions. It therefore
cannot be used with simple mirrors (that only mirror file content).

**M√©thodes :**

- `__init__()`
- `get_distribution_names()`
- `_get_project()`

##### PyPIJSONLocator

This locator uses PyPI's JSON interface. It's very limited in functionality
and probably not worth using.

**M√©thodes :**

- `__init__()`
- `get_distribution_names()`
- `_get_project()`

##### Page

This class represents a scraped HTML page.

**M√©thodes :**

- `__init__()`
- `links()`

##### SimpleScrapingLocator

A locator which scrapes HTML pages to locate downloads for a distribution.
This runs multiple threads to do the I/O; performance is at least as good
as pip's PackageFinder, which works in an analogous fashion.

**M√©thodes :**

- `__init__()`
- `_prepare_threads()`
- `_wait_threads()`
- `_get_project()`
- `_is_platform_dependent()`
- `_process_download()`
- `_should_queue()`
- `_fetch()`
- `get_page()`
- `get_distribution_names()`

##### DirectoryLocator

This class locates distributions in a directory tree.

**M√©thodes :**

- `__init__()`
- `should_include()`
- `_get_project()`
- `get_distribution_names()`

##### JSONLocator

This locator uses special extended metadata (not available on PyPI) and is
the basis of performant dependency resolution in distlib. Other locators
require archive downloads before dependencies can be determined! As you
might imagine, that can be slow.

**M√©thodes :**

- `get_distribution_names()`
- `_get_project()`

##### DistPathLocator

This locator finds installed distributions in a path. It can be useful for
adding to an :class:`AggregatingLocator`.

**M√©thodes :**

- `__init__()`
- `_get_project()`

##### AggregatingLocator

This class allows you to chain and/or merge a list of locators.

**M√©thodes :**

- `__init__()`
- `clear_cache()`
- `_set_scheme()`
- `_get_project()`
- `get_distribution_names()`

##### DependencyFinder

Locate dependencies for distributions.

**M√©thodes :**

- `__init__()`
- `add_distribution()`
- `remove_distribution()`
- `get_matcher()`
- `find_providers()`
- `try_to_replace()`
- `find()`

#### Fonctions

##### get_all_distribution_names

Return all distribution names known by an index.
:param url: The URL of the index.
:return: A list of all known distribution names.

**Param√®tres :**

- `url`

##### http_error_302

**Param√®tres :**

- `req`
- `fp`
- `code`
- `msg`
- `headers`

##### __init__

Initialise an instance.
:param scheme: Because locators look for most recent versions, they
               need to know the version scheme to use. This specifies
               the current PEP-recommended scheme - use ``'legacy'``
               if you need to support existing distributions on PyPI.

**Param√®tres :**

- `scheme`

##### get_errors

Return any errors which have occurred.

##### clear_errors

Clear any errors which may have been logged.

##### clear_cache

##### _get_scheme

##### _set_scheme

**Param√®tres :**

- `value`

##### _get_project

For a given project, get a dictionary mapping available versions to Distribution
instances.

This should be implemented in subclasses.

If called from a locate() request, self.matcher will be set to a
matcher for the requirement to satisfy, otherwise it will be None.

**Param√®tres :**

- `name`

##### get_distribution_names

Return all the distribution names known to this locator.

##### get_project

For a given project, get a dictionary mapping available versions to Distribution
instances.

This calls _get_project to do all the work, and just implements a caching layer on top.

**Param√®tres :**

- `name`

##### score_url

Give an url a score which can be used to choose preferred URLs
for a given project release.

**Param√®tres :**

- `url`

##### prefer_url

Choose one of two URLs where both are candidates for distribution
archives for the same version of a distribution (for example,
.tar.gz vs. zip).

The current implementation favours https:// URLs over http://, archives
from PyPI over those from other locations, wheel compatibility (if a
wheel) and then the archive name.

**Param√®tres :**

- `url1`
- `url2`

##### split_filename

Attempt to split a filename in project name, version and Python version.

**Param√®tres :**

- `filename`
- `project_name`

##### convert_url_to_download_info

See if a URL is a candidate for a download URL for a project (the URL
has typically been scraped from an HTML page).

If it is, a dictionary is returned with keys "name", "version",
"filename" and "url"; otherwise, None is returned.

**Param√®tres :**

- `url`
- `project_name`

##### _get_digest

Get a digest from a dictionary by looking at a "digests" dictionary
or keys of the form 'algo_digest'.

Returns a 2-tuple (algo, digest) if found, else None. Currently
looks only for SHA256, then MD5.

**Param√®tres :**

- `info`

##### _update_version_data

Update a result dictionary (the final result from _get_project) with a
dictionary for a specific version, which typically holds information
gleaned from a filename or URL for an archive for the distribution.

**Param√®tres :**

- `result`
- `info`

##### locate

Find the most recent distribution which matches the given
requirement.

:param requirement: A requirement of the form 'foo (1.0)' or perhaps
                    'foo (>= 1.0, < 2.0, != 1.3)'
:param prereleases: If ``True``, allow pre-release versions
                    to be located. Otherwise, pre-release versions
                    are not returned.
:return: A :class:`Distribution` instance, or ``None`` if no such
         distribution could be located.

**Param√®tres :**

- `requirement`
- `prereleases`

##### __init__

Initialise an instance.

:param url: The URL to use for XML-RPC.
:param kwargs: Passed to the superclass constructor.

**Param√®tres :**

- `url`

##### get_distribution_names

Return all the distribution names known to this locator.

##### _get_project

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `url`

##### get_distribution_names

Return all the distribution names known to this locator.

##### _get_project

**Param√®tres :**

- `name`

##### __init__

Initialise an instance with the Unicode page contents and the URL they
came from.

**Param√®tres :**

- `data`
- `url`

##### links

Return the URLs of all the links on a page together with information
about their "rel" attribute, for determining which ones to treat as
downloads and which ones to queue for further scraping.

##### __init__

Initialise an instance.
:param url: The root URL to use for scraping.
:param timeout: The timeout, in seconds, to be applied to requests.
                This defaults to ``None`` (no timeout specified).
:param num_workers: The number of worker threads you want to do I/O,
                    This defaults to 10.
:param kwargs: Passed to the superclass.

**Param√®tres :**

- `url`
- `timeout`
- `num_workers`

##### _prepare_threads

Threads are created only when get_project is called, and terminate
before it returns. They are there primarily to parallelise I/O (i.e.
fetching web pages).

##### _wait_threads

Tell all the threads to terminate (by sending a sentinel value) and
wait for them to do so.

##### _get_project

**Param√®tres :**

- `name`

##### _is_platform_dependent

Does an URL refer to a platform-specific download?

**Param√®tres :**

- `url`

##### _process_download

See if an URL is a suitable download for a project.

If it is, register information in the result dictionary (for
_get_project) about the specific version it's for.

Note that the return value isn't actually used other than as a boolean
value.

**Param√®tres :**

- `url`

##### _should_queue

Determine whether a link URL from a referring page and with a
particular "rel" attribute should be queued for scraping.

**Param√®tres :**

- `link`
- `referrer`
- `rel`

##### _fetch

Get a URL to fetch from the work queue, get the HTML page, examine its
links for download candidates and candidates for further scraping.

This is a handy method to run in a thread.

##### get_page

Get the HTML for an URL, possibly from an in-memory cache.

XXX TODO Note: this cache is never actually cleared. It's assumed that
the data won't get stale over the lifetime of a locator instance (not
necessarily true for the default_locator).

**Param√®tres :**

- `url`

##### get_distribution_names

Return all the distribution names known to this locator.

##### __init__

Initialise an instance.
:param path: The root of the directory tree to search.
:param kwargs: Passed to the superclass constructor,
               except for:
               * recursive - if True (the default), subdirectories are
                 recursed into. If False, only the top-level directory
                 is searched,

**Param√®tres :**

- `path`

##### should_include

Should a filename be considered as a candidate for a distribution
archive? As well as the filename, the directory which contains it
is provided, though not used by the current implementation.

**Param√®tres :**

- `filename`
- `parent`

##### _get_project

**Param√®tres :**

- `name`

##### get_distribution_names

Return all the distribution names known to this locator.

##### get_distribution_names

Return all the distribution names known to this locator.

##### _get_project

**Param√®tres :**

- `name`

##### __init__

Initialise an instance.

:param distpath: A :class:`DistributionPath` instance to search.

**Param√®tres :**

- `distpath`

##### _get_project

**Param√®tres :**

- `name`

##### __init__

Initialise an instance.

:param locators: The list of locators to search.
:param kwargs: Passed to the superclass constructor,
               except for:
               * merge - if False (the default), the first successful
                 search from any of the locators is returned. If True,
                 the results from all locators are merged (this can be
                 slow).

##### clear_cache

##### _set_scheme

**Param√®tres :**

- `value`

##### _get_project

**Param√®tres :**

- `name`

##### get_distribution_names

Return all the distribution names known to this locator.

##### __init__

Initialise an instance, using the specified locator
to locate distributions.

**Param√®tres :**

- `locator`

##### add_distribution

Add a distribution to the finder. This will update internal information
about who provides what.
:param dist: The distribution to add.

**Param√®tres :**

- `dist`

##### remove_distribution

Remove a distribution from the finder. This will update internal
information about who provides what.
:param dist: The distribution to remove.

**Param√®tres :**

- `dist`

##### get_matcher

Get a version matcher for a requirement.
:param reqt: The requirement
:type reqt: str
:return: A version matcher (an instance of
         :class:`distlib.version.Matcher`).

**Param√®tres :**

- `reqt`

##### find_providers

Find the distributions which can fulfill a requirement.

:param reqt: The requirement.
 :type reqt: str
:return: A set of distribution which can fulfill the requirement.

**Param√®tres :**

- `reqt`

##### try_to_replace

Attempt to replace one provider with another. This is typically used
when resolving dependencies from multiple sources, e.g. A requires
(B >= 1.0) while C requires (B >= 1.1).

For successful replacement, ``provider`` must meet all the requirements
which ``other`` fulfills.

:param provider: The provider we are trying to replace with.
:param other: The provider we're trying to replace.
:param problems: If False is returned, this will contain what
                 problems prevented replacement. This is currently
                 a tuple of the literal string 'cantreplace',
                 ``provider``, ``other``  and the set of requirements
                 that ``provider`` couldn't fulfill.
:return: True if we can replace ``other`` with ``provider``, else
         False.

**Param√®tres :**

- `provider`
- `other`
- `problems`

##### find

Find a distribution and all distributions it depends on.

:param requirement: The requirement specifying the distribution to
                    find, or a Distribution instance.
:param meta_extras: A list of meta extras such as :test:, :build: and
                    so on.
:param prereleases: If ``True``, allow pre-release versions to be
                    returned - otherwise, don't return prereleases
                    unless they're all that's available.

Return a set of :class:`Distribution` instances and a set of
problems.

The distributions returned should be such that they have the
:attr:`required` attribute set to ``True`` if they were
from the ``requirement`` passed to ``find()``, and they have the
:attr:`build_time_dependency` attribute set to ``True`` unless they
are post-installation dependencies of the ``requirement``.

The problems should be a tuple consisting of the string
``'unsatisfied'`` and the requirement which couldn't be satisfied
by any distribution known to the locator.

**Param√®tres :**

- `requirement`
- `meta_extras`
- `prereleases`

##### same_project

**Param√®tres :**

- `name1`
- `name2`

##### clean

Tidy up an URL.

**Param√®tres :**

- `url`

---

### manifest

Class representing the list of files in a distribution.

Equivalent to distutils.filelist, but fixes some problems.

#### Classes

##### Manifest

A list of files built by exploring the filesystem and filtered by applying various
patterns to what we find there.

**M√©thodes :**

- `__init__()`
- `findall()`
- `add()`
- `add_many()`
- `sorted()`
- `clear()`
- `process_directive()`
- `_parse_directive()`
- `_include_pattern()`
- `_exclude_pattern()`
- `_translate_pattern()`
- `_glob_to_re()`

#### Fonctions

##### __init__

Initialise an instance.

:param base: The base directory to explore under.

**Param√®tres :**

- `base`

##### findall

Find all files under the base and set ``allfiles`` to the absolute
pathnames of files found.

##### add

Add a file to the manifest.

:param item: The pathname to add. This can be relative to the base.

**Param√®tres :**

- `item`

##### add_many

Add a list of files to the manifest.

:param items: The pathnames to add. These can be relative to the base.

**Param√®tres :**

- `items`

##### sorted

Return sorted files in directory order

**Param√®tres :**

- `wantdirs`

##### clear

Clear all collected files.

##### process_directive

Process a directive which either adds some files from ``allfiles`` to
``files``, or removes some files from ``files``.

:param directive: The directive to process. This should be in a format
             compatible with distutils ``MANIFEST.in`` files:

             http://docs.python.org/distutils/sourcedist.html#commands

**Param√®tres :**

- `directive`

##### _parse_directive

Validate a directive.
:param directive: The directive to validate.
:return: A tuple of action, patterns, thedir, dir_patterns

**Param√®tres :**

- `directive`

##### _include_pattern

Select strings (presumably filenames) from 'self.files' that
match 'pattern', a Unix-style wildcard (glob) pattern.

Patterns are not quite the same as implemented by the 'fnmatch'
module: '*' and '?'  match non-special characters, where "special"
is platform-dependent: slash on Unix; colon, slash, and backslash on
DOS/Windows; and colon on Mac OS.

If 'anchor' is true (the default), then the pattern match is more
stringent: "*.py" will match "foo.py" but not "foo/bar.py".  If
'anchor' is false, both of these will match.

If 'prefix' is supplied, then only filenames starting with 'prefix'
(itself a pattern) and ending with 'pattern', with anything in between
them, will match.  'anchor' is ignored in this case.

If 'is_regex' is true, 'anchor' and 'prefix' are ignored, and
'pattern' is assumed to be either a string containing a regex or a
regex object -- no translation is done, the regex is just compiled
and used as-is.

Selected strings will be added to self.files.

Return True if files are found.

**Param√®tres :**

- `pattern`
- `anchor`
- `prefix`
- `is_regex`

##### _exclude_pattern

Remove strings (presumably filenames) from 'files' that match
'pattern'.

Other parameters are the same as for 'include_pattern()', above.
The list 'self.files' is modified in place. Return True if files are
found.

This API is public to allow e.g. exclusion of SCM subdirs, e.g. when
packaging source distributions

**Param√®tres :**

- `pattern`
- `anchor`
- `prefix`
- `is_regex`

##### _translate_pattern

Translate a shell-like wildcard pattern to a compiled regular
expression.

Return the compiled regex.  If 'is_regex' true,
then 'pattern' is directly compiled to a regex (if it's a string)
or just returned as-is (assumes it's a regex object).

**Param√®tres :**

- `pattern`
- `anchor`
- `prefix`
- `is_regex`

##### _glob_to_re

Translate a shell-like glob pattern to a regular expression.

Return a string containing the regex.  Differs from
'fnmatch.translate()' in that '*' does not match "special characters"
(which are platform-specific).

**Param√®tres :**

- `pattern`

##### add_dir

**Param√®tres :**

- `dirs`
- `d`

---

### markers

Parser for the environment markers micro-language defined in PEP 508.

#### Classes

##### Evaluator

This class is used to evaluate marker expressions.

**M√©thodes :**

- `evaluate()`

#### Fonctions

##### _is_version_marker

**Param√®tres :**

- `s`

##### _is_literal

**Param√®tres :**

- `o`

##### _get_versions

**Param√®tres :**

- `s`

##### default_context

##### interpret

Interpret a marker and return a result depending on environment.

:param marker: The marker to interpret.
:type marker: str
:param execution_context: The context used for name lookup.
:type execution_context: mapping

**Param√®tres :**

- `marker`
- `execution_context`

##### evaluate

Evaluate a marker expression returned by the :func:`parse_requirement`
function in the specified context.

**Param√®tres :**

- `expr`
- `context`

##### format_full_version

**Param√®tres :**

- `info`

---

### metadata

Implementation of the Metadata for Python packages PEPs.

Supports all metadata formats (1.0, 1.1, 1.2, 1.3/2.1 and 2.2).

#### Classes

##### MetadataMissingError

A required metadata is missing

##### MetadataConflictError

Attempt to read or write metadata fields that are conflictual.

##### MetadataUnrecognizedVersionError

Unknown metadata version number.

##### MetadataInvalidError

A metadata value is invalid

##### LegacyMetadata

The legacy metadata of a release.

Supports versions 1.0, 1.1, 1.2, 2.0 and 1.3/2.1 (auto-detected). You can
instantiate the class with one of these arguments (or none):
- *path*, the path to a metadata file
- *fileobj* give a file-like object with metadata as content
- *mapping* is a dict-like object
- *scheme* is a version scheme name

**M√©thodes :**

- `__init__()`
- `set_metadata_version()`
- `_write_field()`
- `__getitem__()`
- `__setitem__()`
- `__delitem__()`
- `__contains__()`
- `_convert_name()`
- `_default_value()`
- `_remove_line_prefix()`
- `__getattr__()`
- `get_fullname()`
- `is_field()`
- `is_multi_field()`
- `read()`
- `read_file()`
- `write()`
- `write_file()`
- `update()`
- `set()`
- `get()`
- `check()`
- `todict()`
- `add_requirements()`
- `keys()`
- `__iter__()`
- `values()`
- `items()`
- `__repr__()`

##### Metadata

The metadata of a release. This implementation uses 2.1
metadata where possible. If not possible, it wraps a LegacyMetadata
instance which handles the key-value metadata format.

**M√©thodes :**

- `__init__()`
- `__getattribute__()`
- `_validate_value()`
- `__setattr__()`
- `name_and_version()`
- `provides()`
- `provides()`
- `get_requirements()`
- `dictionary()`
- `dependencies()`
- `dependencies()`
- `_validate_mapping()`
- `validate()`
- `todict()`
- `_from_legacy()`
- `_to_legacy()`
- `write()`
- `add_requirements()`
- `__repr__()`

#### Fonctions

##### _version2fieldlist

**Param√®tres :**

- `version`

##### _best_version

Detect the best version depending on the fields used.

**Param√®tres :**

- `fields`

##### _get_name_and_version

Return the distribution name with version.

If for_filename is true, return a filename-escaped form.

**Param√®tres :**

- `name`
- `version`
- `for_filename`

##### _has_marker

**Param√®tres :**

- `keys`
- `markers`

##### __init__

**Param√®tres :**

- `path`
- `fileobj`
- `mapping`
- `scheme`

##### set_metadata_version

##### _write_field

**Param√®tres :**

- `fileobj`
- `name`
- `value`

##### __getitem__

**Param√®tres :**

- `name`

##### __setitem__

**Param√®tres :**

- `name`
- `value`

##### __delitem__

**Param√®tres :**

- `name`

##### __contains__

**Param√®tres :**

- `name`

##### _convert_name

**Param√®tres :**

- `name`

##### _default_value

**Param√®tres :**

- `name`

##### _remove_line_prefix

**Param√®tres :**

- `value`

##### __getattr__

**Param√®tres :**

- `name`

##### get_fullname

Return the distribution name with version.

If filesafe is true, return a filename-escaped form.

**Param√®tres :**

- `filesafe`

##### is_field

return True if name is a valid metadata key

**Param√®tres :**

- `name`

##### is_multi_field

**Param√®tres :**

- `name`

##### read

Read the metadata values from a file path.

**Param√®tres :**

- `filepath`

##### read_file

Read the metadata values from a file object.

**Param√®tres :**

- `fileob`

##### write

Write the metadata fields to filepath.

**Param√®tres :**

- `filepath`
- `skip_unknown`

##### write_file

Write the PKG-INFO format data to a file object.

**Param√®tres :**

- `fileobject`
- `skip_unknown`

##### update

Set metadata values from the given iterable `other` and kwargs.

Behavior is like `dict.update`: If `other` has a ``keys`` method,
they are looped over and ``self[key]`` is assigned ``other[key]``.
Else, ``other`` is an iterable of ``(key, value)`` iterables.

Keys that don't match a metadata field or that have an empty value are
dropped.

**Param√®tres :**

- `other`

##### set

Control then set a metadata field.

**Param√®tres :**

- `name`
- `value`

##### get

Get a metadata field.

**Param√®tres :**

- `name`
- `default`

##### check

Check if the metadata is compliant. If strict is True then raise if
no Name or Version are provided

**Param√®tres :**

- `strict`

##### todict

Return fields as a dict.

Field names will be converted to use the underscore-lowercase style
instead of hyphen-mixed case (i.e. home_page instead of Home-page).
This is as per https://www.python.org/dev/peps/pep-0566/#id17.

**Param√®tres :**

- `skip_missing`

##### add_requirements

**Param√®tres :**

- `requirements`

##### keys

##### __iter__

##### values

##### items

##### __repr__

##### __init__

**Param√®tres :**

- `path`
- `fileobj`
- `mapping`
- `scheme`

##### __getattribute__

**Param√®tres :**

- `key`

##### _validate_value

**Param√®tres :**

- `key`
- `value`
- `scheme`

##### __setattr__

**Param√®tres :**

- `key`
- `value`

##### name_and_version

##### provides

##### provides

**Param√®tres :**

- `value`

##### get_requirements

Base method to get dependencies, given a set of extras
to satisfy and an optional environment context.
:param reqts: A list of sometimes-wanted dependencies,
              perhaps dependent on extras and environment.
:param extras: A list of optional components being requested.
:param env: An optional environment for marker evaluation.

**Param√®tres :**

- `reqts`
- `extras`
- `env`

##### dictionary

##### dependencies

##### dependencies

**Param√®tres :**

- `value`

##### _validate_mapping

**Param√®tres :**

- `mapping`
- `scheme`

##### validate

##### todict

##### _from_legacy

##### _to_legacy

##### write

**Param√®tres :**

- `path`
- `fileobj`
- `legacy`
- `skip_unknown`

##### add_requirements

**Param√®tres :**

- `requirements`

##### __repr__

##### _set

**Param√®tres :**

- `key`
- `value`

##### are_valid_constraints

**Param√®tres :**

- `value`

##### process_entries

**Param√®tres :**

- `entries`

---

### resources

#### Classes

##### ResourceCache

**M√©thodes :**

- `__init__()`
- `is_stale()`
- `get()`

##### ResourceBase

**M√©thodes :**

- `__init__()`

##### Resource

A class representing an in-package resource, such as a data file. This is
not normally instantiated by user code, but rather by a
:class:`ResourceFinder` which manages the resource.

**M√©thodes :**

- `as_stream()`
- `file_path()`
- `bytes()`
- `size()`

##### ResourceContainer

**M√©thodes :**

- `resources()`

##### ResourceFinder

Resource finder for file system resources.

**M√©thodes :**

- `__init__()`
- `_adjust_path()`
- `_make_path()`
- `_find()`
- `get_cache_info()`
- `find()`
- `get_stream()`
- `get_bytes()`
- `get_size()`
- `get_resources()`
- `is_container()`
- `iterator()`

##### ZipResourceFinder

Resource finder for resources in .zip files.

**M√©thodes :**

- `__init__()`
- `_adjust_path()`
- `_find()`
- `get_cache_info()`
- `get_bytes()`
- `get_stream()`
- `get_size()`
- `get_resources()`
- `_is_directory()`

#### Fonctions

##### register_finder

**Param√®tres :**

- `loader`
- `finder_maker`

##### finder

Return a resource finder for a package.
:param package: The name of the package.
:return: A :class:`ResourceFinder` instance for the package.

**Param√®tres :**

- `package`

##### finder_for_path

Return a resource finder for a path, which should represent a container.

:param path: The path.
:return: A :class:`ResourceFinder` instance for the path.

**Param√®tres :**

- `path`

##### __init__

**Param√®tres :**

- `base`

##### is_stale

Is the cache stale for the given resource?

:param resource: The :class:`Resource` being cached.
:param path: The path of the resource in the cache.
:return: True if the cache is stale.

**Param√®tres :**

- `resource`
- `path`

##### get

Get a resource into the cache,

:param resource: A :class:`Resource` instance.
:return: The pathname of the resource in the cache.

**Param√®tres :**

- `resource`

##### __init__

**Param√®tres :**

- `finder`
- `name`

##### as_stream

Get the resource as a stream.

This is not a property to make it obvious that it returns a new stream
each time.

##### file_path

##### bytes

##### size

##### resources

##### __init__

**Param√®tres :**

- `module`

##### _adjust_path

**Param√®tres :**

- `path`

##### _make_path

**Param√®tres :**

- `resource_name`

##### _find

**Param√®tres :**

- `path`

##### get_cache_info

**Param√®tres :**

- `resource`

##### find

**Param√®tres :**

- `resource_name`

##### get_stream

**Param√®tres :**

- `resource`

##### get_bytes

**Param√®tres :**

- `resource`

##### get_size

**Param√®tres :**

- `resource`

##### get_resources

**Param√®tres :**

- `resource`

##### is_container

**Param√®tres :**

- `resource`

##### iterator

**Param√®tres :**

- `resource_name`

##### __init__

**Param√®tres :**

- `module`

##### _adjust_path

**Param√®tres :**

- `path`

##### _find

**Param√®tres :**

- `path`

##### get_cache_info

**Param√®tres :**

- `resource`

##### get_bytes

**Param√®tres :**

- `resource`

##### get_stream

**Param√®tres :**

- `resource`

##### get_size

**Param√®tres :**

- `resource`

##### get_resources

**Param√®tres :**

- `resource`

##### _is_directory

**Param√®tres :**

- `path`

##### allowed

**Param√®tres :**

- `f`

---

### scripts

#### Classes

##### ScriptMaker

A class to copy or create scripts from source scripts or callable
specifications.

**M√©thodes :**

- `__init__()`
- `_get_alternate_executable()`
- `_build_shebang()`
- `_get_shebang()`
- `_get_script_text()`
- `get_manifest()`
- `_write_script()`
- `get_script_filenames()`
- `_make_script()`
- `_copy_script()`
- `dry_run()`
- `dry_run()`
- `make()`
- `make_multiple()`

#### Fonctions

##### enquote_executable

**Param√®tres :**

- `executable`

##### __init__

**Param√®tres :**

- `source_dir`
- `target_dir`
- `add_launchers`
- `dry_run`
- `fileop`

##### _get_alternate_executable

**Param√®tres :**

- `executable`
- `options`

##### _build_shebang

Build a shebang line. In the simple case (on Windows, or a shebang line
which is not too long or contains spaces) use a simple formulation for
the shebang. Otherwise, use /bin/sh as the executable, with a contrived
shebang which allows the script to run either under Python or sh, using
suitable quoting. Thanks to Harald Nordgren for his input.

See also: http://www.in-ulm.de/~mascheck/various/shebang/#length
          https://hg.mozilla.org/mozilla-central/file/tip/mach

**Param√®tres :**

- `executable`
- `post_interp`

##### _get_shebang

**Param√®tres :**

- `encoding`
- `post_interp`
- `options`

##### _get_script_text

**Param√®tres :**

- `entry`

##### get_manifest

**Param√®tres :**

- `exename`

##### _write_script

**Param√®tres :**

- `names`
- `shebang`
- `script_bytes`
- `filenames`
- `ext`

##### get_script_filenames

**Param√®tres :**

- `name`

##### _make_script

**Param√®tres :**

- `entry`
- `filenames`
- `options`

##### _copy_script

**Param√®tres :**

- `script`
- `filenames`

##### dry_run

##### dry_run

**Param√®tres :**

- `value`

##### make

Make a script.

:param specification: The specification, which is either a valid export
                      entry specification (to make a script from a
                      callable) or a filename (to make a script by
                      copying from a source location).
:param options: A dictionary of options controlling script generation.
:return: A list of all absolute pathnames written to.

**Param√®tres :**

- `specification`
- `options`

##### make_multiple

Take a list of specifications and make scripts from them,
:param specifications: A list of specifications.
:return: A list of all absolute pathnames written to,

**Param√®tres :**

- `specifications`
- `options`

##### _is_shell

Determine if the specified executable is a script
(contains a #! line)

**Param√®tres :**

- `executable`

##### _fix_jython_executable

**Param√®tres :**

- `executable`

##### _get_launcher

**Param√®tres :**

- `kind`

---

### util

#### Classes

##### cached_property

**M√©thodes :**

- `__init__()`
- `__get__()`

##### FileOperator

**M√©thodes :**

- `__init__()`
- `_init_record()`
- `record_as_written()`
- `newer()`
- `copy_file()`
- `copy_stream()`
- `write_binary_file()`
- `write_text_file()`
- `set_mode()`
- `ensure_dir()`
- `byte_compile()`
- `ensure_removed()`
- `is_writable()`
- `commit()`
- `rollback()`

##### ExportEntry

**M√©thodes :**

- `__init__()`
- `value()`
- `__repr__()`
- `__eq__()`

##### Cache

A class implementing a cache for resources that need to live in the file system
e.g. shared libraries. This class was moved from resources to here because it
could be used by other modules, e.g. the wheel module.

**M√©thodes :**

- `__init__()`
- `prefix_to_dir()`
- `clear()`

##### EventMixin

A very simple publish/subscribe system.

**M√©thodes :**

- `__init__()`
- `add()`
- `remove()`
- `get_subscribers()`
- `publish()`

##### Sequencer

**M√©thodes :**

- `__init__()`
- `add_node()`
- `remove_node()`
- `add()`
- `remove()`
- `is_step()`
- `get_steps()`
- `strong_connections()`
- `dot()`

##### Progress

**M√©thodes :**

- `__init__()`
- `update()`
- `increment()`
- `start()`
- `stop()`
- `maximum()`
- `percentage()`
- `format_duration()`
- `ETA()`
- `speed()`

##### Transport

**M√©thodes :**

- `__init__()`
- `make_connection()`

##### ServerProxy

**M√©thodes :**

- `__init__()`

##### CSVBase

**M√©thodes :**

- `__enter__()`
- `__exit__()`

##### CSVReader

**M√©thodes :**

- `__init__()`
- `__iter__()`
- `next()`

##### CSVWriter

**M√©thodes :**

- `__init__()`
- `writerow()`

##### Configurator

**M√©thodes :**

- `__init__()`
- `configure_custom()`
- `__getitem__()`
- `inc_convert()`

##### SubprocessMixin

Mixin for running subprocesses and capturing their output

**M√©thodes :**

- `__init__()`
- `reader()`
- `run_command()`

##### PyPIRCFile

**M√©thodes :**

- `__init__()`
- `read()`
- `update()`

##### HTTPSConnection

**M√©thodes :**

- `connect()`

##### HTTPSHandler

**M√©thodes :**

- `__init__()`
- `_conn_maker()`
- `https_open()`

##### HTTPSOnlyHandler

**M√©thodes :**

- `http_open()`

##### SafeTransport

**M√©thodes :**

- `__init__()`
- `make_connection()`

#### Fonctions

##### parse_marker

Parse a marker string and return a dictionary containing a marker expression.

The dictionary will contain keys "op", "lhs" and "rhs" for non-terminals in
the expression grammar, or strings. A string contained in quotes is to be
interpreted as a literal string, and a string not contained in quotes is a
variable (such as os_name).

**Param√®tres :**

- `marker_string`

##### parse_requirement

Parse a requirement passed in as a string. Return a Container
whose attributes contain the various parts of the requirement.

**Param√®tres :**

- `req`

##### get_resources_dests

Find destinations for resources files

**Param√®tres :**

- `resources_root`
- `rules`

##### in_venv

##### get_executable

##### proceed

**Param√®tres :**

- `prompt`
- `allowed_chars`
- `error_prompt`
- `default`

##### extract_by_key

**Param√®tres :**

- `d`
- `keys`

##### read_exports

**Param√®tres :**

- `stream`

##### write_exports

**Param√®tres :**

- `exports`
- `stream`

##### tempdir

##### chdir

**Param√®tres :**

- `d`

##### socket_timeout

**Param√®tres :**

- `seconds`

##### convert_path

Return 'pathname' as a name that will work on the native filesystem.

The path is split on '/' and put back together again using the current
directory separator.  Needed because filenames in the setup script are
always supplied in Unix style, and have to be converted to the local
convention before we can actually use them in the filesystem.  Raises
ValueError on non-Unix-ish systems if 'pathname' either starts or
ends with a slash.

**Param√®tres :**

- `pathname`

##### resolve

**Param√®tres :**

- `module_name`
- `dotted_path`

##### get_export_entry

**Param√®tres :**

- `specification`

##### get_cache_base

Return the default base location for distlib caches. If the directory does
not exist, it is created. Use the suffix provided for the base directory,
and default to '.distlib' if it isn't provided.

On Windows, if LOCALAPPDATA is defined in the environment, then it is
assumed to be a directory, and will be the parent directory of the result.
On POSIX, and on Windows if LOCALAPPDATA is not defined, the user's home
directory - using os.expanduser('~') - will be the parent directory of
the result.

The result is just the directory '.distlib' in the parent directory as
determined above, or with the name specified with ``suffix``.

**Param√®tres :**

- `suffix`

##### path_to_cache_dir

Convert an absolute path to a directory name for use in a cache.

The algorithm used is:

#. On Windows, any ``':'`` in the drive is replaced with ``'---'``.
#. Any occurrence of ``os.sep`` is replaced with ``'--'``.
#. ``'.cache'`` is appended.

**Param√®tres :**

- `path`
- `use_abspath`

##### ensure_slash

**Param√®tres :**

- `s`

##### parse_credentials

**Param√®tres :**

- `netloc`

##### get_process_umask

##### is_string_sequence

**Param√®tres :**

- `seq`

##### split_filename

Extract name, version, python version from a filename (no extension)

Return name, version, pyver or None

**Param√®tres :**

- `filename`
- `project_name`

##### parse_name_and_version

A utility method used to get name and version from a string.

From e.g. a Provides-Dist value.

:param p: A value in a form 'foo (1.0)'
:return: The name and version as a tuple.

**Param√®tres :**

- `p`

##### get_extras

**Param√®tres :**

- `requested`
- `available`

##### _get_external_data

**Param√®tres :**

- `url`

##### get_project_data

**Param√®tres :**

- `name`

##### get_package_data

**Param√®tres :**

- `name`
- `version`

##### unarchive

**Param√®tres :**

- `archive_filename`
- `dest_dir`
- `format`
- `check`

##### zip_dir

zip a directory tree into a BytesIO object

**Param√®tres :**

- `directory`

##### iglob

Extended globbing function that supports ** and {opt1,opt2,opt3}.

**Param√®tres :**

- `path_glob`

##### _iglob

**Param√®tres :**

- `path_glob`

##### _csv_open

**Param√®tres :**

- `fn`
- `mode`

##### normalize_name

Normalize a python package name a la PEP 503

**Param√®tres :**

- `name`

##### _load_pypirc

Read the PyPI access configuration as supported by distutils.

**Param√®tres :**

- `index`

##### _store_pypirc

**Param√®tres :**

- `index`

##### get_host_platform

Return a string that identifies the current platform.  This is used mainly to
distinguish platform-specific build directories and platform-specific built
distributions.  Typically includes the OS name and version and the
architecture (as supplied by 'os.uname()'), although the exact information
included depends on the OS; eg. on Linux, the kernel version isn't
particularly important.

Examples of returned values:
   linux-i586
   linux-alpha (?)
   solaris-2.6-sun4u

Windows will return one of:
   win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64, EM64T, etc)
   win32 (all others - specifically, sys.platform is returned)

For other non-POSIX platforms, currently just returns 'sys.platform'.

##### get_platform

##### marker_var

**Param√®tres :**

- `remaining`

##### marker_expr

**Param√®tres :**

- `remaining`

##### marker_and

**Param√®tres :**

- `remaining`

##### marker

**Param√®tres :**

- `remaining`

##### get_rel_path

**Param√®tres :**

- `root`
- `path`

##### read_stream

**Param√®tres :**

- `cp`
- `stream`

##### __init__

**Param√®tres :**

- `func`

##### __get__

**Param√®tres :**

- `obj`
- `cls`

##### __init__

**Param√®tres :**

- `dry_run`

##### _init_record

##### record_as_written

**Param√®tres :**

- `path`

##### newer

Tell if the target is newer than the source.

Returns true if 'source' exists and is more recently modified than
'target', or if 'source' exists and 'target' doesn't.

Returns false if both exist and 'target' is the same age or younger
than 'source'. Raise PackagingFileError if 'source' does not exist.

Note that this test is not very accurate: files created in the same
second will have the same "age".

**Param√®tres :**

- `source`
- `target`

##### copy_file

Copy a file respecting dry-run and force flags.
        

**Param√®tres :**

- `infile`
- `outfile`
- `check`

##### copy_stream

**Param√®tres :**

- `instream`
- `outfile`
- `encoding`

##### write_binary_file

**Param√®tres :**

- `path`
- `data`

##### write_text_file

**Param√®tres :**

- `path`
- `data`
- `encoding`

##### set_mode

**Param√®tres :**

- `bits`
- `mask`
- `files`

##### ensure_dir

**Param√®tres :**

- `path`

##### byte_compile

**Param√®tres :**

- `path`
- `optimize`
- `force`
- `prefix`
- `hashed_invalidation`

##### ensure_removed

**Param√®tres :**

- `path`

##### is_writable

**Param√®tres :**

- `path`

##### commit

Commit recorded changes, turn off recording, return
changes.

##### rollback

##### __init__

**Param√®tres :**

- `name`
- `prefix`
- `suffix`
- `flags`

##### value

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __init__

Initialise an instance.

:param base: The base directory where the cache should be located.

**Param√®tres :**

- `base`

##### prefix_to_dir

Converts a resource prefix to a directory name in the cache.

**Param√®tres :**

- `prefix`
- `use_abspath`

##### clear

Clear the cache.

##### __init__

##### add

Add a subscriber for an event.

:param event: The name of an event.
:param subscriber: The subscriber to be added (and called when the
                   event is published).
:param append: Whether to append or prepend the subscriber to an
               existing subscriber list for the event.

**Param√®tres :**

- `event`
- `subscriber`
- `append`

##### remove

Remove a subscriber for an event.

:param event: The name of an event.
:param subscriber: The subscriber to be removed.

**Param√®tres :**

- `event`
- `subscriber`

##### get_subscribers

Return an iterator for the subscribers for an event.
:param event: The event to return subscribers for.

**Param√®tres :**

- `event`

##### publish

Publish a event and return a list of values returned by its
subscribers.

:param event: The event to publish.
:param args: The positional arguments to pass to the event's
             subscribers.
:param kwargs: The keyword arguments to pass to the event's
               subscribers.

**Param√®tres :**

- `event`

##### __init__

##### add_node

**Param√®tres :**

- `node`

##### remove_node

**Param√®tres :**

- `node`
- `edges`

##### add

**Param√®tres :**

- `pred`
- `succ`

##### remove

**Param√®tres :**

- `pred`
- `succ`

##### is_step

**Param√®tres :**

- `step`

##### get_steps

**Param√®tres :**

- `final`

##### strong_connections

##### dot

##### check_path

**Param√®tres :**

- `path`

##### __init__

**Param√®tres :**

- `minval`
- `maxval`

##### update

**Param√®tres :**

- `curval`

##### increment

**Param√®tres :**

- `incr`

##### start

##### stop

##### maximum

##### percentage

##### format_duration

**Param√®tres :**

- `duration`

##### ETA

##### speed

##### __init__

**Param√®tres :**

- `timeout`
- `use_datetime`

##### make_connection

**Param√®tres :**

- `host`

##### __init__

**Param√®tres :**

- `uri`

##### __enter__

##### __exit__

##### __init__

##### __iter__

##### next

##### __init__

**Param√®tres :**

- `fn`

##### writerow

**Param√®tres :**

- `row`

##### __init__

**Param√®tres :**

- `config`
- `base`

##### configure_custom

**Param√®tres :**

- `config`

##### __getitem__

**Param√®tres :**

- `key`

##### inc_convert

Default converter for the inc:// protocol.

**Param√®tres :**

- `value`

##### __init__

**Param√®tres :**

- `verbose`
- `progress`

##### reader

Read lines from a subprocess' output stream and either pass to a progress
callable (if specified) or write progress information to sys.stderr.

**Param√®tres :**

- `stream`
- `context`

##### run_command

**Param√®tres :**

- `cmd`

##### __init__

**Param√®tres :**

- `fn`
- `url`

##### read

##### update

**Param√®tres :**

- `username`
- `password`

##### strongconnect

**Param√®tres :**

- `node`

##### extraction_filter

Run tarfile.tar_filter, but raise the expected ValueError

**Param√®tres :**

- `member`
- `path`

##### connect

##### __init__

**Param√®tres :**

- `ca_certs`
- `check_domain`

##### _conn_maker

This is called to create a connection instance. Normally you'd
pass a connection class to do_open, but it doesn't actually check for
a class, and just expects a callable. As long as we behave just as a
constructor would have, we should be OK. If it ever changes so that
we *must* pass a class, we'll create an UnsafeHTTPSConnection class
which just sets check_domain to False in the class definition, and
choose which one to pass to do_open.

##### https_open

**Param√®tres :**

- `req`

##### http_open

**Param√®tres :**

- `req`

##### __init__

**Param√®tres :**

- `timeout`
- `use_datetime`

##### make_connection

**Param√®tres :**

- `host`

##### convert

**Param√®tres :**

- `o`

##### get_versions

Return a list of operator, version tuples if any are
specified, else None.

**Param√®tres :**

- `ver_remaining`

---

### version

Implementation of a flexible versioning scheme providing support for PEP-440,
setuptools-compatible and semantic versioning.

#### Classes

##### UnsupportedVersionError

This is an unsupported version.

##### Version

**M√©thodes :**

- `__init__()`
- `parse()`
- `_check_compatible()`
- `__eq__()`
- `__ne__()`
- `__lt__()`
- `__gt__()`
- `__le__()`
- `__ge__()`
- `__hash__()`
- `__repr__()`
- `__str__()`
- `is_prerelease()`

##### Matcher

**M√©thodes :**

- `parse_requirement()`
- `__init__()`
- `match()`
- `exact_version()`
- `_check_compatible()`
- `__eq__()`
- `__ne__()`
- `__hash__()`
- `__repr__()`
- `__str__()`

##### NormalizedVersion

A rational version.

Good:
    1.2         # equivalent to "1.2.0"
    1.2.0
    1.2a1
    1.2.3a2
    1.2.3b1
    1.2.3c1
    1.2.3.4
    TODO: fill this out

Bad:
    1           # minimum two numbers
    1.2a        # release level must have a release serial
    1.2.3b

**M√©thodes :**

- `parse()`
- `is_prerelease()`

##### NormalizedMatcher

**M√©thodes :**

- `_adjust_local()`
- `_match_lt()`
- `_match_gt()`
- `_match_le()`
- `_match_ge()`
- `_match_eq()`
- `_match_arbitrary()`
- `_match_ne()`
- `_match_compatible()`

##### LegacyVersion

**M√©thodes :**

- `parse()`
- `is_prerelease()`

##### LegacyMatcher

**M√©thodes :**

- `_match_compatible()`

##### SemanticVersion

**M√©thodes :**

- `parse()`
- `is_prerelease()`

##### SemanticMatcher

##### VersionScheme

**M√©thodes :**

- `__init__()`
- `is_valid_version()`
- `is_valid_matcher()`
- `is_valid_constraint_list()`
- `suggest()`

#### Fonctions

##### _pep_440_key

**Param√®tres :**

- `s`

##### _match_prefix

**Param√®tres :**

- `x`
- `y`

##### _suggest_semantic_version

Try to suggest a semantic form for a version for which
_suggest_normalized_version couldn't come up with anything.

**Param√®tres :**

- `s`

##### _suggest_normalized_version

Suggest a normalized version close to the given version string.

If you have a version string that isn't rational (i.e. NormalizedVersion
doesn't like it) then you might be able to get an equivalent (or close)
rational version from this function.

This does a number of simple normalizations to the given string, based
on observation of versions currently in use on PyPI. Given a dump of
those version during PyCon 2009, 4287 of them:
- 2312 (53.93%) match NormalizedVersion without change
  with the automatic suggestion
- 3474 (81.04%) match when using this suggestion method

@param s {str} An irrational version string.
@returns A rational version string, or None, if couldn't determine one.

**Param√®tres :**

- `s`

##### _legacy_key

**Param√®tres :**

- `s`

##### is_semver

**Param√®tres :**

- `s`

##### _semantic_key

**Param√®tres :**

- `s`

##### get_scheme

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `s`

##### parse

**Param√®tres :**

- `s`

##### _check_compatible

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __lt__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __hash__

##### __repr__

##### __str__

##### is_prerelease

##### parse_requirement

**Param√®tres :**

- `s`

##### __init__

**Param√®tres :**

- `s`

##### match

Check if the provided version matches the constraints.

:param version: The version to match against this instance.
:type version: String or :class:`Version` instance.

**Param√®tres :**

- `version`

##### exact_version

##### _check_compatible

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __hash__

##### __repr__

##### __str__

##### parse

**Param√®tres :**

- `s`

##### is_prerelease

##### _adjust_local

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_lt

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_gt

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_le

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_ge

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_eq

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_arbitrary

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_ne

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### _match_compatible

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### get_parts

**Param√®tres :**

- `s`

##### parse

**Param√®tres :**

- `s`

##### is_prerelease

##### _match_compatible

**Param√®tres :**

- `version`
- `constraint`
- `prefix`

##### make_tuple

**Param√®tres :**

- `s`
- `absent`

##### parse

**Param√®tres :**

- `s`

##### is_prerelease

##### __init__

**Param√®tres :**

- `key`
- `matcher`
- `suggester`

##### is_valid_version

**Param√®tres :**

- `s`

##### is_valid_matcher

**Param√®tres :**

- `s`

##### is_valid_constraint_list

Used for processing some metadata fields

**Param√®tres :**

- `s`

##### suggest

**Param√®tres :**

- `s`

---

### wheel

#### Classes

##### Mounter

**M√©thodes :**

- `__init__()`
- `add()`
- `remove()`
- `find_module()`
- `load_module()`

##### Wheel

Class to build and install from Wheel files (PEP 427).

**M√©thodes :**

- `__init__()`
- `filename()`
- `exists()`
- `tags()`
- `metadata()`
- `get_wheel_metadata()`
- `info()`
- `process_shebang()`
- `get_hash()`
- `write_record()`
- `write_records()`
- `build_zip()`
- `build()`
- `skip_entry()`
- `install()`
- `_get_dylib_cache()`
- `_get_extensions()`
- `is_compatible()`
- `is_mountable()`
- `mount()`
- `unmount()`
- `verify()`
- `update()`

##### _Version

**M√©thodes :**

- `__init__()`
- `__str__()`

#### Fonctions

##### _get_suffixes

##### _load_dynamic

**Param√®tres :**

- `name`
- `path`

##### _get_glibc_version

##### compatible_tags

Return (pyver, abi, arch) tuples compatible with this Python.

##### is_compatible

**Param√®tres :**

- `wheel`
- `tags`

##### _derive_abi

##### __init__

##### add

**Param√®tres :**

- `pathname`
- `extensions`

##### remove

**Param√®tres :**

- `pathname`

##### find_module

**Param√®tres :**

- `fullname`
- `path`

##### load_module

**Param√®tres :**

- `fullname`

##### __init__

Initialise an instance using a (valid) filename.

**Param√®tres :**

- `filename`
- `sign`
- `verify`

##### filename

Build and return a filename from the various components.

##### exists

##### tags

##### metadata

##### get_wheel_metadata

**Param√®tres :**

- `zf`

##### info

##### process_shebang

**Param√®tres :**

- `data`

##### get_hash

**Param√®tres :**

- `data`
- `hash_kind`

##### write_record

**Param√®tres :**

- `records`
- `record_path`
- `archive_record_path`

##### write_records

**Param√®tres :**

- `info`
- `libdir`
- `archive_paths`

##### build_zip

**Param√®tres :**

- `pathname`
- `archive_paths`

##### build

Build a wheel from files in specified paths, and use any specified tags
when determining the name of the wheel.

**Param√®tres :**

- `paths`
- `tags`
- `wheel_version`

##### skip_entry

Determine whether an archive entry should be skipped when verifying
or installing.

**Param√®tres :**

- `arcname`

##### install

Install a wheel to the specified paths. If kwarg ``warner`` is
specified, it should be a callable, which will be called with two
tuples indicating the wheel version of this software and the wheel
version in the file, if there is a discrepancy in the versions.
This can be used to issue any warnings to raise any exceptions.
If kwarg ``lib_only`` is True, only the purelib/platlib files are
installed, and the headers, scripts, data and dist-info metadata are
not written. If kwarg ``bytecode_hashed_invalidation`` is True, written
bytecode will try to use file-hash based invalidation (PEP-552) on
supported interpreter versions (CPython 3.7+).

The return value is a :class:`InstalledDistribution` instance unless
``options.lib_only`` is True, in which case the return value is ``None``.

**Param√®tres :**

- `paths`
- `maker`

##### _get_dylib_cache

##### _get_extensions

##### is_compatible

Determine if a wheel is compatible with the running system.

##### is_mountable

Determine if a wheel is asserted as mountable by its metadata.

##### mount

**Param√®tres :**

- `append`

##### unmount

##### verify

##### update

Update the contents of a wheel in a generic way. The modifier should
be a callable which expects a dictionary argument: its keys are
archive-entry paths, and its values are absolute filesystem paths
where the contents the corresponding archive entries can be found. The
modifier is free to change the contents of the files pointed to, add
new entries and remove entries, before returning. This method will
extract the entire contents of the wheel to a temporary location, call
the modifier, and then use the passed (and possibly updated)
dictionary to write a new wheel. If ``dest_dir`` is specified, the new
wheel is written there -- otherwise, the original wheel is overwritten.

The modifier should return True if it updated the wheel, else False.
This method returns the same value the modifier returns.

**Param√®tres :**

- `modifier`
- `dest_dir`

##### sorter

**Param√®tres :**

- `t`

##### get_version

**Param√®tres :**

- `path_map`
- `info_dir`

##### update_version

**Param√®tres :**

- `version`
- `path`

##### __init__

**Param√®tres :**

- `major`
- `minor`

##### __str__

---

### .!23324!__init__

---

### .!23328!compat

---

### .!23333!database

---

### .!23336!index

---

### .!23340!locators

---

### .!23345!manifest

---

### .!23349!markers

---

### .!23355!metadata

---

### .!23360!resources

---

### .!23364!scripts

---

### .!23375!version

---

### .!23381!wheel

---

### __main__

---

### distro

The ``distro`` package (``distro`` stands for Linux Distribution) provides
information about the Linux distribution it runs on, such as a reliable
machine-readable distro ID, or version information.

It is the recommended replacement for Python's original
:py:func:`platform.linux_distribution` function, but it provides much more
functionality. An alternative implementation became necessary because Python
3.5 deprecated this function, and Python 3.8 removed it altogether. Its
predecessor function :py:func:`platform.dist` was already deprecated since
Python 2.6 and removed in Python 3.8. Still, there are many cases in which
access to OS distribution information is needed. See `Python issue 1322
<https://bugs.python.org/issue1322>`_ for more information.

#### Classes

##### VersionDict

##### InfoDict

##### LinuxDistribution

Provides information about a OS distribution.

This package creates a private module-global instance of this class with
default initialization arguments, that is used by the
`consolidated accessor functions`_ and `single source accessor functions`_.
By using default initialization arguments, that module-global instance
returns data about the current OS distribution (i.e. the distro this
package runs on).

Normally, it is not necessary to create additional instances of this class.
However, in situations where control is needed over the exact data sources
that are used, instances of this class can be created with a specific
distro release file, or a specific os-release file, or without invoking the
lsb_release command.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `linux_distribution()`
- `id()`
- `name()`
- `version()`
- `version_parts()`
- `major_version()`
- `minor_version()`
- `build_number()`
- `like()`
- `codename()`
- `info()`
- `os_release_info()`
- `lsb_release_info()`
- `distro_release_info()`
- `uname_info()`
- `oslevel_info()`
- `os_release_attr()`
- `lsb_release_attr()`
- `distro_release_attr()`
- `uname_attr()`
- `_os_release_info()`
- `_parse_os_release_content()`
- `_lsb_release_info()`
- `_parse_lsb_release_content()`
- `_uname_info()`
- `_oslevel_info()`
- `_debian_version()`
- `_parse_uname_content()`
- `_to_str()`
- `_distro_release_info()`
- `_parse_distro_release_file()`
- `_parse_distro_release_content()`

##### cached_property

A version of @property which caches the value.  On access, it calls the
underlying function and sets the value in `__dict__` so future accesses
will not re-call the property.

**M√©thodes :**

- `__init__()`
- `__get__()`

#### Fonctions

##### linux_distribution

.. deprecated:: 1.6.0

    :func:`distro.linux_distribution()` is deprecated. It should only be
    used as a compatibility shim with Python's
    :py:func:`platform.linux_distribution()`. Please use :func:`distro.id`,
    :func:`distro.version` and :func:`distro.name` instead.

Return information about the current OS distribution as a tuple
``(id_name, version, codename)`` with items as follows:

* ``id_name``:  If *full_distribution_name* is false, the result of
  :func:`distro.id`. Otherwise, the result of :func:`distro.name`.

* ``version``:  The result of :func:`distro.version`.

* ``codename``:  The extra item (usually in parentheses) after the
  os-release version number, or the result of :func:`distro.codename`.

The interface of this function is compatible with the original
:py:func:`platform.linux_distribution` function, supporting a subset of
its parameters.

The data it returns may not exactly be the same, because it uses more data
sources than the original function, and that may lead to different data if
the OS distribution is not consistent across multiple data sources it
provides (there are indeed such distributions ...).

Another reason for differences is the fact that the :func:`distro.id`
method normalizes the distro ID string to a reliable machine-readable value
for a number of popular OS distributions.

**Param√®tres :**

- `full_distribution_name`

##### id

Return the distro ID of the current distribution, as a
machine-readable string.

For a number of OS distributions, the returned distro ID value is
*reliable*, in the sense that it is documented and that it does not change
across releases of the distribution.

This package maintains the following reliable distro ID values:

==============  =========================================
Distro ID       Distribution
==============  =========================================
"ubuntu"        Ubuntu
"debian"        Debian
"rhel"          RedHat Enterprise Linux
"centos"        CentOS
"fedora"        Fedora
"sles"          SUSE Linux Enterprise Server
"opensuse"      openSUSE
"amzn"          Amazon Linux
"arch"          Arch Linux
"buildroot"     Buildroot
"cloudlinux"    CloudLinux OS
"exherbo"       Exherbo Linux
"gentoo"        GenToo Linux
"ibm_powerkvm"  IBM PowerKVM
"kvmibm"        KVM for IBM z Systems
"linuxmint"     Linux Mint
"mageia"        Mageia
"mandriva"      Mandriva Linux
"parallels"     Parallels
"pidora"        Pidora
"raspbian"      Raspbian
"oracle"        Oracle Linux (and Oracle Enterprise Linux)
"scientific"    Scientific Linux
"slackware"     Slackware
"xenserver"     XenServer
"openbsd"       OpenBSD
"netbsd"        NetBSD
"freebsd"       FreeBSD
"midnightbsd"   MidnightBSD
"rocky"         Rocky Linux
"aix"           AIX
"guix"          Guix System
"altlinux"      ALT Linux
==============  =========================================

If you have a need to get distros for reliable IDs added into this set,
or if you find that the :func:`distro.id` function returns a different
distro ID for one of the listed distros, please create an issue in the
`distro issue tracker`_.

**Lookup hierarchy and transformations:**

First, the ID is obtained from the following sources, in the specified
order. The first available and non-empty value is used:

* the value of the "ID" attribute of the os-release file,

* the value of the "Distributor ID" attribute returned by the lsb_release
  command,

* the first part of the file name of the distro release file,

The so determined ID value then passes the following transformations,
before it is returned by this method:

* it is translated to lower case,

* blanks (which should not be there anyway) are translated to underscores,

* a normalization of the ID is performed, based upon
  `normalization tables`_. The purpose of this normalization is to ensure
  that the ID is as reliable as possible, even across incompatible changes
  in the OS distributions. A common reason for an incompatible change is
  the addition of an os-release file, or the addition of the lsb_release
  command, with ID values that differ from what was previously determined
  from the distro release file name.

##### name

Return the name of the current OS distribution, as a human-readable
string.

If *pretty* is false, the name is returned without version or codename.
(e.g. "CentOS Linux")

If *pretty* is true, the version and codename are appended.
(e.g. "CentOS Linux 7.1.1503 (Core)")

**Lookup hierarchy:**

The name is obtained from the following sources, in the specified order.
The first available and non-empty value is used:

* If *pretty* is false:

  - the value of the "NAME" attribute of the os-release file,

  - the value of the "Distributor ID" attribute returned by the lsb_release
    command,

  - the value of the "<name>" field of the distro release file.

* If *pretty* is true:

  - the value of the "PRETTY_NAME" attribute of the os-release file,

  - the value of the "Description" attribute returned by the lsb_release
    command,

  - the value of the "<name>" field of the distro release file, appended
    with the value of the pretty version ("<version_id>" and "<codename>"
    fields) of the distro release file, if available.

**Param√®tres :**

- `pretty`

##### version

Return the version of the current OS distribution, as a human-readable
string.

If *pretty* is false, the version is returned without codename (e.g.
"7.0").

If *pretty* is true, the codename in parenthesis is appended, if the
codename is non-empty (e.g. "7.0 (Maipo)").

Some distributions provide version numbers with different precisions in
the different sources of distribution information. Examining the different
sources in a fixed priority order does not always yield the most precise
version (e.g. for Debian 8.2, or CentOS 7.1).

Some other distributions may not provide this kind of information. In these
cases, an empty string would be returned. This behavior can be observed
with rolling releases distributions (e.g. Arch Linux).

The *best* parameter can be used to control the approach for the returned
version:

If *best* is false, the first non-empty version number in priority order of
the examined sources is returned.

If *best* is true, the most precise version number out of all examined
sources is returned.

**Lookup hierarchy:**

In all cases, the version number is obtained from the following sources.
If *best* is false, this order represents the priority order:

* the value of the "VERSION_ID" attribute of the os-release file,
* the value of the "Release" attribute returned by the lsb_release
  command,
* the version number parsed from the "<version_id>" field of the first line
  of the distro release file,
* the version number parsed from the "PRETTY_NAME" attribute of the
  os-release file, if it follows the format of the distro release files.
* the version number parsed from the "Description" attribute returned by
  the lsb_release command, if it follows the format of the distro release
  files.

**Param√®tres :**

- `pretty`
- `best`

##### version_parts

Return the version of the current OS distribution as a tuple
``(major, minor, build_number)`` with items as follows:

* ``major``:  The result of :func:`distro.major_version`.

* ``minor``:  The result of :func:`distro.minor_version`.

* ``build_number``:  The result of :func:`distro.build_number`.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Param√®tres :**

- `best`

##### major_version

Return the major version of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The major version is the first
part of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Param√®tres :**

- `best`

##### minor_version

Return the minor version of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The minor version is the second
part of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Param√®tres :**

- `best`

##### build_number

Return the build number of the current OS distribution, as a string,
if provided.
Otherwise, the empty string is returned. The build number is the third part
of the dot-separated version string.

For a description of the *best* parameter, see the :func:`distro.version`
method.

**Param√®tres :**

- `best`

##### like

Return a space-separated list of distro IDs of distributions that are
closely related to the current OS distribution in regards to packaging
and programming interfaces, for example distributions the current
distribution is a derivative from.

**Lookup hierarchy:**

This information item is only provided by the os-release file.
For details, see the description of the "ID_LIKE" attribute in the
`os-release man page
<http://www.freedesktop.org/software/systemd/man/os-release.html>`_.

##### codename

Return the codename for the release of the current OS distribution,
as a string.

If the distribution does not have a codename, an empty string is returned.

Note that the returned codename is not always really a codename. For
example, openSUSE returns "x86_64". This function does not handle such
cases in any special way and just returns the string it finds, if any.

**Lookup hierarchy:**

* the codename within the "VERSION" attribute of the os-release file, if
  provided,

* the value of the "Codename" attribute returned by the lsb_release
  command,

* the value of the "<codename>" field of the distro release file.

##### info

Return certain machine-readable information items about the current OS
distribution in a dictionary, as shown in the following example:

.. sourcecode:: python

    {
        'id': 'rhel',
        'version': '7.0',
        'version_parts': {
            'major': '7',
            'minor': '0',
            'build_number': ''
        },
        'like': 'fedora',
        'codename': 'Maipo'
    }

The dictionary structure and keys are always the same, regardless of which
information items are available in the underlying data sources. The values
for the various keys are as follows:

* ``id``:  The result of :func:`distro.id`.

* ``version``:  The result of :func:`distro.version`.

* ``version_parts -> major``:  The result of :func:`distro.major_version`.

* ``version_parts -> minor``:  The result of :func:`distro.minor_version`.

* ``version_parts -> build_number``:  The result of
  :func:`distro.build_number`.

* ``like``:  The result of :func:`distro.like`.

* ``codename``:  The result of :func:`distro.codename`.

For a description of the *pretty* and *best* parameters, see the
:func:`distro.version` method.

**Param√®tres :**

- `pretty`
- `best`

##### os_release_info

Return a dictionary containing key-value pairs for the information items
from the os-release file data source of the current OS distribution.

See `os-release file`_ for details about these information items.

##### lsb_release_info

Return a dictionary containing key-value pairs for the information items
from the lsb_release command data source of the current OS distribution.

See `lsb_release command output`_ for details about these information
items.

##### distro_release_info

Return a dictionary containing key-value pairs for the information items
from the distro release file data source of the current OS distribution.

See `distro release file`_ for details about these information items.

##### uname_info

Return a dictionary containing key-value pairs for the information items
from the distro release file data source of the current OS distribution.

##### os_release_attr

Return a single named information item from the os-release file data source
of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
  The empty string, if the item does not exist.

See `os-release file`_ for details about these information items.

**Param√®tres :**

- `attribute`

##### lsb_release_attr

Return a single named information item from the lsb_release command output
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
  The empty string, if the item does not exist.

See `lsb_release command output`_ for details about these information
items.

**Param√®tres :**

- `attribute`

##### distro_release_attr

Return a single named information item from the distro release file
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
  The empty string, if the item does not exist.

See `distro release file`_ for details about these information items.

**Param√®tres :**

- `attribute`

##### uname_attr

Return a single named information item from the distro release file
data source of the current OS distribution.

Parameters:

* ``attribute`` (string): Key of the information item.

Returns:

* (string): Value of the information item, if the item exists.
            The empty string, if the item does not exist.

**Param√®tres :**

- `attribute`

##### main

##### __init__

The initialization method of this class gathers information from the
available data sources, and stores that in private instance attributes.
Subsequent access to the information items uses these private instance
attributes, so that the data sources are read only once.

Parameters:

* ``include_lsb`` (bool): Controls whether the
  `lsb_release command output`_ is included as a data source.

  If the lsb_release command is not available in the program execution
  path, the data source for the lsb_release command will be empty.

* ``os_release_file`` (string): The path name of the
  `os-release file`_ that is to be used as a data source.

  An empty string (the default) will cause the default path name to
  be used (see `os-release file`_ for details).

  If the specified or defaulted os-release file does not exist, the
  data source for the os-release file will be empty.

* ``distro_release_file`` (string): The path name of the
  `distro release file`_ that is to be used as a data source.

  An empty string (the default) will cause a default search algorithm
  to be used (see `distro release file`_ for details).

  If the specified distro release file does not exist, or if no default
  distro release file can be found, the data source for the distro
  release file will be empty.

* ``include_uname`` (bool): Controls whether uname command output is
  included as a data source. If the uname command is not available in
  the program execution path the data source for the uname command will
  be empty.

* ``root_dir`` (string): The absolute path to the root directory to use
  to find distro-related information files. Note that ``include_*``
  parameters must not be enabled in combination with ``root_dir``.

* ``include_oslevel`` (bool): Controls whether (AIX) oslevel command
  output is included as a data source. If the oslevel command is not
  available in the program execution path the data source will be
  empty.

Public instance attributes:

* ``os_release_file`` (string): The path name of the
  `os-release file`_ that is actually used as a data source. The
  empty string if no distro release file is used as a data source.

* ``distro_release_file`` (string): The path name of the
  `distro release file`_ that is actually used as a data source. The
  empty string if no distro release file is used as a data source.

* ``include_lsb`` (bool): The result of the ``include_lsb`` parameter.
  This controls whether the lsb information will be loaded.

* ``include_uname`` (bool): The result of the ``include_uname``
  parameter. This controls whether the uname information will
  be loaded.

* ``include_oslevel`` (bool): The result of the ``include_oslevel``
  parameter. This controls whether (AIX) oslevel information will be
  loaded.

* ``root_dir`` (string): The result of the ``root_dir`` parameter.
  The absolute path to the root directory to use to find distro-related
  information files.

Raises:

* :py:exc:`ValueError`: Initialization parameters combination is not
   supported.

* :py:exc:`OSError`: Some I/O issue with an os-release file or distro
  release file.

* :py:exc:`UnicodeError`: A data source has unexpected characters or
  uses an unexpected encoding.

**Param√®tres :**

- `include_lsb`
- `os_release_file`
- `distro_release_file`
- `include_uname`
- `root_dir`
- `include_oslevel`

##### __repr__

Return repr of all info

##### linux_distribution

Return information about the OS distribution that is compatible
with Python's :func:`platform.linux_distribution`, supporting a subset
of its parameters.

For details, see :func:`distro.linux_distribution`.

**Param√®tres :**

- `full_distribution_name`

##### id

Return the distro ID of the OS distribution, as a string.

For details, see :func:`distro.id`.

##### name

Return the name of the OS distribution, as a string.

For details, see :func:`distro.name`.

**Param√®tres :**

- `pretty`

##### version

Return the version of the OS distribution, as a string.

For details, see :func:`distro.version`.

**Param√®tres :**

- `pretty`
- `best`

##### version_parts

Return the version of the OS distribution, as a tuple of version
numbers.

For details, see :func:`distro.version_parts`.

**Param√®tres :**

- `best`

##### major_version

Return the major version number of the current distribution.

For details, see :func:`distro.major_version`.

**Param√®tres :**

- `best`

##### minor_version

Return the minor version number of the current distribution.

For details, see :func:`distro.minor_version`.

**Param√®tres :**

- `best`

##### build_number

Return the build number of the current distribution.

For details, see :func:`distro.build_number`.

**Param√®tres :**

- `best`

##### like

Return the IDs of distributions that are like the OS distribution.

For details, see :func:`distro.like`.

##### codename

Return the codename of the OS distribution.

For details, see :func:`distro.codename`.

##### info

Return certain machine-readable information about the OS
distribution.

For details, see :func:`distro.info`.

**Param√®tres :**

- `pretty`
- `best`

##### os_release_info

Return a dictionary containing key-value pairs for the information
items from the os-release file data source of the OS distribution.

For details, see :func:`distro.os_release_info`.

##### lsb_release_info

Return a dictionary containing key-value pairs for the information
items from the lsb_release command data source of the OS
distribution.

For details, see :func:`distro.lsb_release_info`.

##### distro_release_info

Return a dictionary containing key-value pairs for the information
items from the distro release file data source of the OS
distribution.

For details, see :func:`distro.distro_release_info`.

##### uname_info

Return a dictionary containing key-value pairs for the information
items from the uname command data source of the OS distribution.

For details, see :func:`distro.uname_info`.

##### oslevel_info

Return AIX' oslevel command output.

##### os_release_attr

Return a single named information item from the os-release file data
source of the OS distribution.

For details, see :func:`distro.os_release_attr`.

**Param√®tres :**

- `attribute`

##### lsb_release_attr

Return a single named information item from the lsb_release command
output data source of the OS distribution.

For details, see :func:`distro.lsb_release_attr`.

**Param√®tres :**

- `attribute`

##### distro_release_attr

Return a single named information item from the distro release file
data source of the OS distribution.

For details, see :func:`distro.distro_release_attr`.

**Param√®tres :**

- `attribute`

##### uname_attr

Return a single named information item from the uname command
output data source of the OS distribution.

For details, see :func:`distro.uname_attr`.

**Param√®tres :**

- `attribute`

##### _os_release_info

Get the information items from the specified os-release file.

Returns:
    A dictionary containing all information items.

##### _parse_os_release_content

Parse the lines of an os-release file.

Parameters:

* lines: Iterable through the lines in the os-release file.
         Each line must be a unicode string or a UTF-8 encoded byte
         string.

Returns:
    A dictionary containing all information items.

**Param√®tres :**

- `lines`

##### _lsb_release_info

Get the information items from the lsb_release command output.

Returns:
    A dictionary containing all information items.

##### _parse_lsb_release_content

Parse the output of the lsb_release command.

Parameters:

* lines: Iterable through the lines of the lsb_release output.
         Each line must be a unicode string or a UTF-8 encoded byte
         string.

Returns:
    A dictionary containing all information items.

**Param√®tres :**

- `lines`

##### _uname_info

##### _oslevel_info

##### _debian_version

##### _parse_uname_content

**Param√®tres :**

- `lines`

##### _to_str

**Param√®tres :**

- `bytestring`

##### _distro_release_info

Get the information items from the specified distro release file.

Returns:
    A dictionary containing all information items.

##### _parse_distro_release_file

Parse a distro release file.

Parameters:

* filepath: Path name of the distro release file.

Returns:
    A dictionary containing all information items.

**Param√®tres :**

- `filepath`

##### _parse_distro_release_content

Parse a line from a distro release file.

Parameters:
* line: Line from the distro release file. Must be a unicode string
        or a UTF-8 encoded byte string.

Returns:
    A dictionary containing all information items.

**Param√®tres :**

- `line`

##### normalize

**Param√®tres :**

- `distro_id`
- `table`

##### __init__

**Param√®tres :**

- `f`

##### __get__

**Param√®tres :**

- `obj`
- `owner`

---

### .!23385!__init__

---

### .!23390!__main__

---

### .!23395!distro

---

### codec

#### Classes

##### Codec

**M√©thodes :**

- `encode()`
- `decode()`

##### IncrementalEncoder

**M√©thodes :**

- `_buffer_encode()`

##### IncrementalDecoder

**M√©thodes :**

- `_buffer_decode()`

##### StreamWriter

##### StreamReader

#### Fonctions

##### search_function

**Param√®tres :**

- `name`

##### encode

**Param√®tres :**

- `data`
- `errors`

##### decode

**Param√®tres :**

- `data`
- `errors`

##### _buffer_encode

**Param√®tres :**

- `data`
- `errors`
- `final`

##### _buffer_decode

**Param√®tres :**

- `data`
- `errors`
- `final`

---

### compat

#### Fonctions

##### ToASCII

**Param√®tres :**

- `label`

##### ToUnicode

**Param√®tres :**

- `label`

##### nameprep

**Param√®tres :**

- `s`

---

### .!23414!core

---

### core

#### Classes

##### IDNAError

Base exception for all IDNA-encoding related problems

##### IDNABidiError

Exception when bidirectional requirements are not satisfied

##### InvalidCodepoint

Exception when a disallowed or unallocated codepoint is used

##### InvalidCodepointContext

Exception when the codepoint is not valid in the context it is used

#### Fonctions

##### _combining_class

**Param√®tres :**

- `cp`

##### _is_script

**Param√®tres :**

- `cp`
- `script`

##### _punycode

**Param√®tres :**

- `s`

##### _unot

**Param√®tres :**

- `s`

##### valid_label_length

**Param√®tres :**

- `label`

##### valid_string_length

**Param√®tres :**

- `label`
- `trailing_dot`

##### check_bidi

**Param√®tres :**

- `label`
- `check_ltr`

##### check_initial_combiner

**Param√®tres :**

- `label`

##### check_hyphen_ok

**Param√®tres :**

- `label`

##### check_nfc

**Param√®tres :**

- `label`

##### valid_contextj

**Param√®tres :**

- `label`
- `pos`

##### valid_contexto

**Param√®tres :**

- `label`
- `pos`
- `exception`

##### check_label

**Param√®tres :**

- `label`

##### alabel

**Param√®tres :**

- `label`

##### ulabel

**Param√®tres :**

- `label`

##### uts46_remap

Re-map the characters in the string according to UTS46 processing.

**Param√®tres :**

- `domain`
- `std3_rules`
- `transitional`

##### encode

**Param√®tres :**

- `s`
- `strict`
- `uts46`
- `std3_rules`
- `transitional`

##### decode

**Param√®tres :**

- `s`
- `strict`
- `uts46`
- `std3_rules`

---

### idnadata

---

### intranges

Given a list of integers, made up of (hopefully) a small number of long runs
of consecutive integers, compute a representation of the form
((start1, end1), (start2, end2) ...). Then answer the question "was x present
in the original list?" in time O(log(# runs)).

#### Fonctions

##### intranges_from_list

Represent a list of integers as a sequence of ranges:
((start_0, end_0), (start_1, end_1), ...), such that the original
integers are exactly those x such that start_i <= x < end_i for some i.

Ranges are encoded as single integers (start << 32 | end), not as tuples.

**Param√®tres :**

- `list_`

##### _encode_range

**Param√®tres :**

- `start`
- `end`

##### _decode_range

**Param√®tres :**

- `r`

##### intranges_contain

Determine if `int_` falls into one of the ranges in `ranges`.

**Param√®tres :**

- `int_`
- `ranges`

---

### package_data

---

### uts46data

#### Fonctions

##### _seg_0

##### _seg_1

##### _seg_2

##### _seg_3

##### _seg_4

##### _seg_5

##### _seg_6

##### _seg_7

##### _seg_8

##### _seg_9

##### _seg_10

##### _seg_11

##### _seg_12

##### _seg_13

##### _seg_14

##### _seg_15

##### _seg_16

##### _seg_17

##### _seg_18

##### _seg_19

##### _seg_20

##### _seg_21

##### _seg_22

##### _seg_23

##### _seg_24

##### _seg_25

##### _seg_26

##### _seg_27

##### _seg_28

##### _seg_29

##### _seg_30

##### _seg_31

##### _seg_32

##### _seg_33

##### _seg_34

##### _seg_35

##### _seg_36

##### _seg_37

##### _seg_38

##### _seg_39

##### _seg_40

##### _seg_41

##### _seg_42

##### _seg_43

##### _seg_44

##### _seg_45

##### _seg_46

##### _seg_47

##### _seg_48

##### _seg_49

##### _seg_50

##### _seg_51

##### _seg_52

##### _seg_53

##### _seg_54

##### _seg_55

##### _seg_56

##### _seg_57

##### _seg_58

##### _seg_59

##### _seg_60

##### _seg_61

##### _seg_62

##### _seg_63

##### _seg_64

##### _seg_65

##### _seg_66

##### _seg_67

##### _seg_68

##### _seg_69

##### _seg_70

##### _seg_71

##### _seg_72

##### _seg_73

##### _seg_74

##### _seg_75

##### _seg_76

##### _seg_77

##### _seg_78

##### _seg_79

##### _seg_80

##### _seg_81

---

### .!23402!__init__

---

### .!23407!codec

---

### .!23413!compat

---

### .!23421!idnadata

---

### .!23426!intranges

---

### .!23430!package_data

---

### .!23434!uts46data

---

### exceptions

#### Classes

##### UnpackException

Base class for some exceptions raised while unpacking.

NOTE: unpack may raise exception other than subclass of
UnpackException.  If you want to catch all error, catch
Exception instead.

##### BufferFull

##### OutOfData

##### FormatError

Invalid msgpack format

##### StackError

Too nested

##### ExtraData

ExtraData is raised when there is trailing data.

This exception is raised while only one-shot (not streaming)
unpack.

**M√©thodes :**

- `__init__()`
- `__str__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `unpacked`
- `extra`

##### __str__

---

### ext

#### Classes

##### ExtType

ExtType represents ext type in msgpack.

**M√©thodes :**

- `__new__()`

##### Timestamp

Timestamp represents the Timestamp extension type in msgpack.

When built with Cython, msgpack uses C methods to pack and unpack `Timestamp`.
When using pure-Python msgpack, :func:`to_bytes` and :func:`from_bytes` are used to pack and
unpack `Timestamp`.

This class is immutable: Do not override seconds and nanoseconds.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__eq__()`
- `__ne__()`
- `__hash__()`
- `from_bytes()`
- `to_bytes()`
- `from_unix()`
- `to_unix()`
- `from_unix_nano()`
- `to_unix_nano()`
- `to_datetime()`
- `from_datetime()`

#### Fonctions

##### __new__

**Param√®tres :**

- `cls`
- `code`
- `data`

##### __init__

Initialize a Timestamp object.

:param int seconds:
    Number of seconds since the UNIX epoch (00:00:00 UTC Jan 1 1970, minus leap seconds).
    May be negative.

:param int nanoseconds:
    Number of nanoseconds to add to `seconds` to get fractional time.
    Maximum is 999_999_999.  Default is 0.

Note: Negative times (before the UNIX epoch) are represented as neg. seconds + pos. ns.

**Param√®tres :**

- `seconds`
- `nanoseconds`

##### __repr__

String representation of Timestamp.

##### __eq__

Check for equality with another Timestamp object

**Param√®tres :**

- `other`

##### __ne__

not-equals method (see :func:`__eq__()`)

**Param√®tres :**

- `other`

##### __hash__

##### from_bytes

Unpack bytes into a `Timestamp` object.

Used for pure-Python msgpack unpacking.

:param b: Payload from msgpack ext message with code -1
:type b: bytes

:returns: Timestamp object unpacked from msgpack ext payload
:rtype: Timestamp

**Param√®tres :**

- `b`

##### to_bytes

Pack this Timestamp object into bytes.

Used for pure-Python msgpack packing.

:returns data: Payload for EXT message with code -1 (timestamp type)
:rtype: bytes

##### from_unix

Create a Timestamp from posix timestamp in seconds.

:param unix_float: Posix timestamp in seconds.
:type unix_float: int or float

**Param√®tres :**

- `unix_sec`

##### to_unix

Get the timestamp as a floating-point value.

:returns: posix timestamp
:rtype: float

##### from_unix_nano

Create a Timestamp from posix timestamp in nanoseconds.

:param int unix_ns: Posix timestamp in nanoseconds.
:rtype: Timestamp

**Param√®tres :**

- `unix_ns`

##### to_unix_nano

Get the timestamp as a unixtime in nanoseconds.

:returns: posix timestamp in nanoseconds
:rtype: int

##### to_datetime

Get the timestamp as a UTC datetime.

:rtype: `datetime.datetime`

##### from_datetime

Create a Timestamp from datetime with tzinfo.

:rtype: Timestamp

**Param√®tres :**

- `dt`

---

### .!23450!ext

---

### fallback

Fallback pure Python implementation of msgpack

#### Classes

##### Unpacker

Streaming unpacker.

Arguments:

:param file_like:
    File-like object having `.read(n)` method.
    If specified, unpacker reads serialized data from it and `.feed()` is not usable.

:param int read_size:
    Used as `file_like.read(read_size)`. (default: `min(16*1024, max_buffer_size)`)

:param bool use_list:
    If true, unpack msgpack array to Python list.
    Otherwise, unpack to Python tuple. (default: True)

:param bool raw:
    If true, unpack msgpack raw to Python bytes.
    Otherwise, unpack to Python str by decoding with UTF-8 encoding (default).

:param int timestamp:
    Control how timestamp type is unpacked:

        0 - Timestamp
        1 - float  (Seconds from the EPOCH)
        2 - int  (Nanoseconds from the EPOCH)
        3 - datetime.datetime  (UTC).

:param bool strict_map_key:
    If true (default), only str or bytes are accepted for map (dict) keys.

:param object_hook:
    When specified, it should be callable.
    Unpacker calls it with a dict argument after unpacking msgpack map.
    (See also simplejson)

:param object_pairs_hook:
    When specified, it should be callable.
    Unpacker calls it with a list of key-value pairs after unpacking msgpack map.
    (See also simplejson)

:param str unicode_errors:
    The error handler for decoding unicode. (default: 'strict')
    This option should be used only when you have msgpack data which
    contains invalid UTF-8 string.

:param int max_buffer_size:
    Limits size of data waiting unpacked.  0 means 2**32-1.
    The default value is 100*1024*1024 (100MiB).
    Raises `BufferFull` exception when it is insufficient.
    You should set this parameter when unpacking data from untrusted source.

:param int max_str_len:
    Deprecated, use *max_buffer_size* instead.
    Limits max length of str. (default: max_buffer_size)

:param int max_bin_len:
    Deprecated, use *max_buffer_size* instead.
    Limits max length of bin. (default: max_buffer_size)

:param int max_array_len:
    Limits max length of array.
    (default: max_buffer_size)

:param int max_map_len:
    Limits max length of map.
    (default: max_buffer_size//2)

:param int max_ext_len:
    Deprecated, use *max_buffer_size* instead.
    Limits max size of ext type.  (default: max_buffer_size)

Example of streaming deserialize from file-like object::

    unpacker = Unpacker(file_like)
    for o in unpacker:
        process(o)

Example of streaming deserialize from socket::

    unpacker = Unpacker()
    while True:
        buf = sock.recv(1024**2)
        if not buf:
            break
        unpacker.feed(buf)
        for o in unpacker:
            process(o)

Raises ``ExtraData`` when *packed* contains extra bytes.
Raises ``OutOfData`` when *packed* is incomplete.
Raises ``FormatError`` when *packed* is not valid msgpack.
Raises ``StackError`` when *packed* contains too nested.
Other exceptions can be raised during unpacking.

**M√©thodes :**

- `__init__()`
- `feed()`
- `_consume()`
- `_got_extradata()`
- `_get_extradata()`
- `read_bytes()`
- `_read()`
- `_reserve()`
- `_read_header()`
- `_unpack()`
- `__iter__()`
- `__next__()`
- `skip()`
- `unpack()`
- `read_array_header()`
- `read_map_header()`
- `tell()`

##### Packer

MessagePack Packer

Usage::

    packer = Packer()
    astream.write(packer.pack(a))
    astream.write(packer.pack(b))

Packer's constructor has some keyword arguments:

:param default:
    When specified, it should be callable.
    Convert user type to builtin type that Packer supports.
    See also simplejson's document.

:param bool use_single_float:
    Use single precision float type for float. (default: False)

:param bool autoreset:
    Reset buffer after each pack and return its content as `bytes`. (default: True).
    If set this to false, use `bytes()` to get content and `.reset()` to clear buffer.

:param bool use_bin_type:
    Use bin type introduced in msgpack spec 2.0 for bytes.
    It also enables str8 type for unicode. (default: True)

:param bool strict_types:
    If set to true, types will be checked to be exact. Derived classes
    from serializable types will not be serialized and will be
    treated as unsupported type and forwarded to default.
    Additionally tuples will not be serialized as lists.
    This is useful when trying to implement accurate serialization
    for python types.

:param bool datetime:
    If set to true, datetime with tzinfo is packed into Timestamp type.
    Note that the tzinfo is stripped in the timestamp.
    You can get UTC datetime with `timestamp=3` option of the Unpacker.

:param str unicode_errors:
    The error handler for encoding unicode. (default: 'strict')
    DO NOT USE THIS!!  This option is kept for very specific usage.

:param int buf_size:
    Internal buffer size. This option is used only for C implementation.

**M√©thodes :**

- `__init__()`
- `_pack()`
- `pack()`
- `pack_map_pairs()`
- `pack_array_header()`
- `pack_map_header()`
- `pack_ext_type()`
- `_pack_array_header()`
- `_pack_map_header()`
- `_pack_map_pairs()`
- `_pack_raw_header()`
- `_pack_bin_header()`
- `bytes()`
- `reset()`
- `getbuffer()`

##### BytesIO

**M√©thodes :**

- `__init__()`
- `write()`
- `getvalue()`

#### Fonctions

##### _check_type_strict

**Param√®tres :**

- `obj`
- `t`
- `type`
- `tuple`

##### _get_data_from_buffer

**Param√®tres :**

- `obj`

##### unpackb

Unpack an object from `packed`.

Raises ``ExtraData`` when *packed* contains extra bytes.
Raises ``ValueError`` when *packed* is incomplete.
Raises ``FormatError`` when *packed* is not valid msgpack.
Raises ``StackError`` when *packed* contains too nested.
Other exceptions can be raised during unpacking.

See :class:`Unpacker` for options.

**Param√®tres :**

- `packed`

##### newlist_hint

**Param√®tres :**

- `size`

##### __init__

**Param√®tres :**

- `file_like`

##### feed

**Param√®tres :**

- `next_bytes`

##### _consume

Gets rid of the used parts of the buffer.

##### _got_extradata

##### _get_extradata

##### read_bytes

**Param√®tres :**

- `n`

##### _read

**Param√®tres :**

- `n`
- `raise_outofdata`

##### _reserve

**Param√®tres :**

- `n`
- `raise_outofdata`

##### _read_header

##### _unpack

**Param√®tres :**

- `execute`

##### __iter__

##### __next__

##### skip

##### unpack

##### read_array_header

##### read_map_header

##### tell

##### __init__

##### _pack

**Param√®tres :**

- `obj`
- `nest_limit`
- `check`
- `check_type_strict`

##### pack

**Param√®tres :**

- `obj`

##### pack_map_pairs

**Param√®tres :**

- `pairs`

##### pack_array_header

**Param√®tres :**

- `n`

##### pack_map_header

**Param√®tres :**

- `n`

##### pack_ext_type

**Param√®tres :**

- `typecode`
- `data`

##### _pack_array_header

**Param√®tres :**

- `n`

##### _pack_map_header

**Param√®tres :**

- `n`

##### _pack_map_pairs

**Param√®tres :**

- `n`
- `pairs`
- `nest_limit`

##### _pack_raw_header

**Param√®tres :**

- `n`

##### _pack_bin_header

**Param√®tres :**

- `n`

##### bytes

Return internal buffer contents as bytes object

##### reset

Reset internal buffer.

This method is useful only when autoreset=False.

##### getbuffer

Return view of internal buffer.

##### __init__

**Param√®tres :**

- `s`

##### write

**Param√®tres :**

- `s`

##### getvalue

---

### .!23439!__init__

---

### .!23445!exceptions

---

### .!23454!fallback

---

### _elffile

ELF file parser.

This provides a class ``ELFFile`` that parses an ELF executable in a similar
interface to ``ZipFile``. Only the read interface is implemented.

Based on: https://gist.github.com/lyssdod/f51579ae8d93c8657a5564aefc2ffbca
ELF header: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html

#### Classes

##### ELFInvalid

##### EIClass

##### EIData

##### EMachine

##### ELFFile

Representation of an ELF executable.

**M√©thodes :**

- `__init__()`
- `_read()`
- `interpreter()`

#### Fonctions

##### __init__

**Param√®tres :**

- `f`

##### _read

**Param√®tres :**

- `fmt`

##### interpreter

The path recorded in the ``PT_INTERP`` section header.

---

### _manylinux

#### Classes

##### _GLibCVersion

#### Fonctions

##### _parse_elf

**Param√®tres :**

- `path`

##### _is_linux_armhf

**Param√®tres :**

- `executable`

##### _is_linux_i686

**Param√®tres :**

- `executable`

##### _have_compatible_abi

**Param√®tres :**

- `executable`
- `archs`

##### _glibc_version_string_confstr

Primary implementation of glibc_version_string using os.confstr.

##### _glibc_version_string_ctypes

Fallback implementation of glibc_version_string using ctypes.

##### _glibc_version_string

Returns glibc version string, or None if not using glibc.

##### _parse_glibc_version

Parse glibc version.

We use a regexp instead of str.split because we want to discard any
random junk that might come after the minor version -- this might happen
in patched/forked versions of glibc (e.g. Linaro's version of glibc
uses version strings like "2.20-2014.11"). See gh-3588.

**Param√®tres :**

- `version_str`

##### _get_glibc_version

##### _is_compatible

**Param√®tres :**

- `arch`
- `version`

##### platform_tags

Generate manylinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
    The first one shall be the closest to the actual architecture and be the part of
    platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
    The ``linux_`` prefix is assumed as a prerequisite for the current platform to
    be manylinux-compatible.

:returns: An iterator of compatible manylinux tags.

**Param√®tres :**

- `archs`

---

### .!23512!tags

---

### _musllinux

PEP 656 support.

This module implements logic to detect if the currently running Python is
linked against musl, and what musl version is used.

#### Classes

##### _MuslVersion

#### Fonctions

##### _parse_musl_version

**Param√®tres :**

- `output`

##### _get_musl_version

Detect currently-running musl runtime version.

This is done by checking the specified executable's dynamic linking
information, and invoking the loader to parse its output for a version
string. If the loader is musl, the output would be something like::

    musl libc (x86_64)
    Version 1.2.2
    Dynamic Program Loader

**Param√®tres :**

- `executable`

##### platform_tags

Generate musllinux tags compatible to the current platform.

:param archs: Sequence of compatible architectures.
    The first one shall be the closest to the actual architecture and be the part of
    platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
    The ``linux_`` prefix is assumed as a prerequisite for the current platform to
    be musllinux-compatible.

:returns: An iterator of compatible musllinux tags.

**Param√®tres :**

- `archs`

---

### _parser

Handwritten parser of dependency specifiers.

The docstring for each __parse_* function contains EBNF-inspired grammar representing
the implementation.

#### Classes

##### Node

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `serialize()`

##### Variable

**M√©thodes :**

- `serialize()`

##### Value

**M√©thodes :**

- `serialize()`

##### Op

**M√©thodes :**

- `serialize()`

##### ParsedRequirement

#### Fonctions

##### parse_requirement

**Param√®tres :**

- `source`

##### _parse_requirement

requirement = WS? IDENTIFIER WS? extras WS? requirement_details

**Param√®tres :**

- `tokenizer`

##### _parse_requirement_details

requirement_details = AT URL (WS requirement_marker?)?
                    | specifier WS? (requirement_marker)?

**Param√®tres :**

- `tokenizer`

##### _parse_requirement_marker

requirement_marker = SEMICOLON marker WS?

**Param√®tres :**

- `tokenizer`

##### _parse_extras

extras = (LEFT_BRACKET wsp* extras_list? wsp* RIGHT_BRACKET)?

**Param√®tres :**

- `tokenizer`

##### _parse_extras_list

extras_list = identifier (wsp* ',' wsp* identifier)*

**Param√®tres :**

- `tokenizer`

##### _parse_specifier

specifier = LEFT_PARENTHESIS WS? version_many WS? RIGHT_PARENTHESIS
          | WS? version_many WS?

**Param√®tres :**

- `tokenizer`

##### _parse_version_many

version_many = (SPECIFIER (WS? COMMA WS? SPECIFIER)*)?

**Param√®tres :**

- `tokenizer`

##### parse_marker

**Param√®tres :**

- `source`

##### _parse_full_marker

**Param√®tres :**

- `tokenizer`

##### _parse_marker

marker = marker_atom (BOOLOP marker_atom)+

**Param√®tres :**

- `tokenizer`

##### _parse_marker_atom

marker_atom = WS? LEFT_PARENTHESIS WS? marker WS? RIGHT_PARENTHESIS WS?
            | WS? marker_item WS?

**Param√®tres :**

- `tokenizer`

##### _parse_marker_item

marker_item = WS? marker_var WS? marker_op WS? marker_var WS?

**Param√®tres :**

- `tokenizer`

##### _parse_marker_var

marker_var = VARIABLE | QUOTED_STRING

**Param√®tres :**

- `tokenizer`

##### process_env_var

**Param√®tres :**

- `env_var`

##### process_python_str

**Param√®tres :**

- `python_str`

##### _parse_marker_op

marker_op = IN | NOT IN | OP

**Param√®tres :**

- `tokenizer`

##### __init__

**Param√®tres :**

- `value`

##### __str__

##### __repr__

##### serialize

##### serialize

##### serialize

##### serialize

---

### _structures

#### Classes

##### InfinityType

**M√©thodes :**

- `__repr__()`
- `__hash__()`
- `__lt__()`
- `__le__()`
- `__eq__()`
- `__gt__()`
- `__ge__()`
- `__neg__()`

##### NegativeInfinityType

**M√©thodes :**

- `__repr__()`
- `__hash__()`
- `__lt__()`
- `__le__()`
- `__eq__()`
- `__gt__()`
- `__ge__()`
- `__neg__()`

#### Fonctions

##### __repr__

##### __hash__

##### __lt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __neg__

##### __repr__

##### __hash__

##### __lt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __neg__

---

### _tokenizer

#### Classes

##### Token

##### ParserSyntaxError

The provided source text could not be parsed correctly.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### Tokenizer

Context-sensitive token parsing.

Provides methods to examine the input stream to check whether the next token
matches.

**M√©thodes :**

- `__init__()`
- `consume()`
- `check()`
- `expect()`
- `read()`
- `raise_syntax_error()`
- `enclosing_tokens()`

#### Fonctions

##### __init__

**Param√®tres :**

- `message`

##### __str__

##### __init__

**Param√®tres :**

- `source`

##### consume

Move beyond provided token name, if at current position.

**Param√®tres :**

- `name`

##### check

Check whether the next token has the provided name.

By default, if the check succeeds, the token *must* be read before
another check. If `peek` is set to `True`, the token is not loaded and
would need to be checked again.

**Param√®tres :**

- `name`

##### expect

Expect a certain token name next, failing with a syntax error otherwise.

The token is *not* read.

**Param√®tres :**

- `name`

##### read

Consume the next token and return it.

##### raise_syntax_error

Raise ParserSyntaxError at the given position.

**Param√®tres :**

- `message`

##### enclosing_tokens

**Param√®tres :**

- `open_token`
- `close_token`

---

### markers

#### Classes

##### InvalidMarker

An invalid marker was found, users should refer to PEP 508.

##### UndefinedComparison

An invalid operation was attempted on a value that doesn't support it.

##### UndefinedEnvironmentName

A name was attempted to be used that does not exist inside of the
environment.

##### Environment

##### Marker

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`
- `evaluate()`

#### Fonctions

##### _normalize_extra_values

Normalize extra values.

**Param√®tres :**

- `results`

##### _format_marker

**Param√®tres :**

- `marker`
- `first`

##### _eval_op

**Param√®tres :**

- `lhs`
- `op`
- `rhs`

##### _normalize

**Param√®tres :**

- `lhs`
- `rhs`
- `key`

##### _evaluate_markers

**Param√®tres :**

- `markers`
- `environment`

##### format_full_version

**Param√®tres :**

- `info`

##### default_environment

##### _repair_python_full_version

Work around platform.python_version() returning something that is not PEP 440
compliant for non-tagged Python builds.

**Param√®tres :**

- `env`

##### __init__

**Param√®tres :**

- `marker`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### evaluate

Evaluate a marker.

Return the boolean from evaluating the given marker against the
environment. environment is an optional argument to override all or
part of the determined environment. The *context* parameter specifies what
context the markers are being evaluated for, which influences what markers
are considered valid. Acceptable values are "metadata" (for core metadata;
default), "lock_file", and "requirement" (i.e. all other situations).

The environment is determined from the current Python process.

**Param√®tres :**

- `environment`
- `context`

---

### metadata

#### Classes

##### InvalidMetadata

A metadata field contains invalid data.

**M√©thodes :**

- `__init__()`

##### RawMetadata

A dictionary of raw core metadata.

Each field in core metadata maps to a key of this dictionary (when data is
provided). The key is lower-case and underscores are used instead of dashes
compared to the equivalent core metadata field. Any core metadata field that
can be specified multiple times or can hold multiple values in a single
field have a key with a plural name. See :class:`Metadata` whose attributes
match the keys of this dictionary.

Core metadata fields that can be specified multiple times are stored as a
list or dict depending on which is appropriate for the field. Any fields
which hold multiple values in a single field are stored as a list.

##### _Validator

Validate a metadata field.

All _process_*() methods correspond to a core metadata field. The method is
called with the field's raw value. If the raw value is valid it is returned
in its "enriched" form (e.g. ``version.Version`` for the ``Version`` field).
If the raw value is invalid, :exc:`InvalidMetadata` is raised (with a cause
as appropriate).

**M√©thodes :**

- `__init__()`
- `__set_name__()`
- `__get__()`
- `_invalid_metadata()`
- `_process_metadata_version()`
- `_process_name()`
- `_process_version()`
- `_process_summary()`
- `_process_description_content_type()`
- `_process_dynamic()`
- `_process_provides_extra()`
- `_process_requires_python()`
- `_process_requires_dist()`
- `_process_license_expression()`
- `_process_license_files()`

##### Metadata

Representation of distribution metadata.

Compared to :class:`RawMetadata`, this class provides objects representing
metadata fields instead of only using built-in types. Any invalid metadata
will cause :exc:`InvalidMetadata` to be raised (with a
:py:attr:`~BaseException.__cause__` attribute as appropriate).

**M√©thodes :**

- `from_raw()`
- `from_email()`

##### ExceptionGroup

A minimal implementation of :external:exc:`ExceptionGroup` from Python 3.11.

If :external:exc:`ExceptionGroup` is already defined by Python itself,
that version is used instead.

**M√©thodes :**

- `__init__()`
- `__repr__()`

#### Fonctions

##### _parse_keywords

Split a string of comma-separated keywords into a list of keywords.

**Param√®tres :**

- `data`

##### _parse_project_urls

Parse a list of label/URL string pairings separated by a comma.

**Param√®tres :**

- `data`

##### _get_payload

Get the body of the message.

**Param√®tres :**

- `msg`
- `source`

##### parse_email

Parse a distribution's metadata stored as email headers (e.g. from ``METADATA``).

This function returns a two-item tuple of dicts. The first dict is of
recognized fields from the core metadata specification. Fields that can be
parsed and translated into Python's built-in types are converted
appropriately. All other fields are left as-is. Fields that are allowed to
appear multiple times are stored as lists.

The second dict contains all other fields from the metadata. This includes
any unrecognized fields. It also includes any fields which are expected to
be parsed into a built-in type but were not formatted appropriately. Finally,
any fields that are expected to appear only once but are repeated are
included in this dict.

**Param√®tres :**

- `data`

##### __init__

**Param√®tres :**

- `field`
- `message`

##### __init__

##### __set_name__

**Param√®tres :**

- `_owner`
- `name`

##### __get__

**Param√®tres :**

- `instance`
- `_owner`

##### _invalid_metadata

**Param√®tres :**

- `msg`
- `cause`

##### _process_metadata_version

**Param√®tres :**

- `value`

##### _process_name

**Param√®tres :**

- `value`

##### _process_version

**Param√®tres :**

- `value`

##### _process_summary

Check the field contains no newlines.

**Param√®tres :**

- `value`

##### _process_description_content_type

**Param√®tres :**

- `value`

##### _process_dynamic

**Param√®tres :**

- `value`

##### _process_provides_extra

**Param√®tres :**

- `value`

##### _process_requires_python

**Param√®tres :**

- `value`

##### _process_requires_dist

**Param√®tres :**

- `value`

##### _process_license_expression

**Param√®tres :**

- `value`

##### _process_license_files

**Param√®tres :**

- `value`

##### from_raw

Create an instance from :class:`RawMetadata`.

If *validate* is true, all metadata will be validated. All exceptions
related to validation will be gathered and raised as an :class:`ExceptionGroup`.

**Param√®tres :**

- `cls`
- `data`

##### from_email

Parse metadata from email headers.

If *validate* is true, the metadata will be validated. All exceptions
related to validation will be gathered and raised as an :class:`ExceptionGroup`.

**Param√®tres :**

- `cls`
- `data`

##### __init__

**Param√®tres :**

- `message`
- `exceptions`

##### __repr__

---

### requirements

#### Classes

##### InvalidRequirement

An invalid requirement was found, users should refer to PEP 508.

##### Requirement

Parse a requirement.

Parse a given requirement string into its parts, such as name, specifier,
URL, and extras. Raises InvalidRequirement on a badly-formed requirement
string.

**M√©thodes :**

- `__init__()`
- `_iter_parts()`
- `__str__()`
- `__repr__()`
- `__hash__()`
- `__eq__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `requirement_string`

##### _iter_parts

**Param√®tres :**

- `name`

##### __str__

##### __repr__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

---

### specifiers

.. testsetup::

    from pip._vendor.packaging.specifiers import Specifier, SpecifierSet, InvalidSpecifier
    from pip._vendor.packaging.version import Version

#### Classes

##### InvalidSpecifier

Raised when attempting to create a :class:`Specifier` with a specifier
string that is invalid.

>>> Specifier("lolwat")
Traceback (most recent call last):
    ...
packaging.specifiers.InvalidSpecifier: Invalid specifier: 'lolwat'

##### BaseSpecifier

**M√©thodes :**

- `__str__()`
- `__hash__()`
- `__eq__()`
- `prereleases()`
- `prereleases()`
- `contains()`
- `filter()`

##### Specifier

This class abstracts handling of version specifiers.

.. tip::

    It is generally not required to instantiate this manually. You should instead
    prefer to work with :class:`SpecifierSet` instead, which can parse
    comma-separated version specifiers (which is what package metadata contains).

**M√©thodes :**

- `__init__()`
- `prereleases()`
- `prereleases()`
- `operator()`
- `version()`
- `__repr__()`
- `__str__()`
- `_canonical_spec()`
- `__hash__()`
- `__eq__()`
- `_get_operator()`
- `_compare_compatible()`
- `_compare_equal()`
- `_compare_not_equal()`
- `_compare_less_than_equal()`
- `_compare_greater_than_equal()`
- `_compare_less_than()`
- `_compare_greater_than()`
- `_compare_arbitrary()`
- `__contains__()`
- `contains()`
- `filter()`

##### SpecifierSet

This class abstracts handling of a set of version specifiers.

It can be passed a single specifier (``>=3.0``), a comma-separated list of
specifiers (``>=3.0,!=3.1``), or no specifier at all.

**M√©thodes :**

- `__init__()`
- `prereleases()`
- `prereleases()`
- `__repr__()`
- `__str__()`
- `__hash__()`
- `__and__()`
- `__eq__()`
- `__len__()`
- `__iter__()`
- `__contains__()`
- `contains()`
- `filter()`

#### Fonctions

##### _coerce_version

**Param√®tres :**

- `version`

##### _version_split

Split version into components.

The split components are intended for version comparison. The logic does
not attempt to retain the original version string, so joining the
components back with :func:`_version_join` may not produce the original
version string.

**Param√®tres :**

- `version`

##### _version_join

Join split version components into a version string.

This function assumes the input came from :func:`_version_split`, where the
first component must be the epoch (either empty or numeric), and all other
components numeric.

**Param√®tres :**

- `components`

##### _is_not_suffix

**Param√®tres :**

- `segment`

##### _pad_version

**Param√®tres :**

- `left`
- `right`

##### __str__

Returns the str representation of this Specifier-like object. This
should be representative of the Specifier itself.

##### __hash__

Returns a hash value for this Specifier-like object.

##### __eq__

Returns a boolean representing whether or not the two Specifier-like
objects are equal.

:param other: The other object to check against.

**Param√®tres :**

- `other`

##### prereleases

Whether or not pre-releases as a whole are allowed.

This can be set to either ``True`` or ``False`` to explicitly enable or disable
prereleases or it can be set to ``None`` (the default) to use default semantics.

##### prereleases

Setter for :attr:`prereleases`.

:param value: The value to set.

**Param√®tres :**

- `value`

##### contains

Determines if the given item is contained within this specifier.

**Param√®tres :**

- `item`
- `prereleases`

##### filter

Takes an iterable of items and filters them so that only items which
are contained within this specifier are allowed in it.

**Param√®tres :**

- `iterable`
- `prereleases`

##### __init__

Initialize a Specifier instance.

:param spec:
    The string representation of a specifier which will be parsed and
    normalized before use.
:param prereleases:
    This tells the specifier if it should accept prerelease versions if
    applicable or not. The default of ``None`` will autodetect it from the
    given specifiers.
:raises InvalidSpecifier:
    If the given specifier is invalid (i.e. bad syntax).

**Param√®tres :**

- `spec`
- `prereleases`

##### prereleases

##### prereleases

**Param√®tres :**

- `value`

##### operator

The operator of this specifier.

>>> Specifier("==1.2.3").operator
'=='

##### version

The version of this specifier.

>>> Specifier("==1.2.3").version
'1.2.3'

##### __repr__

A representation of the Specifier that shows all internal state.

>>> Specifier('>=1.0.0')
<Specifier('>=1.0.0')>
>>> Specifier('>=1.0.0', prereleases=False)
<Specifier('>=1.0.0', prereleases=False)>
>>> Specifier('>=1.0.0', prereleases=True)
<Specifier('>=1.0.0', prereleases=True)>

##### __str__

A string representation of the Specifier that can be round-tripped.

>>> str(Specifier('>=1.0.0'))
'>=1.0.0'
>>> str(Specifier('>=1.0.0', prereleases=False))
'>=1.0.0'

##### _canonical_spec

##### __hash__

##### __eq__

Whether or not the two Specifier-like objects are equal.

:param other: The other object to check against.

The value of :attr:`prereleases` is ignored.

>>> Specifier("==1.2.3") == Specifier("== 1.2.3.0")
True
>>> (Specifier("==1.2.3", prereleases=False) ==
...  Specifier("==1.2.3", prereleases=True))
True
>>> Specifier("==1.2.3") == "==1.2.3"
True
>>> Specifier("==1.2.3") == Specifier("==1.2.4")
False
>>> Specifier("==1.2.3") == Specifier("~=1.2.3")
False

**Param√®tres :**

- `other`

##### _get_operator

**Param√®tres :**

- `op`

##### _compare_compatible

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_not_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_less_than_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_greater_than_equal

**Param√®tres :**

- `prospective`
- `spec`

##### _compare_less_than

**Param√®tres :**

- `prospective`
- `spec_str`

##### _compare_greater_than

**Param√®tres :**

- `prospective`
- `spec_str`

##### _compare_arbitrary

**Param√®tres :**

- `prospective`
- `spec`

##### __contains__

Return whether or not the item is contained in this specifier.

:param item: The item to check for.

This is used for the ``in`` operator and behaves the same as
:meth:`contains` with no ``prereleases`` argument passed.

>>> "1.2.3" in Specifier(">=1.2.3")
True
>>> Version("1.2.3") in Specifier(">=1.2.3")
True
>>> "1.0.0" in Specifier(">=1.2.3")
False
>>> "1.3.0a1" in Specifier(">=1.2.3")
False
>>> "1.3.0a1" in Specifier(">=1.2.3", prereleases=True)
True

**Param√®tres :**

- `item`

##### contains

Return whether or not the item is contained in this specifier.

:param item:
    The item to check for, which can be a version string or a
    :class:`Version` instance.
:param prereleases:
    Whether or not to match prereleases with this Specifier. If set to
    ``None`` (the default), it uses :attr:`prereleases` to determine
    whether or not prereleases are allowed.

>>> Specifier(">=1.2.3").contains("1.2.3")
True
>>> Specifier(">=1.2.3").contains(Version("1.2.3"))
True
>>> Specifier(">=1.2.3").contains("1.0.0")
False
>>> Specifier(">=1.2.3").contains("1.3.0a1")
False
>>> Specifier(">=1.2.3", prereleases=True).contains("1.3.0a1")
True
>>> Specifier(">=1.2.3").contains("1.3.0a1", prereleases=True)
True

**Param√®tres :**

- `item`
- `prereleases`

##### filter

Filter items in the given iterable, that match the specifier.

:param iterable:
    An iterable that can contain version strings and :class:`Version` instances.
    The items in the iterable will be filtered according to the specifier.
:param prereleases:
    Whether or not to allow prereleases in the returned iterator. If set to
    ``None`` (the default), it will be intelligently decide whether to allow
    prereleases or not (based on the :attr:`prereleases` attribute, and
    whether the only versions matching are prereleases).

This method is smarter than just ``filter(Specifier().contains, [...])``
because it implements the rule from :pep:`440` that a prerelease item
SHOULD be accepted if no other versions match the given specifier.

>>> list(Specifier(">=1.2.3").filter(["1.2", "1.3", "1.5a1"]))
['1.3']
>>> list(Specifier(">=1.2.3").filter(["1.2", "1.2.3", "1.3", Version("1.4")]))
['1.2.3', '1.3', <Version('1.4')>]
>>> list(Specifier(">=1.2.3").filter(["1.2", "1.5a1"]))
['1.5a1']
>>> list(Specifier(">=1.2.3").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']
>>> list(Specifier(">=1.2.3", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']

**Param√®tres :**

- `iterable`
- `prereleases`

##### __init__

Initialize a SpecifierSet instance.

:param specifiers:
    The string representation of a specifier or a comma-separated list of
    specifiers which will be parsed and normalized before use.
    May also be an iterable of ``Specifier`` instances, which will be used
    as is.
:param prereleases:
    This tells the SpecifierSet if it should accept prerelease versions if
    applicable or not. The default of ``None`` will autodetect it from the
    given specifiers.

:raises InvalidSpecifier:
    If the given ``specifiers`` are not parseable than this exception will be
    raised.

**Param√®tres :**

- `specifiers`
- `prereleases`

##### prereleases

##### prereleases

**Param√®tres :**

- `value`

##### __repr__

A representation of the specifier set that shows all internal state.

Note that the ordering of the individual specifiers within the set may not
match the input string.

>>> SpecifierSet('>=1.0.0,!=2.0.0')
<SpecifierSet('!=2.0.0,>=1.0.0')>
>>> SpecifierSet('>=1.0.0,!=2.0.0', prereleases=False)
<SpecifierSet('!=2.0.0,>=1.0.0', prereleases=False)>
>>> SpecifierSet('>=1.0.0,!=2.0.0', prereleases=True)
<SpecifierSet('!=2.0.0,>=1.0.0', prereleases=True)>

##### __str__

A string representation of the specifier set that can be round-tripped.

Note that the ordering of the individual specifiers within the set may not
match the input string.

>>> str(SpecifierSet(">=1.0.0,!=1.0.1"))
'!=1.0.1,>=1.0.0'
>>> str(SpecifierSet(">=1.0.0,!=1.0.1", prereleases=False))
'!=1.0.1,>=1.0.0'

##### __hash__

##### __and__

Return a SpecifierSet which is a combination of the two sets.

:param other: The other object to combine with.

>>> SpecifierSet(">=1.0.0,!=1.0.1") & '<=2.0.0,!=2.0.1'
<SpecifierSet('!=1.0.1,!=2.0.1,<=2.0.0,>=1.0.0')>
>>> SpecifierSet(">=1.0.0,!=1.0.1") & SpecifierSet('<=2.0.0,!=2.0.1')
<SpecifierSet('!=1.0.1,!=2.0.1,<=2.0.0,>=1.0.0')>

**Param√®tres :**

- `other`

##### __eq__

Whether or not the two SpecifierSet-like objects are equal.

:param other: The other object to check against.

The value of :attr:`prereleases` is ignored.

>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> (SpecifierSet(">=1.0.0,!=1.0.1", prereleases=False) ==
...  SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True))
True
>>> SpecifierSet(">=1.0.0,!=1.0.1") == ">=1.0.0,!=1.0.1"
True
>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1") == SpecifierSet(">=1.0.0,!=1.0.2")
False

**Param√®tres :**

- `other`

##### __len__

Returns the number of specifiers in this specifier set.

##### __iter__

Returns an iterator over all the underlying :class:`Specifier` instances
in this specifier set.

>>> sorted(SpecifierSet(">=1.0.0,!=1.0.1"), key=str)
[<Specifier('!=1.0.1')>, <Specifier('>=1.0.0')>]

##### __contains__

Return whether or not the item is contained in this specifier.

:param item: The item to check for.

This is used for the ``in`` operator and behaves the same as
:meth:`contains` with no ``prereleases`` argument passed.

>>> "1.2.3" in SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> Version("1.2.3") in SpecifierSet(">=1.0.0,!=1.0.1")
True
>>> "1.0.1" in SpecifierSet(">=1.0.0,!=1.0.1")
False
>>> "1.3.0a1" in SpecifierSet(">=1.0.0,!=1.0.1")
False
>>> "1.3.0a1" in SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True)
True

**Param√®tres :**

- `item`

##### contains

Return whether or not the item is contained in this SpecifierSet.

:param item:
    The item to check for, which can be a version string or a
    :class:`Version` instance.
:param prereleases:
    Whether or not to match prereleases with this SpecifierSet. If set to
    ``None`` (the default), it uses :attr:`prereleases` to determine
    whether or not prereleases are allowed.

>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.2.3")
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains(Version("1.2.3"))
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.0.1")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.3.0a1")
False
>>> SpecifierSet(">=1.0.0,!=1.0.1", prereleases=True).contains("1.3.0a1")
True
>>> SpecifierSet(">=1.0.0,!=1.0.1").contains("1.3.0a1", prereleases=True)
True

**Param√®tres :**

- `item`
- `prereleases`
- `installed`

##### filter

Filter items in the given iterable, that match the specifiers in this set.

:param iterable:
    An iterable that can contain version strings and :class:`Version` instances.
    The items in the iterable will be filtered according to the specifier.
:param prereleases:
    Whether or not to allow prereleases in the returned iterator. If set to
    ``None`` (the default), it will be intelligently decide whether to allow
    prereleases or not (based on the :attr:`prereleases` attribute, and
    whether the only versions matching are prereleases).

This method is smarter than just ``filter(SpecifierSet(...).contains, [...])``
because it implements the rule from :pep:`440` that a prerelease item
SHOULD be accepted if no other versions match the given specifier.

>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.3", "1.5a1"]))
['1.3']
>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.3", Version("1.4")]))
['1.3', <Version('1.4')>]
>>> list(SpecifierSet(">=1.2.3").filter(["1.2", "1.5a1"]))
[]
>>> list(SpecifierSet(">=1.2.3").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']
>>> list(SpecifierSet(">=1.2.3", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']

An "empty" SpecifierSet will filter items based on the presence of prerelease
versions in the set.

>>> list(SpecifierSet("").filter(["1.3", "1.5a1"]))
['1.3']
>>> list(SpecifierSet("").filter(["1.5a1"]))
['1.5a1']
>>> list(SpecifierSet("", prereleases=True).filter(["1.3", "1.5a1"]))
['1.3', '1.5a1']
>>> list(SpecifierSet("").filter(["1.3", "1.5a1"], prereleases=True))
['1.3', '1.5a1']

**Param√®tres :**

- `iterable`
- `prereleases`

---

### tags

#### Classes

##### Tag

A representation of the tag triple for a wheel.

Instances are considered immutable and thus are hashable. Equality checking
is also supported.

**M√©thodes :**

- `__init__()`
- `interpreter()`
- `abi()`
- `platform()`
- `__eq__()`
- `__hash__()`
- `__str__()`
- `__repr__()`

#### Fonctions

##### parse_tag

Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.

Returning a set is required due to the possibility that the tag is a
compressed tag set.

**Param√®tres :**

- `tag`

##### _get_config_var

**Param√®tres :**

- `name`
- `warn`

##### _normalize_string

**Param√®tres :**

- `string`

##### _is_threaded_cpython

Determine if the ABI corresponds to a threaded (`--disable-gil`) build.

The threaded builds are indicated by a "t" in the abiflags.

**Param√®tres :**

- `abis`

##### _abi3_applies

Determine if the Python version supports abi3.

PEP 384 was first implemented in Python 3.2. The threaded (`--disable-gil`)
builds do not support abi3.

**Param√®tres :**

- `python_version`
- `threading`

##### _cpython_abis

**Param√®tres :**

- `py_version`
- `warn`

##### cpython_tags

Yields the tags for a CPython interpreter.

The tags consist of:
- cp<python_version>-<abi>-<platform>
- cp<python_version>-abi3-<platform>
- cp<python_version>-none-<platform>
- cp<less than python_version>-abi3-<platform>  # Older Python versions down to 3.2.

If python_version only specifies a major version then user-provided ABIs and
the 'none' ABItag will be used.

If 'abi3' or 'none' are specified in 'abis' then they will be yielded at
their normal position and not at the beginning.

**Param√®tres :**

- `python_version`
- `abis`
- `platforms`

##### _generic_abi

Return the ABI tag based on EXT_SUFFIX.

##### generic_tags

Yields the tags for a generic interpreter.

The tags consist of:
- <interpreter>-<abi>-<platform>

The "none" ABI will be added if it was not explicitly provided.

**Param√®tres :**

- `interpreter`
- `abis`
- `platforms`

##### _py_interpreter_range

Yields Python versions in descending order.

After the latest version, the major-only version will be yielded, and then
all previous versions of that major version.

**Param√®tres :**

- `py_version`

##### compatible_tags

Yields the sequence of tags that are compatible with a specific version of Python.

The tags consist of:
- py*-none-<platform>
- <interpreter>-none-any  # ... if `interpreter` is provided.
- py*-none-any

**Param√®tres :**

- `python_version`
- `interpreter`
- `platforms`

##### _mac_arch

**Param√®tres :**

- `arch`
- `is_32bit`

##### _mac_binary_formats

**Param√®tres :**

- `version`
- `cpu_arch`

##### mac_platforms

Yields the platform tags for a macOS system.

The `version` parameter is a two-item tuple specifying the macOS version to
generate platform tags for. The `arch` parameter is the CPU architecture to
generate platform tags for. Both parameters default to the appropriate value
for the current system.

**Param√®tres :**

- `version`
- `arch`

##### ios_platforms

Yields the platform tags for an iOS system.

:param version: A two-item tuple specifying the iOS version to generate
    platform tags for. Defaults to the current iOS version.
:param multiarch: The CPU architecture+ABI to generate platform tags for -
    (the value used by `sys.implementation._multiarch` e.g.,
    `arm64_iphoneos` or `x84_64_iphonesimulator`). Defaults to the current
    multiarch value.

**Param√®tres :**

- `version`
- `multiarch`

##### android_platforms

Yields the :attr:`~Tag.platform` tags for Android. If this function is invoked on
non-Android platforms, the ``api_level`` and ``abi`` arguments are required.

:param int api_level: The maximum `API level
    <https://developer.android.com/tools/releases/platforms>`__ to return. Defaults
    to the current system's version, as returned by ``platform.android_ver``.
:param str abi: The `Android ABI <https://developer.android.com/ndk/guides/abis>`__,
    e.g. ``arm64_v8a``. Defaults to the current system's ABI , as returned by
    ``sysconfig.get_platform``. Hyphens and periods will be replaced with
    underscores.

**Param√®tres :**

- `api_level`
- `abi`

##### _linux_platforms

**Param√®tres :**

- `is_32bit`

##### _generic_platforms

##### platform_tags

Provides the platform tags for this installation.

##### interpreter_name

Returns the name of the running interpreter.

Some implementations have a reserved, two-letter abbreviation which will
be returned when appropriate.

##### interpreter_version

Returns the version of the running interpreter.

##### _version_nodot

**Param√®tres :**

- `version`

##### sys_tags

Returns the sequence of tag triples for the running interpreter.

The order of the sequence corresponds to priority order for the
interpreter, from most to least important.

##### __init__

**Param√®tres :**

- `interpreter`
- `abi`
- `platform`

##### interpreter

##### abi

##### platform

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __str__

##### __repr__

---

### utils

#### Classes

##### InvalidName

An invalid distribution name; users should refer to the packaging user guide.

##### InvalidWheelFilename

An invalid wheel filename was found, users should refer to PEP 427.

##### InvalidSdistFilename

An invalid sdist filename was found, users should refer to the packaging user guide.

#### Fonctions

##### canonicalize_name

**Param√®tres :**

- `name`

##### is_normalized_name

**Param√®tres :**

- `name`

##### canonicalize_version

Return a canonical form of a version as a string.

>>> canonicalize_version('1.0.1')
'1.0.1'

Per PEP 625, versions may have multiple canonical forms, differing
only by trailing zeros.

>>> canonicalize_version('1.0.0')
'1'
>>> canonicalize_version('1.0.0', strip_trailing_zero=False)
'1.0.0'

Invalid versions are returned unaltered.

>>> canonicalize_version('foo bar baz')
'foo bar baz'

**Param√®tres :**

- `version`

##### _

**Param√®tres :**

- `version`

##### parse_wheel_filename

**Param√®tres :**

- `filename`

##### parse_sdist_filename

**Param√®tres :**

- `filename`

---

### version

.. testsetup::

    from pip._vendor.packaging.version import parse, Version

#### Classes

##### _Version

##### InvalidVersion

Raised when a version string is not a valid version.

>>> Version("invalid")
Traceback (most recent call last):
    ...
packaging.version.InvalidVersion: Invalid version: 'invalid'

##### _BaseVersion

**M√©thodes :**

- `__hash__()`
- `__lt__()`
- `__le__()`
- `__eq__()`
- `__ge__()`
- `__gt__()`
- `__ne__()`

##### Version

This class abstracts handling of a project's versions.

A :class:`Version` instance is comparison aware and can be compared and
sorted using the standard Python interfaces.

>>> v1 = Version("1.0a5")
>>> v2 = Version("1.0")
>>> v1
<Version('1.0a5')>
>>> v2
<Version('1.0')>
>>> v1 < v2
True
>>> v1 == v2
False
>>> v1 > v2
False
>>> v1 >= v2
False
>>> v1 <= v2
True

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__str__()`
- `epoch()`
- `release()`
- `pre()`
- `post()`
- `dev()`
- `local()`
- `public()`
- `base_version()`
- `is_prerelease()`
- `is_postrelease()`
- `is_devrelease()`
- `major()`
- `minor()`
- `micro()`

##### _TrimmedRelease

**M√©thodes :**

- `release()`

#### Fonctions

##### parse

Parse the given version string.

>>> parse('1.0.dev1')
<Version('1.0.dev1')>

:param version: The version string to parse.
:raises InvalidVersion: When the version string is not a valid version.

**Param√®tres :**

- `version`

##### _parse_letter_version

**Param√®tres :**

- `letter`
- `number`

##### _parse_local_version

Takes a string like abc.1.twelve and turns it into ("abc", 1, "twelve").

**Param√®tres :**

- `local`

##### _cmpkey

**Param√®tres :**

- `epoch`
- `release`
- `pre`
- `post`
- `dev`
- `local`

##### __hash__

##### __lt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __init__

Initialize a Version object.

:param version:
    The string representation of a version which will be parsed and normalized
    before use.
:raises InvalidVersion:
    If the ``version`` does not conform to PEP 440 in any way then this
    exception will be raised.

**Param√®tres :**

- `version`

##### __repr__

A representation of the Version that shows all internal state.

>>> Version('1.0.0')
<Version('1.0.0')>

##### __str__

A string representation of the version that can be round-tripped.

>>> str(Version("1.0a5"))
'1.0a5'

##### epoch

The epoch of the version.

>>> Version("2.0.0").epoch
0
>>> Version("1!2.0.0").epoch
1

##### release

The components of the "release" segment of the version.

>>> Version("1.2.3").release
(1, 2, 3)
>>> Version("2.0.0").release
(2, 0, 0)
>>> Version("1!2.0.0.post0").release
(2, 0, 0)

Includes trailing zeroes but not the epoch or any pre-release / development /
post-release suffixes.

##### pre

The pre-release segment of the version.

>>> print(Version("1.2.3").pre)
None
>>> Version("1.2.3a1").pre
('a', 1)
>>> Version("1.2.3b1").pre
('b', 1)
>>> Version("1.2.3rc1").pre
('rc', 1)

##### post

The post-release number of the version.

>>> print(Version("1.2.3").post)
None
>>> Version("1.2.3.post1").post
1

##### dev

The development number of the version.

>>> print(Version("1.2.3").dev)
None
>>> Version("1.2.3.dev1").dev
1

##### local

The local version segment of the version.

>>> print(Version("1.2.3").local)
None
>>> Version("1.2.3+abc").local
'abc'

##### public

The public portion of the version.

>>> Version("1.2.3").public
'1.2.3'
>>> Version("1.2.3+abc").public
'1.2.3'
>>> Version("1!1.2.3dev1+abc").public
'1!1.2.3.dev1'

##### base_version

The "base version" of the version.

>>> Version("1.2.3").base_version
'1.2.3'
>>> Version("1.2.3+abc").base_version
'1.2.3'
>>> Version("1!1.2.3dev1+abc").base_version
'1!1.2.3'

The "base version" is the public version of the project without any pre or post
release markers.

##### is_prerelease

Whether this version is a pre-release.

>>> Version("1.2.3").is_prerelease
False
>>> Version("1.2.3a1").is_prerelease
True
>>> Version("1.2.3b1").is_prerelease
True
>>> Version("1.2.3rc1").is_prerelease
True
>>> Version("1.2.3dev1").is_prerelease
True

##### is_postrelease

Whether this version is a post-release.

>>> Version("1.2.3").is_postrelease
False
>>> Version("1.2.3.post1").is_postrelease
True

##### is_devrelease

Whether this version is a development release.

>>> Version("1.2.3").is_devrelease
False
>>> Version("1.2.3.dev1").is_devrelease
True

##### major

The first item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").major
1

##### minor

The second item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").minor
2
>>> Version("1").minor
0

##### micro

The third item of :attr:`release` or ``0`` if unavailable.

>>> Version("1.2.3").micro
3
>>> Version("1").micro
0

##### release

Release segment without any trailing zeros.

>>> _TrimmedRelease('1.0.0').release
(1,)
>>> _TrimmedRelease('0.0').release
(0,)

---

### .!23459!__init__

---

### .!23464!_elffile

---

### .!23468!_manylinux

---

### .!23473!_musllinux

---

### .!23477!_parser

---

### .!23482!_structures

---

### .!23487!_tokenizer

---

### .!23493!markers

---

### .!23498!metadata

---

### .!23502!requirements

---

### .!23508!specifiers

---

### .!23516!utils

---

### .!23522!version

---

### _spdx

#### Classes

##### SPDXLicense

##### SPDXException

---

### .!23527!__init__

---

### .!23533!_spdx

---

### .!23537!__init__

---

### __main__

Main entry point.

#### Fonctions

##### main

Run the main entry point.

---

### android

Android.

#### Classes

##### Android

Follows the guidance `from here <https://android.stackexchange.com/a/216132>`_.

Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `version
<platformdirs.api.PlatformDirsABC.version>`, `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.

**M√©thodes :**

- `user_data_dir()`
- `site_data_dir()`
- `user_config_dir()`
- `site_config_dir()`
- `user_cache_dir()`
- `site_cache_dir()`
- `user_state_dir()`
- `user_log_dir()`
- `user_documents_dir()`
- `user_downloads_dir()`
- `user_pictures_dir()`
- `user_videos_dir()`
- `user_music_dir()`
- `user_desktop_dir()`
- `user_runtime_dir()`
- `site_runtime_dir()`

#### Fonctions

##### _android_folder

:return: base folder for the Android OS or None if it cannot be found

##### _android_documents_folder

:return: documents folder for the Android OS

##### _android_downloads_folder

:return: downloads folder for the Android OS

##### _android_pictures_folder

:return: pictures folder for the Android OS

##### _android_videos_folder

:return: videos folder for the Android OS

##### _android_music_folder

:return: music folder for the Android OS

##### user_data_dir

:return: data directory tied to the user, e.g. ``/data/user/<userid>/<packagename>/files/<AppName>``

##### site_data_dir

:return: data directory shared by users, same as `user_data_dir`

##### user_config_dir

:return: config directory tied to the user, e.g.         ``/data/user/<userid>/<packagename>/shared_prefs/<AppName>``

##### site_config_dir

:return: config directory shared by the users, same as `user_config_dir`

##### user_cache_dir

:return: cache directory tied to the user, e.g.,``/data/user/<userid>/<packagename>/cache/<AppName>``

##### site_cache_dir

:return: cache directory shared by users, same as `user_cache_dir`

##### user_state_dir

:return: state directory tied to the user, same as `user_data_dir`

##### user_log_dir

:return: log directory tied to the user, same as `user_cache_dir` if not opinionated else ``log`` in it,
  e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/log``

##### user_documents_dir

:return: documents directory tied to the user e.g. ``/storage/emulated/0/Documents``

##### user_downloads_dir

:return: downloads directory tied to the user e.g. ``/storage/emulated/0/Downloads``

##### user_pictures_dir

:return: pictures directory tied to the user e.g. ``/storage/emulated/0/Pictures``

##### user_videos_dir

:return: videos directory tied to the user e.g. ``/storage/emulated/0/DCIM/Camera``

##### user_music_dir

:return: music directory tied to the user e.g. ``/storage/emulated/0/Music``

##### user_desktop_dir

:return: desktop directory tied to the user e.g. ``/storage/emulated/0/Desktop``

##### user_runtime_dir

:return: runtime directory tied to the user, same as `user_cache_dir` if not opinionated else ``tmp`` in it,
  e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/tmp``

##### site_runtime_dir

:return: runtime directory shared by users, same as `user_runtime_dir`

---

### api

Base API.

#### Classes

##### PlatformDirsABC

Abstract base class for platform directories.

**M√©thodes :**

- `__init__()`
- `_append_app_name_and_version()`
- `_optionally_create_directory()`
- `_first_item_as_path_if_multipath()`
- `user_data_dir()`
- `site_data_dir()`
- `user_config_dir()`
- `site_config_dir()`
- `user_cache_dir()`
- `site_cache_dir()`
- `user_state_dir()`
- `user_log_dir()`
- `user_documents_dir()`
- `user_downloads_dir()`
- `user_pictures_dir()`
- `user_videos_dir()`
- `user_music_dir()`
- `user_desktop_dir()`
- `user_runtime_dir()`
- `site_runtime_dir()`
- `user_data_path()`
- `site_data_path()`
- `user_config_path()`
- `site_config_path()`
- `user_cache_path()`
- `site_cache_path()`
- `user_state_path()`
- `user_log_path()`
- `user_documents_path()`
- `user_downloads_path()`
- `user_pictures_path()`
- `user_videos_path()`
- `user_music_path()`
- `user_desktop_path()`
- `user_runtime_path()`
- `site_runtime_path()`
- `iter_config_dirs()`
- `iter_data_dirs()`
- `iter_cache_dirs()`
- `iter_runtime_dirs()`
- `iter_config_paths()`
- `iter_data_paths()`
- `iter_cache_paths()`
- `iter_runtime_paths()`

#### Fonctions

##### __init__

Create a new platform directory.

:param appname: See `appname`.
:param appauthor: See `appauthor`.
:param version: See `version`.
:param roaming: See `roaming`.
:param multipath: See `multipath`.
:param opinion: See `opinion`.
:param ensure_exists: See `ensure_exists`.

**Param√®tres :**

- `appname`
- `appauthor`
- `version`
- `roaming`
- `multipath`
- `opinion`
- `ensure_exists`

##### _append_app_name_and_version

##### _optionally_create_directory

**Param√®tres :**

- `path`

##### _first_item_as_path_if_multipath

**Param√®tres :**

- `directory`

##### user_data_dir

:return: data directory tied to the user

##### site_data_dir

:return: data directory shared by users

##### user_config_dir

:return: config directory tied to the user

##### site_config_dir

:return: config directory shared by the users

##### user_cache_dir

:return: cache directory tied to the user

##### site_cache_dir

:return: cache directory shared by users

##### user_state_dir

:return: state directory tied to the user

##### user_log_dir

:return: log directory tied to the user

##### user_documents_dir

:return: documents directory tied to the user

##### user_downloads_dir

:return: downloads directory tied to the user

##### user_pictures_dir

:return: pictures directory tied to the user

##### user_videos_dir

:return: videos directory tied to the user

##### user_music_dir

:return: music directory tied to the user

##### user_desktop_dir

:return: desktop directory tied to the user

##### user_runtime_dir

:return: runtime directory tied to the user

##### site_runtime_dir

:return: runtime directory shared by users

##### user_data_path

:return: data path tied to the user

##### site_data_path

:return: data path shared by users

##### user_config_path

:return: config path tied to the user

##### site_config_path

:return: config path shared by the users

##### user_cache_path

:return: cache path tied to the user

##### site_cache_path

:return: cache path shared by users

##### user_state_path

:return: state path tied to the user

##### user_log_path

:return: log path tied to the user

##### user_documents_path

:return: documents a path tied to the user

##### user_downloads_path

:return: downloads path tied to the user

##### user_pictures_path

:return: pictures path tied to the user

##### user_videos_path

:return: videos path tied to the user

##### user_music_path

:return: music path tied to the user

##### user_desktop_path

:return: desktop path tied to the user

##### user_runtime_path

:return: runtime path tied to the user

##### site_runtime_path

:return: runtime path shared by users

##### iter_config_dirs

:yield: all user and site configuration directories.

##### iter_data_dirs

:yield: all user and site data directories.

##### iter_cache_dirs

:yield: all user and site cache directories.

##### iter_runtime_dirs

:yield: all user and site runtime directories.

##### iter_config_paths

:yield: all user and site configuration paths.

##### iter_data_paths

:yield: all user and site data paths.

##### iter_cache_paths

:yield: all user and site cache paths.

##### iter_runtime_paths

:yield: all user and site runtime paths.

---

### .!23559!api

---

### .!23570!unix

---

### macos

macOS.

#### Classes

##### MacOS

Platform directories for the macOS operating system.

Follows the guidance from
`Apple documentation <https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/MacOSXDirectories/MacOSXDirectories.html>`_.
Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`,
`version <platformdirs.api.PlatformDirsABC.version>`,
`ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.

**M√©thodes :**

- `user_data_dir()`
- `site_data_dir()`
- `site_data_path()`
- `user_config_dir()`
- `site_config_dir()`
- `user_cache_dir()`
- `site_cache_dir()`
- `site_cache_path()`
- `user_state_dir()`
- `user_log_dir()`
- `user_documents_dir()`
- `user_downloads_dir()`
- `user_pictures_dir()`
- `user_videos_dir()`
- `user_music_dir()`
- `user_desktop_dir()`
- `user_runtime_dir()`
- `site_runtime_dir()`

#### Fonctions

##### user_data_dir

:return: data directory tied to the user, e.g. ``~/Library/Application Support/$appname/$version``

##### site_data_dir

:return: data directory shared by users, e.g. ``/Library/Application Support/$appname/$version``.
  If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory
  will be under the Homebrew prefix, e.g. ``/opt/homebrew/share/$appname/$version``.
  If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,
  the response is a multi-path string separated by ":", e.g.
  ``/opt/homebrew/share/$appname/$version:/Library/Application Support/$appname/$version``

##### site_data_path

:return: data path shared by users. Only return the first item, even if ``multipath`` is set to ``True``

##### user_config_dir

:return: config directory tied to the user, same as `user_data_dir`

##### site_config_dir

:return: config directory shared by the users, same as `site_data_dir`

##### user_cache_dir

:return: cache directory tied to the user, e.g. ``~/Library/Caches/$appname/$version``

##### site_cache_dir

:return: cache directory shared by users, e.g. ``/Library/Caches/$appname/$version``.
  If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory
  will be under the Homebrew prefix, e.g. ``/opt/homebrew/var/cache/$appname/$version``.
  If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,
  the response is a multi-path string separated by ":", e.g.
  ``/opt/homebrew/var/cache/$appname/$version:/Library/Caches/$appname/$version``

##### site_cache_path

:return: cache path shared by users. Only return the first item, even if ``multipath`` is set to ``True``

##### user_state_dir

:return: state directory tied to the user, same as `user_data_dir`

##### user_log_dir

:return: log directory tied to the user, e.g. ``~/Library/Logs/$appname/$version``

##### user_documents_dir

:return: documents directory tied to the user, e.g. ``~/Documents``

##### user_downloads_dir

:return: downloads directory tied to the user, e.g. ``~/Downloads``

##### user_pictures_dir

:return: pictures directory tied to the user, e.g. ``~/Pictures``

##### user_videos_dir

:return: videos directory tied to the user, e.g. ``~/Movies``

##### user_music_dir

:return: music directory tied to the user, e.g. ``~/Music``

##### user_desktop_dir

:return: desktop directory tied to the user, e.g. ``~/Desktop``

##### user_runtime_dir

:return: runtime directory tied to the user, e.g. ``~/Library/Caches/TemporaryItems/$appname/$version``

##### site_runtime_dir

:return: runtime directory shared by users, same as `user_runtime_dir`

---

### unix

Unix.

#### Classes

##### Unix

On Unix/Linux, we follow the `XDG Basedir Spec <https://specifications.freedesktop.org/basedir-spec/basedir-spec-
latest.html>`_.

The spec allows overriding directories with environment variables. The examples shown are the default values,
alongside the name of the environment variable that overrides them. Makes use of the `appname
<platformdirs.api.PlatformDirsABC.appname>`, `version <platformdirs.api.PlatformDirsABC.version>`, `multipath
<platformdirs.api.PlatformDirsABC.multipath>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists
<platformdirs.api.PlatformDirsABC.ensure_exists>`.

**M√©thodes :**

- `user_data_dir()`
- `_site_data_dirs()`
- `site_data_dir()`
- `user_config_dir()`
- `_site_config_dirs()`
- `site_config_dir()`
- `user_cache_dir()`
- `site_cache_dir()`
- `user_state_dir()`
- `user_log_dir()`
- `user_documents_dir()`
- `user_downloads_dir()`
- `user_pictures_dir()`
- `user_videos_dir()`
- `user_music_dir()`
- `user_desktop_dir()`
- `user_runtime_dir()`
- `site_runtime_dir()`
- `site_data_path()`
- `site_config_path()`
- `site_cache_path()`
- `iter_config_dirs()`
- `iter_data_dirs()`

#### Fonctions

##### _get_user_media_dir

**Param√®tres :**

- `env_var`
- `fallback_tilde_path`

##### _get_user_dirs_folder

Return directory from user-dirs.dirs config file.

See https://freedesktop.org/wiki/Software/xdg-user-dirs/.

**Param√®tres :**

- `key`

##### getuid

##### user_data_dir

:return: data directory tied to the user, e.g. ``~/.local/share/$appname/$version`` or
 ``$XDG_DATA_HOME/$appname/$version``

##### _site_data_dirs

##### site_data_dir

:return: data directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>` is
 enabled and ``XDG_DATA_DIRS`` is set and a multi path the response is also a multi path separated by the
 OS path separator), e.g. ``/usr/local/share/$appname/$version`` or ``/usr/share/$appname/$version``

##### user_config_dir

:return: config directory tied to the user, e.g. ``~/.config/$appname/$version`` or
 ``$XDG_CONFIG_HOME/$appname/$version``

##### _site_config_dirs

##### site_config_dir

:return: config directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>`
 is enabled and ``XDG_CONFIG_DIRS`` is set and a multi path the response is also a multi path separated by
 the OS path separator), e.g. ``/etc/xdg/$appname/$version``

##### user_cache_dir

:return: cache directory tied to the user, e.g. ``~/.cache/$appname/$version`` or
 ``~/$XDG_CACHE_HOME/$appname/$version``

##### site_cache_dir

:return: cache directory shared by users, e.g. ``/var/cache/$appname/$version``

##### user_state_dir

:return: state directory tied to the user, e.g. ``~/.local/state/$appname/$version`` or
 ``$XDG_STATE_HOME/$appname/$version``

##### user_log_dir

:return: log directory tied to the user, same as `user_state_dir` if not opinionated else ``log`` in it

##### user_documents_dir

:return: documents directory tied to the user, e.g. ``~/Documents``

##### user_downloads_dir

:return: downloads directory tied to the user, e.g. ``~/Downloads``

##### user_pictures_dir

:return: pictures directory tied to the user, e.g. ``~/Pictures``

##### user_videos_dir

:return: videos directory tied to the user, e.g. ``~/Videos``

##### user_music_dir

:return: music directory tied to the user, e.g. ``~/Music``

##### user_desktop_dir

:return: desktop directory tied to the user, e.g. ``~/Desktop``

##### user_runtime_dir

:return: runtime directory tied to the user, e.g. ``/run/user/$(id -u)/$appname/$version`` or
 ``$XDG_RUNTIME_DIR/$appname/$version``.

 For FreeBSD/OpenBSD/NetBSD, it would return ``/var/run/user/$(id -u)/$appname/$version`` if
 exists, otherwise ``/tmp/runtime-$(id -u)/$appname/$version``, if``$XDG_RUNTIME_DIR``
 is not set.

##### site_runtime_dir

:return: runtime directory shared by users, e.g. ``/run/$appname/$version`` or         ``$XDG_RUNTIME_DIR/$appname/$version``.

Note that this behaves almost exactly like `user_runtime_dir` if ``$XDG_RUNTIME_DIR`` is set, but will
fall back to paths associated to the root user instead of a regular logged-in user if it's not set.

If you wish to ensure that a logged-in root user path is returned e.g. ``/run/user/0``, use `user_runtime_dir`
instead.

For FreeBSD/OpenBSD/NetBSD, it would return ``/var/run/$appname/$version`` if ``$XDG_RUNTIME_DIR`` is not set.

##### site_data_path

:return: data path shared by users. Only return the first item, even if ``multipath`` is set to ``True``

##### site_config_path

:return: config path shared by the users, returns the first item, even if ``multipath`` is set to ``True``

##### site_cache_path

:return: cache path shared by users. Only return the first item, even if ``multipath`` is set to ``True``

##### iter_config_dirs

:yield: all user and site configuration directories.

##### iter_data_dirs

:yield: all user and site data directories.

---

### version

---

### windows

Windows.

#### Classes

##### Windows

`MSDN on where to store app data files <https://learn.microsoft.com/en-us/windows/win32/shell/knownfolderid>`_.

Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `appauthor
<platformdirs.api.PlatformDirsABC.appauthor>`, `version <platformdirs.api.PlatformDirsABC.version>`, `roaming
<platformdirs.api.PlatformDirsABC.roaming>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists
<platformdirs.api.PlatformDirsABC.ensure_exists>`.

**M√©thodes :**

- `user_data_dir()`
- `_append_parts()`
- `site_data_dir()`
- `user_config_dir()`
- `site_config_dir()`
- `user_cache_dir()`
- `site_cache_dir()`
- `user_state_dir()`
- `user_log_dir()`
- `user_documents_dir()`
- `user_downloads_dir()`
- `user_pictures_dir()`
- `user_videos_dir()`
- `user_music_dir()`
- `user_desktop_dir()`
- `user_runtime_dir()`
- `site_runtime_dir()`

#### Fonctions

##### get_win_folder_from_env_vars

Get folder from environment variables.

**Param√®tres :**

- `csidl_name`

##### get_win_folder_if_csidl_name_not_env_var

Get a folder for a CSIDL name that does not exist as an environment variable.

**Param√®tres :**

- `csidl_name`

##### get_win_folder_from_registry

Get folder from the registry.

This is a fallback technique at best. I'm not sure if using the registry for these guarantees us the correct answer
for all CSIDL_* names.

**Param√®tres :**

- `csidl_name`

##### get_win_folder_via_ctypes

Get folder with ctypes.

**Param√®tres :**

- `csidl_name`

##### _pick_get_win_folder

##### user_data_dir

:return: data directory tied to the user, e.g.
 ``%USERPROFILE%\AppData\Local\$appauthor\$appname`` (not roaming) or
 ``%USERPROFILE%\AppData\Roaming\$appauthor\$appname`` (roaming)

##### _append_parts

**Param√®tres :**

- `path`

##### site_data_dir

:return: data directory shared by users, e.g. ``C:\ProgramData\$appauthor\$appname``

##### user_config_dir

:return: config directory tied to the user, same as `user_data_dir`

##### site_config_dir

:return: config directory shared by the users, same as `site_data_dir`

##### user_cache_dir

:return: cache directory tied to the user (if opinionated with ``Cache`` folder within ``$appname``) e.g.
 ``%USERPROFILE%\AppData\Local\$appauthor\$appname\Cache\$version``

##### site_cache_dir

:return: cache directory shared by users, e.g. ``C:\ProgramData\$appauthor\$appname\Cache\$version``

##### user_state_dir

:return: state directory tied to the user, same as `user_data_dir`

##### user_log_dir

:return: log directory tied to the user, same as `user_data_dir` if not opinionated else ``Logs`` in it

##### user_documents_dir

:return: documents directory tied to the user e.g. ``%USERPROFILE%\Documents``

##### user_downloads_dir

:return: downloads directory tied to the user e.g. ``%USERPROFILE%\Downloads``

##### user_pictures_dir

:return: pictures directory tied to the user e.g. ``%USERPROFILE%\Pictures``

##### user_videos_dir

:return: videos directory tied to the user e.g. ``%USERPROFILE%\Videos``

##### user_music_dir

:return: music directory tied to the user e.g. ``%USERPROFILE%\Music``

##### user_desktop_dir

:return: desktop directory tied to the user, e.g. ``%USERPROFILE%\Desktop``

##### user_runtime_dir

:return: runtime directory tied to the user, e.g.
 ``%USERPROFILE%\AppData\Local\Temp\$appauthor\$appname``

##### site_runtime_dir

:return: runtime directory shared by users, same as `user_runtime_dir`

---

### .!23542!__init__

---

### .!23549!__main__

---

### .!23555!android

---

### .!23564!macos

---

### .!23573!version

---

### .!23577!windows

---

### __main__

pygments.__main__
~~~~~~~~~~~~~~~~~

Main entry point for ``python -m pygments``.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### console

pygments.console
~~~~~~~~~~~~~~~~

Format colored console output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### reset_color

##### colorize

**Param√®tres :**

- `color_key`
- `text`

##### ansiformat

Format ``text`` with a color and/or some attributes::

    color       normal color
    *color*     bold color
    _color_     underlined color
    +color+     blinking color

**Param√®tres :**

- `attr`
- `text`

---

### .!23653!util

---

### filter

pygments.filter
~~~~~~~~~~~~~~~

Module that implements the default filter.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Filter

Default filter. Subclass this class or use the `simplefilter`
decorator to create own filters.

**M√©thodes :**

- `__init__()`
- `filter()`

##### FunctionFilter

Abstract class used by `simplefilter` to create simple
function filters on the fly. The `simplefilter` decorator
automatically creates subclasses of this class for
functions passed to it.

**M√©thodes :**

- `__init__()`
- `filter()`

#### Fonctions

##### apply_filters

Use this method to apply an iterable of filters to
a stream. If lexer is given it's forwarded to the
filter, otherwise the filter receives `None`.

**Param√®tres :**

- `stream`
- `filters`
- `lexer`

##### simplefilter

Decorator that converts a function into a filter::

    @simplefilter
    def lowercase(self, lexer, stream, options):
        for ttype, value in stream:
            yield ttype, value.lower()

**Param√®tres :**

- `f`

##### _apply

**Param√®tres :**

- `filter_`
- `stream`

##### __init__

##### filter

**Param√®tres :**

- `lexer`
- `stream`

##### __init__

##### filter

**Param√®tres :**

- `lexer`
- `stream`

---

### formatter

pygments.formatter
~~~~~~~~~~~~~~~~~~

Base formatter class.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Formatter

Converts a token stream to text.

Formatters should have attributes to help selecting them. These
are similar to the corresponding :class:`~pygments.lexer.Lexer`
attributes.

.. autoattribute:: name
   :no-value:

.. autoattribute:: aliases
   :no-value:

.. autoattribute:: filenames
   :no-value:

You can pass options as keyword arguments to the constructor.
All formatters accept these basic options:

``style``
    The style to use, can be a string or a Style subclass
    (default: "default"). Not used by e.g. the
    TerminalFormatter.
``full``
    Tells the formatter to output a "full" document, i.e.
    a complete self-contained document. This doesn't have
    any effect for some formatters (default: false).
``title``
    If ``full`` is true, the title that should be used to
    caption the document (default: '').
``encoding``
    If given, must be an encoding name. This will be used to
    convert the Unicode token strings to byte strings in the
    output. If it is "" or None, Unicode strings will be written
    to the output file, which most file-like objects do not
    support (default: None).
``outencoding``
    Overrides ``encoding`` if given.

**M√©thodes :**

- `__init__()`
- `get_style_defs()`
- `format()`
- `__class_getitem__()`

#### Fonctions

##### _lookup_style

**Param√®tres :**

- `style`

##### __init__

As with lexers, this constructor takes arbitrary optional arguments,
and if you override it, you should first process your own options, then
call the base class implementation.

##### get_style_defs

This method must return statements or declarations suitable to define
the current style for subsequent highlighted text (e.g. CSS classes
in the `HTMLFormatter`).

The optional argument `arg` can be used to modify the generation and
is formatter dependent (it is standardized because it can be given on
the command line).

This method is called by the ``-S`` :doc:`command-line option <cmdline>`,
the `arg` is then given by the ``-a`` option.

**Param√®tres :**

- `arg`

##### format

This method must format the tokens from the `tokensource` iterable and
write the formatted version to the file object `outfile`.

Formatter options can control how exactly the tokens are converted.

**Param√®tres :**

- `tokensource`
- `outfile`

##### __class_getitem__

**Param√®tres :**

- `cls`
- `name`

---

### lexer

pygments.lexer
~~~~~~~~~~~~~~

Base lexer classes.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LexerMeta

This metaclass automagically converts ``analyse_text`` methods into
static methods which always return float values.

**M√©thodes :**

- `__new__()`

##### Lexer

Lexer for a specific language.

See also :doc:`lexerdevelopment`, a high-level guide to writing
lexers.

Lexer classes have attributes used for choosing the most appropriate
lexer based on various criteria.

.. autoattribute:: name
   :no-value:
.. autoattribute:: aliases
   :no-value:
.. autoattribute:: filenames
   :no-value:
.. autoattribute:: alias_filenames
.. autoattribute:: mimetypes
   :no-value:
.. autoattribute:: priority

Lexers included in Pygments should have two additional attributes:

.. autoattribute:: url
   :no-value:
.. autoattribute:: version_added
   :no-value:

Lexers included in Pygments may have additional attributes:

.. autoattribute:: _example
   :no-value:

You can pass options to the constructor. The basic options recognized
by all lexers and processed by the base `Lexer` class are:

``stripnl``
    Strip leading and trailing newlines from the input (default: True).
``stripall``
    Strip all leading and trailing whitespace from the input
    (default: False).
``ensurenl``
    Make sure that the input ends with a newline (default: True).  This
    is required for some lexers that consume input linewise.

    .. versionadded:: 1.3

``tabsize``
    If given and greater than 0, expand tabs in the input (default: 0).
``encoding``
    If given, must be an encoding name. This encoding will be used to
    convert the input string to Unicode, if it is not already a Unicode
    string (default: ``'guess'``, which uses a simple UTF-8 / Locale /
    Latin1 detection.  Can also be ``'chardet'`` to use the chardet
    library, if it is installed.
``inencoding``
    Overrides the ``encoding`` if given.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `add_filter()`
- `analyse_text()`
- `_preprocess_lexer_input()`
- `get_tokens()`
- `get_tokens_unprocessed()`

##### DelegatingLexer

This lexer takes two lexer as arguments. A root lexer and
a language lexer. First everything is scanned using the language
lexer, afterwards all ``Other`` tokens are lexed using the root
lexer.

The lexers from the ``template`` lexer package use this base lexer.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### include

Indicates that a state should include rules from another state.

##### _inherit

Indicates the a state should inherit from its superclass.

**M√©thodes :**

- `__repr__()`

##### combined

Indicates a state combined from multiple states.

**M√©thodes :**

- `__new__()`
- `__init__()`

##### _PseudoMatch

A pseudo match object constructed from a string.

**M√©thodes :**

- `__init__()`
- `start()`
- `end()`
- `group()`
- `groups()`
- `groupdict()`

##### _This

Special singleton used for indicating the caller class.
Used by ``using``.

##### default

Indicates a state or state action (e.g. #pop) to apply.
For example default('#pop') is equivalent to ('', Token, '#pop')
Note that state tuples may be used as well.

.. versionadded:: 2.0

**M√©thodes :**

- `__init__()`

##### words

Indicates a list of literal words that is transformed into an optimized
regex that matches any of the words.

.. versionadded:: 2.0

**M√©thodes :**

- `__init__()`
- `get()`

##### RegexLexerMeta

Metaclass for RegexLexer, creates the self._tokens attribute from
self.tokens on the first instantiation.

**M√©thodes :**

- `_process_regex()`
- `_process_token()`
- `_process_new_state()`
- `_process_state()`
- `process_tokendef()`
- `get_tokendefs()`
- `__call__()`

##### RegexLexer

Base for simple stateful regular expression-based lexers.
Simplifies the lexing process so that you need only
provide a list of states and regular expressions.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### LexerContext

A helper object that holds lexer position data.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### ExtendedRegexLexer

A RegexLexer that uses a context object to store its state.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### ProfilingRegexLexerMeta

Metaclass for ProfilingRegexLexer, collects regex timing info.

**M√©thodes :**

- `_process_regex()`

##### ProfilingRegexLexer

Drop-in replacement for RegexLexer that does profiling of its regexes.

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### bygroups

Callback that yields multiple actions for each group in the match.

##### using

Callback that processes the match with a different lexer.

The keyword arguments are forwarded to the lexer, except `state` which
is handled separately.

`state` specifies the state that the new lexer will start in, and can
be an enumerable such as ('root', 'inline', 'string') or a simple
string which is assumed to be on top of the root state.

Note: For that to work, `_other` must not be an `ExtendedRegexLexer`.

**Param√®tres :**

- `_other`

##### do_insertions

Helper for lexers which must combine the results of several
sublexers.

``insertions`` is a list of ``(index, itokens)`` pairs.
Each ``itokens`` iterable should be inserted at position
``index`` into the token stream given by the ``tokens``
argument.

The result is a combined token stream.

TODO: clean up the code here.

**Param√®tres :**

- `insertions`
- `tokens`

##### __new__

**Param√®tres :**

- `mcs`
- `name`
- `bases`
- `d`

##### __init__

This constructor takes arbitrary options as keyword arguments.
Every subclass must first process its own options and then call
the `Lexer` constructor, since it processes the basic
options like `stripnl`.

An example looks like this:

.. sourcecode:: python

   def __init__(self, **options):
       self.compress = options.get('compress', '')
       Lexer.__init__(self, **options)

As these options must all be specifiable as strings (due to the
command line usage), there are various utility functions
available to help with that, see `Utilities`_.

##### __repr__

##### add_filter

Add a new stream filter to this lexer.

**Param√®tres :**

- `filter_`

##### analyse_text

A static method which is called for lexer guessing.

It should analyse the text and return a float in the range
from ``0.0`` to ``1.0``.  If it returns ``0.0``, the lexer
will not be selected as the most probable one, if it returns
``1.0``, it will be selected immediately.  This is used by
`guess_lexer`.

The `LexerMeta` metaclass automatically wraps this function so
that it works like a static method (no ``self`` or ``cls``
parameter) and the return value is automatically converted to
`float`. If the return value is an object that is boolean `False`
it's the same as if the return values was ``0.0``.

**Param√®tres :**

- `text`

##### _preprocess_lexer_input

Apply preprocessing such as decoding the input, removing BOM and normalizing newlines.

**Param√®tres :**

- `text`

##### get_tokens

This method is the basic interface of a lexer. It is called by
the `highlight()` function. It must process the text and return an
iterable of ``(tokentype, value)`` pairs from `text`.

Normally, you don't need to override this method. The default
implementation processes the options recognized by all lexers
(`stripnl`, `stripall` and so on), and then yields all tokens
from `get_tokens_unprocessed()`, with the ``index`` dropped.

If `unfiltered` is set to `True`, the filtering mechanism is
bypassed even if filters are defined.

**Param√®tres :**

- `text`
- `unfiltered`

##### get_tokens_unprocessed

This method should process the text and return an iterable of
``(index, tokentype, value)`` tuples where ``index`` is the starting
position of the token within the input text.

It must be overridden by subclasses. It is recommended to
implement it as a generator to maximize effectiveness.

**Param√®tres :**

- `text`

##### __init__

**Param√®tres :**

- `_root_lexer`
- `_language_lexer`
- `_needle`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __repr__

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### __init__

**Param√®tres :**

- `start`
- `text`

##### start

**Param√®tres :**

- `arg`

##### end

**Param√®tres :**

- `arg`

##### group

**Param√®tres :**

- `arg`

##### groups

##### groupdict

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### __init__

**Param√®tres :**

- `state`

##### __init__

**Param√®tres :**

- `words`
- `prefix`
- `suffix`

##### get

##### _process_regex

Preprocess the regular expression component of a token definition.

**Param√®tres :**

- `cls`
- `regex`
- `rflags`
- `state`

##### _process_token

Preprocess the token component of a token definition.

**Param√®tres :**

- `cls`
- `token`

##### _process_new_state

Preprocess the state transition action of a token definition.

**Param√®tres :**

- `cls`
- `new_state`
- `unprocessed`
- `processed`

##### _process_state

Preprocess a single state definition.

**Param√®tres :**

- `cls`
- `unprocessed`
- `processed`
- `state`

##### process_tokendef

Preprocess a dictionary of token definitions.

**Param√®tres :**

- `cls`
- `name`
- `tokendefs`

##### get_tokendefs

Merge tokens from superclasses in MRO order, returning a single tokendef
dictionary.

Any state that is not defined by a subclass will be inherited
automatically.  States that *are* defined by subclasses will, by
default, override that state in the superclass.  If a subclass wishes to
inherit definitions from a superclass, it can use the special value
"inherit", which will cause the superclass' state definition to be
included at that point in the state.

**Param√®tres :**

- `cls`

##### __call__

Instantiate cls after preprocessing its token definitions.

**Param√®tres :**

- `cls`

##### get_tokens_unprocessed

Split ``text`` into (tokentype, text) pairs.

``stack`` is the initial stack (default: ``['root']``)

**Param√®tres :**

- `text`
- `stack`

##### __init__

**Param√®tres :**

- `text`
- `pos`
- `stack`
- `end`

##### __repr__

##### get_tokens_unprocessed

Split ``text`` into (tokentype, text) pairs.
If ``context`` is given, use this lexer context instead.

**Param√®tres :**

- `text`
- `context`

##### _process_regex

**Param√®tres :**

- `cls`
- `regex`
- `rflags`
- `state`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

##### streamer

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### match_func

**Param√®tres :**

- `text`
- `pos`
- `endpos`

---

### modeline

pygments.modeline
~~~~~~~~~~~~~~~~~

A simple modeline parser (based on pymodeline).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### get_filetype_from_line

**Param√®tres :**

- `l`

##### get_filetype_from_buffer

Scan the buffer for modelines and return filetype if one is found.

**Param√®tres :**

- `buf`
- `max_lines`

---

### plugin

pygments.plugin
~~~~~~~~~~~~~~~

Pygments plugin interface.

lexer plugins::

    [pygments.lexers]
    yourlexer = yourmodule:YourLexer

formatter plugins::

    [pygments.formatters]
    yourformatter = yourformatter:YourFormatter
    /.ext = yourformatter:YourFormatter

As you can see, you can define extensions for the formatter
with a leading slash.

syntax plugins::

    [pygments.styles]
    yourstyle = yourstyle:YourStyle

filter plugin::

    [pygments.filter]
    yourfilter = yourfilter:YourFilter


:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### iter_entry_points

**Param√®tres :**

- `group_name`

##### find_plugin_lexers

##### find_plugin_formatters

##### find_plugin_styles

##### find_plugin_filters

---

### regexopt

pygments.regexopt
~~~~~~~~~~~~~~~~~

An algorithm that generates optimized regexes for matching long lists of
literal strings.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### make_charset

**Param√®tres :**

- `letters`

##### regex_opt_inner

Return a regex that matches any string in the sorted list of strings.

**Param√®tres :**

- `strings`
- `open_paren`

##### regex_opt

Return a compiled regex that matches any string in the given list.

The strings to match must be literal strings, not regexes.  They will be
regex-escaped.

*prefix* and *suffix* are pre- and appended to the final regex.

**Param√®tres :**

- `strings`
- `prefix`
- `suffix`

---

### scanner

pygments.scanner
~~~~~~~~~~~~~~~~

This library implements a regex based scanner. Some languages
like Pascal are easy to parse but have some keywords that
depend on the context. Because of this it's impossible to lex
that just by using a regular expression lexer like the
`RegexLexer`.

Have a look at the `DelphiLexer` to get an idea of how to use
this scanner.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### EndOfText

Raise if end of text is reached and the user
tried to call a match function.

##### Scanner

Simple scanner

All method patterns are regular expression strings (not
compiled expressions!)

**M√©thodes :**

- `__init__()`
- `eos()`
- `check()`
- `test()`
- `scan()`
- `get_char()`
- `__repr__()`

#### Fonctions

##### __init__

:param text:    The text which should be scanned
:param flags:   default regular expression flags

**Param√®tres :**

- `text`
- `flags`

##### eos

`True` if the scanner reached the end of text.

##### check

Apply `pattern` on the current position and return
the match object. (Doesn't touch pos). Use this for
lookahead.

**Param√®tres :**

- `pattern`

##### test

Apply a pattern on the current position and check
if it patches. Doesn't touch pos.

**Param√®tres :**

- `pattern`

##### scan

Scan the text for the given pattern and update pos/match
and related fields. The return value is a boolean that
indicates if the pattern matched. The matched value is
stored on the instance as ``match``, the last value is
stored as ``last``. ``start_pos`` is the position of the
pointer before the pattern was matched, ``pos`` is the
end position.

**Param√®tres :**

- `pattern`

##### get_char

Scan exactly one char.

##### __repr__

---

### sphinxext

pygments.sphinxext
~~~~~~~~~~~~~~~~~~

Sphinx extension to generate automatic documentation of lexers,
formatters and filters.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PygmentsDoc

A directive to collect all lexers/formatters/filters and generate
autoclass directives for them.

**M√©thodes :**

- `run()`
- `document_lexers_overview()`
- `document_lexers()`
- `document_formatters()`
- `document_filters()`

#### Fonctions

##### setup

**Param√®tres :**

- `app`

##### run

##### document_lexers_overview

Generate a tabular overview of all lexers.

The columns are the lexer name, the extensions handled by this lexer
(or "None"), the aliases and a link to the lexer class.

##### document_lexers

##### document_formatters

##### document_filters

##### format_link

**Param√®tres :**

- `name`
- `url`

##### write_row

Format a table row

##### write_seperator

Write a table separator row

---

### style

pygments.style
~~~~~~~~~~~~~~

Basic style object.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### StyleMeta

**M√©thodes :**

- `__new__()`
- `style_for_token()`
- `list_styles()`
- `styles_token()`
- `__iter__()`
- `__len__()`

##### Style

#### Fonctions

##### __new__

**Param√®tres :**

- `mcs`
- `name`
- `bases`
- `dct`

##### style_for_token

**Param√®tres :**

- `cls`
- `token`

##### list_styles

**Param√®tres :**

- `cls`

##### styles_token

**Param√®tres :**

- `cls`
- `ttype`

##### __iter__

**Param√®tres :**

- `cls`

##### __len__

**Param√®tres :**

- `cls`

##### colorformat

**Param√®tres :**

- `text`

---

### token

pygments.token
~~~~~~~~~~~~~~

Basic token types and the standard tokens.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### _TokenType

**M√©thodes :**

- `split()`
- `__init__()`
- `__contains__()`
- `__getattr__()`
- `__repr__()`
- `__copy__()`
- `__deepcopy__()`

#### Fonctions

##### is_token_subtype

Return True if ``ttype`` is a subtype of ``other``.

exists for backwards compatibility. use ``ttype in other`` now.

**Param√®tres :**

- `ttype`
- `other`

##### string_to_tokentype

Convert a string into a token type::

    >>> string_to_token('String.Double')
    Token.Literal.String.Double
    >>> string_to_token('Token.Literal.Number')
    Token.Literal.Number
    >>> string_to_token('')
    Token

Tokens that are already tokens are returned unchanged:

    >>> string_to_token(String)
    Token.Literal.String

**Param√®tres :**

- `s`

##### split

##### __init__

##### __contains__

**Param√®tres :**

- `val`

##### __getattr__

**Param√®tres :**

- `val`

##### __repr__

##### __copy__

##### __deepcopy__

**Param√®tres :**

- `memo`

---

### unistring

pygments.unistring
~~~~~~~~~~~~~~~~~~

Strings of all Unicode characters of a certain category.
Used for matching in Unicode-aware languages. Run to regenerate.

Inspired by chartypes_create.py from the MoinMoin project.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### combine

##### allexcept

##### _handle_runs

**Param√®tres :**

- `char_list`

---

### util

pygments.util
~~~~~~~~~~~~~

Utility functions.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ClassNotFound

Raised if one of the lookup functions didn't find a matching class.

##### OptionError

This exception will be raised by all option processing functions if
the type or value of the argument is not correct.

##### Future

Generic class to defer some work.

Handled specially in RegexLexerMeta, to support regex string construction at
first use.

**M√©thodes :**

- `get()`

##### UnclosingTextIOWrapper

**M√©thodes :**

- `close()`

#### Fonctions

##### get_choice_opt

If the key `optname` from the dictionary is not in the sequence
`allowed`, raise an error, otherwise return it.

**Param√®tres :**

- `options`
- `optname`
- `allowed`
- `default`
- `normcase`

##### get_bool_opt

Intuitively, this is `options.get(optname, default)`, but restricted to
Boolean value. The Booleans can be represented as string, in order to accept
Boolean value from the command line arguments. If the key `optname` is
present in the dictionary `options` and is not associated with a Boolean,
raise an `OptionError`. If it is absent, `default` is returned instead.

The valid string values for ``True`` are ``1``, ``yes``, ``true`` and
``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``
(matched case-insensitively).

**Param√®tres :**

- `options`
- `optname`
- `default`

##### get_int_opt

As :func:`get_bool_opt`, but interpret the value as an integer.

**Param√®tres :**

- `options`
- `optname`
- `default`

##### get_list_opt

If the key `optname` from the dictionary `options` is a string,
split it at whitespace and return it. If it is already a list
or a tuple, it is returned as a list.

**Param√®tres :**

- `options`
- `optname`
- `default`

##### docstring_headline

**Param√®tres :**

- `obj`

##### make_analysator

Return a static text analyser function that returns float values.

**Param√®tres :**

- `f`

##### shebang_matches

Check if the given regular expression matches the last part of the
shebang if one exists.

    >>> from pygments.util import shebang_matches
    >>> shebang_matches('#!/usr/bin/env python', r'python(2\.\d)?')
    True
    >>> shebang_matches('#!/usr/bin/python2.4', r'python(2\.\d)?')
    True
    >>> shebang_matches('#!/usr/bin/python-ruby', r'python(2\.\d)?')
    False
    >>> shebang_matches('#!/usr/bin/python/ruby', r'python(2\.\d)?')
    False
    >>> shebang_matches('#!/usr/bin/startsomethingwith python',
    ...                 r'python(2\.\d)?')
    True

It also checks for common windows executable file extensions::

    >>> shebang_matches('#!C:\\Python2.4\\Python.exe', r'python(2\.\d)?')
    True

Parameters (``'-f'`` or ``'--foo'`` are ignored so ``'perl'`` does
the same as ``'perl -e'``)

Note that this method automatically searches the whole string (eg:
the regular expression is wrapped in ``'^$'``)

**Param√®tres :**

- `text`
- `regex`

##### doctype_matches

Check if the doctype matches a regular expression (if present).

Note that this method only checks the first part of a DOCTYPE.
eg: 'html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"'

**Param√®tres :**

- `text`
- `regex`

##### html_doctype_matches

Check if the file looks like it has a html doctype.

**Param√®tres :**

- `text`

##### looks_like_xml

Check if a doctype exists or if we have some tags.

**Param√®tres :**

- `text`

##### surrogatepair

Given a unicode character code with length greater than 16 bits,
return the two 16 bit surrogate pair.

**Param√®tres :**

- `c`

##### format_lines

Formats a sequence of strings for output.

**Param√®tres :**

- `var_name`
- `seq`
- `raw`
- `indent_level`

##### duplicates_removed

Returns a list with duplicates removed from the iterable `it`.

Order is preserved.

**Param√®tres :**

- `it`
- `already_seen`

##### guess_decode

Decode *text* with guessed encoding.

First try UTF-8; this should fail for non-UTF-8 encodings.
Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Param√®tres :**

- `text`

##### guess_decode_from_terminal

Decode *text* coming from terminal *term*.

First try the terminal encoding, if given.
Then try UTF-8.  Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Param√®tres :**

- `text`
- `term`

##### terminal_encoding

Return our best guess of encoding for the given *term*.

**Param√®tres :**

- `term`

##### text_analyse

**Param√®tres :**

- `text`

##### get

##### close

---

### .!23582!__init__

---

### .!23589!__main__

---

### .!23595!console

---

### .!23601!filter

---

### .!23606!formatter

---

### .!23611!lexer

---

### .!23615!modeline

---

### .!23620!plugin

---

### .!23625!regexopt

---

### .!23630!scanner

---

### .!23633!sphinxext

---

### .!23637!style

---

### .!23642!token

---

### .!23648!unistring

---

### .!23657!__init__

---

### _mapping

---

### .!23663!__init__

---

### .!23668!_mapping

---

### _mapping

---

### python

pygments.lexers.python
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Python and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PythonLexer

For Python source code (version 3.x).

.. versionchanged:: 2.5
   This is now the default ``PythonLexer``.  It is still available as the
   alias ``Python3Lexer``.

**M√©thodes :**

- `innerstring_rules()`
- `fstring_rules()`
- `analyse_text()`

##### Python2Lexer

For Python 2.x source code.

.. versionchanged:: 2.5
   This class has been renamed from ``PythonLexer``.  ``PythonLexer`` now
   refers to the Python 3 variant.  File name patterns like ``*.py`` have
   been moved to Python 3 as well.

**M√©thodes :**

- `innerstring_rules()`
- `analyse_text()`

##### _PythonConsoleLexerBase

##### PythonConsoleLexer

For Python console output or doctests, such as:

.. sourcecode:: pycon

    >>> a = 'foo'
    >>> print(a)
    foo
    >>> 1 / 0
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ZeroDivisionError: integer division or modulo by zero

Additional options:

`python3`
    Use Python 3 lexer for code.  Default is ``True``.

    .. versionadded:: 1.0
    .. versionchanged:: 2.5
       Now defaults to ``True``.

**M√©thodes :**

- `__init__()`

##### PythonTracebackLexer

For Python 3.x tracebacks, with support for chained exceptions.

.. versionchanged:: 2.5
   This is now the default ``PythonTracebackLexer``.  It is still available
   as the alias ``Python3TracebackLexer``.

##### Python2TracebackLexer

For Python tracebacks.

.. versionchanged:: 2.5
   This class has been renamed from ``PythonTracebackLexer``.
   ``PythonTracebackLexer`` now refers to the Python 3 variant.

##### CythonLexer

For Pyrex and Cython source code.

##### DgLexer

Lexer for dg,
a functional and object-oriented programming language
running on the CPython 3 VM.

##### NumPyLexer

A Python lexer recognizing Numerical Python builtins.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `analyse_text()`

##### _ReplaceInnerCode

**M√©thodes :**

- `__init__()`

#### Fonctions

##### innerstring_rules

**Param√®tres :**

- `ttype`

##### fstring_rules

**Param√®tres :**

- `ttype`

##### analyse_text

**Param√®tres :**

- `text`

##### innerstring_rules

**Param√®tres :**

- `ttype`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

---

### .!23672!__init__

---

### .!23678!_mapping

---

### .!23681!python

---

### _mapping

---

### .!23686!__init__

---

### .!23693!_mapping

---

### _impl

#### Classes

##### BackendUnavailable

Will be raised if the backend cannot be imported in the hook process.

**M√©thodes :**

- `__init__()`

##### HookMissing

Will be raised on missing hooks (if a fallback can't be used).

**M√©thodes :**

- `__init__()`

##### UnsupportedOperation

May be raised by build_sdist if the backend indicates that it can't.

**M√©thodes :**

- `__init__()`

##### BuildBackendHookCaller

A wrapper to call the build backend hooks for a source directory.

**M√©thodes :**

- `__init__()`
- `subprocess_runner()`
- `_supported_features()`
- `get_requires_for_build_wheel()`
- `prepare_metadata_for_build_wheel()`
- `build_wheel()`
- `get_requires_for_build_editable()`
- `prepare_metadata_for_build_editable()`
- `build_editable()`
- `get_requires_for_build_sdist()`
- `build_sdist()`
- `_call_hook()`

##### SubprocessRunner

A protocol for the subprocess runner.

**M√©thodes :**

- `__call__()`

#### Fonctions

##### write_json

**Param√®tres :**

- `obj`
- `path`

##### read_json

**Param√®tres :**

- `path`

##### default_subprocess_runner

The default method of calling the wrapper subprocess.

This uses :func:`subprocess.check_call` under the hood.

**Param√®tres :**

- `cmd`
- `cwd`
- `extra_environ`

##### quiet_subprocess_runner

Call the subprocess while suppressing output.

This uses :func:`subprocess.check_output` under the hood.

**Param√®tres :**

- `cmd`
- `cwd`
- `extra_environ`

##### norm_and_check

Normalise and check a backend path.

Ensure that the requested backend path is specified as a relative path,
and resolves to a location under the given source tree.

Return an absolute version of the requested path.

**Param√®tres :**

- `source_tree`
- `requested`

##### __init__

**Param√®tres :**

- `traceback`
- `message`
- `backend_name`
- `backend_path`

##### __init__

**Param√®tres :**

- `hook_name`

##### __init__

**Param√®tres :**

- `traceback`

##### __init__

:param source_dir: The source directory to invoke the build backend for
:param build_backend: The build backend spec
:param backend_path: Additional path entries for the build backend spec
:param runner: The :ref:`subprocess runner <Subprocess Runners>` to use
:param python_executable:
    The Python executable used to invoke the build backend

**Param√®tres :**

- `source_dir`
- `build_backend`
- `backend_path`
- `runner`
- `python_executable`

##### subprocess_runner

A context manager for temporarily overriding the default
:ref:`subprocess runner <Subprocess Runners>`.

:param runner: The new subprocess runner to use within the context.

.. code-block:: python

    hook_caller = BuildBackendHookCaller(...)
    with hook_caller.subprocess_runner(quiet_subprocess_runner):
        ...

**Param√®tres :**

- `runner`

##### _supported_features

Return the list of optional features supported by the backend.

##### get_requires_for_build_wheel

Get additional dependencies required for building a wheel.

:param config_settings: The configuration settings for the build backend
:returns: A list of :pep:`dependency specifiers <508>`.

.. admonition:: Fallback

    If the build backend does not defined a hook with this name, an
    empty list will be returned.

**Param√®tres :**

- `config_settings`

##### prepare_metadata_for_build_wheel

Prepare a ``*.dist-info`` folder with metadata for this project.

:param metadata_directory: The directory to write the metadata to
:param config_settings: The configuration settings for the build backend
:param _allow_fallback:
    Whether to allow the fallback to building a wheel and extracting
    the metadata from it. Should be passed as a keyword argument only.

:returns: Name of the newly created subfolder within
          ``metadata_directory``, containing the metadata.

.. admonition:: Fallback

    If the build backend does not define a hook with this name and
    ``_allow_fallback`` is truthy, the backend will be asked to build a
    wheel via the ``build_wheel`` hook and the dist-info extracted from
    that will be returned.

**Param√®tres :**

- `metadata_directory`
- `config_settings`
- `_allow_fallback`

##### build_wheel

Build a wheel from this project.

:param wheel_directory: The directory to write the wheel to
:param config_settings: The configuration settings for the build backend
:param metadata_directory: The directory to reuse existing metadata from
:returns:
    The name of the newly created wheel within ``wheel_directory``.

.. admonition:: Interaction with fallback

    If the ``build_wheel`` hook was called in the fallback for
    :meth:`prepare_metadata_for_build_wheel`, the build backend would
    not be invoked. Instead, the previously built wheel will be copied
    to ``wheel_directory`` and the name of that file will be returned.

**Param√®tres :**

- `wheel_directory`
- `config_settings`
- `metadata_directory`

##### get_requires_for_build_editable

Get additional dependencies required for building an editable wheel.

:param config_settings: The configuration settings for the build backend
:returns: A list of :pep:`dependency specifiers <508>`.

.. admonition:: Fallback

    If the build backend does not defined a hook with this name, an
    empty list will be returned.

**Param√®tres :**

- `config_settings`

##### prepare_metadata_for_build_editable

Prepare a ``*.dist-info`` folder with metadata for this project.

:param metadata_directory: The directory to write the metadata to
:param config_settings: The configuration settings for the build backend
:param _allow_fallback:
    Whether to allow the fallback to building a wheel and extracting
    the metadata from it. Should be passed as a keyword argument only.
:returns: Name of the newly created subfolder within
          ``metadata_directory``, containing the metadata.

.. admonition:: Fallback

    If the build backend does not define a hook with this name and
    ``_allow_fallback`` is truthy, the backend will be asked to build a
    wheel via the ``build_editable`` hook and the dist-info
    extracted from that will be returned.

**Param√®tres :**

- `metadata_directory`
- `config_settings`
- `_allow_fallback`

##### build_editable

Build an editable wheel from this project.

:param wheel_directory: The directory to write the wheel to
:param config_settings: The configuration settings for the build backend
:param metadata_directory: The directory to reuse existing metadata from
:returns:
    The name of the newly created wheel within ``wheel_directory``.

.. admonition:: Interaction with fallback

    If the ``build_editable`` hook was called in the fallback for
    :meth:`prepare_metadata_for_build_editable`, the build backend
    would not be invoked. Instead, the previously built wheel will be
    copied to ``wheel_directory`` and the name of that file will be
    returned.

**Param√®tres :**

- `wheel_directory`
- `config_settings`
- `metadata_directory`

##### get_requires_for_build_sdist

Get additional dependencies required for building an sdist.

:returns: A list of :pep:`dependency specifiers <508>`.

**Param√®tres :**

- `config_settings`

##### build_sdist

Build an sdist from this project.

:returns:
    The name of the newly created sdist within ``wheel_directory``.

**Param√®tres :**

- `sdist_directory`
- `config_settings`

##### _call_hook

**Param√®tres :**

- `hook_name`
- `kwargs`

##### __call__

**Param√®tres :**

- `cmd`
- `cwd`
- `extra_environ`

---

### .!23697!__init__

---

### .!23703!_impl

---

### _in_process

This is invoked in a subprocess to call the build backend hooks.

It expects:
- Command line args: hook_name, control_dir
- Environment variables:
      _PYPROJECT_HOOKS_BUILD_BACKEND=entry.point:spec
      _PYPROJECT_HOOKS_BACKEND_PATH=paths (separated with os.pathsep)
- control_dir/input.json:
  - {"kwargs": {...}}

Results:
- control_dir/output.json
  - {"return_val": ...}

#### Classes

##### BackendUnavailable

Raised if we cannot import the backend

**M√©thodes :**

- `__init__()`

##### HookMissing

Raised if a hook is missing and we are not executing the fallback

**M√©thodes :**

- `__init__()`

##### _BackendPathFinder

Implements the MetaPathFinder interface to locate modules in ``backend-path``.

Since the environment provided by the frontend can contain all sorts of
MetaPathFinders, the only way to ensure the backend is loaded from the
right place is to prepend our own.

**M√©thodes :**

- `__init__()`
- `find_spec()`

##### _DummyException

Nothing should ever raise this exception

##### GotUnsupportedOperation

For internal use when backend raises UnsupportedOperation

**M√©thodes :**

- `__init__()`

#### Fonctions

##### write_json

**Param√®tres :**

- `obj`
- `path`

##### read_json

**Param√®tres :**

- `path`

##### _build_backend

Find and load the build backend

##### _supported_features

Return the list of options features supported by the backend.

Returns a list of strings.
The only possible value is 'build_editable'.

##### get_requires_for_build_wheel

Invoke the optional get_requires_for_build_wheel hook

Returns [] if the hook is not defined.

**Param√®tres :**

- `config_settings`

##### get_requires_for_build_editable

Invoke the optional get_requires_for_build_editable hook

Returns [] if the hook is not defined.

**Param√®tres :**

- `config_settings`

##### prepare_metadata_for_build_wheel

Invoke optional prepare_metadata_for_build_wheel

Implements a fallback by building a wheel if the hook isn't defined,
unless _allow_fallback is False in which case HookMissing is raised.

**Param√®tres :**

- `metadata_directory`
- `config_settings`
- `_allow_fallback`

##### prepare_metadata_for_build_editable

Invoke optional prepare_metadata_for_build_editable

Implements a fallback by building an editable wheel if the hook isn't
defined, unless _allow_fallback is False in which case HookMissing is
raised.

**Param√®tres :**

- `metadata_directory`
- `config_settings`
- `_allow_fallback`

##### _dist_info_files

Identify the .dist-info folder inside a wheel ZipFile.

**Param√®tres :**

- `whl_zip`

##### _get_wheel_metadata_from_wheel

Extract the metadata from a wheel.

Fallback for when the build backend does not
define the 'get_wheel_metadata' hook.

**Param√®tres :**

- `whl_basename`
- `metadata_directory`
- `config_settings`

##### _find_already_built_wheel

Check for a wheel already built during the get_wheel_metadata hook.

**Param√®tres :**

- `metadata_directory`

##### build_wheel

Invoke the mandatory build_wheel hook.

If a wheel was already built in the
prepare_metadata_for_build_wheel fallback, this
will copy it rather than rebuilding the wheel.

**Param√®tres :**

- `wheel_directory`
- `config_settings`
- `metadata_directory`

##### build_editable

Invoke the optional build_editable hook.

If a wheel was already built in the
prepare_metadata_for_build_editable fallback, this
will copy it rather than rebuilding the wheel.

**Param√®tres :**

- `wheel_directory`
- `config_settings`
- `metadata_directory`

##### get_requires_for_build_sdist

Invoke the optional get_requires_for_build_wheel hook

Returns [] if the hook is not defined.

**Param√®tres :**

- `config_settings`

##### build_sdist

Invoke the mandatory build_sdist hook.

**Param√®tres :**

- `sdist_directory`
- `config_settings`

##### main

##### __init__

**Param√®tres :**

- `message`
- `traceback`

##### __init__

**Param√®tres :**

- `hook_name`

##### __init__

**Param√®tres :**

- `backend_path`
- `backend_module`

##### find_spec

**Param√®tres :**

- `fullname`
- `_path`
- `_target`

##### __init__

**Param√®tres :**

- `traceback`

##### find_distributions

**Param√®tres :**

- `context`

---

### .!23706!__init__

---

### .!23712!_in_process

---

### __version__

---

### _internal_utils

requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)

#### Fonctions

##### to_native_string

Given a string object, regardless of type, returns a representation of
that string in the native string type, encoding and decoding where
necessary. This assumes ASCII unless told otherwise.

**Param√®tres :**

- `string`
- `encoding`

##### unicode_is_ascii

Determine if unicode string only contains ASCII characters.

:param str u_string: unicode string to check. Must be unicode
    and not Python 2 `str`.
:rtype: bool

**Param√®tres :**

- `u_string`

---

### adapters

requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.

#### Classes

##### BaseAdapter

The Base Transport Adapter

**M√©thodes :**

- `__init__()`
- `send()`
- `close()`

##### HTTPAdapter

The built-in HTTP Adapter for urllib3.

Provides a general-case interface for Requests sessions to contact HTTP and
HTTPS urls by implementing the Transport Adapter interface. This class will
usually be created by the :class:`Session <Session>` class under the
covers.

:param pool_connections: The number of urllib3 connection pools to cache.
:param pool_maxsize: The maximum number of connections to save in the pool.
:param max_retries: The maximum number of retries each connection
    should attempt. Note, this applies only to failed DNS lookups, socket
    connections and connection timeouts, never to requests where data has
    made it to the server. By default, Requests does not retry failed
    connections. If you need granular control over the conditions under
    which we retry a request, import urllib3's ``Retry`` class and pass
    that instead.
:param pool_block: Whether the connection pool should block for connections.

Usage::

  >>> import requests
  >>> s = requests.Session()
  >>> a = requests.adapters.HTTPAdapter(max_retries=3)
  >>> s.mount('http://', a)

**M√©thodes :**

- `__init__()`
- `__getstate__()`
- `__setstate__()`
- `init_poolmanager()`
- `proxy_manager_for()`
- `cert_verify()`
- `build_response()`
- `build_connection_pool_key_attributes()`
- `get_connection_with_tls_context()`
- `get_connection()`
- `close()`
- `request_url()`
- `add_headers()`
- `proxy_headers()`
- `send()`

#### Fonctions

##### _urllib3_request_context

**Param√®tres :**

- `request`
- `verify`
- `client_cert`
- `poolmanager`

##### __init__

##### send

Sends PreparedRequest object. Returns Response object.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param stream: (optional) Whether to stream the request content.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param verify: (optional) Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use
:param cert: (optional) Any user-provided SSL certificate to be trusted.
:param proxies: (optional) The proxies dictionary to apply to the request.

**Param√®tres :**

- `request`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`

##### close

Cleans up adapter specific items.

##### __init__

**Param√®tres :**

- `pool_connections`
- `pool_maxsize`
- `max_retries`
- `pool_block`

##### __getstate__

##### __setstate__

**Param√®tres :**

- `state`

##### init_poolmanager

Initializes a urllib3 PoolManager.

This method should not be called from user code, and is only
exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param connections: The number of urllib3 connection pools to cache.
:param maxsize: The maximum number of connections to save in the pool.
:param block: Block when no free connections are available.
:param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.

**Param√®tres :**

- `connections`
- `maxsize`
- `block`

##### proxy_manager_for

Return urllib3 ProxyManager for the given proxy.

This method should not be called from user code, and is only
exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param proxy: The proxy to return a urllib3 ProxyManager for.
:param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
:returns: ProxyManager
:rtype: urllib3.ProxyManager

**Param√®tres :**

- `proxy`

##### cert_verify

Verify a SSL certificate. This method should not be called from user
code, and is only exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param conn: The urllib3 connection object associated with the cert.
:param url: The requested URL.
:param verify: Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use
:param cert: The SSL certificate to verify.

**Param√®tres :**

- `conn`
- `url`
- `verify`
- `cert`

##### build_response

Builds a :class:`Response <requests.Response>` object from a urllib3
response. This should not be called from user code, and is only exposed
for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

:param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
:param resp: The urllib3 response object.
:rtype: requests.Response

**Param√®tres :**

- `req`
- `resp`

##### build_connection_pool_key_attributes

Build the PoolKey attributes used by urllib3 to return a connection.

This looks at the PreparedRequest, the user-specified verify value,
and the value of the cert parameter to determine what PoolKey values
to use to select a connection from a given urllib3 Connection Pool.

The SSL related pool key arguments are not consistently set. As of
this writing, use the following to determine what keys may be in that
dictionary:

* If ``verify`` is ``True``, ``"ssl_context"`` will be set and will be the
  default Requests SSL Context
* If ``verify`` is ``False``, ``"ssl_context"`` will not be set but
  ``"cert_reqs"`` will be set
* If ``verify`` is a string, (i.e., it is a user-specified trust bundle)
  ``"ca_certs"`` will be set if the string is not a directory recognized
  by :py:func:`os.path.isdir`, otherwise ``"ca_certs_dir"`` will be
  set.
* If ``"cert"`` is specified, ``"cert_file"`` will always be set. If
  ``"cert"`` is a tuple with a second item, ``"key_file"`` will also
  be present

To override these settings, one may subclass this class, call this
method and use the above logic to change parameters as desired. For
example, if one wishes to use a custom :py:class:`ssl.SSLContext` one
must both set ``"ssl_context"`` and based on what else they require,
alter the other keys to ensure the desired behaviour.

:param request:
    The PreparedReqest being sent over the connection.
:type request:
    :class:`~requests.models.PreparedRequest`
:param verify:
    Either a boolean, in which case it controls whether
    we verify the server's TLS certificate, or a string, in which case it
    must be a path to a CA bundle to use.
:param cert:
    (optional) Any user-provided SSL certificate for client
    authentication (a.k.a., mTLS). This may be a string (i.e., just
    the path to a file which holds both certificate and key) or a
    tuple of length 2 with the certificate file path and key file
    path.
:returns:
    A tuple of two dictionaries. The first is the "host parameters"
    portion of the Pool Key including scheme, hostname, and port. The
    second is a dictionary of SSLContext related parameters.

**Param√®tres :**

- `request`
- `verify`
- `cert`

##### get_connection_with_tls_context

Returns a urllib3 connection for the given request and TLS settings.
This should not be called from user code, and is only exposed for use
when subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request:
    The :class:`PreparedRequest <PreparedRequest>` object to be sent
    over the connection.
:param verify:
    Either a boolean, in which case it controls whether we verify the
    server's TLS certificate, or a string, in which case it must be a
    path to a CA bundle to use.
:param proxies:
    (optional) The proxies dictionary to apply to the request.
:param cert:
    (optional) Any user-provided SSL certificate to be used for client
    authentication (a.k.a., mTLS).
:rtype:
    urllib3.ConnectionPool

**Param√®tres :**

- `request`
- `verify`
- `proxies`
- `cert`

##### get_connection

DEPRECATED: Users should move to `get_connection_with_tls_context`
for all subclasses of HTTPAdapter using Requests>=2.32.2.

Returns a urllib3 connection for the given URL. This should not be
called from user code, and is only exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param url: The URL to connect to.
:param proxies: (optional) A Requests-style dictionary of proxies used on this request.
:rtype: urllib3.ConnectionPool

**Param√®tres :**

- `url`
- `proxies`

##### close

Disposes of any internal state.

Currently, this closes the PoolManager and any active ProxyManager,
which closes any pooled connections.

##### request_url

Obtain the url to use when making the final request.

If the message is being sent through a HTTP proxy, the full URL has to
be used. Otherwise, we should only use the path portion of the URL.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
:rtype: str

**Param√®tres :**

- `request`
- `proxies`

##### add_headers

Add any headers needed by the connection. As of v2.0 this does
nothing by default, but is left for overriding by users that subclass
the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
:param kwargs: The keyword arguments from the call to send().

**Param√®tres :**

- `request`

##### proxy_headers

Returns a dictionary of the headers to add to any request sent
through a proxy. This works with urllib3 magic to ensure that they are
correctly sent to the proxy, rather than in a tunnelled request if
CONNECT is being used.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param proxy: The url of the proxy being used for this request.
:rtype: dict

**Param√®tres :**

- `proxy`

##### send

Sends PreparedRequest object. Returns Response object.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param stream: (optional) Whether to stream the request content.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple or urllib3 Timeout object
:param verify: (optional) Either a boolean, in which case it controls whether
    we verify the server's TLS certificate, or a string, in which case it
    must be a path to a CA bundle to use
:param cert: (optional) Any user-provided SSL certificate to be trusted.
:param proxies: (optional) The proxies dictionary to apply to the request.
:rtype: requests.Response

**Param√®tres :**

- `request`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`

##### SOCKSProxyManager

---

### api

requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.

#### Fonctions

##### request

Constructs and sends a :class:`Request <Request>`.

:param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
    in the query string for the :class:`Request`.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
:param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
:param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
    ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
    or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string
    defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
    to add for the file.
:param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
:param timeout: (optional) How many seconds to wait for the server to send data
    before giving up, as a float, or a :ref:`(connect timeout, read
    timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
:type allow_redirects: bool
:param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
:param verify: (optional) Either a boolean, in which case it controls whether we verify
        the server's TLS certificate, or a string, in which case it must be a path
        to a CA bundle to use. Defaults to ``True``.
:param stream: (optional) if ``False``, the response content will be immediately downloaded.
:param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
:return: :class:`Response <Response>` object
:rtype: requests.Response

Usage::

  >>> import requests
  >>> req = requests.request('GET', 'https://httpbin.org/get')
  >>> req
  <Response [200]>

**Param√®tres :**

- `method`
- `url`

##### get

Sends a GET request.

:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
    in the query string for the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `params`

##### options

Sends an OPTIONS request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`

##### head

Sends a HEAD request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes. If
    `allow_redirects` is not provided, it will be set to `False` (as
    opposed to the default :meth:`request` behavior).
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`

##### post

Sends a POST request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`
- `json`

##### put

Sends a PUT request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### patch

Sends a PATCH request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### delete

Sends a DELETE request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`

---

### auth

requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.

#### Classes

##### AuthBase

Base class that all auth implementations derive from

**M√©thodes :**

- `__call__()`

##### HTTPBasicAuth

Attaches HTTP Basic Authentication to the given Request object.

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `__ne__()`
- `__call__()`

##### HTTPProxyAuth

Attaches HTTP Proxy Authentication to a given Request object.

**M√©thodes :**

- `__call__()`

##### HTTPDigestAuth

Attaches HTTP Digest Authentication to the given Request object.

**M√©thodes :**

- `__init__()`
- `init_per_thread_state()`
- `build_digest_header()`
- `handle_redirect()`
- `handle_401()`
- `__call__()`
- `__eq__()`
- `__ne__()`

#### Fonctions

##### _basic_auth_str

Returns a Basic Auth string.

**Param√®tres :**

- `username`
- `password`

##### __call__

**Param√®tres :**

- `r`

##### __init__

**Param√®tres :**

- `username`
- `password`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __call__

**Param√®tres :**

- `r`

##### __call__

**Param√®tres :**

- `r`

##### __init__

**Param√®tres :**

- `username`
- `password`

##### init_per_thread_state

##### build_digest_header

:rtype: str

**Param√®tres :**

- `method`
- `url`

##### handle_redirect

Reset num_401_calls counter on redirects.

**Param√®tres :**

- `r`

##### handle_401

Takes the given response and tries digest-auth, if needed.

:rtype: requests.Response

**Param√®tres :**

- `r`

##### __call__

**Param√®tres :**

- `r`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### md5_utf8

**Param√®tres :**

- `x`

##### sha_utf8

**Param√®tres :**

- `x`

##### sha256_utf8

**Param√®tres :**

- `x`

##### sha512_utf8

**Param√®tres :**

- `x`

---

### .!23738!api

---

### .!23742!auth

---

### certs

requests.certs
~~~~~~~~~~~~~~

This module returns the preferred default CA certificate bundle. There is
only one ‚Äî the one from the certifi package.

If you are packaging Requests, e.g., for a Linux distribution or a managed
environment, you can change the definition of where() to return a separately
packaged CA bundle.

---

### .!23765!help

---

### compat

requests.compat
~~~~~~~~~~~~~~~

This module previously handled import compatibility issues
between Python 2 and Python 3. It remains for backwards
compatibility until the next major version.

#### Fonctions

##### _resolve_char_detection

Find supported character detection libraries.

---

### cookies

requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `http.cookiejar.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.

#### Classes

##### MockRequest

Wraps a `requests.Request` to mimic a `urllib2.Request`.

The code in `http.cookiejar.CookieJar` expects this interface in order to correctly
manage cookie policies, i.e., determine whether a cookie can be set, given the
domains of the request and the cookie.

The original request object is read-only. The client is responsible for collecting
the new headers via `get_new_headers()` and interpreting them appropriately. You
probably want `get_cookie_header`, defined below.

**M√©thodes :**

- `__init__()`
- `get_type()`
- `get_host()`
- `get_origin_req_host()`
- `get_full_url()`
- `is_unverifiable()`
- `has_header()`
- `get_header()`
- `add_header()`
- `add_unredirected_header()`
- `get_new_headers()`
- `unverifiable()`
- `origin_req_host()`
- `host()`

##### MockResponse

Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

...what? Basically, expose the parsed HTTP headers from the server response
the way `http.cookiejar` expects to see them.

**M√©thodes :**

- `__init__()`
- `info()`
- `getheaders()`

##### CookieConflictError

There are two cookies that meet the criteria specified in the cookie jar.
Use .get and .set and include domain and path args in order to be more specific.

##### RequestsCookieJar

Compatibility class; is a http.cookiejar.CookieJar, but exposes a dict
interface.

This is the CookieJar we create by default for requests and sessions that
don't specify one, since some clients may expect response.cookies and
session.cookies to support dict operations.

Requests does not use the dict interface internally; it's just for
compatibility with external client code. All requests code should work
out of the box with externally provided instances of ``CookieJar``, e.g.
``LWPCookieJar`` and ``FileCookieJar``.

Unlike a regular CookieJar, this class is pickleable.

.. warning:: dictionary operations that are normally O(1) may be O(n).

**M√©thodes :**

- `get()`
- `set()`
- `iterkeys()`
- `keys()`
- `itervalues()`
- `values()`
- `iteritems()`
- `items()`
- `list_domains()`
- `list_paths()`
- `multiple_domains()`
- `get_dict()`
- `__contains__()`
- `__getitem__()`
- `__setitem__()`
- `__delitem__()`
- `set_cookie()`
- `update()`
- `_find()`
- `_find_no_duplicates()`
- `__getstate__()`
- `__setstate__()`
- `copy()`
- `get_policy()`

#### Fonctions

##### extract_cookies_to_jar

Extract the cookies from the response into a CookieJar.

:param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)
:param request: our own requests.Request object
:param response: urllib3.HTTPResponse object

**Param√®tres :**

- `jar`
- `request`
- `response`

##### get_cookie_header

Produce an appropriate Cookie header string to be sent with `request`, or None.

:rtype: str

**Param√®tres :**

- `jar`
- `request`

##### remove_cookie_by_name

Unsets a cookie by name, by default over all domains and paths.

Wraps CookieJar.clear(), is O(n).

**Param√®tres :**

- `cookiejar`
- `name`
- `domain`
- `path`

##### _copy_cookie_jar

**Param√®tres :**

- `jar`

##### create_cookie

Make a cookie from underspecified parameters.

By default, the pair of `name` and `value` will be set for the domain ''
and sent on every request (this is sometimes called a "supercookie").

**Param√®tres :**

- `name`
- `value`

##### morsel_to_cookie

Convert a Morsel object into a Cookie containing the one k/v pair.

**Param√®tres :**

- `morsel`

##### cookiejar_from_dict

Returns a CookieJar from a key/value dictionary.

:param cookie_dict: Dict of key/values to insert into CookieJar.
:param cookiejar: (optional) A cookiejar to add the cookies to.
:param overwrite: (optional) If False, will not replace cookies
    already in the jar with new ones.
:rtype: CookieJar

**Param√®tres :**

- `cookie_dict`
- `cookiejar`
- `overwrite`

##### merge_cookies

Add cookies to cookiejar and returns a merged CookieJar.

:param cookiejar: CookieJar object to add the cookies to.
:param cookies: Dictionary or CookieJar object to be added.
:rtype: CookieJar

**Param√®tres :**

- `cookiejar`
- `cookies`

##### __init__

**Param√®tres :**

- `request`

##### get_type

##### get_host

##### get_origin_req_host

##### get_full_url

##### is_unverifiable

##### has_header

**Param√®tres :**

- `name`

##### get_header

**Param√®tres :**

- `name`
- `default`

##### add_header

cookiejar has no legitimate use for this method; add it back if you find one.

**Param√®tres :**

- `key`
- `val`

##### add_unredirected_header

**Param√®tres :**

- `name`
- `value`

##### get_new_headers

##### unverifiable

##### origin_req_host

##### host

##### __init__

Make a MockResponse for `cookiejar` to read.

:param headers: a httplib.HTTPMessage or analogous carrying the headers

**Param√®tres :**

- `headers`

##### info

##### getheaders

**Param√®tres :**

- `name`

##### get

Dict-like get() that also supports optional domain and path args in
order to resolve naming collisions from using one cookie jar over
multiple domains.

.. warning:: operation is O(n), not O(1).

**Param√®tres :**

- `name`
- `default`
- `domain`
- `path`

##### set

Dict-like set() that also supports optional domain and path args in
order to resolve naming collisions from using one cookie jar over
multiple domains.

**Param√®tres :**

- `name`
- `value`

##### iterkeys

Dict-like iterkeys() that returns an iterator of names of cookies
from the jar.

.. seealso:: itervalues() and iteritems().

##### keys

Dict-like keys() that returns a list of names of cookies from the
jar.

.. seealso:: values() and items().

##### itervalues

Dict-like itervalues() that returns an iterator of values of cookies
from the jar.

.. seealso:: iterkeys() and iteritems().

##### values

Dict-like values() that returns a list of values of cookies from the
jar.

.. seealso:: keys() and items().

##### iteritems

Dict-like iteritems() that returns an iterator of name-value tuples
from the jar.

.. seealso:: iterkeys() and itervalues().

##### items

Dict-like items() that returns a list of name-value tuples from the
jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
vanilla python dict of key value pairs.

.. seealso:: keys() and values().

##### list_domains

Utility method to list all the domains in the jar.

##### list_paths

Utility method to list all the paths in the jar.

##### multiple_domains

Returns True if there are multiple domains in the jar.
Returns False otherwise.

:rtype: bool

##### get_dict

Takes as an argument an optional domain and path and returns a plain
old Python dict of name-value pairs of cookies that meet the
requirements.

:rtype: dict

**Param√®tres :**

- `domain`
- `path`

##### __contains__

**Param√®tres :**

- `name`

##### __getitem__

Dict-like __getitem__() for compatibility with client code. Throws
exception if there are more than one cookie with name. In that case,
use the more explicit get() method instead.

.. warning:: operation is O(n), not O(1).

**Param√®tres :**

- `name`

##### __setitem__

Dict-like __setitem__ for compatibility with client code. Throws
exception if there is already a cookie of that name in the jar. In that
case, use the more explicit set() method instead.

**Param√®tres :**

- `name`
- `value`

##### __delitem__

Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s
``remove_cookie_by_name()``.

**Param√®tres :**

- `name`

##### set_cookie

**Param√®tres :**

- `cookie`

##### update

Updates this jar with cookies from another CookieJar or dict-like

**Param√®tres :**

- `other`

##### _find

Requests uses this method internally to get cookie values.

If there are conflicting cookies, _find arbitrarily chooses one.
See _find_no_duplicates if you want an exception thrown if there are
conflicting cookies.

:param name: a string containing name of cookie
:param domain: (optional) string containing domain of cookie
:param path: (optional) string containing path of cookie
:return: cookie.value

**Param√®tres :**

- `name`
- `domain`
- `path`

##### _find_no_duplicates

Both ``__get_item__`` and ``get`` call this function: it's never
used elsewhere in Requests.

:param name: a string containing name of cookie
:param domain: (optional) string containing domain of cookie
:param path: (optional) string containing path of cookie
:raises KeyError: if cookie is not found
:raises CookieConflictError: if there are multiple cookies
    that match name and optionally domain and path
:return: cookie.value

**Param√®tres :**

- `name`
- `domain`
- `path`

##### __getstate__

Unlike a normal CookieJar, this class is pickleable.

##### __setstate__

Unlike a normal CookieJar, this class is pickleable.

**Param√®tres :**

- `state`

##### copy

Return a copy of this RequestsCookieJar.

##### get_policy

Return the CookiePolicy instance used.

---

### exceptions

requests.exceptions
~~~~~~~~~~~~~~~~~~~

This module contains the set of Requests' exceptions.

#### Classes

##### RequestException

There was an ambiguous exception that occurred while handling your
request.

**M√©thodes :**

- `__init__()`

##### InvalidJSONError

A JSON error occurred.

##### JSONDecodeError

Couldn't decode the text into json

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### HTTPError

An HTTP error occurred.

##### ConnectionError

A Connection error occurred.

##### ProxyError

A proxy error occurred.

##### SSLError

An SSL error occurred.

##### Timeout

The request timed out.

Catching this error will catch both
:exc:`~requests.exceptions.ConnectTimeout` and
:exc:`~requests.exceptions.ReadTimeout` errors.

##### ConnectTimeout

The request timed out while trying to connect to the remote server.

Requests that produced this error are safe to retry.

##### ReadTimeout

The server did not send any data in the allotted amount of time.

##### URLRequired

A valid URL is required to make a request.

##### TooManyRedirects

Too many redirects.

##### MissingSchema

The URL scheme (e.g. http or https) is missing.

##### InvalidSchema

The URL scheme provided is either invalid or unsupported.

##### InvalidURL

The URL provided was somehow invalid.

##### InvalidHeader

The header value provided was somehow invalid.

##### InvalidProxyURL

The proxy URL provided is invalid.

##### ChunkedEncodingError

The server declared chunked encoding but sent an invalid chunk.

##### ContentDecodingError

Failed to decode response content.

##### StreamConsumedError

The content for this response was already consumed.

##### RetryError

Custom retries logic failed

##### UnrewindableBodyError

Requests encountered an error when trying to rewind a body.

##### RequestsWarning

Base warning for Requests.

##### FileModeWarning

A file was opened in text mode, but Requests determined its binary length.

##### RequestsDependencyWarning

An imported dependency doesn't match the expected version range.

#### Fonctions

##### __init__

Initialize RequestException with `request` and `response` objects.

##### __init__

Construct the JSONDecodeError instance first with all
args. Then use it's args to construct the IOError so that
the json specific args aren't used as IOError specific args
and the error message from JSONDecodeError is preserved.

##### __reduce__

The __reduce__ method called when pickling the object must
be the one from the JSONDecodeError (be it json/simplejson)
as it expects all the arguments for instantiation, not just
one like the IOError, and the MRO would by default call the
__reduce__ method from the IOError due to the inheritance order.

---

### help

Module containing bug report helper(s).

#### Fonctions

##### _implementation

Return a dict with the Python implementation and version.

Provide both the name and the version of the Python implementation
currently running. For example, on CPython 3.10.3 it will return
{'name': 'CPython', 'version': '3.10.3'}.

This function works best on CPython and PyPy: in particular, it probably
doesn't work for Jython or IronPython. Future investigation should be done
to work out the correct shape of the code for those platforms.

##### info

Generate information for a bug report.

##### main

Pretty-print the bug information as JSON.

---

### hooks

requests.hooks
~~~~~~~~~~~~~~

This module provides the capabilities for the Requests hooks system.

Available hooks:

``response``:
    The response generated from a Request.

#### Fonctions

##### default_hooks

##### dispatch_hook

Dispatches a hook dictionary on a given piece of data.

**Param√®tres :**

- `key`
- `hooks`
- `hook_data`

---

### models

requests.models
~~~~~~~~~~~~~~~

This module contains the primary objects that power Requests.

#### Classes

##### RequestEncodingMixin

**M√©thodes :**

- `path_url()`
- `_encode_params()`
- `_encode_files()`

##### RequestHooksMixin

**M√©thodes :**

- `register_hook()`
- `deregister_hook()`

##### Request

A user-created :class:`Request <Request>` object.

Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.

:param method: HTTP method to use.
:param url: URL to send.
:param headers: dictionary of headers to send.
:param files: dictionary of {filename: fileobject} files to multipart upload.
:param data: the body to attach to the request. If a dictionary or
    list of tuples ``[(key, value)]`` is provided, form-encoding will
    take place.
:param json: json for the body to attach to the request (if files or data is not specified).
:param params: URL parameters to append to the URL. If a dictionary or
    list of tuples ``[(key, value)]`` is provided, form-encoding will
    take place.
:param auth: Auth handler or (user, pass) tuple.
:param cookies: dictionary or CookieJar of cookies to attach to this request.
:param hooks: dictionary of callback hooks, for internal usage.

Usage::

  >>> import requests
  >>> req = requests.Request('GET', 'https://httpbin.org/get')
  >>> req.prepare()
  <PreparedRequest [GET]>

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `prepare()`

##### PreparedRequest

The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
containing the exact bytes that will be sent to the server.

Instances are generated from a :class:`Request <Request>` object, and
should not be instantiated manually; doing so may produce undesirable
effects.

Usage::

  >>> import requests
  >>> req = requests.Request('GET', 'https://httpbin.org/get')
  >>> r = req.prepare()
  >>> r
  <PreparedRequest [GET]>

  >>> s = requests.Session()
  >>> s.send(r)
  <Response [200]>

**M√©thodes :**

- `__init__()`
- `prepare()`
- `__repr__()`
- `copy()`
- `prepare_method()`
- `_get_idna_encoded_host()`
- `prepare_url()`
- `prepare_headers()`
- `prepare_body()`
- `prepare_content_length()`
- `prepare_auth()`
- `prepare_cookies()`
- `prepare_hooks()`

##### Response

The :class:`Response <Response>` object, which contains a
server's response to an HTTP request.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `__getstate__()`
- `__setstate__()`
- `__repr__()`
- `__bool__()`
- `__nonzero__()`
- `__iter__()`
- `ok()`
- `is_redirect()`
- `is_permanent_redirect()`
- `next()`
- `apparent_encoding()`
- `iter_content()`
- `iter_lines()`
- `content()`
- `text()`
- `json()`
- `links()`
- `raise_for_status()`
- `close()`

#### Fonctions

##### path_url

Build the path URL to use.

##### _encode_params

Encode parameters in a piece of data.

Will successfully encode parameters when passed as a dict or a list of
2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
if parameters are supplied as a dict.

**Param√®tres :**

- `data`

##### _encode_files

Build the body for a multipart/form-data request.

Will successfully encode files when passed as a dict or a list of
tuples. Order is retained if data is a list of tuples but arbitrary
if parameters are supplied as a dict.
The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
or 4-tuples (filename, fileobj, contentype, custom_headers).

**Param√®tres :**

- `files`
- `data`

##### register_hook

Properly register a hook.

**Param√®tres :**

- `event`
- `hook`

##### deregister_hook

Deregister a previously registered hook.
Returns True if the hook existed, False if not.

**Param√®tres :**

- `event`
- `hook`

##### __init__

**Param√®tres :**

- `method`
- `url`
- `headers`
- `files`
- `data`
- `params`
- `auth`
- `cookies`
- `hooks`
- `json`

##### __repr__

##### prepare

Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.

##### __init__

##### prepare

Prepares the entire request with the given parameters.

**Param√®tres :**

- `method`
- `url`
- `headers`
- `files`
- `data`
- `params`
- `auth`
- `cookies`
- `hooks`
- `json`

##### __repr__

##### copy

##### prepare_method

Prepares the given HTTP method.

**Param√®tres :**

- `method`

##### _get_idna_encoded_host

**Param√®tres :**

- `host`

##### prepare_url

Prepares the given HTTP URL.

**Param√®tres :**

- `url`
- `params`

##### prepare_headers

Prepares the given HTTP headers.

**Param√®tres :**

- `headers`

##### prepare_body

Prepares the given HTTP body data.

**Param√®tres :**

- `data`
- `files`
- `json`

##### prepare_content_length

Prepare Content-Length header based on request method and body

**Param√®tres :**

- `body`

##### prepare_auth

Prepares the given HTTP auth data.

**Param√®tres :**

- `auth`
- `url`

##### prepare_cookies

Prepares the given HTTP cookie data.

This function eventually generates a ``Cookie`` header from the
given cookies using cookielib. Due to cookielib's design, the header
will not be regenerated if it already exists, meaning this function
can only be called once for the life of the
:class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
header is removed beforehand.

**Param√®tres :**

- `cookies`

##### prepare_hooks

Prepares the given hooks.

**Param√®tres :**

- `hooks`

##### __init__

##### __enter__

##### __exit__

##### __getstate__

##### __setstate__

**Param√®tres :**

- `state`

##### __repr__

##### __bool__

Returns True if :attr:`status_code` is less than 400.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code, is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``.

##### __nonzero__

Returns True if :attr:`status_code` is less than 400.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code, is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``.

##### __iter__

Allows you to use a response as an iterator.

##### ok

Returns True if :attr:`status_code` is less than 400, False if not.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``.

##### is_redirect

True if this Response is a well-formed HTTP redirect that could have
been processed automatically (by :meth:`Session.resolve_redirects`).

##### is_permanent_redirect

True if this Response one of the permanent versions of redirect.

##### next

Returns a PreparedRequest for the next request in a redirect chain, if there is one.

##### apparent_encoding

The apparent encoding, provided by the charset_normalizer or chardet libraries.

##### iter_content

Iterates over the response data.  When stream=True is set on the
request, this avoids reading the content at once into memory for
large responses.  The chunk size is the number of bytes it should
read into memory.  This is not necessarily the length of each item
returned as decoding can take place.

chunk_size must be of type int or None. A value of None will
function differently depending on the value of `stream`.
stream=True will read data as it arrives in whatever size the
chunks are received. If stream=False, data is returned as
a single chunk.

If decode_unicode is True, content will be decoded using the best
available encoding based on the response.

**Param√®tres :**

- `chunk_size`
- `decode_unicode`

##### iter_lines

Iterates over the response data, one line at a time.  When
stream=True is set on the request, this avoids reading the
content at once into memory for large responses.

.. note:: This method is not reentrant safe.

**Param√®tres :**

- `chunk_size`
- `decode_unicode`
- `delimiter`

##### content

Content of the response, in bytes.

##### text

Content of the response, in unicode.

If Response.encoding is None, encoding will be guessed using
``charset_normalizer`` or ``chardet``.

The encoding of the response content is determined based solely on HTTP
headers, following RFC 2616 to the letter. If you can take advantage of
non-HTTP knowledge to make a better guess at the encoding, you should
set ``r.encoding`` appropriately before accessing this property.

##### json

Returns the json-encoded content of a response, if any.

:param \*\*kwargs: Optional arguments that ``json.loads`` takes.
:raises requests.exceptions.JSONDecodeError: If the response body does not
    contain valid json.

##### links

Returns the parsed header links of the response, if any.

##### raise_for_status

Raises :class:`HTTPError`, if one occurred.

##### close

Releases the connection back to the pool. Once this method has been
called the underlying ``raw`` object must not be accessed again.

*Note: Should not normally need to be called explicitly.*

##### generate

---

### packages

---

### sessions

requests.sessions
~~~~~~~~~~~~~~~~~

This module provides a Session object to manage and persist settings across
requests (cookies, auth, proxies).

#### Classes

##### SessionRedirectMixin

**M√©thodes :**

- `get_redirect_target()`
- `should_strip_auth()`
- `resolve_redirects()`
- `rebuild_auth()`
- `rebuild_proxies()`
- `rebuild_method()`

##### Session

A Requests session.

Provides cookie persistence, connection-pooling, and configuration.

Basic Usage::

  >>> import requests
  >>> s = requests.Session()
  >>> s.get('https://httpbin.org/get')
  <Response [200]>

Or as a context manager::

  >>> with requests.Session() as s:
  ...     s.get('https://httpbin.org/get')
  <Response [200]>

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `prepare_request()`
- `request()`
- `get()`
- `options()`
- `head()`
- `post()`
- `put()`
- `patch()`
- `delete()`
- `send()`
- `merge_environment_settings()`
- `get_adapter()`
- `close()`
- `mount()`
- `__getstate__()`
- `__setstate__()`

#### Fonctions

##### merge_setting

Determines appropriate setting for a given request, taking into account
the explicit setting on that request, and the setting in the session. If a
setting is a dictionary, they will be merged together using `dict_class`

**Param√®tres :**

- `request_setting`
- `session_setting`
- `dict_class`

##### merge_hooks

Properly merges both requests and session hooks.

This is necessary because when request_hooks == {'response': []}, the
merge breaks Session hooks entirely.

**Param√®tres :**

- `request_hooks`
- `session_hooks`
- `dict_class`

##### session

Returns a :class:`Session` for context-management.

.. deprecated:: 1.0.0

    This method has been deprecated since version 1.0.0 and is only kept for
    backwards compatibility. New code should use :class:`~requests.sessions.Session`
    to create a session. This may be removed at a future date.

:rtype: Session

##### get_redirect_target

Receives a Response. Returns a redirect URI or ``None``

**Param√®tres :**

- `resp`

##### should_strip_auth

Decide whether Authorization header should be removed when redirecting

**Param√®tres :**

- `old_url`
- `new_url`

##### resolve_redirects

Receives a Response. Returns a generator of Responses or Requests.

**Param√®tres :**

- `resp`
- `req`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`
- `yield_requests`

##### rebuild_auth

When being redirected we may want to strip authentication from the
request to avoid leaking credentials. This method intelligently removes
and reapplies authentication where possible to avoid credential loss.

**Param√®tres :**

- `prepared_request`
- `response`

##### rebuild_proxies

This method re-evaluates the proxy configuration by considering the
environment variables. If we are redirected to a URL covered by
NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
proxy keys for this URL (in case they were stripped by a previous
redirect).

This method also replaces the Proxy-Authorization header where
necessary.

:rtype: dict

**Param√®tres :**

- `prepared_request`
- `proxies`

##### rebuild_method

When being redirected we may want to change the method of the request
based on certain specs or browser behavior.

**Param√®tres :**

- `prepared_request`
- `response`

##### __init__

##### __enter__

##### __exit__

##### prepare_request

Constructs a :class:`PreparedRequest <PreparedRequest>` for
transmission and returns it. The :class:`PreparedRequest` has settings
merged from the :class:`Request <Request>` instance and those of the
:class:`Session`.

:param request: :class:`Request` instance to prepare with this
    session's settings.
:rtype: requests.PreparedRequest

**Param√®tres :**

- `request`

##### request

Constructs a :class:`Request <Request>`, prepares it and sends it.
Returns :class:`Response <Response>` object.

:param method: method for the new :class:`Request` object.
:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary or bytes to be sent in the query
    string for the :class:`Request`.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) json to send in the body of the
    :class:`Request`.
:param headers: (optional) Dictionary of HTTP Headers to send with the
    :class:`Request`.
:param cookies: (optional) Dict or CookieJar object to send with the
    :class:`Request`.
:param files: (optional) Dictionary of ``'filename': file-like-objects``
    for multipart encoding upload.
:param auth: (optional) Auth tuple or callable to enable
    Basic/Digest/Custom HTTP Auth.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param allow_redirects: (optional) Set to True by default.
:type allow_redirects: bool
:param proxies: (optional) Dictionary mapping protocol or protocol and
    hostname to the URL of the proxy.
:param hooks: (optional) Dictionary mapping hook name to one event or
    list of events, event must be callable.
:param stream: (optional) whether to immediately download the response
    content. Defaults to ``False``.
:param verify: (optional) Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use. Defaults to ``True``. When set to
    ``False``, requests will accept any TLS certificate presented by
    the server, and will ignore hostname mismatches and/or expired
    certificates, which will make your application vulnerable to
    man-in-the-middle (MitM) attacks. Setting verify to ``False``
    may be useful during local development or testing.
:param cert: (optional) if String, path to ssl client cert file (.pem).
    If Tuple, ('cert', 'key') pair.
:rtype: requests.Response

**Param√®tres :**

- `method`
- `url`
- `params`
- `data`
- `headers`
- `cookies`
- `files`
- `auth`
- `timeout`
- `allow_redirects`
- `proxies`
- `hooks`
- `stream`
- `verify`
- `cert`
- `json`

##### get

Sends a GET request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### options

Sends a OPTIONS request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### head

Sends a HEAD request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### post

Sends a POST request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) json to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`
- `json`

##### put

Sends a PUT request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### patch

Sends a PATCH request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### delete

Sends a DELETE request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### send

Send a given PreparedRequest.

:rtype: requests.Response

**Param√®tres :**

- `request`

##### merge_environment_settings

Check the environment and merge it with some settings.

:rtype: dict

**Param√®tres :**

- `url`
- `proxies`
- `stream`
- `verify`
- `cert`

##### get_adapter

Returns the appropriate connection adapter for the given URL.

:rtype: requests.adapters.BaseAdapter

**Param√®tres :**

- `url`

##### close

Closes all adapters and as such the session

##### mount

Registers a connection adapter to a prefix.

Adapters are sorted in descending order by prefix length.

**Param√®tres :**

- `prefix`
- `adapter`

##### __getstate__

##### __setstate__

**Param√®tres :**

- `state`

---

### status_codes

The ``codes`` object defines a mapping from common names for HTTP statuses
to their numerical codes, accessible either as attributes or as dictionary
items.

Example::

    >>> import requests
    >>> requests.codes['temporary_redirect']
    307
    >>> requests.codes.teapot
    418
    >>> requests.codes['\o/']
    200

Some codes have multiple names, and both upper- and lower-case versions of
the names are allowed. For example, ``codes.ok``, ``codes.OK``, and
``codes.okay`` all correspond to the HTTP status code 200.

#### Fonctions

##### _init

##### doc

**Param√®tres :**

- `code`

---

### structures

requests.structures
~~~~~~~~~~~~~~~~~~~

Data structures that power Requests.

#### Classes

##### CaseInsensitiveDict

A case-insensitive ``dict``-like object.

Implements all methods and operations of
``MutableMapping`` as well as dict's ``copy``. Also
provides ``lower_items``.

All keys are expected to be strings. The structure remembers the
case of the last key to be set, and ``iter(instance)``,
``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``
will contain case-sensitive keys. However, querying and contains
testing is case insensitive::

    cid = CaseInsensitiveDict()
    cid['Accept'] = 'application/json'
    cid['aCCEPT'] == 'application/json'  # True
    list(cid) == ['Accept']  # True

For example, ``headers['content-encoding']`` will return the
value of a ``'Content-Encoding'`` response header, regardless
of how the header name was originally stored.

If the constructor, ``.update``, or equality comparison
operations are given keys that have equal ``.lower()``s, the
behavior is undefined.

**M√©thodes :**

- `__init__()`
- `__setitem__()`
- `__getitem__()`
- `__delitem__()`
- `__iter__()`
- `__len__()`
- `lower_items()`
- `__eq__()`
- `copy()`
- `__repr__()`

##### LookupDict

Dictionary lookup object.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__getitem__()`
- `get()`

#### Fonctions

##### __init__

**Param√®tres :**

- `data`

##### __setitem__

**Param√®tres :**

- `key`
- `value`

##### __getitem__

**Param√®tres :**

- `key`

##### __delitem__

**Param√®tres :**

- `key`

##### __iter__

##### __len__

##### lower_items

Like iteritems(), but with all lowercase keys.

##### __eq__

**Param√®tres :**

- `other`

##### copy

##### __repr__

##### __init__

**Param√®tres :**

- `name`

##### __repr__

##### __getitem__

**Param√®tres :**

- `key`

##### get

**Param√®tres :**

- `key`
- `default`

---

### utils

requests.utils
~~~~~~~~~~~~~~

This module provides utility functions that are used within Requests
that are also useful for external consumption.

#### Fonctions

##### dict_to_sequence

Returns an internal sequence dictionary update.

**Param√®tres :**

- `d`

##### super_len

**Param√®tres :**

- `o`

##### get_netrc_auth

Returns the Requests tuple auth for a given url from netrc.

**Param√®tres :**

- `url`
- `raise_errors`

##### guess_filename

Tries to guess the filename of the given object.

**Param√®tres :**

- `obj`

##### extract_zipped_paths

Replace nonexistent paths that look like they refer to a member of a zip
archive with the location of an extracted copy of the target, or else
just return the provided path unchanged.

**Param√®tres :**

- `path`

##### atomic_open

Write a file to the disk in an atomic fashion

**Param√®tres :**

- `filename`

##### from_key_val_list

Take an object and test to see if it can be represented as a
dictionary. Unless it can not be represented as such, return an
OrderedDict, e.g.,

::

    >>> from_key_val_list([('key', 'val')])
    OrderedDict([('key', 'val')])
    >>> from_key_val_list('string')
    Traceback (most recent call last):
    ...
    ValueError: cannot encode objects that are not 2-tuples
    >>> from_key_val_list({'key': 'val'})
    OrderedDict([('key', 'val')])

:rtype: OrderedDict

**Param√®tres :**

- `value`

##### to_key_val_list

Take an object and test to see if it can be represented as a
dictionary. If it can be, return a list of tuples, e.g.,

::

    >>> to_key_val_list([('key', 'val')])
    [('key', 'val')]
    >>> to_key_val_list({'key': 'val'})
    [('key', 'val')]
    >>> to_key_val_list('string')
    Traceback (most recent call last):
    ...
    ValueError: cannot encode objects that are not 2-tuples

:rtype: list

**Param√®tres :**

- `value`

##### parse_list_header

Parse lists as described by RFC 2068 Section 2.

In particular, parse comma-separated lists where the elements of
the list may include quoted-strings.  A quoted-string could
contain a comma.  A non-quoted string could have quotes in the
middle.  Quotes are removed automatically after parsing.

It basically works like :func:`parse_set_header` just that items
may appear multiple times and case sensitivity is preserved.

The return value is a standard :class:`list`:

>>> parse_list_header('token, "quoted value"')
['token', 'quoted value']

To create a header from the :class:`list` again, use the
:func:`dump_header` function.

:param value: a string with a list header.
:return: :class:`list`
:rtype: list

**Param√®tres :**

- `value`

##### parse_dict_header

Parse lists of key, value pairs as described by RFC 2068 Section 2 and
convert them into a python dict:

>>> d = parse_dict_header('foo="is a fish", bar="as well"')
>>> type(d) is dict
True
>>> sorted(d.items())
[('bar', 'as well'), ('foo', 'is a fish')]

If there is no value for a key it will be `None`:

>>> parse_dict_header('key_without_value')
{'key_without_value': None}

To create a header from the :class:`dict` again, use the
:func:`dump_header` function.

:param value: a string with a dict header.
:return: :class:`dict`
:rtype: dict

**Param√®tres :**

- `value`

##### unquote_header_value

Unquotes a header value.  (Reversal of :func:`quote_header_value`).
This does not use the real unquoting but what browsers are actually
using for quoting.

:param value: the header value to unquote.
:rtype: str

**Param√®tres :**

- `value`
- `is_filename`

##### dict_from_cookiejar

Returns a key/value dictionary from a CookieJar.

:param cj: CookieJar object to extract cookies from.
:rtype: dict

**Param√®tres :**

- `cj`

##### add_dict_to_cookiejar

Returns a CookieJar from a key/value dictionary.

:param cj: CookieJar to insert cookies into.
:param cookie_dict: Dict of key/values to insert into CookieJar.
:rtype: CookieJar

**Param√®tres :**

- `cj`
- `cookie_dict`

##### get_encodings_from_content

Returns encodings from given content string.

:param content: bytestring to extract encodings from.

**Param√®tres :**

- `content`

##### _parse_content_type_header

Returns content type and parameters from given header

:param header: string
:return: tuple containing content type and dictionary of
     parameters

**Param√®tres :**

- `header`

##### get_encoding_from_headers

Returns encodings from given HTTP Header Dict.

:param headers: dictionary to extract encoding from.
:rtype: str

**Param√®tres :**

- `headers`

##### stream_decode_response_unicode

Stream decodes an iterator.

**Param√®tres :**

- `iterator`
- `r`

##### iter_slices

Iterate over slices of a string.

**Param√®tres :**

- `string`
- `slice_length`

##### get_unicode_from_response

Returns the requested content back in unicode.

:param r: Response object to get unicode content from.

Tried:

1. charset from content-type
2. fall back and replace all unicode characters

:rtype: str

**Param√®tres :**

- `r`

##### unquote_unreserved

Un-escape any percent-escape sequences in a URI that are unreserved
characters. This leaves all reserved, illegal and non-ASCII bytes encoded.

:rtype: str

**Param√®tres :**

- `uri`

##### requote_uri

Re-quote the given URI.

This function passes the given URI through an unquote/quote cycle to
ensure that it is fully and consistently quoted.

:rtype: str

**Param√®tres :**

- `uri`

##### address_in_network

This function allows you to check if an IP belongs to a network subnet

Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24
         returns False if ip = 192.168.1.1 and net = 192.168.100.0/24

:rtype: bool

**Param√®tres :**

- `ip`
- `net`

##### dotted_netmask

Converts mask from /xx format to xxx.xxx.xxx.xxx

Example: if mask is 24 function returns 255.255.255.0

:rtype: str

**Param√®tres :**

- `mask`

##### is_ipv4_address

:rtype: bool

**Param√®tres :**

- `string_ip`

##### is_valid_cidr

Very simple check of the cidr format in no_proxy variable.

:rtype: bool

**Param√®tres :**

- `string_network`

##### set_environ

Set the environment variable 'env_name' to 'value'

Save previous value, yield, and then restore the previous value stored in
the environment variable 'env_name'.

If 'value' is None, do nothing

**Param√®tres :**

- `env_name`
- `value`

##### should_bypass_proxies

Returns whether we should bypass proxies or not.

:rtype: bool

**Param√®tres :**

- `url`
- `no_proxy`

##### get_environ_proxies

Return a dict of environment proxies.

:rtype: dict

**Param√®tres :**

- `url`
- `no_proxy`

##### select_proxy

Select a proxy for the url, if applicable.

:param url: The url being for the request
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs

**Param√®tres :**

- `url`
- `proxies`

##### resolve_proxies

This method takes proxy information from a request and configuration
input to resolve a mapping of target proxies. This will consider settings
such as NO_PROXY to strip proxy configurations.

:param request: Request or PreparedRequest
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
:param trust_env: Boolean declaring whether to trust environment configs

:rtype: dict

**Param√®tres :**

- `request`
- `proxies`
- `trust_env`

##### default_user_agent

Return a string representing the default user agent.

:rtype: str

**Param√®tres :**

- `name`

##### default_headers

:rtype: requests.structures.CaseInsensitiveDict

##### parse_header_links

Return a list of parsed link headers proxies.

i.e. Link: <http:/.../front.jpeg>; rel=front; type="image/jpeg",<http://.../back.jpeg>; rel=back;type="image/jpeg"

:rtype: list

**Param√®tres :**

- `value`

##### guess_json_utf

:rtype: str

**Param√®tres :**

- `data`

##### prepend_scheme_if_needed

Given a URL that may or may not have a scheme, prepend the given scheme.
Does not replace a present scheme with the one provided as an argument.

:rtype: str

**Param√®tres :**

- `url`
- `new_scheme`

##### get_auth_from_url

Given a url with authentication components, extract them into a tuple of
username,password.

:rtype: (str,str)

**Param√®tres :**

- `url`

##### check_header_validity

Verifies that header parts don't contain leading whitespace
reserved characters, or return characters.

:param header: tuple, in the format (name, value).

**Param√®tres :**

- `header`

##### _validate_header_part

**Param√®tres :**

- `header`
- `header_part`
- `header_validator_index`

##### urldefragauth

Given a url remove the fragment and the authentication part.

:rtype: str

**Param√®tres :**

- `url`

##### rewind_body

Move file pointer back to its recorded starting position
so it can be read again on redirect.

**Param√®tres :**

- `prepared_request`

##### proxy_bypass_registry

**Param√®tres :**

- `host`

##### proxy_bypass

Return True, if the host should be bypassed.

Checks proxy settings gathered from the environment, if specified,
or the registry.

**Param√®tres :**

- `host`

##### get_proxy

**Param√®tres :**

- `key`

---

### .!23719!__init__

---

### .!23724!__version__

---

### .!23729!_internal_utils

---

### .!23735!adapters

---

### .!23747!certs

---

### .!23751!compat

---

### .!23756!cookies

---

### .!23761!exceptions

---

### .!23770!hooks

---

### .!23774!models

---

### .!23779!packages

---

### .!23784!sessions

---

### .!23790!status_codes

---

### .!23794!structures

---

### .!23799!utils

---

### providers

#### Classes

##### AbstractProvider

Delegate class to provide the required interface for the resolver.

**M√©thodes :**

- `identify()`
- `get_preference()`
- `find_matches()`
- `is_satisfied_by()`
- `get_dependencies()`
- `narrow_requirement_selection()`

##### Preference

**M√©thodes :**

- `__lt__()`

#### Fonctions

##### identify

Given a requirement or candidate, return an identifier for it.

This is used to identify, e.g. whether two requirements
should have their specifier parts merged or a candidate matches a
requirement via ``find_matches()``.

**Param√®tres :**

- `requirement_or_candidate`

##### get_preference

Produce a sort key for given requirement based on preference.

As this is a sort key it will be called O(n) times per backtrack
step, where n is the number of `identifier`s, if you have a check
which is expensive in some sense. E.g. It needs to make O(n) checks
per call or takes significant wall clock time, consider using
`narrow_requirement_selection` to filter the `identifier`s, which
is applied before this sort key is called.

The preference is defined as "I think this requirement should be
resolved first". The lower the return value is, the more preferred
this group of arguments is.

:param identifier: An identifier as returned by ``identify()``. This
    identifies the requirement being considered.
:param resolutions: Mapping of candidates currently pinned by the
    resolver. Each key is an identifier, and the value is a candidate.
    The candidate may conflict with requirements from ``information``.
:param candidates: Mapping of each dependency's possible candidates.
    Each value is an iterator of candidates.
:param information: Mapping of requirement information of each package.
    Each value is an iterator of *requirement information*.
:param backtrack_causes: Sequence of *requirement information* that are
    the requirements that caused the resolver to most recently
    backtrack.

A *requirement information* instance is a named tuple with two members:

* ``requirement`` specifies a requirement contributing to the current
  list of candidates.
* ``parent`` specifies the candidate that provides (depended on) the
  requirement, or ``None`` to indicate a root requirement.

The preference could depend on various issues, including (not
necessarily in this order):

* Is this package pinned in the current resolution result?
* How relaxed is the requirement? Stricter ones should probably be
  worked on first? (I don't know, actually.)
* How many possibilities are there to satisfy this requirement? Those
  with few left should likely be worked on first, I guess?
* Are there any known conflicts for this requirement? We should
  probably work on those with the most known conflicts.

A sortable value should be returned (this will be used as the ``key``
parameter of the built-in sorting function). The smaller the value is,
the more preferred this requirement is (i.e. the sorting function
is called with ``reverse=False``).

**Param√®tres :**

- `identifier`
- `resolutions`
- `candidates`
- `information`
- `backtrack_causes`

##### find_matches

Find all possible candidates that satisfy the given constraints.

:param identifier: An identifier as returned by ``identify()``. All
    candidates returned by this method should produce the same
    identifier.
:param requirements: A mapping of requirements that all returned
    candidates must satisfy. Each key is an identifier, and the value
    an iterator of requirements for that dependency.
:param incompatibilities: A mapping of known incompatibile candidates of
    each dependency. Each key is an identifier, and the value an
    iterator of incompatibilities known to the resolver. All
    incompatibilities *must* be excluded from the return value.

This should try to get candidates based on the requirements' types.
For VCS, local, and archive requirements, the one-and-only match is
returned, and for a "named" requirement, the index(es) should be
consulted to find concrete candidates for this requirement.

The return value should produce candidates ordered by preference; the
most preferred candidate should come first. The return type may be one
of the following:

* A callable that returns an iterator that yields candidates.
* An collection of candidates.
* An iterable of candidates. This will be consumed immediately into a
  list of candidates.

**Param√®tres :**

- `identifier`
- `requirements`
- `incompatibilities`

##### is_satisfied_by

Whether the given requirement can be satisfied by a candidate.

The candidate is guaranteed to have been generated from the
requirement.

A boolean should be returned to indicate whether ``candidate`` is a
viable solution to the requirement.

**Param√®tres :**

- `requirement`
- `candidate`

##### get_dependencies

Get dependencies of a candidate.

This should return a collection of requirements that `candidate`
specifies as its dependencies.

**Param√®tres :**

- `candidate`

##### narrow_requirement_selection

An optional method to narrow the selection of requirements being
considered during resolution. This method is called O(1) time per
backtrack step.

:param identifiers: An iterable of `identifiers` as returned by
    ``identify()``. These identify all requirements currently being
    considered.
:param resolutions: A mapping of candidates currently pinned by the
    resolver. Each key is an identifier, and the value is a candidate
    that may conflict with requirements from ``information``.
:param candidates: A mapping of each dependency's possible candidates.
    Each value is an iterator of candidates.
:param information: A mapping of requirement information for each package.
    Each value is an iterator of *requirement information*.
:param backtrack_causes: A sequence of *requirement information* that are
    the requirements causing the resolver to most recently
    backtrack.

A *requirement information* instance is a named tuple with two members:

* ``requirement`` specifies a requirement contributing to the current
  list of candidates.
* ``parent`` specifies the candidate that provides (is depended on for)
  the requirement, or ``None`` to indicate a root requirement.

Must return a non-empty subset of `identifiers`, with the default
implementation being to return `identifiers` unchanged. Those `identifiers`
will then be passed to the sort key `get_preference` to pick the most
prefered requirement to attempt to pin, unless `narrow_requirement_selection`
returns only 1 requirement, in which case that will be used without
calling the sort key `get_preference`.

This method is designed to be used by the provider to optimize the
dependency resolution, e.g. if a check cost is O(m) and it can be done
against all identifiers at once then filtering the requirement selection
here will cost O(m) but making it part of the sort key in `get_preference`
will cost O(m*n), where n is the number of `identifiers`.

Returns:
    Iterable[KT]: A non-empty subset of `identifiers`.

**Param√®tres :**

- `identifiers`
- `resolutions`
- `candidates`
- `information`
- `backtrack_causes`

##### __lt__

**Param√®tres :**

- `__other`

---

### reporters

#### Classes

##### BaseReporter

Delegate class to provider progress reporting for the resolver.

**M√©thodes :**

- `starting()`
- `starting_round()`
- `ending_round()`
- `ending()`
- `adding_requirement()`
- `resolving_conflicts()`
- `rejecting_candidate()`
- `pinning()`

#### Fonctions

##### starting

Called before the resolution actually starts.

##### starting_round

Called before each round of resolution starts.

The index is zero-based.

**Param√®tres :**

- `index`

##### ending_round

Called before each round of resolution ends.

This is NOT called if the resolution ends at this round. Use `ending`
if you want to report finalization. The index is zero-based.

**Param√®tres :**

- `index`
- `state`

##### ending

Called before the resolution ends successfully.

**Param√®tres :**

- `state`

##### adding_requirement

Called when adding a new requirement into the resolve criteria.

:param requirement: The additional requirement to be applied to filter
    the available candidaites.
:param parent: The candidate that requires ``requirement`` as a
    dependency, or None if ``requirement`` is one of the root
    requirements passed in from ``Resolver.resolve()``.

**Param√®tres :**

- `requirement`
- `parent`

##### resolving_conflicts

Called when starting to attempt requirement conflict resolution.

:param causes: The information on the collision that caused the backtracking.

**Param√®tres :**

- `causes`

##### rejecting_candidate

Called when rejecting a candidate during backtracking.

**Param√®tres :**

- `criterion`
- `candidate`

##### pinning

Called when adding a candidate to the potential solution.

**Param√®tres :**

- `candidate`

---

### structs

#### Classes

##### DirectedGraph

A graph structure with directed edges.

**M√©thodes :**

- `__init__()`
- `__iter__()`
- `__len__()`
- `__contains__()`
- `copy()`
- `add()`
- `remove()`
- `connected()`
- `connect()`
- `iter_edges()`
- `iter_children()`
- `iter_parents()`

##### IteratorMapping

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__bool__()`
- `__contains__()`
- `__getitem__()`
- `__iter__()`
- `__len__()`

##### _FactoryIterableView

Wrap an iterator factory returned by `find_matches()`.

Calling `iter()` on this class would invoke the underlying iterator
factory, making it a "collection with ordering" that can be iterated
through multiple times, but lacks random access methods presented in
built-in Python sequence types.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__bool__()`
- `__iter__()`

##### _SequenceIterableView

Wrap an iterable returned by find_matches().

This is essentially just a proxy to the underlying sequence that provides
the same interface as `_FactoryIterableView`.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__bool__()`
- `__iter__()`

##### RequirementInformation

##### State

Resolution state in a round.

#### Fonctions

##### build_iter_view

Build an iterable view from the value returned by `find_matches()`.

**Param√®tres :**

- `matches`

##### __init__

##### __iter__

##### __len__

##### __contains__

**Param√®tres :**

- `key`

##### copy

Return a shallow copy of this graph.

##### add

Add a new vertex to the graph.

**Param√®tres :**

- `key`

##### remove

Remove a vertex from the graph, disconnecting all edges from/to it.

**Param√®tres :**

- `key`

##### connected

**Param√®tres :**

- `f`
- `t`

##### connect

Connect two existing vertices.

Nothing happens if the vertices are already connected.

**Param√®tres :**

- `f`
- `t`

##### iter_edges

##### iter_children

**Param√®tres :**

- `key`

##### iter_parents

**Param√®tres :**

- `key`

##### __init__

**Param√®tres :**

- `mapping`
- `accessor`
- `appends`

##### __repr__

##### __bool__

##### __contains__

**Param√®tres :**

- `key`

##### __getitem__

**Param√®tres :**

- `k`

##### __iter__

##### __len__

##### __init__

**Param√®tres :**

- `factory`

##### __repr__

##### __bool__

##### __iter__

##### __init__

**Param√®tres :**

- `sequence`

##### __repr__

##### __bool__

##### __iter__

---

### .!23806!__init__

---

### .!23812!providers

---

### .!23816!reporters

---

### .!23822!structs

---

### abstract

#### Classes

##### AbstractResolver

The thing that performs the actual resolution work.

**M√©thodes :**

- `__init__()`
- `resolve()`

##### Result

#### Fonctions

##### __init__

**Param√®tres :**

- `provider`
- `reporter`

##### resolve

Take a collection of constraints, spit out the resolution result.

This returns a representation of the final resolution state, with one
guarenteed attribute ``mapping`` that contains resolved candidates as
values. The keys are their respective identifiers.

:param requirements: A collection of constraints.
:param kwargs: Additional keyword arguments that subclasses may accept.

:raises: ``self.base_exception`` or its subclass.

**Param√®tres :**

- `requirements`

---

### criterion

#### Classes

##### Criterion

Representation of possible resolution results of a package.

This holds three attributes:

* `information` is a collection of `RequirementInformation` pairs.
  Each pair is a requirement contributing to this criterion, and the
  candidate that provides the requirement.
* `incompatibilities` is a collection of all known not-to-work candidates
  to exclude from consideration.
* `candidates` is a collection containing all possible candidates deducted
  from the union of contributing requirements and known incompatibilities.
  It should never be empty, except when the criterion is an attribute of a
  raised `RequirementsConflicted` (in which case it is always empty).

.. note::
    This class is intended to be externally immutable. **Do not** mutate
    any of its attribute containers.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `iter_requirement()`
- `iter_parent()`

#### Fonctions

##### __init__

**Param√®tres :**

- `candidates`
- `information`
- `incompatibilities`

##### __repr__

##### iter_requirement

##### iter_parent

---

### exceptions

#### Classes

##### ResolverException

A base class for all exceptions raised by this module.

Exceptions derived by this class should all be handled in this module. Any
bubbling pass the resolver should be treated as a bug.

##### RequirementsConflicted

**M√©thodes :**

- `__init__()`
- `__str__()`

##### InconsistentCandidate

**M√©thodes :**

- `__init__()`
- `__str__()`

##### ResolutionError

##### ResolutionImpossible

**M√©thodes :**

- `__init__()`

##### ResolutionTooDeep

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `criterion`

##### __str__

##### __init__

**Param√®tres :**

- `candidate`
- `criterion`

##### __str__

##### __init__

**Param√®tres :**

- `causes`

##### __init__

**Param√®tres :**

- `round_count`

---

### resolution

#### Classes

##### Resolution

Stateful resolution object.

This is designed as a one-off object that holds information to kick start
the resolution process, and holds the results afterwards.

**M√©thodes :**

- `__init__()`
- `state()`
- `_push_new_state()`
- `_add_to_criteria()`
- `_remove_information_from_criteria()`
- `_get_preference()`
- `_is_current_pin_satisfying()`
- `_get_updated_criteria()`
- `_attempt_to_pin_criterion()`
- `_patch_criteria()`
- `_backjump()`
- `_extract_causes()`
- `resolve()`

##### Resolver

The thing that performs the actual resolution work.

**M√©thodes :**

- `resolve()`

#### Fonctions

##### _build_result

**Param√®tres :**

- `state`

##### _has_route_to_root

**Param√®tres :**

- `criteria`
- `key`
- `all_keys`
- `connected`

##### __init__

**Param√®tres :**

- `provider`
- `reporter`

##### state

##### _push_new_state

Push a new state into history.

This new state will be used to hold resolution results of the next
coming round.

##### _add_to_criteria

**Param√®tres :**

- `criteria`
- `requirement`
- `parent`

##### _remove_information_from_criteria

Remove information from parents of criteria.

Concretely, removes all values from each criterion's ``information``
field that have one of ``parents`` as provider of the requirement.

:param criteria: The criteria to update.
:param parents: Identifiers for which to remove information from all criteria.

**Param√®tres :**

- `criteria`
- `parents`

##### _get_preference

**Param√®tres :**

- `name`

##### _is_current_pin_satisfying

**Param√®tres :**

- `name`
- `criterion`

##### _get_updated_criteria

**Param√®tres :**

- `candidate`

##### _attempt_to_pin_criterion

**Param√®tres :**

- `name`

##### _patch_criteria

**Param√®tres :**

- `incompatibilities_from_broken`

##### _backjump

Perform backjumping.

When we enter here, the stack is like this::

    [ state Z ]
    [ state Y ]
    [ state X ]
    .... earlier states are irrelevant.

1. No pins worked for Z, so it does not have a pin.
2. We want to reset state Y to unpinned, and pin another candidate.
3. State X holds what state Y was before the pin, but does not
   have the incompatibility information gathered in state Y.

Each iteration of the loop will:

1.  Identify Z. The incompatibility is not always caused by the latest
    state. For example, given three requirements A, B and C, with
    dependencies A1, B1 and C1, where A1 and B1 are incompatible: the
    last state might be related to C, so we want to discard the
    previous state.
2.  Discard Z.
3.  Discard Y but remember its incompatibility information gathered
    previously, and the failure we're dealing with right now.
4.  Push a new state Y' based on X, and apply the incompatibility
    information from Y to Y'.
5a. If this causes Y' to conflict, we need to backtrack again. Make Y'
    the new Z and go back to step 2.
5b. If the incompatibilities apply cleanly, end backtracking.

**Param√®tres :**

- `causes`

##### _extract_causes

Extract causes from list of criterion and deduplicate

**Param√®tres :**

- `criteron`

##### resolve

**Param√®tres :**

- `requirements`
- `max_rounds`

##### resolve

Take a collection of constraints, spit out the resolution result.

The return value is a representation to the final resolution result. It
is a tuple subclass with three public members:

* `mapping`: A dict of resolved candidates. Each key is an identifier
    of a requirement (as returned by the provider's `identify` method),
    and the value is the resolved candidate.
* `graph`: A `DirectedGraph` instance representing the dependency tree.
    The vertices are keys of `mapping`, and each edge represents *why*
    a particular package is included. A special vertex `None` is
    included to represent parents of user-supplied requirements.
* `criteria`: A dict of "criteria" that hold detailed information on
    how edges in the graph are derived. Each key is an identifier of a
    requirement, and the value is a `Criterion` instance.

The following exceptions may be raised if a resolution cannot be found:

* `ResolutionImpossible`: A resolution cannot be found for the given
    combination of requirements. The `causes` attribute of the
    exception is a list of (requirement, parent), giving the
    requirements that could not be satisfied.
* `ResolutionTooDeep`: The dependency tree is too deeply nested and
    the resolver gave up. This is usually caused by a circular
    dependency, but you can try to resolve this by increasing the
    `max_rounds` argument.

**Param√®tres :**

- `requirements`
- `max_rounds`

---

### .!23827!__init__

---

### .!23833!abstract

---

### .!23837!criterion

---

### .!23842!exceptions

---

### .!23849!resolution

---

### __main__

#### Classes

##### ColorBox

**M√©thodes :**

- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### make_test_card

Get a renderable that demonstrates a number of features.

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### comparison

**Param√®tres :**

- `renderable1`
- `renderable2`

---

### _cell_widths

---

### _emoji_codes

---

### _emoji_replace

#### Fonctions

##### _emoji_replace

Replace emoji code in text.

**Param√®tres :**

- `text`
- `default_variant`
- `_emoji_sub`

##### do_replace

**Param√®tres :**

- `match`

---

### _export_format

---

### _extension

#### Fonctions

##### load_ipython_extension

**Param√®tres :**

- `ip`

---

### _fileno

#### Fonctions

##### get_fileno

Get fileno() from a file, accounting for poorly implemented file-like objects.

Args:
    file_like (IO): A file-like object.

Returns:
    int | None: The result of fileno if available, or None if operation failed.

**Param√®tres :**

- `file_like`

---

### _inspect

#### Classes

##### Inspect

A renderable to inspect any Python Object.

Args:
    obj (Any): An object to inspect.
    title (str, optional): Title to display over inspect result, or None use type. Defaults to None.
    help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.
    methods (bool, optional): Enable inspection of callables. Defaults to False.
    docs (bool, optional): Also render doc strings. Defaults to True.
    private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.
    dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.
    sort (bool, optional): Sort attributes alphabetically. Defaults to True.
    all (bool, optional): Show all attributes. Defaults to False.
    value (bool, optional): Pretty print value of object. Defaults to True.

**M√©thodes :**

- `__init__()`
- `_make_title()`
- `__rich__()`
- `_get_signature()`
- `_render()`
- `_get_formatted_doc()`

#### Fonctions

##### _first_paragraph

Get the first paragraph from a docstring.

**Param√®tres :**

- `doc`

##### get_object_types_mro

Returns the MRO of an object's class, or of the object itself if it's a class.

**Param√®tres :**

- `obj`

##### get_object_types_mro_as_strings

Returns the MRO of an object's class as full qualified names, or of the object itself if it's a class.

Examples:
    `object_types_mro_as_strings(JSONDecoder)` will return `['json.decoder.JSONDecoder', 'builtins.object']`

**Param√®tres :**

- `obj`

##### is_object_one_of_types

Returns `True` if the given object's class (or the object itself, if it's a class) has one of the
fully qualified names in its MRO.

**Param√®tres :**

- `obj`
- `fully_qualified_types_names`

##### __init__

**Param√®tres :**

- `obj`

##### _make_title

Make a default title.

**Param√®tres :**

- `obj`

##### __rich__

##### _get_signature

Get a signature for a callable.

**Param√®tres :**

- `name`
- `obj`

##### _render

Render object.

##### _get_formatted_doc

Extract the docstring of an object, process it and returns it.
The processing consists in cleaning up the doctring's indentation,
taking only its 1st paragraph if `self.help` is not True,
and escape its control codes.

Args:
    object_ (Any): the object to get the docstring from.

Returns:
    Optional[str]: the processed docstring, or None if no docstring was found.

**Param√®tres :**

- `object_`

##### sort_items

**Param√®tres :**

- `item`

##### safe_getattr

Get attribute or any exception.

**Param√®tres :**

- `attr_name`

---

### _log_render

#### Classes

##### LogRender

**M√©thodes :**

- `__init__()`
- `__call__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `show_time`
- `show_level`
- `show_path`
- `time_format`
- `omit_repeated_times`
- `level_width`

##### __call__

**Param√®tres :**

- `console`
- `renderables`
- `log_time`
- `time_format`
- `level`
- `path`
- `line_no`
- `link_path`

---

### _loop

#### Fonctions

##### loop_first

Iterate and generate a tuple with a flag for first value.

**Param√®tres :**

- `values`

##### loop_last

Iterate and generate a tuple with a flag for last value.

**Param√®tres :**

- `values`

##### loop_first_last

Iterate and generate a tuple with a flag for first and last value.

**Param√®tres :**

- `values`

---

### _null_file

#### Classes

##### NullFile

**M√©thodes :**

- `close()`
- `isatty()`
- `read()`
- `readable()`
- `readline()`
- `readlines()`
- `seek()`
- `seekable()`
- `tell()`
- `truncate()`
- `writable()`
- `writelines()`
- `__next__()`
- `__iter__()`
- `__enter__()`
- `__exit__()`
- `write()`
- `flush()`
- `fileno()`

#### Fonctions

##### close

##### isatty

##### read

**Param√®tres :**

- `__n`

##### readable

##### readline

**Param√®tres :**

- `__limit`

##### readlines

**Param√®tres :**

- `__hint`

##### seek

**Param√®tres :**

- `__offset`
- `__whence`

##### seekable

##### tell

##### truncate

**Param√®tres :**

- `__size`

##### writable

##### writelines

**Param√®tres :**

- `__lines`

##### __next__

##### __iter__

##### __enter__

##### __exit__

**Param√®tres :**

- `__t`
- `__value`
- `__traceback`

##### write

**Param√®tres :**

- `text`

##### flush

##### fileno

---

### _palettes

---

### _pick

#### Fonctions

##### pick_bool

Pick the first non-none bool or return the last value.

Args:
    *values (bool): Any number of boolean or None values.

Returns:
    bool: First non-none boolean.

---

### _ratio

#### Classes

##### Edge

Any object that defines an edge (such as Layout).

##### E

#### Fonctions

##### ratio_resolve

Divide total space to satisfy size, ratio, and minimum_size, constraints.

The returned list of integers should add up to total in most cases, unless it is
impossible to satisfy all the constraints. For instance, if there are two edges
with a minimum size of 20 each and `total` is 30 then the returned list will be
greater than total. In practice, this would mean that a Layout object would
clip the rows that would overflow the screen height.

Args:
    total (int): Total number of characters.
    edges (List[Edge]): Edges within total space.

Returns:
    List[int]: Number of characters for each edge.

**Param√®tres :**

- `total`
- `edges`

##### ratio_reduce

Divide an integer total in to parts based on ratios.

Args:
    total (int): The total to divide.
    ratios (List[int]): A list of integer ratios.
    maximums (List[int]): List of maximums values for each slot.
    values (List[int]): List of values

Returns:
    List[int]: A list of integers guaranteed to sum to total.

**Param√®tres :**

- `total`
- `ratios`
- `maximums`
- `values`

##### ratio_distribute

Distribute an integer total in to parts based on ratios.

Args:
    total (int): The total to divide.
    ratios (List[int]): A list of integer ratios.
    minimums (List[int]): List of minimum values for each slot.

Returns:
    List[int]: A list of integers guaranteed to sum to total.

**Param√®tres :**

- `total`
- `ratios`
- `minimums`

---

### _spinners

Spinners are from:
* cli-spinners:
    MIT License
    Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
    Permission is hereby granted, free of charge, to any person obtaining a copy
    of this software and associated documentation files (the "Software"), to deal
    in the Software without restriction, including without limitation the rights to
    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
    the Software, and to permit persons to whom the Software is furnished to do so,
    subject to the following conditions:
    The above copyright notice and this permission notice shall be included
    in all copies or substantial portions of the Software.
    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
    INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR
    PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE
    FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
    ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
    IN THE SOFTWARE.

---

### .!23959!abc

---

### .!23967!ansi

---

### _stack

#### Classes

##### Stack

A small shim over builtin list.

**M√©thodes :**

- `top()`
- `push()`

#### Fonctions

##### top

Get top of stack.

##### push

Push an item on to the stack (append in stack nomenclature).

**Param√®tres :**

- `item`

---

### .!23972!bar

---

### _timer

Timer context manager, only used in debug.

#### Fonctions

##### timer

print the elapsed time. (only used in debugging)

**Param√®tres :**

- `subject`

---

### .!23977!box

---

### _win32_console

Light wrapper around the Win32 Console API - this module should only be imported on Windows

The API that this module wraps is documented at https://docs.microsoft.com/en-us/windows/console/console-functions

#### Classes

##### LegacyWindowsError

##### WindowsCoordinates

Coordinates in the Windows Console API are (y, x), not (x, y).
This class is intended to prevent that confusion.
Rows and columns are indexed from 0.
This class can be used in place of wintypes._COORD in arguments and argtypes.

**M√©thodes :**

- `from_param()`

##### CONSOLE_SCREEN_BUFFER_INFO

##### CONSOLE_CURSOR_INFO

##### LegacyWindowsTerm

This class allows interaction with the legacy Windows Console API. It should only be used in the context
of environments where virtual terminal processing is not available. However, if it is used in a Windows environment,
the entire API should work.

Args:
    file (IO[str]): The file which the Windows Console API HANDLE is retrieved from, defaults to sys.stdout.

**M√©thodes :**

- `__init__()`
- `cursor_position()`
- `screen_size()`
- `write_text()`
- `write_styled()`
- `move_cursor_to()`
- `erase_line()`
- `erase_end_of_line()`
- `erase_start_of_line()`
- `move_cursor_up()`
- `move_cursor_down()`
- `move_cursor_forward()`
- `move_cursor_to_column()`
- `move_cursor_backward()`
- `hide_cursor()`
- `show_cursor()`
- `set_title()`
- `_get_cursor_size()`

#### Fonctions

##### GetStdHandle

Retrieves a handle to the specified standard device (standard input, standard output, or standard error).

Args:
    handle (int): Integer identifier for the handle. Defaults to -11 (stdout).

Returns:
    wintypes.HANDLE: The handle

**Param√®tres :**

- `handle`

##### GetConsoleMode

Retrieves the current input mode of a console's input buffer
or the current output mode of a console screen buffer.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Raises:
    LegacyWindowsError: If any error occurs while calling the Windows console API.

Returns:
    int: Value representing the current console mode as documented at
        https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters

**Param√®tres :**

- `std_handle`

##### FillConsoleOutputCharacter

Writes a character to the console screen buffer a specified number of times, beginning at the specified coordinates.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    char (str): The character to write. Must be a string of length 1.
    length (int): The number of times to write the character.
    start (WindowsCoordinates): The coordinates to start writing at.

Returns:
    int: The number of characters written.

**Param√®tres :**

- `std_handle`
- `char`
- `length`
- `start`

##### FillConsoleOutputAttribute

Sets the character attributes for a specified number of character cells,
beginning at the specified coordinates in a screen buffer.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    attributes (int): Integer value representing the foreground and background colours of the cells.
    length (int): The number of cells to set the output attribute of.
    start (WindowsCoordinates): The coordinates of the first cell whose attributes are to be set.

Returns:
    int: The number of cells whose attributes were actually set.

**Param√®tres :**

- `std_handle`
- `attributes`
- `length`
- `start`

##### SetConsoleTextAttribute

Set the colour attributes for all text written after this function is called.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    attributes (int): Integer value representing the foreground and background colours.


Returns:
    bool: True if the attribute was set successfully, otherwise False.

**Param√®tres :**

- `std_handle`
- `attributes`

##### GetConsoleScreenBufferInfo

Retrieves information about the specified console screen buffer.

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.

Returns:
    CONSOLE_SCREEN_BUFFER_INFO: A CONSOLE_SCREEN_BUFFER_INFO ctype struct contain information about
        screen size, cursor position, colour attributes, and more.

**Param√®tres :**

- `std_handle`

##### SetConsoleCursorPosition

Set the position of the cursor in the console screen

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    coords (WindowsCoordinates): The coordinates to move the cursor to.

Returns:
    bool: True if the function succeeds, otherwise False.

**Param√®tres :**

- `std_handle`
- `coords`

##### GetConsoleCursorInfo

Get the cursor info - used to get cursor visibility and width

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct that receives information
        about the console's cursor.

Returns:
      bool: True if the function succeeds, otherwise False.

**Param√®tres :**

- `std_handle`
- `cursor_info`

##### SetConsoleCursorInfo

Set the cursor info - used for adjusting cursor visibility and width

Args:
    std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
    cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct containing the new cursor info.

Returns:
      bool: True if the function succeeds, otherwise False.

**Param√®tres :**

- `std_handle`
- `cursor_info`

##### SetConsoleTitle

Sets the title of the current console window

Args:
    title (str): The new title of the console window.

Returns:
    bool: True if the function succeeds, otherwise False.

**Param√®tres :**

- `title`

##### from_param

Converts a WindowsCoordinates into a wintypes _COORD structure.
This classmethod is internally called by ctypes to perform the conversion.

Args:
    value (WindowsCoordinates): The input coordinates to convert.

Returns:
    wintypes._COORD: The converted coordinates struct.

**Param√®tres :**

- `cls`
- `value`

##### __init__

**Param√®tres :**

- `file`

##### cursor_position

Returns the current position of the cursor (0-based)

Returns:
    WindowsCoordinates: The current cursor position.

##### screen_size

Returns the current size of the console screen buffer, in character columns and rows

Returns:
    WindowsCoordinates: The width and height of the screen as WindowsCoordinates.

##### write_text

Write text directly to the terminal without any modification of styles

Args:
    text (str): The text to write to the console

**Param√®tres :**

- `text`

##### write_styled

Write styled text to the terminal.

Args:
    text (str): The text to write
    style (Style): The style of the text

**Param√®tres :**

- `text`
- `style`

##### move_cursor_to

Set the position of the cursor

Args:
    new_position (WindowsCoordinates): The WindowsCoordinates representing the new position of the cursor.

**Param√®tres :**

- `new_position`

##### erase_line

Erase all content on the line the cursor is currently located at

##### erase_end_of_line

Erase all content from the cursor position to the end of that line

##### erase_start_of_line

Erase all content from the cursor position to the start of that line

##### move_cursor_up

Move the cursor up a single cell

##### move_cursor_down

Move the cursor down a single cell

##### move_cursor_forward

Move the cursor forward a single cell. Wrap to the next line if required.

##### move_cursor_to_column

Move cursor to the column specified by the zero-based column index, staying on the same row

Args:
    column (int): The zero-based column index to move the cursor to.

**Param√®tres :**

- `column`

##### move_cursor_backward

Move the cursor backward a single cell. Wrap to the previous line if required.

##### hide_cursor

Hide the cursor

##### show_cursor

Show the cursor

##### set_title

Set the title of the terminal window

Args:
    title (str): The new title of the console window

**Param√®tres :**

- `title`

##### _get_cursor_size

Get the percentage of the character cell that is filled by the cursor

---

### _windows

#### Classes

##### WindowsConsoleFeatures

Windows features available.

#### Fonctions

##### get_windows_console_features

Get windows console features.

Returns:
    WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.

##### get_windows_console_features

---

### .!24050!json

---

### .!24065!live

---

### _wrap

#### Fonctions

##### words

Yields each word from the text as a tuple
containing (start_index, end_index, word). A "word" in this context may
include the actual word and any whitespace to the right.

**Param√®tres :**

- `text`

##### divide_line

Given a string of text, and a width (measured in cells), return a list
of cell offsets which the string should be split at in order for it to fit
within the given width.

Args:
    text: The text to examine.
    width: The available cell width.
    fold: If True, words longer than `width` will be folded onto a new line.

Returns:
    A list of indices to break the line at.

**Param√®tres :**

- `text`
- `width`
- `fold`

---

### .!24141!repr

---

### .!24145!rule

---

### abc

#### Classes

##### RichRenderable

An abstract base class for Rich renderables.

Note that there is no need to extend this class, the intended use is to check if an
object supports the Rich renderable protocol. For example::

    if isinstance(my_object, RichRenderable):
        console.print(my_object)

**M√©thodes :**

- `__subclasshook__()`

##### Foo

#### Fonctions

##### __subclasshook__

Check if this class supports the rich render protocol.

**Param√®tres :**

- `cls`
- `other`

---

### .!24200!text

---

### .!24220!tree

---

### _windows_renderer

#### Fonctions

##### legacy_windows_render

Makes appropriate Windows Console API calls based on the segments in the buffer.

Args:
    buffer (Iterable[Segment]): Iterable of Segments to convert to Win32 API calls.
    term (LegacyWindowsTerm): Used to call the Windows Console API.

**Param√®tres :**

- `buffer`
- `term`

---

### align

#### Classes

##### Align

Align a renderable by adding spaces if necessary.

Args:
    renderable (RenderableType): A console renderable.
    align (AlignMethod): One of "left", "center", or "right""
    style (StyleType, optional): An optional style to apply to the background.
    vertical (Optional[VerticalAlignMethod], optional): Optional vertical align, one of "top", "middle", or "bottom". Defaults to None.
    pad (bool, optional): Pad the right with spaces. Defaults to True.
    width (int, optional): Restrict contents to given width, or None to use default width. Defaults to None.
    height (int, optional): Set height of align renderable, or None to fit to contents. Defaults to None.

Raises:
    ValueError: if ``align`` is not one of the expected values.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `left()`
- `center()`
- `right()`
- `__rich_console__()`
- `__rich_measure__()`

##### VerticalCenter

Vertically aligns a renderable.

Warn:
    This class is deprecated and may be removed in a future version. Use Align class with
    `vertical="middle"`.

Args:
    renderable (RenderableType): A renderable object.
    style (StyleType, optional): An optional style to apply to the background. Defaults to None.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderable`
- `align`
- `style`

##### __repr__

##### left

Align a renderable to the left.

**Param√®tres :**

- `cls`
- `renderable`
- `style`

##### center

Align a renderable to the center.

**Param√®tres :**

- `cls`
- `renderable`
- `style`

##### right

Align a renderable to the right.

**Param√®tres :**

- `cls`
- `renderable`
- `style`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### __init__

**Param√®tres :**

- `renderable`
- `style`

##### __repr__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### generate_segments

##### blank_lines

**Param√®tres :**

- `count`

##### blank_lines

**Param√®tres :**

- `count`

---

### ansi

#### Classes

##### _AnsiToken

Result of ansi tokenized string.

##### AnsiDecoder

Translate ANSI code in to styled Text.

**M√©thodes :**

- `__init__()`
- `decode()`
- `decode_line()`

#### Fonctions

##### _ansi_tokenize

Tokenize a string in to plain text and ANSI codes.

Args:
    ansi_text (str): A String containing ANSI codes.

Yields:
    AnsiToken: A named tuple of (plain, sgr, osc)

**Param√®tres :**

- `ansi_text`

##### __init__

##### decode

Decode ANSI codes in an iterable of lines.

Args:
    lines (Iterable[str]): An iterable of lines of terminal output.

Yields:
    Text: Marked up Text.

**Param√®tres :**

- `terminal_text`

##### decode_line

Decode a line containing ansi codes.

Args:
    line (str): A line of terminal output.

Returns:
    Text: A Text instance marked up according to ansi codes.

**Param√®tres :**

- `line`

##### read

**Param√®tres :**

- `fd`

---

### bar

#### Classes

##### Bar

Renders a solid block bar.

Args:
    size (float): Value for the end of the bar.
    begin (float): Begin point (between 0 and size, inclusive).
    end (float): End point (between 0 and size, inclusive).
    width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.
    color (Union[Color, str], optional): Color of the bar. Defaults to "default".
    bgcolor (Union[Color, str], optional): Color of bar background. Defaults to "default".

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `size`
- `begin`
- `end`

##### __repr__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

---

### box

#### Classes

##### Box

Defines characters to render boxes.

‚îå‚îÄ‚î¨‚îê top
‚îÇ ‚îÇ‚îÇ head
‚îú‚îÄ‚îº‚î§ head_row
‚îÇ ‚îÇ‚îÇ mid
‚îú‚îÄ‚îº‚î§ row
‚îú‚îÄ‚îº‚î§ foot_row
‚îÇ ‚îÇ‚îÇ foot
‚îî‚îÄ‚î¥‚îò bottom

Args:
    box (str): Characters making up box.
    ascii (bool, optional): True if this box uses ascii characters only. Default is False.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__str__()`
- `substitute()`
- `get_plain_headed_box()`
- `get_top()`
- `get_row()`
- `get_bottom()`

#### Fonctions

##### __init__

**Param√®tres :**

- `box`

##### __repr__

##### __str__

##### substitute

Substitute this box for another if it won't render due to platform issues.

Args:
    options (ConsoleOptions): Console options used in rendering.
    safe (bool, optional): Substitute this for another Box if there are known problems
        displaying on the platform (currently only relevant on Windows). Default is True.

Returns:
    Box: A different Box or the same Box.

**Param√®tres :**

- `options`
- `safe`

##### get_plain_headed_box

If this box uses special characters for the borders of the header, then
return the equivalent box that does not.

Returns:
    Box: The most similar Box that doesn't use header-specific box characters.
        If the current Box already satisfies this criterion, then it's returned.

##### get_top

Get the top of a simple box.

Args:
    widths (List[int]): Widths of columns.

Returns:
    str: A string of box characters.

**Param√®tres :**

- `widths`

##### get_row

Get the top of a simple box.

Args:
    width (List[int]): Widths of columns.

Returns:
    str: A string of box characters.

**Param√®tres :**

- `widths`
- `level`
- `edge`

##### get_bottom

Get the bottom of a simple box.

Args:
    widths (List[int]): Widths of columns.

Returns:
    str: A string of box characters.

**Param√®tres :**

- `widths`

---

### cells

#### Fonctions

##### cached_cell_len

Get the number of cells required to display text.

This method always caches, which may use up a lot of memory. It is recommended to use
`cell_len` over this method.

Args:
    text (str): Text to display.

Returns:
    int: Get the number of cells required to display text.

**Param√®tres :**

- `text`

##### cell_len

Get the number of cells required to display text.

Args:
    text (str): Text to display.

Returns:
    int: Get the number of cells required to display text.

**Param√®tres :**

- `text`
- `_cell_len`

##### get_character_cell_size

Get the cell size of a character.

Args:
    character (str): A single character.

Returns:
    int: Number of cells (0, 1 or 2) occupied by that character.

**Param√®tres :**

- `character`

##### set_cell_size

Set the length of a string to fit within given number of cells.

**Param√®tres :**

- `text`
- `total`

##### chop_cells

Split text into lines such that each line fits within the available (cell) width.

Args:
    text: The text to fold such that it fits in the given width.
    width: The width available (number of cells).

Returns:
    A list of strings such that each string in the list has cell width
    less than or equal to the available width.

**Param√®tres :**

- `text`
- `width`

---

### color

#### Classes

##### ColorSystem

One of the 3 color system supported by terminals.

**M√©thodes :**

- `__repr__()`
- `__str__()`

##### ColorType

Type of color stored in Color class.

**M√©thodes :**

- `__repr__()`

##### ColorParseError

The color could not be parsed.

##### Color

Terminal color definition.

**M√©thodes :**

- `__rich__()`
- `__rich_repr__()`
- `system()`
- `is_system_defined()`
- `is_default()`
- `get_truecolor()`
- `from_ansi()`
- `from_triplet()`
- `from_rgb()`
- `default()`
- `parse()`
- `get_ansi_codes()`
- `downgrade()`

#### Fonctions

##### parse_rgb_hex

Parse six hex characters in to RGB triplet.

**Param√®tres :**

- `hex_color`

##### blend_rgb

Blend one RGB color in to another.

**Param√®tres :**

- `color1`
- `color2`
- `cross_fade`

##### __repr__

##### __str__

##### __repr__

##### __rich__

Displays the actual color if Rich printed.

##### __rich_repr__

##### system

Get the native color system for this color.

##### is_system_defined

Check if the color is ultimately defined by the system.

##### is_default

Check if the color is a default color.

##### get_truecolor

Get an equivalent color triplet for this color.

Args:
    theme (TerminalTheme, optional): Optional terminal theme, or None to use default. Defaults to None.
    foreground (bool, optional): True for a foreground color, or False for background. Defaults to True.

Returns:
    ColorTriplet: A color triplet containing RGB components.

**Param√®tres :**

- `theme`
- `foreground`

##### from_ansi

Create a Color number from it's 8-bit ansi number.

Args:
    number (int): A number between 0-255 inclusive.

Returns:
    Color: A new Color instance.

**Param√®tres :**

- `cls`
- `number`

##### from_triplet

Create a truecolor RGB color from a triplet of values.

Args:
    triplet (ColorTriplet): A color triplet containing red, green and blue components.

Returns:
    Color: A new color object.

**Param√®tres :**

- `cls`
- `triplet`

##### from_rgb

Create a truecolor from three color components in the range(0->255).

Args:
    red (float): Red component in range 0-255.
    green (float): Green component in range 0-255.
    blue (float): Blue component in range 0-255.

Returns:
    Color: A new color object.

**Param√®tres :**

- `cls`
- `red`
- `green`
- `blue`

##### default

Get a Color instance representing the default color.

Returns:
    Color: Default color.

**Param√®tres :**

- `cls`

##### parse

Parse a color definition.

**Param√®tres :**

- `cls`
- `color`

##### get_ansi_codes

Get the ANSI escape codes for this color.

**Param√®tres :**

- `foreground`

##### downgrade

Downgrade a color system to a system with fewer colors.

**Param√®tres :**

- `system`

---

### color_triplet

#### Classes

##### ColorTriplet

The red, green, and blue components of a color.

**M√©thodes :**

- `hex()`
- `rgb()`
- `normalized()`

#### Fonctions

##### hex

get the color triplet in CSS style.

##### rgb

The color in RGB format.

Returns:
    str: An rgb color, e.g. ``"rgb(100,23,255)"``.

##### normalized

Convert components into floats between 0 and 1.

Returns:
    Tuple[float, float, float]: A tuple of three normalized colour components.

---

### columns

#### Classes

##### Columns

Display renderables in neat columns.

Args:
    renderables (Iterable[RenderableType]): Any number of Rich renderables (including str).
    width (int, optional): The desired width of the columns, or None to auto detect. Defaults to None.
    padding (PaddingDimensions, optional): Optional padding around cells. Defaults to (0, 1).
    expand (bool, optional): Expand columns to full width. Defaults to False.
    equal (bool, optional): Arrange in to equal sized columns. Defaults to False.
    column_first (bool, optional): Align items from top to bottom (rather than left to right). Defaults to False.
    right_to_left (bool, optional): Start column from right hand side. Defaults to False.
    align (str, optional): Align value ("left", "right", or "center") or None for default. Defaults to None.
    title (TextType, optional): Optional title for Columns.

**M√©thodes :**

- `__init__()`
- `add_renderable()`
- `__rich_console__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderables`
- `padding`

##### add_renderable

Add a renderable to the columns.

Args:
    renderable (RenderableType): Any renderable object.

**Param√®tres :**

- `renderable`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### iter_renderables

**Param√®tres :**

- `column_count`

---

### console

#### Classes

##### NoChange

##### ConsoleDimensions

Size of the terminal.

##### ConsoleOptions

Options for __rich_console__ method.

**M√©thodes :**

- `ascii_only()`
- `copy()`
- `update()`
- `update_width()`
- `update_height()`
- `reset_height()`
- `update_dimensions()`

##### RichCast

An object that may be 'cast' to a console renderable.

**M√©thodes :**

- `__rich__()`

##### ConsoleRenderable

An object that supports the console protocol.

**M√©thodes :**

- `__rich_console__()`

##### CaptureError

An error in the Capture context manager.

##### NewLine

A renderable to generate new line(s)

**M√©thodes :**

- `__init__()`
- `__rich_console__()`

##### ScreenUpdate

Render a list of lines at a given offset.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`

##### Capture

Context manager to capture the result of printing to the console.
See :meth:`~rich.console.Console.capture` for how to use.

Args:
    console (Console): A console instance to capture output.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `get()`

##### ThemeContext

A context manager to use a temporary theme. See :meth:`~rich.console.Console.use_theme` for usage.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### PagerContext

A context manager that 'pages' content. See :meth:`~rich.console.Console.pager` for usage.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### ScreenContext

A context manager that enables an alternative screen. See :meth:`~rich.console.Console.screen` for usage.

**M√©thodes :**

- `__init__()`
- `update()`
- `__enter__()`
- `__exit__()`

##### Group

Takes a group of renderables and returns a renderable object that renders the group.

Args:
    renderables (Iterable[RenderableType]): An iterable of renderable objects.
    fit (bool, optional): Fit dimension of group to contents, or fill available space. Defaults to True.

**M√©thodes :**

- `__init__()`
- `renderables()`
- `__rich_measure__()`
- `__rich_console__()`

##### ConsoleThreadLocals

Thread local values for Console context.

##### RenderHook

Provides hooks in to the render process.

**M√©thodes :**

- `process_renderables()`

##### Console

A high level console interface.

Args:
    color_system (str, optional): The color system supported by your terminal,
        either ``"standard"``, ``"256"`` or ``"truecolor"``. Leave as ``"auto"`` to autodetect.
    force_terminal (Optional[bool], optional): Enable/disable terminal control codes, or None to auto-detect terminal. Defaults to None.
    force_jupyter (Optional[bool], optional): Enable/disable Jupyter rendering, or None to auto-detect Jupyter. Defaults to None.
    force_interactive (Optional[bool], optional): Enable/disable interactive mode, or None to auto detect. Defaults to None.
    soft_wrap (Optional[bool], optional): Set soft wrap default on print method. Defaults to False.
    theme (Theme, optional): An optional style theme object, or ``None`` for default theme.
    stderr (bool, optional): Use stderr rather than stdout if ``file`` is not specified. Defaults to False.
    file (IO, optional): A file object where the console should write to. Defaults to stdout.
    quiet (bool, Optional): Boolean to suppress all output. Defaults to False.
    width (int, optional): The width of the terminal. Leave as default to auto-detect width.
    height (int, optional): The height of the terminal. Leave as default to auto-detect height.
    style (StyleType, optional): Style to apply to all output, or None for no style. Defaults to None.
    no_color (Optional[bool], optional): Enabled no color mode, or None to auto detect. Defaults to None.
    tab_size (int, optional): Number of spaces used to replace a tab character. Defaults to 8.
    record (bool, optional): Boolean to enable recording of terminal output,
        required to call :meth:`export_html`, :meth:`export_svg`, and :meth:`export_text`. Defaults to False.
    markup (bool, optional): Boolean to enable :ref:`console_markup`. Defaults to True.
    emoji (bool, optional): Enable emoji code. Defaults to True.
    emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.
    highlight (bool, optional): Enable automatic highlighting. Defaults to True.
    log_time (bool, optional): Boolean to enable logging of time by :meth:`log` methods. Defaults to True.
    log_path (bool, optional): Boolean to enable the logging of the caller by :meth:`log`. Defaults to True.
    log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to "[%X] ".
    highlighter (HighlighterType, optional): Default highlighter.
    legacy_windows (bool, optional): Enable legacy Windows mode, or ``None`` to auto detect. Defaults to ``None``.
    safe_box (bool, optional): Restrict box options that don't render on legacy Windows.
    get_datetime (Callable[[], datetime], optional): Callable that gets the current time as a datetime.datetime object (used by Console.log),
        or None for datetime.now.
    get_time (Callable[[], time], optional): Callable that gets the current time in seconds, default uses time.monotonic.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `file()`
- `file()`
- `_buffer()`
- `_buffer_index()`
- `_buffer_index()`
- `_theme_stack()`
- `_detect_color_system()`
- `_enter_buffer()`
- `_exit_buffer()`
- `set_live()`
- `clear_live()`
- `push_render_hook()`
- `pop_render_hook()`
- `__enter__()`
- `__exit__()`
- `begin_capture()`
- `end_capture()`
- `push_theme()`
- `pop_theme()`
- `use_theme()`
- `color_system()`
- `encoding()`
- `is_terminal()`
- `is_dumb_terminal()`
- `options()`
- `size()`
- `size()`
- `width()`
- `width()`
- `height()`
- `height()`
- `bell()`
- `capture()`
- `pager()`
- `line()`
- `clear()`
- `status()`
- `show_cursor()`
- `set_alt_screen()`
- `is_alt_screen()`
- `set_window_title()`
- `screen()`
- `measure()`
- `render()`
- `render_lines()`
- `render_str()`
- `get_style()`
- `_collect_renderables()`
- `rule()`
- `control()`
- `out()`
- `print()`
- `print_json()`
- `update_screen()`
- `update_screen_lines()`
- `print_exception()`
- `_caller_frame_info()`
- `log()`
- `on_broken_pipe()`
- `_check_buffer()`
- `_write_buffer()`
- `_render_buffer()`
- `input()`
- `export_text()`
- `save_text()`
- `export_html()`
- `save_html()`
- `export_svg()`
- `save_svg()`

#### Fonctions

##### group

A decorator that turns an iterable of renderables in to a group.

Args:
    fit (bool, optional): Fit dimension of group to contents, or fill available space. Defaults to True.

**Param√®tres :**

- `fit`

##### _is_jupyter

Check if we're running in a Jupyter notebook.

##### get_windows_console_features

##### detect_legacy_windows

Detect legacy Windows.

##### _svg_hash

Returns a unique hash for the given SVG main code.

Args:
    svg_main_code (str): The content we're going to inject in the SVG envelope.

Returns:
    str: a hash of the given content

**Param√®tres :**

- `svg_main_code`

##### ascii_only

Check if renderables should use ascii only.

##### copy

Return a copy of the options.

Returns:
    ConsoleOptions: a copy of self.

##### update

Update values, return a copy.

##### update_width

Update just the width, return a copy.

Args:
    width (int): New width (sets both min_width and max_width)

Returns:
    ~ConsoleOptions: New console options instance.

**Param√®tres :**

- `width`

##### update_height

Update the height, and return a copy.

Args:
    height (int): New height

Returns:
    ~ConsoleOptions: New Console options instance.

**Param√®tres :**

- `height`

##### reset_height

Return a copy of the options with height set to ``None``.

Returns:
    ~ConsoleOptions: New console options instance.

##### update_dimensions

Update the width and height, and return a copy.

Args:
    width (int): New width (sets both min_width and max_width).
    height (int): New height.

Returns:
    ~ConsoleOptions: New console options instance.

**Param√®tres :**

- `width`
- `height`

##### __rich__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __init__

**Param√®tres :**

- `count`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __init__

**Param√®tres :**

- `lines`
- `x`
- `y`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __init__

**Param√®tres :**

- `console`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### get

Get the result of the capture.

##### __init__

**Param√®tres :**

- `console`
- `theme`
- `inherit`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

**Param√®tres :**

- `console`
- `pager`
- `styles`
- `links`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

**Param√®tres :**

- `console`
- `hide_cursor`
- `style`

##### update

Update the screen.

Args:
    renderable (RenderableType, optional): Optional renderable to replace current renderable,
        or None for no change. Defaults to None.
    style: (Style, optional): Replacement style, or None for no change. Defaults to None.

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

##### renderables

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### decorator

Convert a method that returns an iterable of renderables in to a Group.

**Param√®tres :**

- `method`

##### process_renderables

Called with a list of objects to render.

This method can return a new list of renderables, or modify and return the same list.

Args:
    renderables (List[ConsoleRenderable]): A number of renderable objects.

Returns:
    List[ConsoleRenderable]: A replacement list of renderables.

**Param√®tres :**

- `renderables`

##### __init__

##### __repr__

##### file

Get the file object to write to.

##### file

Set a new file object.

**Param√®tres :**

- `new_file`

##### _buffer

Get a thread local buffer.

##### _buffer_index

Get a thread local buffer.

##### _buffer_index

**Param√®tres :**

- `value`

##### _theme_stack

Get the thread local theme stack.

##### _detect_color_system

Detect color system from env vars.

##### _enter_buffer

Enter in to a buffer context, and buffer all output.

##### _exit_buffer

Leave buffer context, and render content if required.

##### set_live

Set Live instance. Used by Live context manager.

Args:
    live (Live): Live instance using this Console.

Raises:
    errors.LiveError: If this Console has a Live context currently active.

**Param√®tres :**

- `live`

##### clear_live

Clear the Live instance.

##### push_render_hook

Add a new render hook to the stack.

Args:
    hook (RenderHook): Render hook instance.

**Param√®tres :**

- `hook`

##### pop_render_hook

Pop the last renderhook from the stack.

##### __enter__

Own context manager to enter buffer context.

##### __exit__

Exit buffer context.

**Param√®tres :**

- `exc_type`
- `exc_value`
- `traceback`

##### begin_capture

Begin capturing console output. Call :meth:`end_capture` to exit capture mode and return output.

##### end_capture

End capture mode and return captured string.

Returns:
    str: Console output.

##### push_theme

Push a new theme on to the top of the stack, replacing the styles from the previous theme.
Generally speaking, you should call :meth:`~rich.console.Console.use_theme` to get a context manager, rather
than calling this method directly.

Args:
    theme (Theme): A theme instance.
    inherit (bool, optional): Inherit existing styles. Defaults to True.

**Param√®tres :**

- `theme`

##### pop_theme

Remove theme from top of stack, restoring previous theme.

##### use_theme

Use a different theme for the duration of the context manager.

Args:
    theme (Theme): Theme instance to user.
    inherit (bool, optional): Inherit existing console styles. Defaults to True.

Returns:
    ThemeContext: [description]

**Param√®tres :**

- `theme`

##### color_system

Get color system string.

Returns:
    Optional[str]: "standard", "256" or "truecolor".

##### encoding

Get the encoding of the console file, e.g. ``"utf-8"``.

Returns:
    str: A standard encoding string.

##### is_terminal

Check if the console is writing to a terminal.

Returns:
    bool: True if the console writing to a device capable of
        understanding escape sequences, otherwise False.

##### is_dumb_terminal

Detect dumb terminal.

Returns:
    bool: True if writing to a dumb terminal, otherwise False.

##### options

Get default console options.

##### size

Get the size of the console.

Returns:
    ConsoleDimensions: A named tuple containing the dimensions.

##### size

Set a new size for the terminal.

Args:
    new_size (Tuple[int, int]): New width and height.

**Param√®tres :**

- `new_size`

##### width

Get the width of the console.

Returns:
    int: The width (in characters) of the console.

##### width

Set width.

Args:
    width (int): New width.

**Param√®tres :**

- `width`

##### height

Get the height of the console.

Returns:
    int: The height (in lines) of the console.

##### height

Set height.

Args:
    height (int): new height.

**Param√®tres :**

- `height`

##### bell

Play a 'bell' sound (if supported by the terminal).

##### capture

A context manager to *capture* the result of print() or log() in a string,
rather than writing it to the console.

Example:
    >>> from rich.console import Console
    >>> console = Console()
    >>> with console.capture() as capture:
    ...     console.print("[bold magenta]Hello World[/]")
    >>> print(capture.get())

Returns:
    Capture: Context manager with disables writing to the terminal.

##### pager

A context manager to display anything printed within a "pager". The pager application
is defined by the system and will typically support at least pressing a key to scroll.

Args:
    pager (Pager, optional): A pager object, or None to use :class:`~rich.pager.SystemPager`. Defaults to None.
    styles (bool, optional): Show styles in pager. Defaults to False.
    links (bool, optional): Show links in pager. Defaults to False.

Example:
    >>> from rich.console import Console
    >>> from rich.__main__ import make_test_card
    >>> console = Console()
    >>> with console.pager():
            console.print(make_test_card())

Returns:
    PagerContext: A context manager.

**Param√®tres :**

- `pager`
- `styles`
- `links`

##### line

Write new line(s).

Args:
    count (int, optional): Number of new lines. Defaults to 1.

**Param√®tres :**

- `count`

##### clear

Clear the screen.

Args:
    home (bool, optional): Also move the cursor to 'home' position. Defaults to True.

**Param√®tres :**

- `home`

##### status

Display a status and spinner.

Args:
    status (RenderableType): A status renderable (str or Text typically).
    spinner (str, optional): Name of spinner animation (see python -m rich.spinner). Defaults to "dots".
    spinner_style (StyleType, optional): Style of spinner. Defaults to "status.spinner".
    speed (float, optional): Speed factor for spinner animation. Defaults to 1.0.
    refresh_per_second (float, optional): Number of refreshes per second. Defaults to 12.5.

Returns:
    Status: A Status object that may be used as a context manager.

**Param√®tres :**

- `status`

##### show_cursor

Show or hide the cursor.

Args:
    show (bool, optional): Set visibility of the cursor.

**Param√®tres :**

- `show`

##### set_alt_screen

Enables alternative screen mode.

Note, if you enable this mode, you should ensure that is disabled before
the application exits. See :meth:`~rich.Console.screen` for a context manager
that handles this for you.

Args:
    enable (bool, optional): Enable (True) or disable (False) alternate screen. Defaults to True.

Returns:
    bool: True if the control codes were written.

**Param√®tres :**

- `enable`

##### is_alt_screen

Check if the alt screen was enabled.

Returns:
    bool: True if the alt screen was enabled, otherwise False.

##### set_window_title

Set the title of the console terminal window.

Warning: There is no means within Rich of "resetting" the window title to its
previous value, meaning the title you set will persist even after your application
exits.

``fish`` shell resets the window title before and after each command by default,
negating this issue. Windows Terminal and command prompt will also reset the title for you.
Most other shells and terminals, however, do not do this.

Some terminals may require configuration changes before you can set the title.
Some terminals may not support setting the title at all.

Other software (including the terminal itself, the shell, custom prompts, plugins, etc.)
may also set the terminal window title. This could result in whatever value you write
using this method being overwritten.

Args:
    title (str): The new title of the terminal window.

Returns:
    bool: True if the control code to change the terminal title was
        written, otherwise False. Note that a return value of True
        does not guarantee that the window title has actually changed,
        since the feature may be unsupported/disabled in some terminals.

**Param√®tres :**

- `title`

##### screen

Context manager to enable and disable 'alternative screen' mode.

Args:
    hide_cursor (bool, optional): Also hide the cursor. Defaults to False.
    style (Style, optional): Optional style for screen. Defaults to None.

Returns:
    ~ScreenContext: Context which enables alternate screen on enter, and disables it on exit.

**Param√®tres :**

- `hide_cursor`
- `style`

##### measure

Measure a renderable. Returns a :class:`~rich.measure.Measurement` object which contains
information regarding the number of characters required to print the renderable.

Args:
    renderable (RenderableType): Any renderable or string.
    options (Optional[ConsoleOptions], optional): Options to use when measuring, or None
        to use default options. Defaults to None.

Returns:
    Measurement: A measurement of the renderable.

**Param√®tres :**

- `renderable`

##### render

Render an object in to an iterable of `Segment` instances.

This method contains the logic for rendering objects with the console protocol.
You are unlikely to need to use it directly, unless you are extending the library.

Args:
    renderable (RenderableType): An object supporting the console protocol, or
        an object that may be converted to a string.
    options (ConsoleOptions, optional): An options object, or None to use self.options. Defaults to None.

Returns:
    Iterable[Segment]: An iterable of segments that may be rendered.

**Param√®tres :**

- `renderable`
- `options`

##### render_lines

Render objects in to a list of lines.

        The output of render_lines is useful when further formatting of rendered console text
        is required, such as the Panel class which draws a border around any renderable object.

        Args:
            renderable (RenderableType): Any object renderable in the console.
            options (Optional[ConsoleOptions], optional): Console options, or None to use self.options. Default to ``None``.
            style (Style, optional): Optional style to apply to renderables. Defaults to ``None``.
            pad (bool, optional): Pad lines shorter than render width. Defaults to ``True``.
            new_lines (bool, optional): Include "
" characters at end of lines.

        Returns:
            List[List[Segment]]: A list of lines, where a line is a list of Segment objects.
        

**Param√®tres :**

- `renderable`
- `options`

##### render_str

Convert a string to a Text instance. This is called automatically if
you print or log a string.

Args:
    text (str): Text to render.
    style (Union[str, Style], optional): Style to apply to rendered text.
    justify (str, optional): Justify method: "default", "left", "center", "full", or "right". Defaults to ``None``.
    overflow (str, optional): Overflow method: "crop", "fold", or "ellipsis". Defaults to ``None``.
    emoji (Optional[bool], optional): Enable emoji, or ``None`` to use Console default.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use Console default.
    highlight (Optional[bool], optional): Enable highlighting, or ``None`` to use Console default.
    highlighter (HighlighterType, optional): Optional highlighter to apply.
Returns:
    ConsoleRenderable: Renderable object.

**Param√®tres :**

- `text`

##### get_style

Get a Style instance by its theme name or parse a definition.

Args:
    name (str): The name of a style or a style definition.

Returns:
    Style: A Style object.

Raises:
    MissingStyle: If no style could be parsed from name.

**Param√®tres :**

- `name`

##### _collect_renderables

Combine a number of renderables and text into one renderable.

Args:
    objects (Iterable[Any]): Anything that Rich can render.
    sep (str): String to write between print data.
    end (str): String to write at end of print data.
    justify (str, optional): One of "left", "right", "center", or "full". Defaults to ``None``.
    emoji (Optional[bool], optional): Enable emoji code, or ``None`` to use console default.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use console default.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use console default.

Returns:
    List[ConsoleRenderable]: A list of things to render.

**Param√®tres :**

- `objects`
- `sep`
- `end`

##### rule

Draw a line with optional centered title.

Args:
    title (str, optional): Text to render over the rule. Defaults to "".
    characters (str, optional): Character(s) to form the line. Defaults to "‚îÄ".
    style (str, optional): Style of line. Defaults to "rule.line".
    align (str, optional): How to align the title, one of "left", "center", or "right". Defaults to "center".

**Param√®tres :**

- `title`

##### control

Insert non-printing control codes.

Args:
    control_codes (str): Control codes, such as those that may move the cursor.

##### out

Output to the terminal. This is a low-level way of writing to the terminal which unlike
:meth:`~rich.console.Console.print` won't pretty print, wrap text, or apply markup, but will
optionally apply highlighting and a basic style.

Args:
    sep (str, optional): String to write between print data. Defaults to " ".
    end (str, optional): String to write at end of print data. Defaults to "\\n".
    style (Union[str, Style], optional): A style to apply to output. Defaults to None.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use
        console default. Defaults to ``None``.

##### print

Print to the console.

Args:
    objects (positional args): Objects to log to the terminal.
    sep (str, optional): String to write between print data. Defaults to " ".
    end (str, optional): String to write at end of print data. Defaults to "\\n".
    style (Union[str, Style], optional): A style to apply to output. Defaults to None.
    justify (str, optional): Justify method: "default", "left", "right", "center", or "full". Defaults to ``None``.
    overflow (str, optional): Overflow method: "ignore", "crop", "fold", or "ellipsis". Defaults to None.
    no_wrap (Optional[bool], optional): Disable word wrapping. Defaults to None.
    emoji (Optional[bool], optional): Enable emoji code, or ``None`` to use console default. Defaults to ``None``.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use console default. Defaults to ``None``.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use console default. Defaults to ``None``.
    width (Optional[int], optional): Width of output, or ``None`` to auto-detect. Defaults to ``None``.
    crop (Optional[bool], optional): Crop output to width of terminal. Defaults to True.
    soft_wrap (bool, optional): Enable soft wrap mode which disables word wrapping and cropping of text or ``None`` for
        Console default. Defaults to ``None``.
    new_line_start (bool, False): Insert a new line at the start if the output contains more than one line. Defaults to ``False``.

##### print_json

Pretty prints JSON. Output will be valid JSON.

Args:
    json (Optional[str]): A string containing JSON.
    data (Any): If json is not supplied, then encode this data.
    indent (Union[None, int, str], optional): Number of spaces to indent. Defaults to 2.
    highlight (bool, optional): Enable highlighting of output: Defaults to True.
    skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
    ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
    check_circular (bool, optional): Check for circular references. Defaults to True.
    allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
    default (Callable, optional): A callable that converts values that can not be encoded
        in to something that can be JSON encoded. Defaults to None.
    sort_keys (bool, optional): Sort dictionary keys. Defaults to False.

**Param√®tres :**

- `json`

##### update_screen

Update the screen at a given offset.

Args:
    renderable (RenderableType): A Rich renderable.
    region (Region, optional): Region of screen to update, or None for entire screen. Defaults to None.
    x (int, optional): x offset. Defaults to 0.
    y (int, optional): y offset. Defaults to 0.

Raises:
    errors.NoAltScreen: If the Console isn't in alt screen mode.

**Param√®tres :**

- `renderable`

##### update_screen_lines

Update lines of the screen at a given offset.

Args:
    lines (List[List[Segment]]): Rendered lines (as produced by :meth:`~rich.Console.render_lines`).
    x (int, optional): x offset (column no). Defaults to 0.
    y (int, optional): y offset (column no). Defaults to 0.

Raises:
    errors.NoAltScreen: If the Console isn't in alt screen mode.

**Param√®tres :**

- `lines`
- `x`
- `y`

##### print_exception

Prints a rich render of the last exception and traceback.

Args:
    width (Optional[int], optional): Number of characters used to render code. Defaults to 100.
    extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
    theme (str, optional): Override pygments theme used in traceback
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.

##### _caller_frame_info

Get caller frame information.

Args:
    offset (int): the caller offset within the current frame stack.
    currentframe (Callable[[], Optional[FrameType]], optional): the callable to use to
        retrieve the current frame. Defaults to ``inspect.currentframe``.

Returns:
    Tuple[str, int, Dict[str, Any]]: A tuple containing the filename, the line number and
        the dictionary of local variables associated with the caller frame.

Raises:
    RuntimeError: If the stack offset is invalid.

**Param√®tres :**

- `offset`
- `currentframe`

##### log

Log rich content to the terminal.

Args:
    objects (positional args): Objects to log to the terminal.
    sep (str, optional): String to write between print data. Defaults to " ".
    end (str, optional): String to write at end of print data. Defaults to "\\n".
    style (Union[str, Style], optional): A style to apply to output. Defaults to None.
    justify (str, optional): One of "left", "right", "center", or "full". Defaults to ``None``.
    emoji (Optional[bool], optional): Enable emoji code, or ``None`` to use console default. Defaults to None.
    markup (Optional[bool], optional): Enable markup, or ``None`` to use console default. Defaults to None.
    highlight (Optional[bool], optional): Enable automatic highlighting, or ``None`` to use console default. Defaults to None.
    log_locals (bool, optional): Boolean to enable logging of locals where ``log()``
        was called. Defaults to False.
    _stack_offset (int, optional): Offset of caller from end of call stack. Defaults to 1.

##### on_broken_pipe

This function is called when a `BrokenPipeError` is raised.

This can occur when piping Textual output in Linux and macOS.
The default implementation is to exit the app, but you could implement
this method in a subclass to change the behavior.

See https://docs.python.org/3/library/signal.html#note-on-sigpipe for details.

##### _check_buffer

Check if the buffer may be rendered. Render it if it can (e.g. Console.quiet is False)
Rendering is supported on Windows, Unix and Jupyter environments. For
legacy Windows consoles, the win32 API is called directly.
This method will also record what it renders if recording is enabled via Console.record.

##### _write_buffer

Write the buffer to the output file.

##### _render_buffer

Render buffered output, and clear buffer.

**Param√®tres :**

- `buffer`

##### input

Displays a prompt and waits for input from the user. The prompt may contain color / style.

It works in the same way as Python's builtin :func:`input` function and provides elaborate line editing and history features if Python's builtin :mod:`readline` module is previously loaded.

Args:
    prompt (Union[str, Text]): Text to render in the prompt.
    markup (bool, optional): Enable console markup (requires a str prompt). Defaults to True.
    emoji (bool, optional): Enable emoji (requires a str prompt). Defaults to True.
    password: (bool, optional): Hide typed text. Defaults to False.
    stream: (TextIO, optional): Optional file to read input from (rather than stdin). Defaults to None.

Returns:
    str: Text read from stdin.

**Param√®tres :**

- `prompt`

##### export_text

Generate text from console contents (requires record=True argument in constructor).

Args:
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    styles (bool, optional): If ``True``, ansi escape codes will be included. ``False`` for plain text.
        Defaults to ``False``.

Returns:
    str: String containing console contents.

##### save_text

Generate text from console and save to a given location (requires record=True argument in constructor).

Args:
    path (str): Path to write text files.
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    styles (bool, optional): If ``True``, ansi style codes will be included. ``False`` for plain text.
        Defaults to ``False``.

**Param√®tres :**

- `path`

##### export_html

Generate HTML from console contents (requires record=True argument in constructor).

Args:
    theme (TerminalTheme, optional): TerminalTheme object containing console colors.
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    code_format (str, optional): Format string to render HTML. In addition to '{foreground}',
        '{background}', and '{code}', should contain '{stylesheet}' if inline_styles is ``False``.
    inline_styles (bool, optional): If ``True`` styles will be inlined in to spans, which makes files
        larger but easier to cut and paste markup. If ``False``, styles will be embedded in a style tag.
        Defaults to False.

Returns:
    str: String containing console contents as HTML.

##### save_html

Generate HTML from console contents and write to a file (requires record=True argument in constructor).

Args:
    path (str): Path to write html file.
    theme (TerminalTheme, optional): TerminalTheme object containing console colors.
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``.
    code_format (str, optional): Format string to render HTML. In addition to '{foreground}',
        '{background}', and '{code}', should contain '{stylesheet}' if inline_styles is ``False``.
    inline_styles (bool, optional): If ``True`` styles will be inlined in to spans, which makes files
        larger but easier to cut and paste markup. If ``False``, styles will be embedded in a style tag.
        Defaults to False.

**Param√®tres :**

- `path`

##### export_svg

Generate an SVG from the console contents (requires record=True in Console constructor).

Args:
    title (str, optional): The title of the tab in the output image
    theme (TerminalTheme, optional): The ``TerminalTheme`` object to use to style the terminal
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``
    code_format (str, optional): Format string used to generate the SVG. Rich will inject a number of variables
        into the string in order to form the final SVG output. The default template used and the variables
        injected by Rich can be found by inspecting the ``console.CONSOLE_SVG_FORMAT`` variable.
    font_aspect_ratio (float, optional): The width to height ratio of the font used in the ``code_format``
        string. Defaults to 0.61, which is the width to height ratio of Fira Code (the default font).
        If you aren't specifying a different font inside ``code_format``, you probably don't need this.
    unique_id (str, optional): unique id that is used as the prefix for various elements (CSS styles, node
        ids). If not set, this defaults to a computed value based on the recorded content.

##### save_svg

Generate an SVG file from the console contents (requires record=True in Console constructor).

Args:
    path (str): The path to write the SVG to.
    title (str, optional): The title of the tab in the output image
    theme (TerminalTheme, optional): The ``TerminalTheme`` object to use to style the terminal
    clear (bool, optional): Clear record buffer after exporting. Defaults to ``True``
    code_format (str, optional): Format string used to generate the SVG. Rich will inject a number of variables
        into the string in order to form the final SVG output. The default template used and the variables
        injected by Rich can be found by inspecting the ``console.CONSOLE_SVG_FORMAT`` variable.
    font_aspect_ratio (float, optional): The width to height ratio of the font used in the ``code_format``
        string. Defaults to 0.61, which is the width to height ratio of Fira Code (the default font).
        If you aren't specifying a different font inside ``code_format``, you probably don't need this.
    unique_id (str, optional): unique id that is used as the prefix for various elements (CSS styles, node
        ids). If not set, this defaults to a computed value based on the recorded content.

**Param√®tres :**

- `path`

##### _replace

##### check_text

##### get_svg_style

Convert a Style to CSS rules for SVG.

**Param√®tres :**

- `style`

##### escape_text

HTML escape text and replace spaces with nbsp.

**Param√®tres :**

- `text`

##### make_tag

Make a tag from name, content, and attributes.

**Param√®tres :**

- `name`
- `content`

##### align_append

**Param√®tres :**

- `renderable`

##### stringify

**Param√®tres :**

- `value`

---

### constrain

#### Classes

##### Constrain

Constrain the width of a renderable to a given number of characters.

Args:
    renderable (RenderableType): A renderable object.
    width (int, optional): The maximum width (in characters) to render. Defaults to 80.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderable`
- `width`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

---

### containers

#### Classes

##### Renderables

A list subclass which renders its contents to the console.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`
- `__rich_measure__()`
- `append()`
- `__iter__()`

##### Lines

A list subclass which can render to the console.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__iter__()`
- `__getitem__()`
- `__getitem__()`
- `__getitem__()`
- `__setitem__()`
- `__len__()`
- `__rich_console__()`
- `append()`
- `extend()`
- `pop()`
- `justify()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderables`

##### __rich_console__

Console render method to insert line-breaks.

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### append

**Param√®tres :**

- `renderable`

##### __iter__

##### __init__

**Param√®tres :**

- `lines`

##### __repr__

##### __iter__

##### __getitem__

**Param√®tres :**

- `index`

##### __getitem__

**Param√®tres :**

- `index`

##### __getitem__

**Param√®tres :**

- `index`

##### __setitem__

**Param√®tres :**

- `index`
- `value`

##### __len__

##### __rich_console__

Console render method to insert line-breaks.

**Param√®tres :**

- `console`
- `options`

##### append

**Param√®tres :**

- `line`

##### extend

**Param√®tres :**

- `lines`

##### pop

**Param√®tres :**

- `index`

##### justify

Justify and overflow text to a given width.

Args:
    console (Console): Console instance.
    width (int): Number of cells available per line.
    justify (str, optional): Default justify method for text: "left", "center", "full" or "right". Defaults to "left".
    overflow (str, optional): Default overflow for text: "crop", "fold", or "ellipsis". Defaults to "fold".

**Param√®tres :**

- `console`
- `width`
- `justify`
- `overflow`

---

### control

#### Classes

##### Control

A renderable that inserts a control code (non printable but may move cursor).

Args:
    *codes (str): Positional arguments are either a :class:`~rich.segment.ControlType` enum or a
        tuple of ControlType and an integer parameter

**M√©thodes :**

- `__init__()`
- `bell()`
- `home()`
- `move()`
- `move_to_column()`
- `move_to()`
- `clear()`
- `show_cursor()`
- `alt_screen()`
- `title()`
- `__str__()`
- `__rich_console__()`

#### Fonctions

##### strip_control_codes

Remove control codes from text.

Args:
    text (str): A string possibly contain control codes.

Returns:
    str: String with control codes removed.

**Param√®tres :**

- `text`
- `_translate_table`

##### escape_control_codes

Replace control codes with their "escaped" equivalent in the given text.
(e.g. "" becomes "\b")

Args:
    text (str): A string possibly containing control codes.

Returns:
    str: String with control codes replaced with their escaped version.

**Param√®tres :**

- `text`
- `_translate_table`

##### __init__

##### bell

Ring the 'bell'.

**Param√®tres :**

- `cls`

##### home

Move cursor to 'home' position.

**Param√®tres :**

- `cls`

##### move

Move cursor relative to current position.

Args:
    x (int): X offset.
    y (int): Y offset.

Returns:
    ~Control: Control object.

**Param√®tres :**

- `cls`
- `x`
- `y`

##### move_to_column

Move to the given column, optionally add offset to row.

Returns:
    x (int): absolute x (column)
    y (int): optional y offset (row)

Returns:
    ~Control: Control object.

**Param√®tres :**

- `cls`
- `x`
- `y`

##### move_to

Move cursor to absolute position.

Args:
    x (int): x offset (column)
    y (int): y offset (row)

Returns:
    ~Control: Control object.

**Param√®tres :**

- `cls`
- `x`
- `y`

##### clear

Clear the screen.

**Param√®tres :**

- `cls`

##### show_cursor

Show or hide the cursor.

**Param√®tres :**

- `cls`
- `show`

##### alt_screen

Enable or disable alt screen.

**Param√®tres :**

- `cls`
- `enable`

##### title

Set the terminal window title

Args:
    title (str): The new terminal window title

**Param√®tres :**

- `cls`
- `title`

##### __str__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### get_codes

---

### default_styles

---

### diagnose

#### Fonctions

##### report

Print a report to the terminal with debugging information

---

### emoji

#### Classes

##### NoEmoji

No emoji by that name.

##### Emoji

**M√©thodes :**

- `__init__()`
- `replace()`
- `__repr__()`
- `__str__()`
- `__rich_console__()`

#### Fonctions

##### __init__

A single emoji character.

Args:
    name (str): Name of emoji.
    style (Union[str, Style], optional): Optional style. Defaults to None.

Raises:
    NoEmoji: If the emoji doesn't exist.

**Param√®tres :**

- `name`
- `style`
- `variant`

##### replace

Replace emoji markup with corresponding unicode characters.

Args:
    text (str): A string with emojis codes, e.g. "Hello :smiley:!"

Returns:
    str: A string with emoji codes replaces with actual emoji.

**Param√®tres :**

- `cls`
- `text`

##### __repr__

##### __str__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

---

### errors

#### Classes

##### ConsoleError

An error in console operation.

##### StyleError

An error in styles.

##### StyleSyntaxError

Style was badly formatted.

##### MissingStyle

No such style.

##### StyleStackError

Style stack is invalid.

##### NotRenderableError

Object is not renderable.

##### MarkupError

Markup was badly formatted.

##### LiveError

Error related to Live display.

##### NoAltScreen

Alt screen mode was required.

---

### file_proxy

#### Classes

##### FileProxy

Wraps a file (e.g. sys.stdout) and redirects writes to a console.

**M√©thodes :**

- `__init__()`
- `rich_proxied_file()`
- `__getattr__()`
- `write()`
- `flush()`
- `fileno()`

#### Fonctions

##### __init__

**Param√®tres :**

- `console`
- `file`

##### rich_proxied_file

Get proxied file.

##### __getattr__

**Param√®tres :**

- `name`

##### write

**Param√®tres :**

- `text`

##### flush

##### fileno

---

### filesize

Functions for reporting filesizes. Borrowed from https://github.com/PyFilesystem/pyfilesystem2

The functions declared in this module should cover the different
use cases needed to generate a string representation of a file size
using several different units. Since there are many standards regarding
file size units, three different functions have been implemented.

See Also:
    * `Wikipedia: Binary prefix <https://en.wikipedia.org/wiki/Binary_prefix>`_

#### Fonctions

##### _to_str

**Param√®tres :**

- `size`
- `suffixes`
- `base`

##### pick_unit_and_suffix

Pick a suffix and base for the given size.

**Param√®tres :**

- `size`
- `suffixes`
- `base`

##### decimal

Convert a filesize in to a string (powers of 1000, SI prefixes).

In this convention, ``1000 B = 1 kB``.

This is typically the format used to advertise the storage
capacity of USB flash drives and the like (*256 MB* meaning
actually a storage capacity of more than *256 000 000 B*),
or used by **Mac OS X** since v10.6 to report file sizes.

Arguments:
    int (size): A file size.
    int (precision): The number of decimal places to include (default = 1).
    str (separator): The string to separate the value from the units (default = " ").

Returns:
    `str`: A string containing a abbreviated file size and units.

Example:
    >>> filesize.decimal(30000)
    '30.0 kB'
    >>> filesize.decimal(30000, precision=2, separator="")
    '30.00kB'

**Param√®tres :**

- `size`

---

### highlighter

#### Classes

##### Highlighter

Abstract base class for highlighters.

**M√©thodes :**

- `__call__()`
- `highlight()`

##### NullHighlighter

A highlighter object that doesn't highlight.

May be used to disable highlighting entirely.

**M√©thodes :**

- `highlight()`

##### RegexHighlighter

Applies highlighting from a list of regular expressions.

**M√©thodes :**

- `highlight()`

##### ReprHighlighter

Highlights the text typically produced from ``__repr__`` methods.

##### JSONHighlighter

Highlights JSON

**M√©thodes :**

- `highlight()`

##### ISO8601Highlighter

Highlights the ISO8601 date time strings.
Regex reference: https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch04s07.html

#### Fonctions

##### _combine_regex

Combine a number of regexes in to a single regex.

Returns:
    str: New regex with all regexes ORed together.

##### __call__

Highlight a str or Text instance.

Args:
    text (Union[str, ~Text]): Text to highlight.

Raises:
    TypeError: If not called with text or str.

Returns:
    Text: A test instance with highlighting applied.

**Param√®tres :**

- `text`

##### highlight

Apply highlighting in place to text.

Args:
    text (~Text): A text object highlight.

**Param√®tres :**

- `text`

##### highlight

Nothing to do

**Param√®tres :**

- `text`

##### highlight

Highlight :class:`rich.text.Text` using regular expressions.

Args:
    text (~Text): Text to highlighted.

**Param√®tres :**

- `text`

##### highlight

**Param√®tres :**

- `text`

---

### json

#### Classes

##### JSON

A renderable which pretty prints JSON.

Args:
    json (str): JSON encoded data.
    indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.
    highlight (bool, optional): Enable highlighting. Defaults to True.
    skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
    ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
    check_circular (bool, optional): Check for circular references. Defaults to True.
    allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
    default (Callable, optional): A callable that converts values that can not be encoded
        in to something that can be JSON encoded. Defaults to None.
    sort_keys (bool, optional): Sort dictionary keys. Defaults to False.

**M√©thodes :**

- `__init__()`
- `from_data()`
- `__rich__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `json`
- `indent`
- `highlight`
- `skip_keys`
- `ensure_ascii`
- `check_circular`
- `allow_nan`
- `default`
- `sort_keys`

##### from_data

Encodes a JSON object from arbitrary data.

Args:
    data (Any): An object that may be encoded in to JSON
    indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.
    highlight (bool, optional): Enable highlighting. Defaults to True.
    default (Callable, optional): Optional callable which will be called for objects that cannot be serialized. Defaults to None.
    skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
    ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
    check_circular (bool, optional): Check for circular references. Defaults to True.
    allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
    default (Callable, optional): A callable that converts values that can not be encoded
        in to something that can be JSON encoded. Defaults to None.
    sort_keys (bool, optional): Sort dictionary keys. Defaults to False.

Returns:
    JSON: New JSON object from the given data.

**Param√®tres :**

- `cls`
- `data`
- `indent`
- `highlight`
- `skip_keys`
- `ensure_ascii`
- `check_circular`
- `allow_nan`
- `default`
- `sort_keys`

##### __rich__

---

### jupyter

#### Classes

##### JupyterRenderable

A shim to write html to Jupyter notebook.

**M√©thodes :**

- `__init__()`
- `_repr_mimebundle_()`

##### JupyterMixin

Add to an Rich renderable to make it render in Jupyter notebook.

**M√©thodes :**

- `_repr_mimebundle_()`

#### Fonctions

##### _render_segments

**Param√®tres :**

- `segments`

##### display

Render segments to Jupyter.

**Param√®tres :**

- `segments`
- `text`

##### print

Proxy for Console print.

##### __init__

**Param√®tres :**

- `html`
- `text`

##### _repr_mimebundle_

**Param√®tres :**

- `include`
- `exclude`

##### _repr_mimebundle_

**Param√®tres :**

- `include`
- `exclude`

##### escape

Escape html.

**Param√®tres :**

- `text`

---

### layout

#### Classes

##### LayoutRender

An individual layout render.

##### LayoutError

Layout related error.

##### NoSplitter

Requested splitter does not exist.

##### _Placeholder

An internal renderable used as a Layout placeholder.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`

##### Splitter

Base class for a splitter.

**M√©thodes :**

- `get_tree_icon()`
- `divide()`

##### RowSplitter

Split a layout region in to rows.

**M√©thodes :**

- `get_tree_icon()`
- `divide()`

##### ColumnSplitter

Split a layout region in to columns.

**M√©thodes :**

- `get_tree_icon()`
- `divide()`

##### Layout

A renderable to divide a fixed height in to rows or columns.

Args:
    renderable (RenderableType, optional): Renderable content, or None for placeholder. Defaults to None.
    name (str, optional): Optional identifier for Layout. Defaults to None.
    size (int, optional): Optional fixed size of layout. Defaults to None.
    minimum_size (int, optional): Minimum size of layout. Defaults to 1.
    ratio (int, optional): Optional ratio for flexible layout. Defaults to 1.
    visible (bool, optional): Visibility of layout. Defaults to True.

**M√©thodes :**

- `__init__()`
- `__rich_repr__()`
- `renderable()`
- `children()`
- `map()`
- `get()`
- `__getitem__()`
- `tree()`
- `split()`
- `add_split()`
- `split_row()`
- `split_column()`
- `unsplit()`
- `update()`
- `refresh_screen()`
- `_make_region_map()`
- `render()`
- `__rich_console__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `layout`
- `style`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### get_tree_icon

Get the icon (emoji) used in layout.tree

##### divide

Divide a region amongst several child layouts.

Args:
    children (Sequence(Layout)): A number of child layouts.
    region (Region): A rectangular region to divide.

**Param√®tres :**

- `children`
- `region`

##### get_tree_icon

##### divide

**Param√®tres :**

- `children`
- `region`

##### get_tree_icon

##### divide

**Param√®tres :**

- `children`
- `region`

##### __init__

**Param√®tres :**

- `renderable`

##### __rich_repr__

##### renderable

Layout renderable.

##### children

Gets (visible) layout children.

##### map

Get a map of the last render.

##### get

Get a named layout, or None if it doesn't exist.

Args:
    name (str): Name of layout.

Returns:
    Optional[Layout]: Layout instance or None if no layout was found.

**Param√®tres :**

- `name`

##### __getitem__

**Param√®tres :**

- `name`

##### tree

Get a tree renderable to show layout structure.

##### split

Split the layout in to multiple sub-layouts.

Args:
    *layouts (Layout): Positional arguments should be (sub) Layout instances.
    splitter (Union[Splitter, str]): Splitter instance or name of splitter.

##### add_split

Add a new layout(s) to existing split.

Args:
    *layouts (Union[Layout, RenderableType]): Positional arguments should be renderables or (sub) Layout instances.

##### split_row

Split the layout in to a row (layouts side by side).

Args:
    *layouts (Layout): Positional arguments should be (sub) Layout instances.

##### split_column

Split the layout in to a column (layouts stacked on top of each other).

Args:
    *layouts (Layout): Positional arguments should be (sub) Layout instances.

##### unsplit

Reset splits to initial state.

##### update

Update renderable.

Args:
    renderable (RenderableType): New renderable object.

**Param√®tres :**

- `renderable`

##### refresh_screen

Refresh a sub-layout.

Args:
    console (Console): Console instance where Layout is to be rendered.
    layout_name (str): Name of layout.

**Param√®tres :**

- `console`
- `layout_name`

##### _make_region_map

Create a dict that maps layout on to Region.

**Param√®tres :**

- `width`
- `height`

##### render

Render the sub_layouts.

Args:
    console (Console): Console instance.
    options (ConsoleOptions): Console options.

Returns:
    RenderMap: A dict that maps Layout on to a tuple of Region, lines

**Param√®tres :**

- `console`
- `options`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### summary

**Param√®tres :**

- `layout`

##### recurse

**Param√®tres :**

- `tree`
- `layout`

---

### live

#### Classes

##### _RefreshThread

A thread that calls refresh() at regular intervals.

**M√©thodes :**

- `__init__()`
- `stop()`
- `run()`

##### Live

Renders an auto-updating live display of any given renderable.

Args:
    renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.
    console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.
    screen (bool, optional): Enable alternate screen mode. Defaults to False.
    auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True
    refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.
    transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.
    redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.
    redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.
    vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to "ellipsis".
    get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None.

**M√©thodes :**

- `__init__()`
- `is_started()`
- `get_renderable()`
- `start()`
- `stop()`
- `__enter__()`
- `__exit__()`
- `_enable_redirect_io()`
- `_disable_redirect_io()`
- `renderable()`
- `update()`
- `refresh()`
- `process_renderables()`

#### Fonctions

##### __init__

**Param√®tres :**

- `live`
- `refresh_per_second`

##### stop

##### run

##### __init__

**Param√®tres :**

- `renderable`

##### is_started

Check if live display has been started.

##### get_renderable

##### start

Start live rendering display.

Args:
    refresh (bool, optional): Also refresh. Defaults to False.

**Param√®tres :**

- `refresh`

##### stop

Stop live rendering display.

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### _enable_redirect_io

Enable redirecting of stdout / stderr.

##### _disable_redirect_io

Disable redirecting of stdout / stderr.

##### renderable

Get the renderable that is being displayed

Returns:
    RenderableType: Displayed renderable.

##### update

Update the renderable that is being displayed

Args:
    renderable (RenderableType): New renderable to use.
    refresh (bool, optional): Refresh the display. Defaults to False.

**Param√®tres :**

- `renderable`

##### refresh

Update the display of the Live Render.

##### process_renderables

Process renderables to restore cursor and display progress.

**Param√®tres :**

- `renderables`

---

### live_render

#### Classes

##### LiveRender

Creates a renderable that may be updated.

Args:
    renderable (RenderableType): Any renderable object.
    style (StyleType, optional): An optional style to apply to the renderable. Defaults to "".

**M√©thodes :**

- `__init__()`
- `set_renderable()`
- `position_cursor()`
- `restore_cursor()`
- `__rich_console__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderable`
- `style`
- `vertical_overflow`

##### set_renderable

Set a new renderable.

Args:
    renderable (RenderableType): Any renderable object, including str.

**Param√®tres :**

- `renderable`

##### position_cursor

Get control codes to move cursor to beginning of live render.

Returns:
    Control: A control instance that may be printed.

##### restore_cursor

Get control codes to clear the render and restore the cursor to its previous position.

Returns:
    Control: A Control instance that may be printed.

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

---

### logging

#### Classes

##### RichHandler

A logging handler that renders output with Rich. The time / level / message and file are displayed in columns.
The level is color coded, and the message is syntax highlighted.

Note:
    Be careful when enabling console markup in log messages if you have configured logging for libraries not
    under your control. If a dependency writes messages containing square brackets, it may not produce the intended output.

Args:
    level (Union[int, str], optional): Log level. Defaults to logging.NOTSET.
    console (:class:`~rich.console.Console`, optional): Optional console instance to write logs.
        Default will use a global console instance writing to stdout.
    show_time (bool, optional): Show a column for the time. Defaults to True.
    omit_repeated_times (bool, optional): Omit repetition of the same time. Defaults to True.
    show_level (bool, optional): Show a column for the level. Defaults to True.
    show_path (bool, optional): Show the path to the original log call. Defaults to True.
    enable_link_path (bool, optional): Enable terminal link of path column to file. Defaults to True.
    highlighter (Highlighter, optional): Highlighter to style log messages, or None to use ReprHighlighter. Defaults to None.
    markup (bool, optional): Enable console markup in log messages. Defaults to False.
    rich_tracebacks (bool, optional): Enable rich tracebacks with syntax highlighting and formatting. Defaults to False.
    tracebacks_width (Optional[int], optional): Number of characters used to render tracebacks, or None for full width. Defaults to None.
    tracebacks_code_width (int, optional): Number of code characters used to render tracebacks, or None for full width. Defaults to 88.
    tracebacks_extra_lines (int, optional): Additional lines of code to render tracebacks, or None for full width. Defaults to None.
    tracebacks_theme (str, optional): Override pygments theme used in traceback.
    tracebacks_word_wrap (bool, optional): Enable word wrapping of long tracebacks lines. Defaults to True.
    tracebacks_show_locals (bool, optional): Enable display of locals in tracebacks. Defaults to False.
    tracebacks_suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    tracebacks_max_frames (int, optional): Optional maximum number of frames returned by traceback.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to "[%x %X] ".
    keywords (List[str], optional): List of words to highlight instead of ``RichHandler.KEYWORDS``.

**M√©thodes :**

- `__init__()`
- `get_level_text()`
- `emit()`
- `render_message()`
- `render()`

#### Fonctions

##### __init__

**Param√®tres :**

- `level`
- `console`

##### get_level_text

Get the level name from the record.

Args:
    record (LogRecord): LogRecord instance.

Returns:
    Text: A tuple of the style and level name.

**Param√®tres :**

- `record`

##### emit

Invoked by logging.

**Param√®tres :**

- `record`

##### render_message

Render message text in to Text.

Args:
    record (LogRecord): logging Record.
    message (str): String containing log message.

Returns:
    ConsoleRenderable: Renderable to display log message.

**Param√®tres :**

- `record`
- `message`

##### render

Render log for display.

Args:
    record (LogRecord): logging Record.
    traceback (Optional[Traceback]): Traceback instance or None for no Traceback.
    message_renderable (ConsoleRenderable): Renderable (typically Text) containing log message contents.

Returns:
    ConsoleRenderable: Renderable to display log.

##### divide

---

### markup

#### Classes

##### Tag

A tag in console markup.

**M√©thodes :**

- `__str__()`
- `markup()`

#### Fonctions

##### escape

Escapes text so that it won't be interpreted as markup.

Args:
    markup (str): Content to be inserted in to markup.

Returns:
    str: Markup with square brackets escaped.

**Param√®tres :**

- `markup`
- `_escape`

##### _parse

Parse markup in to an iterable of tuples of (position, text, tag).

Args:
    markup (str): A string containing console markup

**Param√®tres :**

- `markup`

##### render

Render console markup in to a Text instance.

Args:
    markup (str): A string containing console markup.
    style: (Union[str, Style]): The style to use.
    emoji (bool, optional): Also render emoji code. Defaults to True.
    emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.


Raises:
    MarkupError: If there is a syntax error in the markup.

Returns:
    Text: A test instance.

**Param√®tres :**

- `markup`
- `style`
- `emoji`
- `emoji_variant`

##### __str__

##### markup

Get the string representation of this tag.

##### escape_backslashes

Called by re.sub replace matches.

**Param√®tres :**

- `match`

##### pop_style

Pop tag matching given style name.

**Param√®tres :**

- `style_name`

---

### measure

#### Classes

##### Measurement

Stores the minimum and maximum widths (in characters) required to render an object.

**M√©thodes :**

- `span()`
- `normalize()`
- `with_maximum()`
- `with_minimum()`
- `clamp()`
- `get()`

#### Fonctions

##### measure_renderables

Get a measurement that would fit a number of renderables.

Args:
    console (~rich.console.Console): Console instance.
    options (~rich.console.ConsoleOptions): Console options.
    renderables (Iterable[RenderableType]): One or more renderable objects.

Returns:
    Measurement: Measurement object containing range of character widths required to
        contain all given renderables.

**Param√®tres :**

- `console`
- `options`
- `renderables`

##### span

Get difference between maximum and minimum.

##### normalize

Get measurement that ensures that minimum <= maximum and minimum >= 0

Returns:
    Measurement: A normalized measurement.

##### with_maximum

Get a RenderableWith where the widths are <= width.

Args:
    width (int): Maximum desired width.

Returns:
    Measurement: New Measurement object.

**Param√®tres :**

- `width`

##### with_minimum

Get a RenderableWith where the widths are >= width.

Args:
    width (int): Minimum desired width.

Returns:
    Measurement: New Measurement object.

**Param√®tres :**

- `width`

##### clamp

Clamp a measurement within the specified range.

Args:
    min_width (int): Minimum desired width, or ``None`` for no minimum. Defaults to None.
    max_width (int): Maximum desired width, or ``None`` for no maximum. Defaults to None.

Returns:
    Measurement: New Measurement object.

**Param√®tres :**

- `min_width`
- `max_width`

##### get

Get a measurement for a renderable.

Args:
    console (~rich.console.Console): Console instance.
    options (~rich.console.ConsoleOptions): Console options.
    renderable (RenderableType): An object that may be rendered with Rich.

Raises:
    errors.NotRenderableError: If the object is not renderable.

Returns:
    Measurement: Measurement object containing range of character widths required to render the object.

**Param√®tres :**

- `cls`
- `console`
- `options`
- `renderable`

---

### padding

#### Classes

##### Padding

Draw space around content.

Example:
    >>> print(Padding("Hello", (2, 4), style="on blue"))

Args:
    renderable (RenderableType): String or other renderable.
    pad (Union[int, Tuple[int]]): Padding for top, right, bottom, and left borders.
        May be specified with 1, 2, or 4 integers (CSS style).
    style (Union[str, Style], optional): Style for padding characters. Defaults to "none".
    expand (bool, optional): Expand padding to fit available width. Defaults to True.

**M√©thodes :**

- `__init__()`
- `indent()`
- `unpack()`
- `__repr__()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderable`
- `pad`

##### indent

Make padding instance to render an indent.

Args:
    renderable (RenderableType): String or other renderable.
    level (int): Number of characters to indent.

Returns:
    Padding: A Padding instance.

**Param√®tres :**

- `cls`
- `renderable`
- `level`

##### unpack

Unpack padding specified in CSS style.

**Param√®tres :**

- `pad`

##### __repr__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

---

### pager

#### Classes

##### Pager

Base class for a pager.

**M√©thodes :**

- `show()`

##### SystemPager

Uses the pager installed on the system.

**M√©thodes :**

- `_pager()`
- `show()`

#### Fonctions

##### show

Show content in pager.

Args:
    content (str): Content to be displayed.

**Param√®tres :**

- `content`

##### _pager

**Param√®tres :**

- `content`

##### show

Use the same pager used by pydoc.

**Param√®tres :**

- `content`

---

### palette

#### Classes

##### Palette

A palette of available colors.

**M√©thodes :**

- `__init__()`
- `__getitem__()`
- `__rich__()`
- `match()`

##### ColorBox

**M√©thodes :**

- `__rich_console__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `colors`

##### __getitem__

**Param√®tres :**

- `number`

##### __rich__

##### match

Find a color from a palette that most closely matches a given color.

Args:
    color (Tuple[int, int, int]): RGB components in range 0 > 255.

Returns:
    int: Index of closes matching color.

**Param√®tres :**

- `color`

##### get_color_distance

Get the distance to a color.

**Param√®tres :**

- `index`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

---

### panel

#### Classes

##### Panel

A console renderable that draws a border around its contents.

Example:
    >>> console.print(Panel("Hello, World!"))

Args:
    renderable (RenderableType): A console renderable object.
    box (Box): A Box instance that defines the look of the border (see :ref:`appendix_box`. Defaults to box.ROUNDED.
    title (Optional[TextType], optional): Optional title displayed in panel header. Defaults to None.
    title_align (AlignMethod, optional): Alignment of title. Defaults to "center".
    subtitle (Optional[TextType], optional): Optional subtitle displayed in panel footer. Defaults to None.
    subtitle_align (AlignMethod, optional): Alignment of subtitle. Defaults to "center".
    safe_box (bool, optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
    expand (bool, optional): If True the panel will stretch to fill the console width, otherwise it will be sized to fit the contents. Defaults to True.
    style (str, optional): The style of the panel (border and contents). Defaults to "none".
    border_style (str, optional): The style of the border. Defaults to "none".
    width (Optional[int], optional): Optional width of panel. Defaults to None to auto-detect.
    height (Optional[int], optional): Optional height of panel. Defaults to None to auto-detect.
    padding (Optional[PaddingDimensions]): Optional padding around renderable. Defaults to 0.
    highlight (bool, optional): Enable automatic highlighting of panel title (if str). Defaults to False.

**M√©thodes :**

- `__init__()`
- `fit()`
- `_title()`
- `_subtitle()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderable`
- `box`

##### fit

An alternative constructor that sets expand=False.

**Param√®tres :**

- `cls`
- `renderable`
- `box`

##### _title

##### _subtitle

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### align_text

Gets new aligned text.

Args:
    text (Text): Title or subtitle text.
    width (int): Desired width.
    align (str): Alignment.
    character (str): Character for alignment.
    style (Style): Border style

Returns:
    Text: New text instance

**Param√®tres :**

- `text`
- `width`
- `align`
- `character`
- `style`

---

### pretty

#### Classes

##### Pretty

A rich renderable that pretty prints an object.

Args:
    _object (Any): An object to pretty print.
    highlighter (HighlighterType, optional): Highlighter object to apply to result, or None for ReprHighlighter. Defaults to None.
    indent_size (int, optional): Number of spaces in indent. Defaults to 4.
    justify (JustifyMethod, optional): Justify method, or None for default. Defaults to None.
    overflow (OverflowMethod, optional): Overflow method, or None for default. Defaults to None.
    no_wrap (Optional[bool], optional): Disable word wrapping. Defaults to False.
    indent_guides (bool, optional): Enable indentation guides. Defaults to False.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
    max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
    expand_all (bool, optional): Expand all containers. Defaults to False.
    margin (int, optional): Subtrace a margin from width to force containers to expand earlier. Defaults to 0.
    insert_line (bool, optional): Insert a new line if the output has multiple new lines. Defaults to False.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`
- `__rich_measure__()`

##### Node

A node in a repr tree. May be atomic or a container.

**M√©thodes :**

- `iter_tokens()`
- `check_length()`
- `__str__()`
- `render()`

##### _Line

A line in repr output.

**M√©thodes :**

- `expandable()`
- `check_length()`
- `expand()`
- `__str__()`

##### BrokenRepr

**M√©thodes :**

- `__repr__()`

##### StockKeepingUnit

##### Thing

**M√©thodes :**

- `__repr__()`

##### RichFormatter

**M√©thodes :**

- `__call__()`

#### Fonctions

##### _is_attr_object

Check if an object was created with attrs module.

**Param√®tres :**

- `obj`

##### _get_attr_fields

Get fields for an attrs object.

**Param√®tres :**

- `obj`

##### _is_dataclass_repr

Check if an instance of a dataclass contains the default repr.

Args:
    obj (object): A dataclass instance.

Returns:
    bool: True if the default repr is used, False if there is a custom repr.

**Param√®tres :**

- `obj`

##### _has_default_namedtuple_repr

Check if an instance of namedtuple contains the default repr

Args:
    obj (object): A namedtuple

Returns:
    bool: True if the default repr is used, False if there's a custom repr.

**Param√®tres :**

- `obj`

##### _ipy_display_hook

**Param√®tres :**

- `value`
- `console`
- `overflow`
- `crop`
- `indent_guides`
- `max_length`
- `max_string`
- `max_depth`
- `expand_all`

##### _safe_isinstance

isinstance can fail in rare cases, for example types with no __class__

**Param√®tres :**

- `obj`
- `class_or_tuple`

##### install

Install automatic pretty printing in the Python REPL.

Args:
    console (Console, optional): Console instance or ``None`` to use global console. Defaults to None.
    overflow (Optional[OverflowMethod], optional): Overflow method. Defaults to "ignore".
    crop (Optional[bool], optional): Enable cropping of long lines. Defaults to False.
    indent_guides (bool, optional): Enable indentation guides. Defaults to False.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
    max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
    expand_all (bool, optional): Expand all containers. Defaults to False.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.

**Param√®tres :**

- `console`
- `overflow`
- `crop`
- `indent_guides`
- `max_length`
- `max_string`
- `max_depth`
- `expand_all`

##### _get_braces_for_defaultdict

**Param√®tres :**

- `_object`

##### _get_braces_for_deque

**Param√®tres :**

- `_object`

##### _get_braces_for_array

**Param√®tres :**

- `_object`

##### is_expandable

Check if an object may be expanded by pretty print.

**Param√®tres :**

- `obj`

##### _is_namedtuple

Checks if an object is most likely a namedtuple. It is possible
to craft an object that passes this check and isn't a namedtuple, but
there is only a minuscule chance of this happening unintentionally.

Args:
    obj (Any): The object to test

Returns:
    bool: True if the object is a namedtuple. False otherwise.

**Param√®tres :**

- `obj`

##### traverse

Traverse object and generate a tree.

Args:
    _object (Any): Object to be traversed.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
        Defaults to None.
    max_depth (int, optional): Maximum depth of data structures, or None for no maximum.
        Defaults to None.

Returns:
    Node: The root of a tree structure which can be used to render a pretty repr.

**Param√®tres :**

- `_object`
- `max_length`
- `max_string`
- `max_depth`

##### pretty_repr

Prettify repr string by expanding on to new lines to fit within a given width.

Args:
    _object (Any): Object to repr.
    max_width (int, optional): Desired maximum width of repr string. Defaults to 80.
    indent_size (int, optional): Number of spaces to indent. Defaults to 4.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
        Defaults to None.
    max_depth (int, optional): Maximum depth of nested data structure, or None for no depth.
        Defaults to None.
    expand_all (bool, optional): Expand all containers regardless of available width. Defaults to False.

Returns:
    str: A possibly multi-line representation of the object.

**Param√®tres :**

- `_object`

##### pprint

A convenience function for pretty printing.

Args:
    _object (Any): Object to pretty print.
    console (Console, optional): Console instance, or None to use default. Defaults to None.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of strings before truncating, or None to disable. Defaults to None.
    max_depth (int, optional): Maximum depth for nested data structures, or None for unlimited depth. Defaults to None.
    indent_guides (bool, optional): Enable indentation guides. Defaults to True.
    expand_all (bool, optional): Expand all containers. Defaults to False.

**Param√®tres :**

- `_object`

##### display_hook

Replacement sys.displayhook which prettifies objects with Rich.

**Param√®tres :**

- `value`

##### __init__

**Param√®tres :**

- `_object`
- `highlighter`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### iter_tokens

Generate tokens for this node.

##### check_length

Check the length fits within a limit.

Args:
    start_length (int): Starting length of the line (indent, prefix, suffix).
    max_length (int): Maximum length.

Returns:
    bool: True if the node can be rendered within max length, otherwise False.

**Param√®tres :**

- `start_length`
- `max_length`

##### __str__

##### render

Render the node to a pretty repr.

Args:
    max_width (int, optional): Maximum width of the repr. Defaults to 80.
    indent_size (int, optional): Size of indents. Defaults to 4.
    expand_all (bool, optional): Expand all levels. Defaults to False.

Returns:
    str: A repr string of the original object.

**Param√®tres :**

- `max_width`
- `indent_size`
- `expand_all`

##### expandable

Check if the line may be expanded.

##### check_length

Check this line fits within a given number of cells.

**Param√®tres :**

- `max_length`

##### expand

Expand this line by adding children on their own line.

**Param√®tres :**

- `indent_size`

##### __str__

##### to_repr

Get repr string for an object, but catch errors.

**Param√®tres :**

- `obj`

##### _traverse

Walk the object depth first.

**Param√®tres :**

- `obj`
- `root`
- `depth`

##### iter_rich_args

**Param√®tres :**

- `rich_args`

##### __repr__

##### __repr__

##### __call__

**Param√®tres :**

- `value`

##### iter_attrs

Iterate over attr fields and values.

---

### progress

#### Classes

##### _TrackThread

A thread to periodically update progress.

**M√©thodes :**

- `__init__()`
- `run()`
- `__enter__()`
- `__exit__()`

##### _Reader

A reader that tracks progress while it's being read from.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `__iter__()`
- `__next__()`
- `closed()`
- `fileno()`
- `isatty()`
- `mode()`
- `name()`
- `readable()`
- `seekable()`
- `writable()`
- `read()`
- `readinto()`
- `readline()`
- `readlines()`
- `close()`
- `seek()`
- `tell()`
- `write()`
- `writelines()`

##### _ReadContext

A utility class to handle a context for both a reader and a progress.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### ProgressColumn

Base class for a widget to use in progress display.

**M√©thodes :**

- `__init__()`
- `get_table_column()`
- `__call__()`
- `render()`

##### RenderableColumn

A column to insert an arbitrary column.

Args:
    renderable (RenderableType, optional): Any renderable. Defaults to empty string.

**M√©thodes :**

- `__init__()`
- `render()`

##### SpinnerColumn

A column with a 'spinner' animation.

Args:
    spinner_name (str, optional): Name of spinner animation. Defaults to "dots".
    style (StyleType, optional): Style of spinner. Defaults to "progress.spinner".
    speed (float, optional): Speed factor of spinner. Defaults to 1.0.
    finished_text (TextType, optional): Text used when task is finished. Defaults to " ".

**M√©thodes :**

- `__init__()`
- `set_spinner()`
- `render()`

##### TextColumn

A column containing text.

**M√©thodes :**

- `__init__()`
- `render()`

##### BarColumn

Renders a visual progress bar.

Args:
    bar_width (Optional[int], optional): Width of bar or None for full width. Defaults to 40.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".

**M√©thodes :**

- `__init__()`
- `render()`

##### TimeElapsedColumn

Renders time elapsed.

**M√©thodes :**

- `render()`

##### TaskProgressColumn

Show task progress as a percentage.

Args:
    text_format (str, optional): Format for percentage display. Defaults to "[progress.percentage]{task.percentage:>3.0f}%".
    text_format_no_percentage (str, optional): Format if percentage is unknown. Defaults to "".
    style (StyleType, optional): Style of output. Defaults to "none".
    justify (JustifyMethod, optional): Text justification. Defaults to "left".
    markup (bool, optional): Enable markup. Defaults to True.
    highlighter (Optional[Highlighter], optional): Highlighter to apply to output. Defaults to None.
    table_column (Optional[Column], optional): Table Column to use. Defaults to None.
    show_speed (bool, optional): Show speed if total is unknown. Defaults to False.

**M√©thodes :**

- `__init__()`
- `render_speed()`
- `render()`

##### TimeRemainingColumn

Renders estimated time remaining.

Args:
    compact (bool, optional): Render MM:SS when time remaining is less than an hour. Defaults to False.
    elapsed_when_finished (bool, optional): Render time elapsed when the task is finished. Defaults to False.

**M√©thodes :**

- `__init__()`
- `render()`

##### FileSizeColumn

Renders completed filesize.

**M√©thodes :**

- `render()`

##### TotalFileSizeColumn

Renders total filesize.

**M√©thodes :**

- `render()`

##### MofNCompleteColumn

Renders completed count/total, e.g. '  10/1000'.

Best for bounded tasks with int quantities.

Space pads the completed count so that progress length does not change as task progresses
past powers of 10.

Args:
    separator (str, optional): Text to separate completed and total values. Defaults to "/".

**M√©thodes :**

- `__init__()`
- `render()`

##### DownloadColumn

Renders file size downloaded and total, e.g. '0.5/2.3 GB'.

Args:
    binary_units (bool, optional): Use binary units, KiB, MiB etc. Defaults to False.

**M√©thodes :**

- `__init__()`
- `render()`

##### TransferSpeedColumn

Renders human readable transfer speed.

**M√©thodes :**

- `render()`

##### ProgressSample

Sample of progress for a given time.

##### Task

Information regarding a progress task.

This object should be considered read-only outside of the :class:`~Progress` class.

**M√©thodes :**

- `get_time()`
- `started()`
- `remaining()`
- `elapsed()`
- `finished()`
- `percentage()`
- `speed()`
- `time_remaining()`
- `_reset()`

##### Progress

Renders an auto-updating progress bar(s).

Args:
    console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.
    auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()`.
    refresh_per_second (Optional[float], optional): Number of times per second to refresh the progress information or None to use default (10). Defaults to None.
    speed_estimate_period: (float, optional): Period (in seconds) used to calculate the speed estimate. Defaults to 30.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    redirect_stdout: (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.
    redirect_stderr: (bool, optional): Enable redirection of stderr. Defaults to True.
    get_time: (Callable, optional): A callable that gets the current time, or None to use Console.get_time. Defaults to None.
    disable (bool, optional): Disable progress display. Defaults to False
    expand (bool, optional): Expand tasks table to fit width. Defaults to False.

**M√©thodes :**

- `__init__()`
- `get_default_columns()`
- `console()`
- `tasks()`
- `task_ids()`
- `finished()`
- `start()`
- `stop()`
- `__enter__()`
- `__exit__()`
- `track()`
- `wrap_file()`
- `open()`
- `open()`
- `open()`
- `start_task()`
- `stop_task()`
- `update()`
- `reset()`
- `advance()`
- `refresh()`
- `get_renderable()`
- `get_renderables()`
- `make_tasks_table()`
- `__rich__()`
- `add_task()`
- `remove_task()`

#### Fonctions

##### track

Track progress by iterating over a sequence.

Args:
    sequence (Iterable[ProgressType]): A sequence (must support "len") you wish to iterate over.
    description (str, optional): Description of task show next to progress bar. Defaults to "Working".
    total: (float, optional): Total number of steps. Default is len(sequence).
    completed (int, optional): Number of steps completed so far. Defaults to 0.
    auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    console (Console, optional): Console to write to. Default creates internal Console instance.
    refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    update_period (float, optional): Minimum time (in seconds) between calls to update(). Defaults to 0.1.
    disable (bool, optional): Disable display of progress.
    show_speed (bool, optional): Show speed if total isn't known. Defaults to True.
Returns:
    Iterable[ProgressType]: An iterable of the values in the sequence.

**Param√®tres :**

- `sequence`
- `description`
- `total`
- `completed`
- `auto_refresh`
- `console`
- `transient`
- `get_time`
- `refresh_per_second`
- `style`
- `complete_style`
- `finished_style`
- `pulse_style`
- `update_period`
- `disable`
- `show_speed`

##### wrap_file

Read bytes from a file while tracking progress.

Args:
    file (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
    total (int): Total number of bytes to read.
    description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
    auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    console (Console, optional): Console to write to. Default creates internal Console instance.
    refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    disable (bool, optional): Disable display of progress.
Returns:
    ContextManager[BinaryIO]: A context manager yielding a progress reader.

**Param√®tres :**

- `file`
- `total`

##### open

**Param√®tres :**

- `file`
- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

##### open

**Param√®tres :**

- `file`
- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

##### open

Read bytes from a file while tracking progress.

Args:
    path (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
    mode (str): The mode to use to open the file. Only supports "r", "rb" or "rt".
    buffering (int): The buffering strategy to use, see :func:`io.open`.
    encoding (str, optional): The encoding to use when reading in text mode, see :func:`io.open`.
    errors (str, optional): The error handling strategy for decoding errors, see :func:`io.open`.
    newline (str, optional): The strategy for handling newlines in text mode, see :func:`io.open`
    total: (int, optional): Total number of bytes to read. Must be provided if reading from a file handle. Default for a path is os.stat(file).st_size.
    description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
    auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
    transient: (bool, optional): Clear the progress on exit. Defaults to False.
    console (Console, optional): Console to write to. Default creates internal Console instance.
    refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    disable (bool, optional): Disable display of progress.
    encoding (str, optional): The encoding to use when reading in text mode.

Returns:
    ContextManager[BinaryIO]: A context manager yielding a progress reader.

**Param√®tres :**

- `file`
- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

##### __init__

**Param√®tres :**

- `progress`
- `task_id`
- `update_period`

##### run

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

**Param√®tres :**

- `handle`
- `progress`
- `task`
- `close_handle`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __iter__

##### __next__

##### closed

##### fileno

##### isatty

##### mode

##### name

##### readable

##### seekable

##### writable

##### read

**Param√®tres :**

- `size`

##### readinto

**Param√®tres :**

- `b`

##### readline

**Param√®tres :**

- `size`

##### readlines

**Param√®tres :**

- `hint`

##### close

##### seek

**Param√®tres :**

- `offset`
- `whence`

##### tell

##### write

**Param√®tres :**

- `s`

##### writelines

**Param√®tres :**

- `lines`

##### __init__

**Param√®tres :**

- `progress`
- `reader`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

**Param√®tres :**

- `table_column`

##### get_table_column

Get a table column, used to build tasks table.

##### __call__

Called by the Progress object to return a renderable for the given task.

Args:
    task (Task): An object containing information regarding the task.

Returns:
    RenderableType: Anything renderable (including str).

**Param√®tres :**

- `task`

##### render

Should return a renderable object.

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `renderable`

##### render

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `spinner_name`
- `style`
- `speed`
- `finished_text`
- `table_column`

##### set_spinner

Set a new spinner.

Args:
    spinner_name (str): Spinner name, see python -m rich.spinner.
    spinner_style (Optional[StyleType], optional): Spinner style. Defaults to "progress.spinner".
    speed (float, optional): Speed factor of spinner. Defaults to 1.0.

**Param√®tres :**

- `spinner_name`
- `spinner_style`
- `speed`

##### render

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `text_format`
- `style`
- `justify`
- `markup`
- `highlighter`
- `table_column`

##### render

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `bar_width`
- `style`
- `complete_style`
- `finished_style`
- `pulse_style`
- `table_column`

##### render

Gets a progress bar widget for a task.

**Param√®tres :**

- `task`

##### render

Show time elapsed.

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `text_format`
- `text_format_no_percentage`
- `style`
- `justify`
- `markup`
- `highlighter`
- `table_column`
- `show_speed`

##### render_speed

Render the speed in iterations per second.

Args:
    task (Task): A Task object.

Returns:
    Text: Text object containing the task speed.

**Param√®tres :**

- `cls`
- `speed`

##### render

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `compact`
- `elapsed_when_finished`
- `table_column`

##### render

Show time remaining.

**Param√®tres :**

- `task`

##### render

Show data completed.

**Param√®tres :**

- `task`

##### render

Show data completed.

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `separator`
- `table_column`

##### render

Show completed/total.

**Param√®tres :**

- `task`

##### __init__

**Param√®tres :**

- `binary_units`
- `table_column`

##### render

Calculate common unit for completed and total.

**Param√®tres :**

- `task`

##### render

Show data transfer speed.

**Param√®tres :**

- `task`

##### get_time

float: Get the current time, in seconds.

##### started

bool: Check if the task as started.

##### remaining

Optional[float]: Get the number of steps remaining, if a non-None total was set.

##### elapsed

Optional[float]: Time elapsed since task was started, or ``None`` if the task hasn't started.

##### finished

Check if the task has finished.

##### percentage

float: Get progress of task as a percentage. If a None total was set, returns 0

##### speed

Optional[float]: Get the estimated speed in steps per second.

##### time_remaining

Optional[float]: Get estimated time to completion, or ``None`` if no data.

##### _reset

Reset progress.

##### __init__

##### get_default_columns

Get the default columns used for a new Progress instance:
   - a text column for the description (TextColumn)
   - the bar itself (BarColumn)
   - a text column showing completion percentage (TextColumn)
   - an estimated-time-remaining column (TimeRemainingColumn)
If the Progress instance is created without passing a columns argument,
the default columns defined here will be used.

You can also create a Progress instance using custom columns before
and/or after the defaults, as in this example:

    progress = Progress(
        SpinnerColumn(),
        *Progress.get_default_columns(),
        "Elapsed:",
        TimeElapsedColumn(),
    )

This code shows the creation of a Progress display, containing
a spinner to the left, the default columns, and a labeled elapsed
time column.

**Param√®tres :**

- `cls`

##### console

##### tasks

Get a list of Task instances.

##### task_ids

A list of task IDs.

##### finished

Check if all tasks have been completed.

##### start

Start the progress display.

##### stop

Stop the progress display.

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### track

Track progress by iterating over a sequence.

Args:
    sequence (Sequence[ProgressType]): A sequence of values you want to iterate over and track progress.
    total: (float, optional): Total number of steps. Default is len(sequence).
    completed (int, optional): Number of steps completed so far. Defaults to 0.
    task_id: (TaskID): Task to track. Default is new task.
    description: (str, optional): Description of task, if new task is created.
    update_period (float, optional): Minimum time (in seconds) between calls to update(). Defaults to 0.1.

Returns:
    Iterable[ProgressType]: An iterable of values taken from the provided sequence.

**Param√®tres :**

- `sequence`
- `total`
- `completed`
- `task_id`
- `description`
- `update_period`

##### wrap_file

Track progress file reading from a binary file.

Args:
    file (BinaryIO): A file-like object opened in binary mode.
    total (int, optional): Total number of bytes to read. This must be provided unless a task with a total is also given.
    task_id (TaskID): Task to track. Default is new task.
    description (str, optional): Description of task, if new task is created.

Returns:
    BinaryIO: A readable file-like object in binary mode.

Raises:
    ValueError: When no total value can be extracted from the arguments or the task.

**Param√®tres :**

- `file`
- `total`

##### open

**Param√®tres :**

- `file`
- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

##### open

**Param√®tres :**

- `file`
- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

##### open

Track progress while reading from a binary file.

Args:
    path (Union[str, PathLike[str]]): The path to the file to read.
    mode (str): The mode to use to open the file. Only supports "r", "rb" or "rt".
    buffering (int): The buffering strategy to use, see :func:`io.open`.
    encoding (str, optional): The encoding to use when reading in text mode, see :func:`io.open`.
    errors (str, optional): The error handling strategy for decoding errors, see :func:`io.open`.
    newline (str, optional): The strategy for handling newlines in text mode, see :func:`io.open`.
    total (int, optional): Total number of bytes to read. If none given, os.stat(path).st_size is used.
    task_id (TaskID): Task to track. Default is new task.
    description (str, optional): Description of task, if new task is created.

Returns:
    BinaryIO: A readable file-like object in binary mode.

Raises:
    ValueError: When an invalid mode is given.

**Param√®tres :**

- `file`
- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

##### start_task

Start a task.

Starts a task (used when calculating elapsed time). You may need to call this manually,
if you called ``add_task`` with ``start=False``.

Args:
    task_id (TaskID): ID of task.

**Param√®tres :**

- `task_id`

##### stop_task

Stop a task.

This will freeze the elapsed time on the task.

Args:
    task_id (TaskID): ID of task.

**Param√®tres :**

- `task_id`

##### update

Update information associated with a task.

Args:
    task_id (TaskID): Task id (returned by add_task).
    total (float, optional): Updates task.total if not None.
    completed (float, optional): Updates task.completed if not None.
    advance (float, optional): Add a value to task.completed if not None.
    description (str, optional): Change task description if not None.
    visible (bool, optional): Set visible flag if not None.
    refresh (bool): Force a refresh of progress information. Default is False.
    **fields (Any): Additional data fields required for rendering.

**Param√®tres :**

- `task_id`

##### reset

Reset a task so completed is 0 and the clock is reset.

Args:
    task_id (TaskID): ID of task.
    start (bool, optional): Start the task after reset. Defaults to True.
    total (float, optional): New total steps in task, or None to use current total. Defaults to None.
    completed (int, optional): Number of steps completed. Defaults to 0.
    visible (bool, optional): Enable display of the task. Defaults to True.
    description (str, optional): Change task description if not None. Defaults to None.
    **fields (str): Additional data fields required for rendering.

**Param√®tres :**

- `task_id`

##### advance

Advance task by a number of steps.

Args:
    task_id (TaskID): ID of task.
    advance (float): Number of steps to advance. Default is 1.

**Param√®tres :**

- `task_id`
- `advance`

##### refresh

Refresh (render) the progress information.

##### get_renderable

Get a renderable for the progress display.

##### get_renderables

Get a number of renderables for the progress display.

##### make_tasks_table

Get a table to render the Progress display.

Args:
    tasks (Iterable[Task]): An iterable of Task instances, one per row of the table.

Returns:
    Table: A table instance.

**Param√®tres :**

- `tasks`

##### __rich__

Makes the Progress class itself renderable.

##### add_task

Add a new 'task' to the Progress display.

Args:
    description (str): A description of the task.
    start (bool, optional): Start the task immediately (to calculate elapsed time). If set to False,
        you will need to call `start` manually. Defaults to True.
    total (float, optional): Number of total steps in the progress if known.
        Set to None to render a pulsing animation. Defaults to 100.
    completed (int, optional): Number of steps completed so far. Defaults to 0.
    visible (bool, optional): Enable display of the task. Defaults to True.
    **fields (str): Additional data fields required for rendering.

Returns:
    TaskID: An ID you can use when calling `update`.

**Param√®tres :**

- `description`
- `start`
- `total`
- `completed`
- `visible`

##### remove_task

Delete a task if it exists.

Args:
    task_id (TaskID): A task ID.

**Param√®tres :**

- `task_id`

---

### progress_bar

#### Classes

##### ProgressBar

Renders a (progress) bar. Used by rich.progress.

Args:
    total (float, optional): Number of steps in the bar. Defaults to 100. Set to None to render a pulsing animation.
    completed (float, optional): Number of steps completed. Defaults to 0.
    width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.
    pulse (bool, optional): Enable pulse effect. Defaults to False. Will pulse if a None total was passed.
    style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
    complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
    finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
    pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
    animation_time (Optional[float], optional): Time in seconds to use for animation, or None to use system time.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `percentage_completed()`
- `_get_pulse_segments()`
- `update()`
- `_render_pulse()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `total`
- `completed`
- `width`
- `pulse`
- `style`
- `complete_style`
- `finished_style`
- `pulse_style`
- `animation_time`

##### __repr__

##### percentage_completed

Calculate percentage complete.

##### _get_pulse_segments

Get a list of segments to render a pulse animation.

Returns:
    List[Segment]: A list of segments, one segment per character.

**Param√®tres :**

- `fore_style`
- `back_style`
- `color_system`
- `no_color`
- `ascii`

##### update

Update progress with new values.

Args:
    completed (float): Number of steps completed.
    total (float, optional): Total number of steps, or ``None`` to not change. Defaults to None.

**Param√®tres :**

- `completed`
- `total`

##### _render_pulse

Renders the pulse animation.

Args:
    console (Console): Console instance.
    width (int): Width in characters of pulse animation.

Returns:
    RenderResult: [description]

Yields:
    Iterator[Segment]: Segments to render pulse

**Param√®tres :**

- `console`
- `width`
- `ascii`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

---

### prompt

#### Classes

##### PromptError

Exception base class for prompt related errors.

##### InvalidResponse

Exception to indicate a response was invalid. Raise this within process_response() to indicate an error
and provide an error message.

Args:
    message (Union[str, Text]): Error message.

**M√©thodes :**

- `__init__()`
- `__rich__()`

##### PromptBase

Ask the user for input until a valid response is received. This is the base class, see one of
the concrete classes for examples.

Args:
    prompt (TextType, optional): Prompt text. Defaults to "".
    console (Console, optional): A Console instance or None to use global console. Defaults to None.
    password (bool, optional): Enable password input. Defaults to False.
    choices (List[str], optional): A list of valid choices. Defaults to None.
    case_sensitive (bool, optional): Matching of choices should be case-sensitive. Defaults to True.
    show_default (bool, optional): Show default in prompt. Defaults to True.
    show_choices (bool, optional): Show choices in prompt. Defaults to True.

**M√©thodes :**

- `__init__()`
- `ask()`
- `ask()`
- `ask()`
- `render_default()`
- `make_prompt()`
- `get_input()`
- `check_choice()`
- `process_response()`
- `on_validate_error()`
- `pre_prompt()`
- `__call__()`
- `__call__()`
- `__call__()`

##### Prompt

A prompt that returns a str.

Example:
    >>> name = Prompt.ask("Enter your name")

##### IntPrompt

A prompt that returns an integer.

Example:
    >>> burrito_count = IntPrompt.ask("How many burritos do you want to order")

##### FloatPrompt

A prompt that returns a float.

Example:
    >>> temperature = FloatPrompt.ask("Enter desired temperature")

##### Confirm

A yes / no confirmation prompt.

Example:
    >>> if Confirm.ask("Continue"):
            run_job()

**M√©thodes :**

- `render_default()`
- `process_response()`

#### Fonctions

##### __init__

**Param√®tres :**

- `message`

##### __rich__

##### __init__

**Param√®tres :**

- `prompt`

##### ask

**Param√®tres :**

- `cls`
- `prompt`

##### ask

**Param√®tres :**

- `cls`
- `prompt`

##### ask

Shortcut to construct and run a prompt loop and return the result.

Example:
    >>> filename = Prompt.ask("Enter a filename")

Args:
    prompt (TextType, optional): Prompt text. Defaults to "".
    console (Console, optional): A Console instance or None to use global console. Defaults to None.
    password (bool, optional): Enable password input. Defaults to False.
    choices (List[str], optional): A list of valid choices. Defaults to None.
    case_sensitive (bool, optional): Matching of choices should be case-sensitive. Defaults to True.
    show_default (bool, optional): Show default in prompt. Defaults to True.
    show_choices (bool, optional): Show choices in prompt. Defaults to True.
    stream (TextIO, optional): Optional text file open for reading to get input. Defaults to None.

**Param√®tres :**

- `cls`
- `prompt`

##### render_default

Turn the supplied default in to a Text instance.

Args:
    default (DefaultType): Default value.

Returns:
    Text: Text containing rendering of default value.

**Param√®tres :**

- `default`

##### make_prompt

Make prompt text.

Args:
    default (DefaultType): Default value.

Returns:
    Text: Text to display in prompt.

**Param√®tres :**

- `default`

##### get_input

Get input from user.

Args:
    console (Console): Console instance.
    prompt (TextType): Prompt text.
    password (bool): Enable password entry.

Returns:
    str: String from user.

**Param√®tres :**

- `cls`
- `console`
- `prompt`
- `password`
- `stream`

##### check_choice

Check value is in the list of valid choices.

Args:
    value (str): Value entered by user.

Returns:
    bool: True if choice was valid, otherwise False.

**Param√®tres :**

- `value`

##### process_response

Process response from user, convert to prompt type.

Args:
    value (str): String typed by user.

Raises:
    InvalidResponse: If ``value`` is invalid.

Returns:
    PromptType: The value to be returned from ask method.

**Param√®tres :**

- `value`

##### on_validate_error

Called to handle validation error.

Args:
    value (str): String entered by user.
    error (InvalidResponse): Exception instance the initiated the error.

**Param√®tres :**

- `value`
- `error`

##### pre_prompt

Hook to display something before the prompt.

##### __call__

##### __call__

##### __call__

Run the prompt loop.

Args:
    default (Any, optional): Optional default value.

Returns:
    PromptType: Processed value.

##### render_default

Render the default as (y) or (n) rather than True/False.

**Param√®tres :**

- `default`

##### process_response

Convert choices to a bool.

**Param√®tres :**

- `value`

---

### protocol

#### Fonctions

##### is_renderable

Check if an object may be rendered by Rich.

**Param√®tres :**

- `check_object`

##### rich_cast

Cast an object to a renderable by calling __rich__ if present.

Args:
    renderable (object): A potentially renderable object

Returns:
    object: The result of recursively calling __rich__.

**Param√®tres :**

- `renderable`

---

### region

#### Classes

##### Region

Defines a rectangular region of the screen.

---

### repr

#### Classes

##### ReprError

An error occurred when attempting to build a repr.

##### Foo

**M√©thodes :**

- `__rich_repr__()`

#### Fonctions

##### auto

**Param√®tres :**

- `cls`

##### auto

##### auto

Class decorator to create __repr__ from __rich_repr__

**Param√®tres :**

- `cls`

##### rich_repr

**Param√®tres :**

- `cls`

##### rich_repr

##### rich_repr

**Param√®tres :**

- `cls`

##### do_replace

**Param√®tres :**

- `cls`
- `angular`

##### auto_repr

Create repr string from __rich_repr__

##### auto_rich_repr

Auto generate __rich_rep__ from signature of __init__

##### __rich_repr__

---

### rule

#### Classes

##### Rule

A console renderable to draw a horizontal rule (line).

Args:
    title (Union[str, Text], optional): Text to render in the rule. Defaults to "".
    characters (str, optional): Character(s) used to draw the line. Defaults to "‚îÄ".
    style (StyleType, optional): Style of Rule. Defaults to "rule.line".
    end (str, optional): Character at end of Rule. defaults to "\\n"
    align (str, optional): How to align the title, one of "left", "center", or "right". Defaults to "center".

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__rich_console__()`
- `_rule_line()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `title`

##### __repr__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### _rule_line

**Param√®tres :**

- `chars_len`
- `width`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

---

### scope

#### Fonctions

##### render_scope

Render python variables in a given scope.

Args:
    scope (Mapping): A mapping containing variable names and values.
    title (str, optional): Optional title. Defaults to None.
    sort_keys (bool, optional): Enable sorting of items. Defaults to True.
    indent_guides (bool, optional): Enable indentation guides. Defaults to False.
    max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to None.
    max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.

Returns:
    ConsoleRenderable: A renderable object.

**Param√®tres :**

- `scope`

##### sort_items

Sort special variables first, then alphabetically.

**Param√®tres :**

- `item`

##### test

**Param√®tres :**

- `foo`
- `bar`

---

### screen

#### Classes

##### Screen

A renderable that fills the terminal screen and crops excess.

Args:
    renderable (RenderableType): Child renderable.
    style (StyleType, optional): Optional background style. Defaults to None.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`

#### Fonctions

##### __init__

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

---

### segment

#### Classes

##### ControlType

Non-printable control codes which typically translate to ANSI codes.

##### Segment

A piece of text with associated style. Segments are produced by the Console render process and
are ultimately converted in to strings to be written to the terminal.

Args:
    text (str): A piece of text.
    style (:class:`~rich.style.Style`, optional): An optional style to apply to the text.
    control (Tuple[ControlCode], optional): Optional sequence of control codes.

Attributes:
    cell_length (int): The cell length of this Segment.

**M√©thodes :**

- `cell_length()`
- `__rich_repr__()`
- `__bool__()`
- `is_control()`
- `_split_cells()`
- `split_cells()`
- `line()`
- `apply_style()`
- `filter_control()`
- `split_lines()`
- `split_and_crop_lines()`
- `adjust_line_length()`
- `get_line_length()`
- `get_shape()`
- `set_shape()`
- `align_top()`
- `align_bottom()`
- `align_middle()`
- `simplify()`
- `strip_links()`
- `strip_styles()`
- `remove_color()`
- `divide()`

##### Segments

A simple renderable to render an iterable of segments. This class may be useful if
you want to print segments outside of a __rich_console__ method.

Args:
    segments (Iterable[Segment]): An iterable of segments.
    new_lines (bool, optional): Add new lines between segments. Defaults to False.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`

##### SegmentLines

**M√©thodes :**

- `__init__()`
- `__rich_console__()`

#### Fonctions

##### cell_length

The number of terminal cells required to display self.text.

Returns:
    int: A number of cells.

##### __rich_repr__

##### __bool__

Check if the segment contains text.

##### is_control

Check if the segment contains control codes.

##### _split_cells

Split a segment in to two at a given cell position.

Note that splitting a double-width character, may result in that character turning
into two spaces.

Args:
    segment (Segment): A segment to split.
    cut (int): A cell position to cut on.

Returns:
    A tuple of two segments.

**Param√®tres :**

- `cls`
- `segment`
- `cut`

##### split_cells

Split segment in to two segments at the specified column.

If the cut point falls in the middle of a 2-cell wide character then it is replaced
by two spaces, to preserve the display width of the parent segment.

Args:
    cut (int): Offset within the segment to cut.

Returns:
    Tuple[Segment, Segment]: Two segments.

**Param√®tres :**

- `cut`

##### line

Make a new line segment.

**Param√®tres :**

- `cls`

##### apply_style

Apply style(s) to an iterable of segments.

Returns an iterable of segments where the style is replaced by ``style + segment.style + post_style``.

Args:
    segments (Iterable[Segment]): Segments to process.
    style (Style, optional): Base style. Defaults to None.
    post_style (Style, optional): Style to apply on top of segment style. Defaults to None.

Returns:
    Iterable[Segments]: A new iterable of segments (possibly the same iterable).

**Param√®tres :**

- `cls`
- `segments`
- `style`
- `post_style`

##### filter_control

Filter segments by ``is_control`` attribute.

Args:
    segments (Iterable[Segment]): An iterable of Segment instances.
    is_control (bool, optional): is_control flag to match in search.

Returns:
    Iterable[Segment]: And iterable of Segment instances.

**Param√®tres :**

- `cls`
- `segments`
- `is_control`

##### split_lines

Split a sequence of segments in to a list of lines.

Args:
    segments (Iterable[Segment]): Segments potentially containing line feeds.

Yields:
    Iterable[List[Segment]]: Iterable of segment lists, one per line.

**Param√®tres :**

- `cls`
- `segments`

##### split_and_crop_lines

Split segments in to lines, and crop lines greater than a given length.

Args:
    segments (Iterable[Segment]): An iterable of segments, probably
        generated from console.render.
    length (int): Desired line length.
    style (Style, optional): Style to use for any padding.
    pad (bool): Enable padding of lines that are less than `length`.

Returns:
    Iterable[List[Segment]]: An iterable of lines of segments.

**Param√®tres :**

- `cls`
- `segments`
- `length`
- `style`
- `pad`
- `include_new_lines`

##### adjust_line_length

Adjust a line to a given width (cropping or padding as required).

Args:
    segments (Iterable[Segment]): A list of segments in a single line.
    length (int): The desired width of the line.
    style (Style, optional): The style of padding if used (space on the end). Defaults to None.
    pad (bool, optional): Pad lines with spaces if they are shorter than `length`. Defaults to True.

Returns:
    List[Segment]: A line of segments with the desired length.

**Param√®tres :**

- `cls`
- `line`
- `length`
- `style`
- `pad`

##### get_line_length

Get the length of list of segments.

Args:
    line (List[Segment]): A line encoded as a list of Segments (assumes no '\\n' characters),

Returns:
    int: The length of the line.

**Param√®tres :**

- `cls`
- `line`

##### get_shape

Get the shape (enclosing rectangle) of a list of lines.

Args:
    lines (List[List[Segment]]): A list of lines (no '\\n' characters).

Returns:
    Tuple[int, int]: Width and height in characters.

**Param√®tres :**

- `cls`
- `lines`

##### set_shape

Set the shape of a list of lines (enclosing rectangle).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style, optional): Style of any padding added.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        

**Param√®tres :**

- `cls`
- `lines`
- `width`
- `height`
- `style`
- `new_lines`

##### align_top

Aligns lines to top (adds extra lines to bottom as required).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style): Style of any padding added.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        

**Param√®tres :**

- `cls`
- `lines`
- `width`
- `height`
- `style`
- `new_lines`

##### align_bottom

Aligns render to bottom (adds extra lines above as required).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style): Style of any padding added. Defaults to None.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        

**Param√®tres :**

- `cls`
- `lines`
- `width`
- `height`
- `style`
- `new_lines`

##### align_middle

Aligns lines to middle (adds extra lines to above and below as required).

        Args:
            lines (List[List[Segment]]): A list of lines.
            width (int): Desired width.
            height (int, optional): Desired height or None for no change.
            style (Style): Style of any padding added.
            new_lines (bool, optional): Padded lines should include "
". Defaults to False.

        Returns:
            List[List[Segment]]: New list of lines.
        

**Param√®tres :**

- `cls`
- `lines`
- `width`
- `height`
- `style`
- `new_lines`

##### simplify

Simplify an iterable of segments by combining contiguous segments with the same style.

Args:
    segments (Iterable[Segment]): An iterable of segments.

Returns:
    Iterable[Segment]: A possibly smaller iterable of segments that will render the same way.

**Param√®tres :**

- `cls`
- `segments`

##### strip_links

Remove all links from an iterable of styles.

Args:
    segments (Iterable[Segment]): An iterable segments.

Yields:
    Segment: Segments with link removed.

**Param√®tres :**

- `cls`
- `segments`

##### strip_styles

Remove all styles from an iterable of segments.

Args:
    segments (Iterable[Segment]): An iterable segments.

Yields:
    Segment: Segments with styles replace with None

**Param√®tres :**

- `cls`
- `segments`

##### remove_color

Remove all color from an iterable of segments.

Args:
    segments (Iterable[Segment]): An iterable segments.

Yields:
    Segment: Segments with colorless style.

**Param√®tres :**

- `cls`
- `segments`

##### divide

Divides an iterable of segments in to portions.

Args:
    cuts (Iterable[int]): Cell positions where to divide.

Yields:
    [Iterable[List[Segment]]]: An iterable of Segments in List.

**Param√®tres :**

- `cls`
- `segments`
- `cuts`

##### __init__

**Param√®tres :**

- `segments`
- `new_lines`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __init__

A simple renderable containing a number of lines of segments. May be used as an intermediate
in rendering process.

Args:
    lines (Iterable[List[Segment]]): Lists of segments forming lines.
    new_lines (bool, optional): Insert new lines after each line. Defaults to False.

**Param√®tres :**

- `lines`
- `new_lines`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

---

### spinner

#### Classes

##### Spinner

A spinner animation.

Args:
    name (str): Name of spinner (run python -m rich.spinner).
    text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to "".
    style (StyleType, optional): Style for spinner animation. Defaults to None.
    speed (float, optional): Speed factor for animation. Defaults to 1.0.

Raises:
    KeyError: If name isn't one of the supported spinner animations.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`
- `__rich_measure__()`
- `render()`
- `update()`

#### Fonctions

##### __init__

**Param√®tres :**

- `name`
- `text`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### render

Render the spinner for a given time.

Args:
    time (float): Time in seconds.

Returns:
    RenderableType: A renderable containing animation frame.

**Param√®tres :**

- `time`

##### update

Updates attributes of a spinner after it has been started.

Args:
    text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to "".
    style (StyleType, optional): Style for spinner animation. Defaults to None.
    speed (float, optional): Speed factor for animation. Defaults to None.

---

### status

#### Classes

##### Status

Displays a status indicator with a 'spinner' animation.

Args:
    status (RenderableType): A status renderable (str or Text typically).
    console (Console, optional): Console instance to use, or None for global console. Defaults to None.
    spinner (str, optional): Name of spinner animation (see python -m rich.spinner). Defaults to "dots".
    spinner_style (StyleType, optional): Style of spinner. Defaults to "status.spinner".
    speed (float, optional): Speed factor for spinner animation. Defaults to 1.0.
    refresh_per_second (float, optional): Number of refreshes per second. Defaults to 12.5.

**M√©thodes :**

- `__init__()`
- `renderable()`
- `console()`
- `update()`
- `start()`
- `stop()`
- `__rich__()`
- `__enter__()`
- `__exit__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `status`

##### renderable

##### console

Get the Console used by the Status objects.

##### update

Update status.

Args:
    status (Optional[RenderableType], optional): New status renderable or None for no change. Defaults to None.
    spinner (Optional[str], optional): New spinner or None for no change. Defaults to None.
    spinner_style (Optional[StyleType], optional): New spinner style or None for no change. Defaults to None.
    speed (Optional[float], optional): Speed factor for spinner animation or None for no change. Defaults to None.

**Param√®tres :**

- `status`

##### start

Start the status animation.

##### stop

Stop the spinner animation.

##### __rich__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

---

### style

#### Classes

##### _Bit

A descriptor to get/set a style attribute bit.

**M√©thodes :**

- `__init__()`
- `__get__()`

##### Style

A terminal style.

A terminal style consists of a color (`color`), a background color (`bgcolor`), and a number of attributes, such
as bold, italic etc. The attributes have 3 states: they can either be on
(``True``), off (``False``), or not set (``None``).

Args:
    color (Union[Color, str], optional): Color of terminal text. Defaults to None.
    bgcolor (Union[Color, str], optional): Color of terminal background. Defaults to None.
    bold (bool, optional): Enable bold text. Defaults to None.
    dim (bool, optional): Enable dim text. Defaults to None.
    italic (bool, optional): Enable italic text. Defaults to None.
    underline (bool, optional): Enable underlined text. Defaults to None.
    blink (bool, optional): Enabled blinking text. Defaults to None.
    blink2 (bool, optional): Enable fast blinking text. Defaults to None.
    reverse (bool, optional): Enabled reverse text. Defaults to None.
    conceal (bool, optional): Enable concealed text. Defaults to None.
    strike (bool, optional): Enable strikethrough text. Defaults to None.
    underline2 (bool, optional): Enable doubly underlined text. Defaults to None.
    frame (bool, optional): Enable framed text. Defaults to None.
    encircle (bool, optional): Enable encircled text. Defaults to None.
    overline (bool, optional): Enable overlined text. Defaults to None.
    link (str, link): Link URL. Defaults to None.

**M√©thodes :**

- `__init__()`
- `null()`
- `from_color()`
- `from_meta()`
- `on()`
- `link_id()`
- `__str__()`
- `__bool__()`
- `_make_ansi_codes()`
- `normalize()`
- `pick_first()`
- `__rich_repr__()`
- `__eq__()`
- `__ne__()`
- `__hash__()`
- `color()`
- `bgcolor()`
- `link()`
- `transparent_background()`
- `background_style()`
- `meta()`
- `without_color()`
- `parse()`
- `get_html_style()`
- `combine()`
- `chain()`
- `copy()`
- `clear_meta_and_links()`
- `update_link()`
- `render()`
- `test()`
- `_add()`
- `__add__()`

##### StyleStack

A stack of styles.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `current()`
- `push()`
- `pop()`

#### Fonctions

##### __init__

**Param√®tres :**

- `bit_no`

##### __get__

**Param√®tres :**

- `obj`
- `objtype`

##### __init__

##### null

Create an 'null' style, equivalent to Style(), but more performant.

**Param√®tres :**

- `cls`

##### from_color

Create a new style with colors and no attributes.

Returns:
    color (Optional[Color]): A (foreground) color, or None for no color. Defaults to None.
    bgcolor (Optional[Color]): A (background) color, or None for no color. Defaults to None.

**Param√®tres :**

- `cls`
- `color`
- `bgcolor`

##### from_meta

Create a new style with meta data.

Returns:
    meta (Optional[Dict[str, Any]]): A dictionary of meta data. Defaults to None.

**Param√®tres :**

- `cls`
- `meta`

##### on

Create a blank style with meta information.

Example:
    style = Style.on(click=self.on_click)

Args:
    meta (Optional[Dict[str, Any]], optional): An optional dict of meta information.
    **handlers (Any): Keyword arguments are translated in to handlers.

Returns:
    Style: A Style with meta information attached.

**Param√®tres :**

- `cls`
- `meta`

##### link_id

Get a link id, used in ansi code for links.

##### __str__

Re-generate style definition from attributes.

##### __bool__

A Style is false if it has no attributes, colors, or links.

##### _make_ansi_codes

Generate ANSI codes for this style.

Args:
    color_system (ColorSystem): Color system.

Returns:
    str: String containing codes.

**Param√®tres :**

- `color_system`

##### normalize

Normalize a style definition so that styles with the same effect have the same string
representation.

Args:
    style (str): A style definition.

Returns:
    str: Normal form of style definition.

**Param√®tres :**

- `cls`
- `style`

##### pick_first

Pick first non-None style.

**Param√®tres :**

- `cls`

##### __rich_repr__

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __hash__

##### color

The foreground color or None if it is not set.

##### bgcolor

The background color or None if it is not set.

##### link

Link text, if set.

##### transparent_background

Check if the style specified a transparent background.

##### background_style

A Style with background only.

##### meta

Get meta information (can not be changed after construction).

##### without_color

Get a copy of the style with color removed.

##### parse

Parse a style definition.

Args:
    style_definition (str): A string containing a style.

Raises:
    errors.StyleSyntaxError: If the style definition syntax is invalid.

Returns:
    `Style`: A Style instance.

**Param√®tres :**

- `cls`
- `style_definition`

##### get_html_style

Get a CSS style rule.

**Param√®tres :**

- `theme`

##### combine

Combine styles and get result.

Args:
    styles (Iterable[Style]): Styles to combine.

Returns:
    Style: A new style instance.

**Param√®tres :**

- `cls`
- `styles`

##### chain

Combine styles from positional argument in to a single style.

Args:
    *styles (Iterable[Style]): Styles to combine.

Returns:
    Style: A new style instance.

**Param√®tres :**

- `cls`

##### copy

Get a copy of this style.

Returns:
    Style: A new Style instance with identical attributes.

##### clear_meta_and_links

Get a copy of this style with link and meta information removed.

Returns:
    Style: New style object.

##### update_link

Get a copy with a different value for link.

Args:
    link (str, optional): New value for link. Defaults to None.

Returns:
    Style: A new Style instance.

**Param√®tres :**

- `link`

##### render

Render the ANSI codes for the style.

Args:
    text (str, optional): A string to style. Defaults to "".
    color_system (Optional[ColorSystem], optional): Color system to render to. Defaults to ColorSystem.TRUECOLOR.

Returns:
    str: A string containing ANSI style codes.

**Param√®tres :**

- `text`

##### test

Write text with style directly to terminal.

This method is for testing purposes only.

Args:
    text (Optional[str], optional): Text to style or None for style name.

**Param√®tres :**

- `text`

##### _add

**Param√®tres :**

- `style`

##### __add__

**Param√®tres :**

- `style`

##### __init__

**Param√®tres :**

- `default_style`

##### __repr__

##### current

Get the Style at the top of the stack.

##### push

Push a new style on to the stack.

Args:
    style (Style): New style to combine with current style.

**Param√®tres :**

- `style`

##### pop

Pop last style and discard.

Returns:
    Style: New current style (also available as stack.current)

##### _make_color

**Param√®tres :**

- `color`

---

### styled

#### Classes

##### Styled

Apply a style to a renderable.

Args:
    renderable (RenderableType): Any renderable.
    style (StyleType): A style to apply across the entire renderable.

**M√©thodes :**

- `__init__()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `renderable`
- `style`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

---

### syntax

#### Classes

##### SyntaxTheme

Base class for a syntax theme.

**M√©thodes :**

- `get_style_for_token()`
- `get_background_style()`

##### PygmentsSyntaxTheme

Syntax theme that delegates to Pygments theme.

**M√©thodes :**

- `__init__()`
- `get_style_for_token()`
- `get_background_style()`

##### ANSISyntaxTheme

Syntax theme to use standard colors.

**M√©thodes :**

- `__init__()`
- `get_style_for_token()`
- `get_background_style()`

##### _SyntaxHighlightRange

A range to highlight in a Syntax object.
`start` and `end` are 2-integers tuples, where the first integer is the line number
(starting from 1) and the second integer is the column index (starting from 0).

##### Syntax

Construct a Syntax object to render syntax highlighted code.

Args:
    code (str): Code to highlight.
    lexer (Lexer | str): Lexer to use (see https://pygments.org/docs/lexers/)
    theme (str, optional): Color theme, aka Pygments style (see https://pygments.org/docs/styles/#getting-a-list-of-available-styles). Defaults to "monokai".
    dedent (bool, optional): Enable stripping of initial whitespace. Defaults to False.
    line_numbers (bool, optional): Enable rendering of line numbers. Defaults to False.
    start_line (int, optional): Starting number for line numbers. Defaults to 1.
    line_range (Tuple[int | None, int | None], optional): If given should be a tuple of the start and end line to render.
        A value of None in the tuple indicates the range is open in that direction.
    highlight_lines (Set[int]): A set of line numbers to highlight.
    code_width: Width of code to render (not including line numbers), or ``None`` to use all available width.
    tab_size (int, optional): Size of tabs. Defaults to 4.
    word_wrap (bool, optional): Enable word wrapping.
    background_color (str, optional): Optional background color, or None to use theme color. Defaults to None.
    indent_guides (bool, optional): Show indent guides. Defaults to False.
    padding (PaddingDimensions): Padding to apply around the syntax. Defaults to 0 (no padding).

**M√©thodes :**

- `get_theme()`
- `__init__()`
- `from_path()`
- `guess_lexer()`
- `_get_base_style()`
- `_get_token_color()`
- `lexer()`
- `default_lexer()`
- `highlight()`
- `stylize_range()`
- `_get_line_numbers_color()`
- `_numbers_column_width()`
- `_get_number_styles()`
- `__rich_measure__()`
- `__rich_console__()`
- `_get_syntax()`
- `_apply_stylized_ranges()`
- `_process_code()`

#### Fonctions

##### _get_code_index_for_syntax_position

Returns the index of the code string for the given positions.

Args:
    newlines_offsets (Sequence[int]): The offset of each newline character found in the code snippet.
    position (SyntaxPosition): The position to search for.

Returns:
    Optional[int]: The index of the code string for this position, or `None`
        if the given position's line number is out of range (if it's the column that is out of range
        we silently clamp its value so that it reaches the end of the line)

**Param√®tres :**

- `newlines_offsets`
- `position`

##### get_style_for_token

Get a style for a given Pygments token.

**Param√®tres :**

- `token_type`

##### get_background_style

Get the background color.

##### __init__

**Param√®tres :**

- `theme`

##### get_style_for_token

Get a style from a Pygments class.

**Param√®tres :**

- `token_type`

##### get_background_style

##### __init__

**Param√®tres :**

- `style_map`

##### get_style_for_token

Look up style in the style map.

**Param√®tres :**

- `token_type`

##### get_background_style

##### get_theme

Get a syntax theme instance.

**Param√®tres :**

- `cls`
- `name`

##### __init__

**Param√®tres :**

- `code`
- `lexer`

##### from_path

Construct a Syntax object from a file.

Args:
    path (str): Path to file to highlight.
    encoding (str): Encoding of file.
    lexer (str | Lexer, optional): Lexer to use. If None, lexer will be auto-detected from path/file content.
    theme (str, optional): Color theme, aka Pygments style (see https://pygments.org/docs/styles/#getting-a-list-of-available-styles). Defaults to "emacs".
    dedent (bool, optional): Enable stripping of initial whitespace. Defaults to True.
    line_numbers (bool, optional): Enable rendering of line numbers. Defaults to False.
    start_line (int, optional): Starting number for line numbers. Defaults to 1.
    line_range (Tuple[int, int], optional): If given should be a tuple of the start and end line to render.
    highlight_lines (Set[int]): A set of line numbers to highlight.
    code_width: Width of code to render (not including line numbers), or ``None`` to use all available width.
    tab_size (int, optional): Size of tabs. Defaults to 4.
    word_wrap (bool, optional): Enable word wrapping of code.
    background_color (str, optional): Optional background color, or None to use theme color. Defaults to None.
    indent_guides (bool, optional): Show indent guides. Defaults to False.
    padding (PaddingDimensions): Padding to apply around the syntax. Defaults to 0 (no padding).

Returns:
    [Syntax]: A Syntax object that may be printed to the console

**Param√®tres :**

- `cls`
- `path`
- `encoding`
- `lexer`
- `theme`
- `dedent`
- `line_numbers`
- `line_range`
- `start_line`
- `highlight_lines`
- `code_width`
- `tab_size`
- `word_wrap`
- `background_color`
- `indent_guides`
- `padding`

##### guess_lexer

Guess the alias of the Pygments lexer to use based on a path and an optional string of code.
If code is supplied, it will use a combination of the code and the filename to determine the
best lexer to use. For example, if the file is ``index.html`` and the file contains Django
templating syntax, then "html+django" will be returned. If the file is ``index.html``, and no
templating language is used, the "html" lexer will be used. If no string of code
is supplied, the lexer will be chosen based on the file extension..

Args:
     path (AnyStr): The path to the file containing the code you wish to know the lexer for.
     code (str, optional): Optional string of code that will be used as a fallback if no lexer
        is found for the supplied path.

Returns:
    str: The name of the Pygments lexer that best matches the supplied path/code.

**Param√®tres :**

- `cls`
- `path`
- `code`

##### _get_base_style

Get the base style.

##### _get_token_color

Get a color (if any) for the given token.

Args:
    token_type (TokenType): A token type tuple from Pygments.

Returns:
    Optional[Color]: Color from theme, or None for no color.

**Param√®tres :**

- `token_type`

##### lexer

The lexer for this syntax, or None if no lexer was found.

Tries to find the lexer by name if a string was passed to the constructor.

##### default_lexer

A Pygments Lexer to use if one is not specified or invalid.

##### highlight

Highlight code and return a Text instance.

Args:
    code (str): Code to highlight.
    line_range(Tuple[int, int], optional): Optional line range to highlight.

Returns:
    Text: A text instance containing highlighted syntax.

**Param√®tres :**

- `code`
- `line_range`

##### stylize_range

Adds a custom style on a part of the code, that will be applied to the syntax display when it's rendered.
Line numbers are 1-based, while column indexes are 0-based.

Args:
    style (StyleType): The style to apply.
    start (Tuple[int, int]): The start of the range, in the form `[line number, column index]`.
    end (Tuple[int, int]): The end of the range, in the form `[line number, column index]`.
    style_before (bool): Apply the style before any existing styles.

**Param√®tres :**

- `style`
- `start`
- `end`
- `style_before`

##### _get_line_numbers_color

**Param√®tres :**

- `blend`

##### _numbers_column_width

Get the number of characters used to render the numbers column.

##### _get_number_styles

Get background, number, and highlight styles for line numbers.

**Param√®tres :**

- `console`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### _get_syntax

Get the Segments for the Syntax object, excluding any vertical/horizontal padding

**Param√®tres :**

- `console`
- `options`

##### _apply_stylized_ranges

Apply stylized ranges to a text instance,
using the given code to determine the right portion to apply the style to.

Args:
    text (Text): Text instance to apply the style to.

**Param√®tres :**

- `text`

##### _process_code

Applies various processing to a raw code string
(normalises it so it always ends with a line return, dedents it if necessary, etc.)

Args:
    code (str): The raw code string to process

Returns:
    Tuple[bool, str]: the boolean indicates whether the raw code ends with a line return,
        while the string is the processed code.

**Param√®tres :**

- `code`

##### line_tokenize

Split tokens to one per line.

##### tokens_to_spans

Convert tokens to spans.

---

### table

#### Classes

##### Column

Defines a column within a ~Table.

Args:
    title (Union[str, Text], optional): The title of the table rendered at the top. Defaults to None.
    caption (Union[str, Text], optional): The table caption rendered below. Defaults to None.
    width (int, optional): The width in characters of the table, or ``None`` to automatically fit. Defaults to None.
    min_width (Optional[int], optional): The minimum width of the table, or ``None`` for no minimum. Defaults to None.
    box (box.Box, optional): One of the constants in box.py used to draw the edges (see :ref:`appendix_box`), or ``None`` for no box lines. Defaults to box.HEAVY_HEAD.
    safe_box (Optional[bool], optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
    padding (PaddingDimensions, optional): Padding for cells (top, right, bottom, left). Defaults to (0, 1).
    collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to False.
    pad_edge (bool, optional): Enable padding of edge cells. Defaults to True.
    expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.
    show_header (bool, optional): Show a header row. Defaults to True.
    show_footer (bool, optional): Show a footer row. Defaults to False.
    show_edge (bool, optional): Draw a box around the outside of the table. Defaults to True.
    show_lines (bool, optional): Draw lines between every row. Defaults to False.
    leading (int, optional): Number of blank lines between rows (precludes ``show_lines``). Defaults to 0.
    style (Union[str, Style], optional): Default style for the table. Defaults to "none".
    row_styles (List[Union, str], optional): Optional list of row styles, if more than one style is given then the styles will alternate. Defaults to None.
    header_style (Union[str, Style], optional): Style of the header. Defaults to "table.header".
    footer_style (Union[str, Style], optional): Style of the footer. Defaults to "table.footer".
    border_style (Union[str, Style], optional): Style of the border. Defaults to None.
    title_style (Union[str, Style], optional): Style of the title. Defaults to None.
    caption_style (Union[str, Style], optional): Style of the caption. Defaults to None.
    title_justify (str, optional): Justify method for title. Defaults to "center".
    caption_justify (str, optional): Justify method for caption. Defaults to "center".
    highlight (bool, optional): Highlight cell contents (if str). Defaults to False.

**M√©thodes :**

- `copy()`
- `cells()`
- `flexible()`

##### Row

Information regarding a row.

##### _Cell

A single cell in a table.

##### Table

A console renderable to draw a table.

Args:
    *headers (Union[Column, str]): Column headers, either as a string, or :class:`~rich.table.Column` instance.
    title (Union[str, Text], optional): The title of the table rendered at the top. Defaults to None.
    caption (Union[str, Text], optional): The table caption rendered below. Defaults to None.
    width (int, optional): The width in characters of the table, or ``None`` to automatically fit. Defaults to None.
    min_width (Optional[int], optional): The minimum width of the table, or ``None`` for no minimum. Defaults to None.
    box (box.Box, optional): One of the constants in box.py used to draw the edges (see :ref:`appendix_box`), or ``None`` for no box lines. Defaults to box.HEAVY_HEAD.
    safe_box (Optional[bool], optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
    padding (PaddingDimensions, optional): Padding for cells (top, right, bottom, left). Defaults to (0, 1).
    collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to False.
    pad_edge (bool, optional): Enable padding of edge cells. Defaults to True.
    expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.
    show_header (bool, optional): Show a header row. Defaults to True.
    show_footer (bool, optional): Show a footer row. Defaults to False.
    show_edge (bool, optional): Draw a box around the outside of the table. Defaults to True.
    show_lines (bool, optional): Draw lines between every row. Defaults to False.
    leading (int, optional): Number of blank lines between rows (precludes ``show_lines``). Defaults to 0.
    style (Union[str, Style], optional): Default style for the table. Defaults to "none".
    row_styles (List[Union, str], optional): Optional list of row styles, if more than one style is given then the styles will alternate. Defaults to None.
    header_style (Union[str, Style], optional): Style of the header. Defaults to "table.header".
    footer_style (Union[str, Style], optional): Style of the footer. Defaults to "table.footer".
    border_style (Union[str, Style], optional): Style of the border. Defaults to None.
    title_style (Union[str, Style], optional): Style of the title. Defaults to None.
    caption_style (Union[str, Style], optional): Style of the caption. Defaults to None.
    title_justify (str, optional): Justify method for title. Defaults to "center".
    caption_justify (str, optional): Justify method for caption. Defaults to "center".
    highlight (bool, optional): Highlight cell contents (if str). Defaults to False.

**M√©thodes :**

- `__init__()`
- `grid()`
- `expand()`
- `expand()`
- `_extra_width()`
- `row_count()`
- `get_row_style()`
- `__rich_measure__()`
- `padding()`
- `padding()`
- `add_column()`
- `add_row()`
- `add_section()`
- `__rich_console__()`
- `_calculate_column_widths()`
- `_collapse_widths()`
- `_get_cells()`
- `_get_padding_width()`
- `_measure_column()`
- `_render()`

#### Fonctions

##### copy

Return a copy of this Column.

##### cells

Get all cells in the column, not including header.

##### flexible

Check if this column is flexible.

##### __init__

##### grid

Get a table with no lines, headers, or footer.

Args:
    *headers (Union[Column, str]): Column headers, either as a string, or :class:`~rich.table.Column` instance.
    padding (PaddingDimensions, optional): Get padding around cells. Defaults to 0.
    collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to True.
    pad_edge (bool, optional): Enable padding around edges of table. Defaults to False.
    expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.

Returns:
    Table: A table instance.

**Param√®tres :**

- `cls`

##### expand

Setting a non-None self.width implies expand.

##### expand

Set expand.

**Param√®tres :**

- `expand`

##### _extra_width

Get extra width to add to cell content.

##### row_count

Get the current number of rows.

##### get_row_style

Get the current row style.

**Param√®tres :**

- `console`
- `index`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### padding

Get cell padding.

##### padding

Set cell padding.

**Param√®tres :**

- `padding`

##### add_column

Add a column to the table.

Args:
    header (RenderableType, optional): Text or renderable for the header.
        Defaults to "".
    footer (RenderableType, optional): Text or renderable for the footer.
        Defaults to "".
    header_style (Union[str, Style], optional): Style for the header, or None for default. Defaults to None.
    highlight (bool, optional): Whether to highlight the text. The default of None uses the value of the table (self) object.
    footer_style (Union[str, Style], optional): Style for the footer, or None for default. Defaults to None.
    style (Union[str, Style], optional): Style for the column cells, or None for default. Defaults to None.
    justify (JustifyMethod, optional): Alignment for cells. Defaults to "left".
    vertical (VerticalAlignMethod, optional): Vertical alignment, one of "top", "middle", or "bottom". Defaults to "top".
    overflow (OverflowMethod): Overflow method: "crop", "fold", "ellipsis". Defaults to "ellipsis".
    width (int, optional): Desired width of column in characters, or None to fit to contents. Defaults to None.
    min_width (Optional[int], optional): Minimum width of column, or ``None`` for no minimum. Defaults to None.
    max_width (Optional[int], optional): Maximum width of column, or ``None`` for no maximum. Defaults to None.
    ratio (int, optional): Flexible ratio for the column (requires ``Table.expand`` or ``Table.width``). Defaults to None.
    no_wrap (bool, optional): Set to ``True`` to disable wrapping of this column.

**Param√®tres :**

- `header`
- `footer`

##### add_row

Add a row of renderables.

Args:
    *renderables (None or renderable): Each cell in a row must be a renderable object (including str),
        or ``None`` for a blank cell.
    style (StyleType, optional): An optional style to apply to the entire row. Defaults to None.
    end_section (bool, optional): End a section and draw a line. Defaults to False.

Raises:
    errors.NotRenderableError: If you add something that can't be rendered.

##### add_section

Add a new section (draw a line after current row).

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### _calculate_column_widths

Calculate the widths of each column, including padding, not including borders.

**Param√®tres :**

- `console`
- `options`

##### _collapse_widths

Reduce widths so that the total is under max_width.

Args:
    widths (List[int]): List of widths.
    wrapable (List[bool]): List of booleans that indicate if a column may shrink.
    max_width (int): Maximum width to reduce to.

Returns:
    List[int]: A new list of widths.

**Param√®tres :**

- `cls`
- `widths`
- `wrapable`
- `max_width`

##### _get_cells

Get all the cells with padding and optional header.

**Param√®tres :**

- `console`
- `column_index`
- `column`

##### _get_padding_width

Get extra width from padding.

**Param√®tres :**

- `column_index`

##### _measure_column

Get the minimum and maximum width of the column.

**Param√®tres :**

- `console`
- `options`
- `column`

##### _render

**Param√®tres :**

- `console`
- `options`
- `widths`

##### add_cell

**Param√®tres :**

- `column`
- `renderable`

##### render_annotation

**Param√®tres :**

- `text`
- `style`
- `justify`

##### get_padding

**Param√®tres :**

- `first_row`
- `last_row`

##### header

**Param√®tres :**

- `text`

##### align_cell

**Param√®tres :**

- `cell`
- `vertical`
- `width`
- `style`

---

### terminal_theme

#### Classes

##### TerminalTheme

A color theme used when exporting console content.

Args:
    background (Tuple[int, int, int]): The background color.
    foreground (Tuple[int, int, int]): The foreground (text) color.
    normal (List[Tuple[int, int, int]]): A list of 8 normal intensity colors.
    bright (List[Tuple[int, int, int]], optional): A list of 8 bright colors, or None
        to repeat normal intensity. Defaults to None.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `background`
- `foreground`
- `normal`
- `bright`

---

### text

#### Classes

##### Span

A marked up region in some text.

**M√©thodes :**

- `__repr__()`
- `__bool__()`
- `split()`
- `move()`
- `right_crop()`
- `extend()`

##### Text

Text with color / style.

Args:
    text (str, optional): Default unstyled text. Defaults to "".
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".
    tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None.
    spans (List[Span], optional). A list of predefined style spans. Defaults to None.

**M√©thodes :**

- `__init__()`
- `__len__()`
- `__bool__()`
- `__str__()`
- `__repr__()`
- `__add__()`
- `__eq__()`
- `__contains__()`
- `__getitem__()`
- `cell_len()`
- `markup()`
- `from_markup()`
- `from_ansi()`
- `styled()`
- `assemble()`
- `plain()`
- `plain()`
- `spans()`
- `spans()`
- `blank_copy()`
- `copy()`
- `stylize()`
- `stylize_before()`
- `apply_meta()`
- `on()`
- `remove_suffix()`
- `get_style_at_offset()`
- `extend_style()`
- `highlight_regex()`
- `highlight_words()`
- `rstrip()`
- `rstrip_end()`
- `set_length()`
- `__rich_console__()`
- `__rich_measure__()`
- `render()`
- `join()`
- `expand_tabs()`
- `truncate()`
- `_trim_spans()`
- `pad()`
- `pad_left()`
- `pad_right()`
- `align()`
- `append()`
- `append_text()`
- `append_tokens()`
- `copy_styles()`
- `split()`
- `divide()`
- `right_crop()`
- `wrap()`
- `fit()`
- `detect_indentation()`
- `with_indent_guides()`

#### Fonctions

##### __repr__

##### __bool__

##### split

Split a span in to 2 from a given offset.

**Param√®tres :**

- `offset`

##### move

Move start and end by a given offset.

Args:
    offset (int): Number of characters to add to start and end.

Returns:
    TextSpan: A new TextSpan with adjusted position.

**Param√®tres :**

- `offset`

##### right_crop

Crop the span at the given offset.

Args:
    offset (int): A value between start and end.

Returns:
    Span: A new (possibly smaller) span.

**Param√®tres :**

- `offset`

##### extend

Extend the span by the given number of cells.

Args:
    cells (int): Additional space to add to end of span.

Returns:
    Span: A span.

**Param√®tres :**

- `cells`

##### __init__

**Param√®tres :**

- `text`
- `style`

##### __len__

##### __bool__

##### __str__

##### __repr__

##### __add__

**Param√®tres :**

- `other`

##### __eq__

**Param√®tres :**

- `other`

##### __contains__

**Param√®tres :**

- `other`

##### __getitem__

**Param√®tres :**

- `slice`

##### cell_len

Get the number of cells required to render this text.

##### markup

Get console markup to render this Text.

Returns:
    str: A string potentially creating markup tags.

##### from_markup

Create Text instance from markup.

Args:
    text (str): A string containing console markup.
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    emoji (bool, optional): Also render emoji code. Defaults to True.
    emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".

Returns:
    Text: A Text instance with markup rendered.

**Param√®tres :**

- `cls`
- `text`

##### from_ansi

Create a Text object from a string containing ANSI escape codes.

Args:
    text (str): A string containing escape codes.
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".
    tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None.

**Param√®tres :**

- `cls`
- `text`

##### styled

Construct a Text instance with a pre-applied styled. A style applied in this way won't be used
to pad the text when it is justified.

Args:
    text (str): A string containing console markup.
    style (Union[str, Style]): Style to apply to the text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.

Returns:
    Text: A text instance with a style applied to the entire string.

**Param√®tres :**

- `cls`
- `text`
- `style`

##### assemble

Construct a text instance by combining a sequence of strings with optional styles.
The positional arguments should be either strings, or a tuple of string + style.

Args:
    style (Union[str, Style], optional): Base style for text. Defaults to "".
    justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
    overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
    no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
    end (str, optional): Character to end text with. Defaults to "\\n".
    tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None.
    meta (Dict[str, Any], optional). Meta data to apply to text, or None for no meta data. Default to None

Returns:
    Text: A new text instance.

**Param√®tres :**

- `cls`

##### plain

Get the text as a single string.

##### plain

Set the text to a new value.

**Param√®tres :**

- `new_text`

##### spans

Get a reference to the internal list of spans.

##### spans

Set spans.

**Param√®tres :**

- `spans`

##### blank_copy

Return a new Text instance with copied metadata (but not the string or spans).

**Param√®tres :**

- `plain`

##### copy

Return a copy of this instance.

##### stylize

Apply a style to the text, or a portion of the text.

Args:
    style (Union[str, Style]): Style instance or style definition to apply.
    start (int): Start offset (negative indexing is supported). Defaults to 0.
    end (Optional[int], optional): End offset (negative indexing is supported), or None for end of text. Defaults to None.

**Param√®tres :**

- `style`
- `start`
- `end`

##### stylize_before

Apply a style to the text, or a portion of the text. Styles will be applied before other styles already present.

Args:
    style (Union[str, Style]): Style instance or style definition to apply.
    start (int): Start offset (negative indexing is supported). Defaults to 0.
    end (Optional[int], optional): End offset (negative indexing is supported), or None for end of text. Defaults to None.

**Param√®tres :**

- `style`
- `start`
- `end`

##### apply_meta

Apply metadata to the text, or a portion of the text.

Args:
    meta (Dict[str, Any]): A dict of meta information.
    start (int): Start offset (negative indexing is supported). Defaults to 0.
    end (Optional[int], optional): End offset (negative indexing is supported), or None for end of text. Defaults to None.

**Param√®tres :**

- `meta`
- `start`
- `end`

##### on

Apply event handlers (used by Textual project).

Example:
    >>> from rich.text import Text
    >>> text = Text("hello world")
    >>> text.on(click="view.toggle('world')")

Args:
    meta (Dict[str, Any]): Mapping of meta information.
    **handlers: Keyword args are prefixed with "@" to defined handlers.

Returns:
    Text: Self is returned to method may be chained.

**Param√®tres :**

- `meta`

##### remove_suffix

Remove a suffix if it exists.

Args:
    suffix (str): Suffix to remove.

**Param√®tres :**

- `suffix`

##### get_style_at_offset

Get the style of a character at give offset.

Args:
    console (~Console): Console where text will be rendered.
    offset (int): Offset in to text (negative indexing supported)

Returns:
    Style: A Style instance.

**Param√®tres :**

- `console`
- `offset`

##### extend_style

Extend the Text given number of spaces where the spaces have the same style as the last character.

Args:
    spaces (int): Number of spaces to add to the Text.

**Param√®tres :**

- `spaces`

##### highlight_regex

Highlight text with a regular expression, where group names are
translated to styles.

Args:
    re_highlight (Union[re.Pattern, str]): A regular expression object or string.
    style (Union[GetStyleCallable, StyleType]): Optional style to apply to whole match, or a callable
        which accepts the matched text and returns a style. Defaults to None.
    style_prefix (str, optional): Optional prefix to add to style group names.

Returns:
    int: Number of regex matches

**Param√®tres :**

- `re_highlight`
- `style`

##### highlight_words

Highlight words with a style.

Args:
    words (Iterable[str]): Words to highlight.
    style (Union[str, Style]): Style to apply.
    case_sensitive (bool, optional): Enable case sensitive matching. Defaults to True.

Returns:
    int: Number of words highlighted.

**Param√®tres :**

- `words`
- `style`

##### rstrip

Strip whitespace from end of text.

##### rstrip_end

Remove whitespace beyond a certain width at the end of the text.

Args:
    size (int): The desired size of the text.

**Param√®tres :**

- `size`

##### set_length

Set new length of the text, clipping or padding is required.

**Param√®tres :**

- `new_length`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### render

Render the text as Segments.

Args:
    console (Console): Console instance.
    end (Optional[str], optional): Optional end character.

Returns:
    Iterable[Segment]: Result of render that may be written to the console.

**Param√®tres :**

- `console`
- `end`

##### join

Join text together with this instance as the separator.

Args:
    lines (Iterable[Text]): An iterable of Text instances to join.

Returns:
    Text: A new text instance containing join text.

**Param√®tres :**

- `lines`

##### expand_tabs

Converts tabs to spaces.

Args:
    tab_size (int, optional): Size of tabs. Defaults to 8.

**Param√®tres :**

- `tab_size`

##### truncate

Truncate text if it is longer that a given width.

Args:
    max_width (int): Maximum number of characters in text.
    overflow (str, optional): Overflow method: "crop", "fold", or "ellipsis". Defaults to None, to use self.overflow.
    pad (bool, optional): Pad with spaces if the length is less than max_width. Defaults to False.

**Param√®tres :**

- `max_width`

##### _trim_spans

Remove or modify any spans that are over the end of the text.

##### pad

Pad left and right with a given number of characters.

Args:
    count (int): Width of padding.
    character (str): The character to pad with. Must be a string of length 1.

**Param√®tres :**

- `count`
- `character`

##### pad_left

Pad the left with a given character.

Args:
    count (int): Number of characters to pad.
    character (str, optional): Character to pad with. Defaults to " ".

**Param√®tres :**

- `count`
- `character`

##### pad_right

Pad the right with a given character.

Args:
    count (int): Number of characters to pad.
    character (str, optional): Character to pad with. Defaults to " ".

**Param√®tres :**

- `count`
- `character`

##### align

Align text to a given width.

Args:
    align (AlignMethod): One of "left", "center", or "right".
    width (int): Desired width.
    character (str, optional): Character to pad with. Defaults to " ".

**Param√®tres :**

- `align`
- `width`
- `character`

##### append

Add text with an optional style.

Args:
    text (Union[Text, str]): A str or Text to append.
    style (str, optional): A style name. Defaults to None.

Returns:
    Text: Returns self for chaining.

**Param√®tres :**

- `text`
- `style`

##### append_text

Append another Text instance. This method is more performant that Text.append, but
only works for Text.

Args:
    text (Text): The Text instance to append to this instance.

Returns:
    Text: Returns self for chaining.

**Param√®tres :**

- `text`

##### append_tokens

Append iterable of str and style. Style may be a Style instance or a str style definition.

Args:
    tokens (Iterable[Tuple[str, Optional[StyleType]]]): An iterable of tuples containing str content and style.

Returns:
    Text: Returns self for chaining.

**Param√®tres :**

- `tokens`

##### copy_styles

Copy styles from another Text instance.

Args:
    text (Text): A Text instance to copy styles from, must be the same length.

**Param√®tres :**

- `text`

##### split

Split rich text in to lines, preserving styles.

Args:
    separator (str, optional): String to split on. Defaults to "\\n".
    include_separator (bool, optional): Include the separator in the lines. Defaults to False.
    allow_blank (bool, optional): Return a blank line if the text ends with a separator. Defaults to False.

Returns:
    List[RichText]: A list of rich text, one per line of the original.

**Param√®tres :**

- `separator`

##### divide

Divide text in to a number of lines at given offsets.

Args:
    offsets (Iterable[int]): Offsets used to divide text.

Returns:
    Lines: New RichText instances between offsets.

**Param√®tres :**

- `offsets`

##### right_crop

Remove a number of characters from the end of the text.

**Param√®tres :**

- `amount`

##### wrap

Word wrap the text.

Args:
    console (Console): Console instance.
    width (int): Number of cells available per line.
    justify (str, optional): Justify method: "default", "left", "center", "full", "right". Defaults to "default".
    overflow (str, optional): Overflow method: "crop", "fold", or "ellipsis". Defaults to None.
    tab_size (int, optional): Default tab size. Defaults to 8.
    no_wrap (bool, optional): Disable wrapping, Defaults to False.

Returns:
    Lines: Number of lines.

**Param√®tres :**

- `console`
- `width`

##### fit

Fit the text in to given width by chopping in to lines.

Args:
    width (int): Maximum characters in a line.

Returns:
    Lines: Lines container.

**Param√®tres :**

- `width`

##### detect_indentation

Auto-detect indentation of code.

Returns:
    int: Number of spaces used to indent code.

##### with_indent_guides

Adds indent guide lines to text.

Args:
    indent_size (Optional[int]): Size of indentation, or None to auto detect. Defaults to None.
    character (str, optional): Character to use for indentation. Defaults to "‚îÇ".
    style (Union[Style, str], optional): Style of indent guides.

Returns:
    Text: New text with indentation guides.

**Param√®tres :**

- `indent_size`

##### get_text_at

**Param√®tres :**

- `offset`

##### get_current_style

Construct current style from stack.

##### iter_text

##### flatten_spans

---

### theme

#### Classes

##### Theme

A container for style information, used by :class:`~rich.console.Console`.

Args:
    styles (Dict[str, Style], optional): A mapping of style names on to styles. Defaults to None for a theme with no styles.
    inherit (bool, optional): Inherit default styles. Defaults to True.

**M√©thodes :**

- `__init__()`
- `config()`
- `from_file()`
- `read()`

##### ThemeStackError

Base exception for errors related to the theme stack.

##### ThemeStack

A stack of themes.

Args:
    theme (Theme): A theme instance

**M√©thodes :**

- `__init__()`
- `push_theme()`
- `pop_theme()`

#### Fonctions

##### __init__

**Param√®tres :**

- `styles`
- `inherit`

##### config

Get contents of a config file for this theme.

##### from_file

Load a theme from a text mode file.

Args:
    config_file (IO[str]): An open conf file.
    source (str, optional): The filename of the open file. Defaults to None.
    inherit (bool, optional): Inherit default styles. Defaults to True.

Returns:
    Theme: A New theme instance.

**Param√®tres :**

- `cls`
- `config_file`
- `source`
- `inherit`

##### read

Read a theme from a path.

Args:
    path (str): Path to a config file readable by Python configparser module.
    inherit (bool, optional): Inherit default styles. Defaults to True.
    encoding (str, optional): Encoding of the config file. Defaults to None.

Returns:
    Theme: A new theme instance.

**Param√®tres :**

- `cls`
- `path`
- `inherit`
- `encoding`

##### __init__

**Param√®tres :**

- `theme`

##### push_theme

Push a theme on the top of the stack.

Args:
    theme (Theme): A Theme instance.
    inherit (boolean, optional): Inherit styles from current top of stack.

**Param√®tres :**

- `theme`
- `inherit`

##### pop_theme

Pop (and discard) the top-most theme.

---

### themes

---

### traceback

#### Classes

##### Frame

##### _SyntaxError

##### Stack

##### Trace

##### PathHighlighter

##### Traceback

A Console renderable that renders a traceback.

Args:
    trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses
        the last exception.
    width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.
    code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.
    extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
    theme (str, optional): Override pygments theme used in traceback.
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.

**M√©thodes :**

- `__init__()`
- `from_exception()`
- `extract()`
- `__rich_console__()`
- `_render_syntax_error()`
- `_guess_lexer()`
- `_render_stack()`

#### Fonctions

##### _iter_syntax_lines

Yield start and end positions per line.

Args:
    start: Start position.
    end: End position.

Returns:
    Iterable of (LINE, COLUMN1, COLUMN2).

**Param√®tres :**

- `start`
- `end`

##### install

Install a rich traceback handler.

Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.


Args:
    console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.
    width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.
    code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.
    extra_lines (int, optional): Extra lines of code. Defaults to 3.
    theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick
        a theme appropriate for the platform.
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
    suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.

Returns:
    Callable: The previous exception handler that was replaced.

##### excepthook

**Param√®tres :**

- `type_`
- `value`
- `traceback`

##### ipy_excepthook_closure

**Param√®tres :**

- `ip`

##### __init__

**Param√®tres :**

- `trace`

##### from_exception

Create a traceback from exception info

Args:
    exc_type (Type[BaseException]): Exception type.
    exc_value (BaseException): Exception value.
    traceback (TracebackType): Python Traceback object.
    width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.
    code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.
    extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
    theme (str, optional): Override pygments theme used in traceback.
    word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
    max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.

Returns:
    Traceback: A Traceback instance that may be printed.

**Param√®tres :**

- `cls`
- `exc_type`
- `exc_value`
- `traceback`

##### extract

Extract traceback information.

Args:
    exc_type (Type[BaseException]): Exception type.
    exc_value (BaseException): Exception value.
    traceback (TracebackType): Python Traceback object.
    show_locals (bool, optional): Enable display of local variables. Defaults to False.
    locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
        Defaults to 10.
    locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
    locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
    locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.

Returns:
    Trace: A Trace instance which you can use to construct a `Traceback`.

**Param√®tres :**

- `cls`
- `exc_type`
- `exc_value`
- `traceback`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### _render_syntax_error

**Param√®tres :**

- `syntax_error`

##### _guess_lexer

**Param√®tres :**

- `cls`
- `filename`
- `code`

##### _render_stack

**Param√®tres :**

- `stack`

##### bar

**Param√®tres :**

- `a`

##### foo

**Param√®tres :**

- `a`

##### error

##### ipy_show_traceback

wrap the default ip.showtraceback to store info for ip._showtraceback

##### ipy_display_traceback

Internally called traceback from ip._showtraceback

##### safe_str

Don't allow exceptions from __str__ to propagate.

**Param√®tres :**

- `_object`

##### render_stack

**Param√®tres :**

- `stack`
- `last`

##### render_locals

**Param√®tres :**

- `frame`

##### get_locals

Extract locals from an iterator of key pairs.

**Param√®tres :**

- `iter_locals`

---

### tree

#### Classes

##### Tree

A renderable for a tree structure.

Attributes:
    ASCII_GUIDES (GuideType): Guide lines used when Console.ascii_only is True.
    TREE_GUIDES (List[GuideType, GuideType, GuideType]): Default guide lines.

Args:
    label (RenderableType): The renderable or str for the tree label.
    style (StyleType, optional): Style of this tree. Defaults to "tree".
    guide_style (StyleType, optional): Style of the guide lines. Defaults to "tree.line".
    expanded (bool, optional): Also display children. Defaults to True.
    highlight (bool, optional): Highlight renderable (if str). Defaults to False.
    hide_root (bool, optional): Hide the root node. Defaults to False.

**M√©thodes :**

- `__init__()`
- `add()`
- `__rich_console__()`
- `__rich_measure__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `label`

##### add

Add a child tree.

Args:
    label (RenderableType): The renderable or str for the tree label.
    style (StyleType, optional): Style of this tree. Defaults to "tree".
    guide_style (StyleType, optional): Style of the guide lines. Defaults to "tree.line".
    expanded (bool, optional): Also display children. Defaults to True.
    highlight (Optional[bool], optional): Highlight renderable (if str). Defaults to False.

Returns:
    Tree: A new child Tree, which may be further modified.

**Param√®tres :**

- `label`

##### __rich_console__

**Param√®tres :**

- `console`
- `options`

##### __rich_measure__

**Param√®tres :**

- `console`
- `options`

##### make_guide

Make a Segment for a level of the guide lines.

**Param√®tres :**

- `index`
- `style`

---

### .!23853!__init__

---

### .!23861!__main__

---

### .!23864!_cell_widths

---

### .!23867!_emoji_codes

---

### .!23872!_emoji_replace

---

### .!23879!_export_format

---

### .!23883!_extension

---

### .!23888!_fileno

---

### .!23893!_inspect

---

### .!23897!_log_render

---

### .!23902!_loop

---

### .!23906!_null_file

---

### .!23911!_palettes

---

### .!23914!_pick

---

### .!23920!_ratio

---

### .!23924!_spinners

---

### .!23929!_stack

---

### .!23934!_timer

---

### .!23939!_win32_console

---

### .!23944!_windows

---

### .!23947!_windows_renderer

---

### .!23952!_wrap

---

### .!23963!align

---

### .!23982!cells

---

### .!23985!color

---

### .!23990!color_triplet

---

### .!23994!columns

---

### .!23999!console

---

### .!24003!constrain

---

### .!24008!containers

---

### .!24012!control

---

### .!24019!default_styles

---

### .!24023!diagnose

---

### .!24028!emoji

---

### .!24033!errors

---

### .!24039!file_proxy

---

### .!24042!filesize

---

### .!24046!highlighter

---

### .!24055!jupyter

---

### .!24060!layout

---

### .!24071!live_render

---

### .!24075!logging

---

### .!24080!markup

---

### .!24085!measure

---

### .!24090!padding

---

### .!24094!pager

---

### .!24101!palette

---

### .!24105!panel

---

### .!24110!pretty

---

### .!24117!progress

---

### .!24121!progress_bar

---

### .!24127!prompt

---

### .!24132!protocol

---

### .!24136!region

---

### .!24151!scope

---

### .!24155!screen

---

### .!24162!segment

---

### .!24166!spinner

---

### .!24171!status

---

### .!24175!style

---

### .!24180!styled

---

### .!24184!syntax

---

### .!24190!table

---

### .!24194!terminal_theme

---

### .!24206!theme

---

### .!24210!themes

---

### .!24215!traceback

---

### _parser

#### Classes

##### DEPRECATED_DEFAULT

Sentinel to be used as default arg during deprecation
period of TOMLDecodeError's free-form arguments.

##### TOMLDecodeError

An error raised if a document is not valid TOML.

Adds the following attributes to ValueError:
msg: The unformatted error message
doc: The TOML document being parsed
pos: The index of doc where parsing failed
lineno: The line corresponding to pos
colno: The column corresponding to pos

**M√©thodes :**

- `__init__()`

##### Flags

Flags that map to parsed keys/namespaces.

**M√©thodes :**

- `__init__()`
- `add_pending()`
- `finalize_pending()`
- `unset_all()`
- `set()`
- `is_()`

##### NestedDict

**M√©thodes :**

- `__init__()`
- `get_or_create_nest()`
- `append_nest_to_list()`

##### Output

#### Fonctions

##### load

Parse TOML from a binary file object.

**Param√®tres :**

- `__fp`

##### loads

Parse TOML from a string.

**Param√®tres :**

- `__s`

##### skip_chars

**Param√®tres :**

- `src`
- `pos`
- `chars`

##### skip_until

**Param√®tres :**

- `src`
- `pos`
- `expect`

##### skip_comment

**Param√®tres :**

- `src`
- `pos`

##### skip_comments_and_array_ws

**Param√®tres :**

- `src`
- `pos`

##### create_dict_rule

**Param√®tres :**

- `src`
- `pos`
- `out`

##### create_list_rule

**Param√®tres :**

- `src`
- `pos`
- `out`

##### key_value_rule

**Param√®tres :**

- `src`
- `pos`
- `out`
- `header`
- `parse_float`

##### parse_key_value_pair

**Param√®tres :**

- `src`
- `pos`
- `parse_float`
- `nest_lvl`

##### parse_key

**Param√®tres :**

- `src`
- `pos`

##### parse_key_part

**Param√®tres :**

- `src`
- `pos`

##### parse_one_line_basic_str

**Param√®tres :**

- `src`
- `pos`

##### parse_array

**Param√®tres :**

- `src`
- `pos`
- `parse_float`
- `nest_lvl`

##### parse_inline_table

**Param√®tres :**

- `src`
- `pos`
- `parse_float`
- `nest_lvl`

##### parse_basic_str_escape

**Param√®tres :**

- `src`
- `pos`

##### parse_basic_str_escape_multiline

**Param√®tres :**

- `src`
- `pos`

##### parse_hex_char

**Param√®tres :**

- `src`
- `pos`
- `hex_len`

##### parse_literal_str

**Param√®tres :**

- `src`
- `pos`

##### parse_multiline_str

**Param√®tres :**

- `src`
- `pos`

##### parse_basic_str

**Param√®tres :**

- `src`
- `pos`

##### parse_value

**Param√®tres :**

- `src`
- `pos`
- `parse_float`
- `nest_lvl`

##### is_unicode_scalar_value

**Param√®tres :**

- `codepoint`

##### make_safe_parse_float

A decorator to make `parse_float` safe.

`parse_float` must not return dicts or lists, because these types
would be mixed with parsed TOML tables and arrays, thus confusing
the parser. The returned decorated callable raises `ValueError`
instead of returning illegal types.

**Param√®tres :**

- `parse_float`

##### __init__

**Param√®tres :**

- `msg`
- `doc`
- `pos`

##### __init__

##### add_pending

**Param√®tres :**

- `key`
- `flag`

##### finalize_pending

##### unset_all

**Param√®tres :**

- `key`

##### set

**Param√®tres :**

- `key`
- `flag`

##### is_

**Param√®tres :**

- `key`
- `flag`

##### __init__

##### get_or_create_nest

**Param√®tres :**

- `key`

##### append_nest_to_list

**Param√®tres :**

- `key`

##### safe_parse_float

**Param√®tres :**

- `float_str`

---

### _re

#### Fonctions

##### match_to_datetime

Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.

Raises ValueError if the match does not correspond to a valid date
or datetime.

**Param√®tres :**

- `match`

##### cached_tz

**Param√®tres :**

- `hour_str`
- `minute_str`
- `sign_str`

##### match_to_localtime

**Param√®tres :**

- `match`

##### match_to_number

**Param√®tres :**

- `match`
- `parse_float`

---

### .!24236!_re

---

### _types

---

### .!24224!__init__

---

### .!24231!_parser

---

### .!24240!_types

---

### _writer

#### Classes

##### Context

**M√©thodes :**

- `__init__()`

#### Fonctions

##### dump

##### dumps

##### gen_table_chunks

**Param√®tres :**

- `table`
- `ctx`

##### format_literal

**Param√®tres :**

- `obj`
- `ctx`

##### format_decimal

**Param√®tres :**

- `obj`

##### format_inline_table

**Param√®tres :**

- `obj`
- `ctx`

##### format_inline_array

**Param√®tres :**

- `obj`
- `ctx`
- `nest_level`

##### format_key_part

**Param√®tres :**

- `part`

##### format_string

**Param√®tres :**

- `s`

##### is_aot

Decides if an object behaves as an array of tables (i.e. a nonempty list
of dicts).

**Param√®tres :**

- `obj`

##### is_suitable_inline_table

Use heuristics to decide if the inline-style representation is a good
choice for a given table.

**Param√®tres :**

- `obj`
- `ctx`

##### __init__

**Param√®tres :**

- `allow_multiline`
- `indent`

---

### .!24246!__init__

---

### .!24251!_writer

---

### _api

#### Classes

##### SSLContext

SSLContext API that uses system certificates on all platforms

**M√©thodes :**

- `__class__()`
- `__init__()`
- `wrap_socket()`
- `wrap_bio()`
- `load_verify_locations()`
- `load_cert_chain()`
- `load_default_certs()`
- `set_alpn_protocols()`
- `set_npn_protocols()`
- `set_ciphers()`
- `get_ciphers()`
- `session_stats()`
- `cert_store_stats()`
- `set_default_verify_paths()`
- `get_ca_certs()`
- `get_ca_certs()`
- `get_ca_certs()`
- `get_ca_certs()`
- `check_hostname()`
- `check_hostname()`
- `hostname_checks_common_name()`
- `hostname_checks_common_name()`
- `keylog_filename()`
- `keylog_filename()`
- `maximum_version()`
- `maximum_version()`
- `minimum_version()`
- `minimum_version()`
- `options()`
- `options()`
- `post_handshake_auth()`
- `post_handshake_auth()`
- `protocol()`
- `security_level()`
- `verify_flags()`
- `verify_flags()`
- `verify_mode()`
- `verify_mode()`

##### TruststoreSSLObject

**M√©thodes :**

- `do_handshake()`

#### Fonctions

##### inject_into_ssl

Injects the :class:`truststore.SSLContext` into the ``ssl``
module by replacing :class:`ssl.SSLContext`.

##### extract_from_ssl

Restores the :class:`ssl.SSLContext` class to its original state

##### _verify_peercerts

Verifies the peer certificates from an SSLSocket or SSLObject
against the certificates in the OS trust store.

**Param√®tres :**

- `sock_or_sslobj`
- `server_hostname`

##### __class__

##### __init__

**Param√®tres :**

- `protocol`

##### wrap_socket

**Param√®tres :**

- `sock`
- `server_side`
- `do_handshake_on_connect`
- `suppress_ragged_eofs`
- `server_hostname`
- `session`

##### wrap_bio

**Param√®tres :**

- `incoming`
- `outgoing`
- `server_side`
- `server_hostname`
- `session`

##### load_verify_locations

**Param√®tres :**

- `cafile`
- `capath`
- `cadata`

##### load_cert_chain

**Param√®tres :**

- `certfile`
- `keyfile`
- `password`

##### load_default_certs

**Param√®tres :**

- `purpose`

##### set_alpn_protocols

**Param√®tres :**

- `alpn_protocols`

##### set_npn_protocols

**Param√®tres :**

- `npn_protocols`

##### set_ciphers

**Param√®tres :**

- `__cipherlist`

##### get_ciphers

##### session_stats

##### cert_store_stats

##### set_default_verify_paths

##### get_ca_certs

**Param√®tres :**

- `binary_form`

##### get_ca_certs

**Param√®tres :**

- `binary_form`

##### get_ca_certs

**Param√®tres :**

- `binary_form`

##### get_ca_certs

**Param√®tres :**

- `binary_form`

##### check_hostname

##### check_hostname

**Param√®tres :**

- `value`

##### hostname_checks_common_name

##### hostname_checks_common_name

**Param√®tres :**

- `value`

##### keylog_filename

##### keylog_filename

**Param√®tres :**

- `value`

##### maximum_version

##### maximum_version

**Param√®tres :**

- `value`

##### minimum_version

##### minimum_version

**Param√®tres :**

- `value`

##### options

##### options

**Param√®tres :**

- `value`

##### post_handshake_auth

##### post_handshake_auth

**Param√®tres :**

- `value`

##### protocol

##### security_level

##### verify_flags

##### verify_flags

**Param√®tres :**

- `value`

##### verify_mode

##### verify_mode

**Param√®tres :**

- `value`

##### _get_unverified_chain_bytes

**Param√®tres :**

- `sslobj`

##### _get_unverified_chain_bytes

**Param√®tres :**

- `sslobj`

##### do_handshake

---

### _macos

#### Classes

##### CFConst

CoreFoundation constants

#### Fonctions

##### _load_cdll

Loads a CDLL by name, falling back to known path on 10.16+

**Param√®tres :**

- `name`
- `macos10_16_path`

##### _handle_osstatus

Raises an error if the OSStatus value is non-zero.

**Param√®tres :**

- `result`
- `_`
- `args`

##### _bytes_to_cf_data_ref

**Param√®tres :**

- `value`

##### _bytes_to_cf_string

Given a Python binary data, create a CFString.
The string must be CFReleased by the caller.

**Param√®tres :**

- `value`

##### _cf_string_ref_to_str

Creates a Unicode string from a CFString object. Used entirely for error
reporting.
Yes, it annoys me quite a lot that this function is this complex.

**Param√®tres :**

- `cf_string_ref`

##### _der_certs_to_cf_cert_array

Builds a CFArray of SecCertificateRefs from a list of DER-encoded certificates.
Responsibility of the caller to call CoreFoundation.CFRelease on the CFArray.

**Param√®tres :**

- `certs`

##### _configure_context

**Param√®tres :**

- `ctx`

##### _verify_peercerts_impl

**Param√®tres :**

- `ssl_context`
- `cert_chain`
- `server_hostname`

##### _verify_peercerts_impl_macos_10_13

Verify using 'SecTrustEvaluate' API for macOS 10.13 and earlier.
macOS 10.14 added the 'SecTrustEvaluateWithError' API.

**Param√®tres :**

- `ssl_context`
- `sec_trust_ref`

##### _verify_peercerts_impl_macos_10_14

Verify using 'SecTrustEvaluateWithError' API for macOS 10.14+.

**Param√®tres :**

- `ssl_context`
- `sec_trust_ref`

---

### .!24263!_api

---

### _openssl

#### Fonctions

##### _configure_context

**Param√®tres :**

- `ctx`

##### _capath_contains_certs

Check whether capath exists and contains certs in the expected format.

**Param√®tres :**

- `capath`

##### _verify_peercerts_impl

**Param√®tres :**

- `ssl_context`
- `cert_chain`
- `server_hostname`

---

### _ssl_constants

#### Fonctions

##### _set_ssl_context_verify_mode

**Param√®tres :**

- `ssl_context`
- `verify_mode`

---

### _windows

#### Classes

##### CERT_CONTEXT

##### CERT_ENHKEY_USAGE

##### CERT_USAGE_MATCH

##### CERT_CHAIN_PARA

##### CERT_TRUST_STATUS

##### CERT_CHAIN_ELEMENT

##### CERT_SIMPLE_CHAIN

##### CERT_CHAIN_CONTEXT

##### SSL_EXTRA_CERT_CHAIN_POLICY_PARA

##### CERT_CHAIN_POLICY_PARA

##### CERT_CHAIN_POLICY_STATUS

##### CERT_CHAIN_ENGINE_CONFIG

#### Fonctions

##### _handle_win_error

**Param√®tres :**

- `result`
- `_`
- `args`

##### _verify_peercerts_impl

Verify the cert_chain from the server using Windows APIs.

**Param√®tres :**

- `ssl_context`
- `cert_chain`
- `server_hostname`

##### _get_and_verify_cert_chain

**Param√®tres :**

- `ssl_context`
- `hChainEngine`
- `hIntermediateCertStore`
- `pPeerCertContext`
- `pChainPara`
- `server_hostname`
- `chain_flags`

##### _verify_using_custom_ca_certs

**Param√®tres :**

- `ssl_context`
- `custom_ca_certs`
- `hIntermediateCertStore`
- `pPeerCertContext`
- `pChainPara`
- `server_hostname`
- `chain_flags`

##### _configure_context

**Param√®tres :**

- `ctx`

---

### .!24257!__init__

---

### .!24269!_macos

---

### .!24275!_openssl

---

### .!24279!_ssl_constants

---

### .!24285!_windows

---

### _collections

#### Classes

##### RecentlyUsedContainer

Provides a thread-safe dict-like container which maintains up to
``maxsize`` keys while throwing away the least-recently-used keys beyond
``maxsize``.

:param maxsize:
    Maximum number of recent elements to retain.

:param dispose_func:
    Every time an item is evicted from the container,
    ``dispose_func(value)`` is called.  Callback which will get called

**M√©thodes :**

- `__init__()`
- `__getitem__()`
- `__setitem__()`
- `__delitem__()`
- `__len__()`
- `__iter__()`
- `clear()`
- `keys()`

##### HTTPHeaderDict

:param headers:
    An iterable of field-value pairs. Must not contain multiple field names
    when compared case-insensitively.

:param kwargs:
    Additional field-value pairs to pass in to ``dict.update``.

A ``dict`` like container for storing HTTP Headers.

Field names are stored and compared case-insensitively in compliance with
RFC 7230. Iteration provides the first case-sensitive key seen for each
case-insensitive pair.

Using ``__setitem__`` syntax overwrites fields that compare equal
case-insensitively in order to maintain ``dict``'s api. For fields that
compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
in a loop.

If multiple fields that are equal case-insensitively are passed to the
constructor or ``.update``, the behavior is undefined and some will be
lost.

>>> headers = HTTPHeaderDict()
>>> headers.add('Set-Cookie', 'foo=bar')
>>> headers.add('set-cookie', 'baz=quxx')
>>> headers['content-length'] = '7'
>>> headers['SET-cookie']
'foo=bar, baz=quxx'
>>> headers['Content-Length']
'7'

**M√©thodes :**

- `__init__()`
- `__setitem__()`
- `__getitem__()`
- `__delitem__()`
- `__contains__()`
- `__eq__()`
- `__ne__()`
- `__len__()`
- `__iter__()`
- `pop()`
- `discard()`
- `add()`
- `extend()`
- `getlist()`
- `_prepare_for_method_change()`
- `__repr__()`
- `_copy_from()`
- `copy()`
- `iteritems()`
- `itermerged()`
- `items()`
- `from_httplib()`

##### RLock

**M√©thodes :**

- `__enter__()`
- `__exit__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `maxsize`
- `dispose_func`

##### __getitem__

**Param√®tres :**

- `key`

##### __setitem__

**Param√®tres :**

- `key`
- `value`

##### __delitem__

**Param√®tres :**

- `key`

##### __len__

##### __iter__

##### clear

##### keys

##### __init__

**Param√®tres :**

- `headers`

##### __setitem__

**Param√®tres :**

- `key`
- `val`

##### __getitem__

**Param√®tres :**

- `key`

##### __delitem__

**Param√®tres :**

- `key`

##### __contains__

**Param√®tres :**

- `key`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __len__

##### __iter__

##### pop

D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
If key is not found, d is returned if given, otherwise KeyError is raised.

**Param√®tres :**

- `key`
- `default`

##### discard

**Param√®tres :**

- `key`

##### add

Adds a (name, value) pair, doesn't overwrite the value if it already
exists.

>>> headers = HTTPHeaderDict(foo='bar')
>>> headers.add('Foo', 'baz')
>>> headers['foo']
'bar, baz'

**Param√®tres :**

- `key`
- `val`

##### extend

Generic import function for any type of header-like object.
Adapted version of MutableMapping.update in order to insert items
with self.add instead of self.__setitem__

##### getlist

Returns a list of all the values for the named field. Returns an
empty list if the key doesn't exist.

**Param√®tres :**

- `key`
- `default`

##### _prepare_for_method_change

Remove content-specific header fields before changing the request
method to GET or HEAD according to RFC 9110, Section 15.4.

##### __repr__

##### _copy_from

**Param√®tres :**

- `other`

##### copy

##### iteritems

Iterate over all header lines, including duplicate ones.

##### itermerged

Iterate over all headers, merging duplicate ones together.

##### items

##### from_httplib

Read headers from a Python 2 httplib message object.

**Param√®tres :**

- `cls`
- `message`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `traceback`

---

### _version

---

### connection

#### Classes

##### HTTPConnection

Based on :class:`http.client.HTTPConnection` but provides an extra constructor
backwards-compatibility layer between older and newer Pythons.

Additional keyword parameters are used to configure attributes of the connection.
Accepted parameters include:

- ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
- ``source_address``: Set the source address for the current connection.
- ``socket_options``: Set specific options on the underlying socket. If not specified, then
  defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
  Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

  For example, if you wish to enable TCP Keep Alive in addition to the defaults,
  you might pass:

  .. code-block:: python

     HTTPConnection.default_socket_options + [
         (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
     ]

  Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).

**M√©thodes :**

- `__init__()`
- `host()`
- `host()`
- `_new_conn()`
- `_is_using_tunnel()`
- `_prepare_conn()`
- `connect()`
- `putrequest()`
- `putheader()`
- `request()`
- `request_chunked()`

##### HTTPSConnection

Many of the parameters to this constructor are passed to the underlying SSL
socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.

**M√©thodes :**

- `__init__()`
- `set_cert()`
- `connect()`
- `_connect_tls_proxy()`

##### DummyConnection

Used to detect a failed ConnectionCls import.

##### BaseSSLError

##### ConnectionError

##### BrokenPipeError

#### Fonctions

##### _match_hostname

**Param√®tres :**

- `cert`
- `asserted_hostname`

##### _get_default_user_agent

##### __init__

##### host

Getter method to remove any trailing dots that indicate the hostname is an FQDN.

In general, SSL certificates don't include the trailing dot indicating a
fully-qualified domain name, and thus, they don't validate properly when
checked against a domain name that includes the dot. In addition, some
servers may not expect to receive the trailing dot when provided.

However, the hostname with trailing dot is critical to DNS resolution; doing a
lookup with the trailing dot will properly only resolve the appropriate FQDN,
whereas a lookup without a trailing dot will search the system's search domain
list. Thus, it's important to keep the original host around for use only in
those cases where it's appropriate (i.e., when doing DNS lookup to establish the
actual TCP connection across which we're going to send HTTP requests).

##### host

Setter for the `host` property.

We assume that only urllib3 uses the _dns_host attribute; httplib itself
only uses `host`, and it seems reasonable that other libraries follow suit.

**Param√®tres :**

- `value`

##### _new_conn

Establish a socket connection and set nodelay settings on it.

:return: New socket connection.

##### _is_using_tunnel

##### _prepare_conn

**Param√®tres :**

- `conn`

##### connect

##### putrequest

**Param√®tres :**

- `method`
- `url`

##### putheader

**Param√®tres :**

- `header`

##### request

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`

##### request_chunked

Alternative to the common request method, which sends the
body with chunked encoding and not as one block

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`

##### __init__

**Param√®tres :**

- `host`
- `port`
- `key_file`
- `cert_file`
- `key_password`
- `strict`
- `timeout`
- `ssl_context`
- `server_hostname`

##### set_cert

This method should only be called once, before the connection is used.

**Param√®tres :**

- `key_file`
- `cert_file`
- `cert_reqs`
- `key_password`
- `ca_certs`
- `assert_hostname`
- `assert_fingerprint`
- `ca_cert_dir`
- `ca_cert_data`

##### connect

##### _connect_tls_proxy

Establish a TLS connection to the proxy using the provided SSL context.

**Param√®tres :**

- `hostname`
- `conn`

---

### connectionpool

#### Classes

##### ConnectionPool

Base class for all connection pools, such as
:class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

.. note::
   ConnectionPool.urlopen() does not normalize or percent-encode target URIs
   which is useful if your target server doesn't support percent-encoded
   target URIs.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__enter__()`
- `__exit__()`
- `close()`

##### HTTPConnectionPool

Thread-safe connection pool for one host.

:param host:
    Host used for this HTTP Connection (e.g. "localhost"), passed into
    :class:`http.client.HTTPConnection`.

:param port:
    Port used for this HTTP Connection (None is equivalent to 80), passed
    into :class:`http.client.HTTPConnection`.

:param strict:
    Causes BadStatusLine to be raised if the status line can't be parsed
    as a valid HTTP/1.0 or 1.1 status line, passed into
    :class:`http.client.HTTPConnection`.

    .. note::
       Only works in Python 2. This parameter is ignored in Python 3.

:param timeout:
    Socket timeout in seconds for each individual connection. This can
    be a float or integer, which sets the timeout for the HTTP request,
    or an instance of :class:`urllib3.util.Timeout` which gives you more
    fine-grained control over request timeouts. After the constructor has
    been parsed, this is always a `urllib3.util.Timeout` object.

:param maxsize:
    Number of connections to save that can be reused. More than 1 is useful
    in multithreaded situations. If ``block`` is set to False, more
    connections will be created but they will not be saved once they've
    been used.

:param block:
    If set to True, no more than ``maxsize`` connections will be used at
    a time. When no free connections are available, the call will block
    until a connection has been released. This is a useful side effect for
    particular multithreaded situations where one does not want to use more
    than maxsize connections per host to prevent flooding.

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

:param retries:
    Retry configuration to use by default with requests in this pool.

:param _proxy:
    Parsed proxy URL, should not be used directly, instead, see
    :class:`urllib3.ProxyManager`

:param _proxy_headers:
    A dictionary with proxy headers, should not be used directly,
    instead, see :class:`urllib3.ProxyManager`

:param \**conn_kw:
    Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
    :class:`urllib3.connection.HTTPSConnection` instances.

**M√©thodes :**

- `__init__()`
- `_new_conn()`
- `_get_conn()`
- `_put_conn()`
- `_validate_conn()`
- `_prepare_proxy()`
- `_get_timeout()`
- `_raise_timeout()`
- `_make_request()`
- `_absolute_url()`
- `close()`
- `is_same_host()`
- `urlopen()`

##### HTTPSConnectionPool

Same as :class:`.HTTPConnectionPool`, but HTTPS.

:class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
``assert_hostname`` and ``host`` in this order to verify connections.
If ``assert_hostname`` is False, no verification is done.

The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
the connection socket into an SSL socket.

**M√©thodes :**

- `__init__()`
- `_prepare_conn()`
- `_prepare_proxy()`
- `_new_conn()`
- `_validate_conn()`

#### Fonctions

##### connection_from_url

Given a url, return an :class:`.ConnectionPool` instance of its host.

This is a shortcut for not having to parse out the scheme, host, and port
of the url before creating an :class:`.ConnectionPool` instance.

:param url:
    Absolute URL string that must include the scheme. Port is optional.

:param \**kw:
    Passes additional parameters to the constructor of the appropriate
    :class:`.ConnectionPool`. Useful for specifying things like
    timeout, maxsize, headers, etc.

Example::

    >>> conn = connection_from_url('http://google.com/')
    >>> r = conn.request('GET', '/')

**Param√®tres :**

- `url`

##### _normalize_host

Normalize hosts for comparisons and use with sockets.

**Param√®tres :**

- `host`
- `scheme`

##### _close_pool_connections

Drains a queue of connections and closes each one.

**Param√®tres :**

- `pool`

##### __init__

**Param√®tres :**

- `host`
- `port`

##### __str__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### close

Close all pooled connections and disable the pool.

##### __init__

**Param√®tres :**

- `host`
- `port`
- `strict`
- `timeout`
- `maxsize`
- `block`
- `headers`
- `retries`
- `_proxy`
- `_proxy_headers`
- `_proxy_config`

##### _new_conn

Return a fresh :class:`HTTPConnection`.

##### _get_conn

Get a connection. Will return a pooled connection if one is available.

If no connections are available and :prop:`.block` is ``False``, then a
fresh connection is returned.

:param timeout:
    Seconds to wait before giving up and raising
    :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
    :prop:`.block` is ``True``.

**Param√®tres :**

- `timeout`

##### _put_conn

Put a connection back into the pool.

:param conn:
    Connection object for the current host and port as returned by
    :meth:`._new_conn` or :meth:`._get_conn`.

If the pool is already full, the connection is closed and discarded
because we exceeded maxsize. If connections are discarded frequently,
then maxsize should be increased.

If the pool is closed, then the connection will be closed and discarded.

**Param√®tres :**

- `conn`

##### _validate_conn

Called right before a request is made, after the socket is created.

**Param√®tres :**

- `conn`

##### _prepare_proxy

**Param√®tres :**

- `conn`

##### _get_timeout

Helper that always returns a :class:`urllib3.util.Timeout`

**Param√®tres :**

- `timeout`

##### _raise_timeout

Is the error actually a timeout? Will raise a ReadTimeout or pass

**Param√®tres :**

- `err`
- `url`
- `timeout_value`

##### _make_request

Perform a request on a given urllib connection object taken from our
pool.

:param conn:
    a connection from one of our connection pools

:param timeout:
    Socket timeout in seconds for the request. This can be a
    float or integer, which will set the same timeout value for
    the socket connect and the socket read, or an instance of
    :class:`urllib3.util.Timeout`, which gives you more fine-grained
    control over your timeouts.

**Param√®tres :**

- `conn`
- `method`
- `url`
- `timeout`
- `chunked`

##### _absolute_url

**Param√®tres :**

- `path`

##### close

Close all pooled connections and disable the pool.

##### is_same_host

Check if the given ``url`` is a member of the same host as this
connection pool.

**Param√®tres :**

- `url`

##### urlopen

Get a connection from the pool and perform an HTTP request. This is the
lowest level call for making a request, so you'll need to specify all
the raw details.

.. note::

   More commonly, it's appropriate to use a convenience method provided
   by :class:`.RequestMethods`, such as :meth:`request`.

.. note::

   `release_conn` will only behave as expected if
   `preload_content=False` because we want to make
   `preload_content=False` the default behaviour someday soon without
   breaking backwards compatibility.

:param method:
    HTTP request method (such as GET, POST, PUT, etc.)

:param url:
    The URL to perform the request on.

:param body:
    Data to send in the request body, either :class:`str`, :class:`bytes`,
    an iterable of :class:`str`/:class:`bytes`, or a file-like object.

:param headers:
    Dictionary of custom headers to send, such as User-Agent,
    If-None-Match, etc. If None, pool headers are used. If provided,
    these headers completely replace any pool-specific headers.

:param retries:
    Configure the number of retries to allow before raising a
    :class:`~urllib3.exceptions.MaxRetryError` exception.

    Pass ``None`` to retry until you receive a response. Pass a
    :class:`~urllib3.util.retry.Retry` object for fine-grained control
    over different types of retries.
    Pass an integer number to retry connection errors that many times,
    but no other types of errors. Pass zero to never retry.

    If ``False``, then retries are disabled and any exception is raised
    immediately. Also, instead of raising a MaxRetryError on redirects,
    the redirect response will be returned.

:type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

:param redirect:
    If True, automatically handle redirects (status codes 301, 302,
    303, 307, 308). Each redirect counts as a retry. Disabling retries
    will disable redirect, too.

:param assert_same_host:
    If ``True``, will make sure that the host of the pool requests is
    consistent else will raise HostChangedError. When ``False``, you can
    use the pool on an HTTP proxy and request foreign hosts.

:param timeout:
    If specified, overrides the default timeout for this one
    request. It may be a float (in seconds) or an instance of
    :class:`urllib3.util.Timeout`.

:param pool_timeout:
    If set and the pool is set to block=True, then this method will
    block for ``pool_timeout`` seconds and raise EmptyPoolError if no
    connection is available within the time period.

:param release_conn:
    If False, then the urlopen call will not release the connection
    back into the pool once a response is received (but will release if
    you read the entire contents of the response such as when
    `preload_content=True`). This is useful if you're not preloading
    the response's content immediately. You will need to call
    ``r.release_conn()`` on the response ``r`` to return the connection
    back into the pool. If None, it takes the value of
    ``response_kw.get('preload_content', True)``.

:param chunked:
    If True, urllib3 will send the body using chunked transfer
    encoding. Otherwise, urllib3 will send the body using the standard
    content-length form. Defaults to False.

:param int body_pos:
    Position to seek to in file-like body in the event of a retry or
    redirect. Typically this won't need to be set because urllib3 will
    auto-populate the value when needed.

:param \**response_kw:
    Additional parameters are passed to
    :meth:`urllib3.response.HTTPResponse.from_httplib`

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`
- `retries`
- `redirect`
- `assert_same_host`
- `timeout`
- `pool_timeout`
- `release_conn`
- `chunked`
- `body_pos`

##### __init__

**Param√®tres :**

- `host`
- `port`
- `strict`
- `timeout`
- `maxsize`
- `block`
- `headers`
- `retries`
- `_proxy`
- `_proxy_headers`
- `key_file`
- `cert_file`
- `cert_reqs`
- `key_password`
- `ca_certs`
- `ssl_version`
- `assert_hostname`
- `assert_fingerprint`
- `ca_cert_dir`

##### _prepare_conn

Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`
and establish the tunnel if proxy is used.

**Param√®tres :**

- `conn`

##### _prepare_proxy

Establishes a tunnel connection through HTTP CONNECT.

Tunnel connection is established early because otherwise httplib would
improperly set Host: header to proxy's IP:port.

**Param√®tres :**

- `conn`

##### _new_conn

Return a fresh :class:`http.client.HTTPSConnection`.

##### _validate_conn

Called right before a request is made, after the socket is created.

**Param√®tres :**

- `conn`

##### _is_ssl_error_message_from_http_proxy

**Param√®tres :**

- `ssl_error`

---

### exceptions

#### Classes

##### HTTPError

Base exception used by this module.

##### HTTPWarning

Base warning used by this module.

##### PoolError

Base exception for errors caused within a pool.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### RequestError

Base exception for PoolErrors that have associated URLs.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### SSLError

Raised when SSL certificate fails in an HTTPS connection.

##### ProxyError

Raised when the connection to a proxy fails.

**M√©thodes :**

- `__init__()`

##### DecodeError

Raised when automatic decoding based on Content-Type fails.

##### ProtocolError

Raised when something unexpected happens mid-request/response.

##### MaxRetryError

Raised when the maximum number of retries is exceeded.

:param pool: The connection pool
:type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`
:param string url: The requested Url
:param exceptions.Exception reason: The underlying error

**M√©thodes :**

- `__init__()`

##### HostChangedError

Raised when an existing pool gets a request for a foreign host.

**M√©thodes :**

- `__init__()`

##### TimeoutStateError

Raised when passing an invalid state to a timeout

##### TimeoutError

Raised when a socket timeout error occurs.

Catching this error will catch both :exc:`ReadTimeoutErrors
<ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.

##### ReadTimeoutError

Raised when a socket timeout occurs while receiving data from a server

##### ConnectTimeoutError

Raised when a socket timeout occurs while connecting to a server

##### NewConnectionError

Raised when we fail to establish a new connection. Usually ECONNREFUSED.

##### EmptyPoolError

Raised when a pool runs out of connections and no more are allowed.

##### ClosedPoolError

Raised when a request enters a pool after the pool has been closed.

##### LocationValueError

Raised when there is something wrong with a given URL input.

##### LocationParseError

Raised when get_host or similar fails to parse the URL input.

**M√©thodes :**

- `__init__()`

##### URLSchemeUnknown

Raised when a URL input has an unsupported scheme.

**M√©thodes :**

- `__init__()`

##### ResponseError

Used as a container for an error reason supplied in a MaxRetryError.

##### SecurityWarning

Warned when performing security reducing actions

##### SubjectAltNameWarning

Warned when connecting to a host with a certificate missing a SAN.

##### InsecureRequestWarning

Warned when making an unverified HTTPS request.

##### SystemTimeWarning

Warned when system time is suspected to be wrong

##### InsecurePlatformWarning

Warned when certain TLS/SSL configuration is not available on a platform.

##### SNIMissingWarning

Warned when making a HTTPS request without SNI available.

##### DependencyWarning

Warned when an attempt is made to import a module with missing optional
dependencies.

##### ResponseNotChunked

Response needs to be chunked in order to read it as chunks.

##### BodyNotHttplibCompatible

Body should be :class:`http.client.HTTPResponse` like
(have an fp attribute which returns raw chunks) for read_chunked().

##### IncompleteRead

Response length doesn't match expected Content-Length

Subclass of :class:`http.client.IncompleteRead` to allow int value
for ``partial`` to avoid creating large objects on streamed reads.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### InvalidChunkLength

Invalid chunk length in a chunked response.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### InvalidHeader

The header provided was somehow invalid.

##### ProxySchemeUnknown

ProxyManager does not support the supplied scheme

**M√©thodes :**

- `__init__()`

##### ProxySchemeUnsupported

Fetching HTTPS resources through HTTPS proxies is unsupported

##### HeaderParsingError

Raised by assert_header_parsing, but we convert it to a log.warning statement.

**M√©thodes :**

- `__init__()`

##### UnrewindableBodyError

urllib3 encountered an error when trying to rewind a body

#### Fonctions

##### __init__

**Param√®tres :**

- `pool`
- `message`

##### __reduce__

##### __init__

**Param√®tres :**

- `pool`
- `url`
- `message`

##### __reduce__

##### __init__

**Param√®tres :**

- `message`
- `error`

##### __init__

**Param√®tres :**

- `pool`
- `url`
- `reason`

##### __init__

**Param√®tres :**

- `pool`
- `url`
- `retries`

##### __init__

**Param√®tres :**

- `location`

##### __init__

**Param√®tres :**

- `scheme`

##### __init__

**Param√®tres :**

- `partial`
- `expected`

##### __repr__

##### __init__

**Param√®tres :**

- `response`
- `length`

##### __repr__

##### __init__

**Param√®tres :**

- `scheme`

##### __init__

**Param√®tres :**

- `defects`
- `unparsed_data`

---

### fields

#### Classes

##### RequestField

A data container for request body parameters.

:param name:
    The name of this request field. Must be unicode.
:param data:
    The data/value body.
:param filename:
    An optional filename of the request field. Must be unicode.
:param headers:
    An optional dict-like object of headers to initially use for the field.
:param header_formatter:
    An optional callable that is used to encode and format the headers. By
    default, this is :func:`format_header_param_html5`.

**M√©thodes :**

- `__init__()`
- `from_tuples()`
- `_render_part()`
- `_render_parts()`
- `render_headers()`
- `make_multipart()`

#### Fonctions

##### guess_content_type

Guess the "Content-Type" of a file.

:param filename:
    The filename to guess the "Content-Type" of using :mod:`mimetypes`.
:param default:
    If no "Content-Type" can be guessed, default to `default`.

**Param√®tres :**

- `filename`
- `default`

##### format_header_param_rfc2231

Helper function to format and quote a single header parameter using the
strategy defined in RFC 2231.

Particularly useful for header parameters which might contain
non-ASCII values, like file names. This follows
`RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.

:param name:
    The name of the parameter, a string expected to be ASCII only.
:param value:
    The value of the parameter, provided as ``bytes`` or `str``.
:ret:
    An RFC-2231-formatted unicode string.

**Param√®tres :**

- `name`
- `value`

##### _replace_multiple

**Param√®tres :**

- `value`
- `needles_and_replacements`

##### format_header_param_html5

Helper function to format and quote a single header parameter using the
HTML5 strategy.

Particularly useful for header parameters which might contain
non-ASCII values, like file names. This follows the `HTML5 Working Draft
Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.

.. _HTML5 Working Draft Section 4.10.22.7:
    https://w3c.github.io/html/sec-forms.html#multipart-form-data

:param name:
    The name of the parameter, a string expected to be ASCII only.
:param value:
    The value of the parameter, provided as ``bytes`` or `str``.
:ret:
    A unicode string, stripped of troublesome characters.

**Param√®tres :**

- `name`
- `value`

##### replacer

**Param√®tres :**

- `match`

##### __init__

**Param√®tres :**

- `name`
- `data`
- `filename`
- `headers`
- `header_formatter`

##### from_tuples

A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.

Supports constructing :class:`~urllib3.fields.RequestField` from
parameter of key/value strings AND key/filetuple. A filetuple is a
(filename, data, MIME type) tuple where the MIME type is optional.
For example::

    'foo': 'bar',
    'fakefile': ('foofile.txt', 'contents of foofile'),
    'realfile': ('barfile.txt', open('realfile').read()),
    'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),
    'nonamefile': 'contents of nonamefile field',

Field names and filenames must be unicode.

**Param√®tres :**

- `cls`
- `fieldname`
- `value`
- `header_formatter`

##### _render_part

Overridable helper function to format a single header parameter. By
default, this calls ``self.header_formatter``.

:param name:
    The name of the parameter, a string expected to be ASCII only.
:param value:
    The value of the parameter, provided as a unicode string.

**Param√®tres :**

- `name`
- `value`

##### _render_parts

Helper function to format and quote a single header.

Useful for single headers that are composed of multiple items. E.g.,
'Content-Disposition' fields.

:param header_parts:
    A sequence of (k, v) tuples or a :class:`dict` of (k, v) to format
    as `k1="v1"; k2="v2"; ...`.

**Param√®tres :**

- `header_parts`

##### render_headers

Renders the headers for this request field.

##### make_multipart

Makes this request field into a multipart request field.

This method overrides "Content-Disposition", "Content-Type" and
"Content-Location" headers to the request parameter.

:param content_type:
    The 'Content-Type' of the request body.
:param content_location:
    The 'Content-Location' of the request body.

**Param√®tres :**

- `content_disposition`
- `content_type`
- `content_location`

---

### filepost

#### Fonctions

##### choose_boundary

Our embarrassingly-simple replacement for mimetools.choose_boundary.

##### iter_field_objects

Iterate over fields.

Supports list of (k, v) tuples and dicts, and lists of
:class:`~urllib3.fields.RequestField`.

**Param√®tres :**

- `fields`

##### iter_fields

.. deprecated:: 1.6

Iterate over fields.

The addition of :class:`~urllib3.fields.RequestField` makes this function
obsolete. Instead, use :func:`iter_field_objects`, which returns
:class:`~urllib3.fields.RequestField` objects.

Supports list of (k, v) tuples and dicts.

**Param√®tres :**

- `fields`

##### encode_multipart_formdata

Encode a dictionary of ``fields`` using the multipart/form-data MIME format.

:param fields:
    Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).

:param boundary:
    If not specified, then a random boundary will be generated using
    :func:`urllib3.filepost.choose_boundary`.

**Param√®tres :**

- `fields`
- `boundary`

---

### poolmanager

#### Classes

##### PoolManager

Allows for arbitrary requests while transparently keeping track of
necessary connection pools for you.

:param num_pools:
    Number of connection pools to cache before discarding the least
    recently used pool.

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

:param \**connection_pool_kw:
    Additional parameters are used to create fresh
    :class:`urllib3.connectionpool.ConnectionPool` instances.

Example::

    >>> manager = PoolManager(num_pools=2)
    >>> r = manager.request('GET', 'http://google.com/')
    >>> r = manager.request('GET', 'http://google.com/mail')
    >>> r = manager.request('GET', 'http://yahoo.com/')
    >>> len(manager.pools)
    2

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `_new_pool()`
- `clear()`
- `connection_from_host()`
- `connection_from_context()`
- `connection_from_pool_key()`
- `connection_from_url()`
- `_merge_pool_kwargs()`
- `_proxy_requires_url_absolute_form()`
- `_validate_proxy_scheme_url_selection()`
- `urlopen()`

##### ProxyManager

Behaves just like :class:`PoolManager`, but sends all requests through
the defined proxy, using the CONNECT method for HTTPS URLs.

:param proxy_url:
    The URL of the proxy to be used.

:param proxy_headers:
    A dictionary containing headers that will be sent to the proxy. In case
    of HTTP they are being sent with each request, while in the
    HTTPS/CONNECT case they are sent only once. Could be used for proxy
    authentication.

:param proxy_ssl_context:
    The proxy SSL context is used to establish the TLS connection to the
    proxy when using HTTPS proxies.

:param use_forwarding_for_https:
    (Defaults to False) If set to True will forward requests to the HTTPS
    proxy to be made on behalf of the client instead of creating a TLS
    tunnel via the CONNECT method. **Enabling this flag means that request
    and response headers and content will be visible from the HTTPS proxy**
    whereas tunneling keeps request and response headers and content
    private.  IP address, target hostname, SNI, and port are always visible
    to an HTTPS proxy even when this flag is disabled.

Example:
    >>> proxy = urllib3.ProxyManager('http://localhost:3128/')
    >>> r1 = proxy.request('GET', 'http://google.com/')
    >>> r2 = proxy.request('GET', 'http://httpbin.org/')
    >>> len(proxy.pools)
    1
    >>> r3 = proxy.request('GET', 'https://httpbin.org/')
    >>> r4 = proxy.request('GET', 'https://twitter.com/')
    >>> len(proxy.pools)
    3

**M√©thodes :**

- `__init__()`
- `connection_from_host()`
- `_set_proxy_headers()`
- `urlopen()`

#### Fonctions

##### _default_key_normalizer

Create a pool key out of a request context dictionary.

According to RFC 3986, both the scheme and host are case-insensitive.
Therefore, this function normalizes both before constructing the pool
key for an HTTPS request. If you wish to change this behaviour, provide
alternate callables to ``key_fn_by_scheme``.

:param key_class:
    The class to use when constructing the key. This should be a namedtuple
    with the ``scheme`` and ``host`` keys at a minimum.
:type  key_class: namedtuple
:param request_context:
    A dictionary-like object that contain the context for a request.
:type  request_context: dict

:return: A namedtuple that can be used as a connection pool key.
:rtype:  PoolKey

**Param√®tres :**

- `key_class`
- `request_context`

##### proxy_from_url

**Param√®tres :**

- `url`

##### __init__

**Param√®tres :**

- `num_pools`
- `headers`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### _new_pool

Create a new :class:`urllib3.connectionpool.ConnectionPool` based on host, port, scheme, and
any additional pool keyword arguments.

If ``request_context`` is provided, it is provided as keyword arguments
to the pool class used. This method is used to actually create the
connection pools handed out by :meth:`connection_from_url` and
companion methods. It is intended to be overridden for customization.

**Param√®tres :**

- `scheme`
- `host`
- `port`
- `request_context`

##### clear

Empty our store of pools and direct them all to close.

This will not affect in-flight connections, but they will not be
re-used after completion.

##### connection_from_host

Get a :class:`urllib3.connectionpool.ConnectionPool` based on the host, port, and scheme.

If ``port`` isn't given, it will be derived from the ``scheme`` using
``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is
provided, it is merged with the instance's ``connection_pool_kw``
variable and used to create the new connection pool, if one is
needed.

**Param√®tres :**

- `host`
- `port`
- `scheme`
- `pool_kwargs`

##### connection_from_context

Get a :class:`urllib3.connectionpool.ConnectionPool` based on the request context.

``request_context`` must at least contain the ``scheme`` key and its
value must be a key in ``key_fn_by_scheme`` instance variable.

**Param√®tres :**

- `request_context`

##### connection_from_pool_key

Get a :class:`urllib3.connectionpool.ConnectionPool` based on the provided pool key.

``pool_key`` should be a namedtuple that only contains immutable
objects. At a minimum it must have the ``scheme``, ``host``, and
``port`` fields.

**Param√®tres :**

- `pool_key`
- `request_context`

##### connection_from_url

Similar to :func:`urllib3.connectionpool.connection_from_url`.

If ``pool_kwargs`` is not provided and a new pool needs to be
constructed, ``self.connection_pool_kw`` is used to initialize
the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``
is provided, it is used instead. Note that if a new pool does not
need to be created for the request, the provided ``pool_kwargs`` are
not used.

**Param√®tres :**

- `url`
- `pool_kwargs`

##### _merge_pool_kwargs

Merge a dictionary of override values for self.connection_pool_kw.

This does not modify self.connection_pool_kw and returns a new dict.
Any keys in the override dictionary with a value of ``None`` are
removed from the merged dictionary.

**Param√®tres :**

- `override`

##### _proxy_requires_url_absolute_form

Indicates if the proxy requires the complete destination URL in the
request.  Normally this is only needed when not using an HTTP CONNECT
tunnel.

**Param√®tres :**

- `parsed_url`

##### _validate_proxy_scheme_url_selection

Validates that were not attempting to do TLS in TLS connections on
Python2 or with unsupported SSL implementations.

**Param√®tres :**

- `url_scheme`

##### urlopen

Same as :meth:`urllib3.HTTPConnectionPool.urlopen`
with custom cross-host redirect logic and only sends the request-uri
portion of the ``url``.

The given ``url`` parameter must be absolute, such that an appropriate
:class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.

**Param√®tres :**

- `method`
- `url`
- `redirect`

##### __init__

**Param√®tres :**

- `proxy_url`
- `num_pools`
- `headers`
- `proxy_headers`
- `proxy_ssl_context`
- `use_forwarding_for_https`

##### connection_from_host

**Param√®tres :**

- `host`
- `port`
- `scheme`
- `pool_kwargs`

##### _set_proxy_headers

Sets headers needed by proxies: specifically, the Accept and Host
headers. Only sets headers not provided by the user.

**Param√®tres :**

- `url`
- `headers`

##### urlopen

Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.

**Param√®tres :**

- `method`
- `url`
- `redirect`

---

### request

#### Classes

##### RequestMethods

Convenience mixin for classes who implement a :meth:`urlopen` method, such
as :class:`urllib3.HTTPConnectionPool` and
:class:`urllib3.PoolManager`.

Provides behavior for making common types of HTTP request methods and
decides which type of request field encoding to use.

Specifically,

:meth:`.request_encode_url` is for sending requests whose fields are
encoded in the URL (such as GET, HEAD, DELETE).

:meth:`.request_encode_body` is for sending requests whose fields are
encoded in the *body* of the request using multipart or www-form-urlencoded
(such as for POST, PUT, PATCH).

:meth:`.request` is for making any kind of request, it will look up the
appropriate encoding format and use one of the above two methods to make
the request.

Initializer parameters:

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

**M√©thodes :**

- `__init__()`
- `urlopen()`
- `request()`
- `request_encode_url()`
- `request_encode_body()`

##### RequestModule

**M√©thodes :**

- `__call__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `headers`

##### urlopen

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`
- `encode_multipart`
- `multipart_boundary`

##### request

Make a request using :meth:`urlopen` with the appropriate encoding of
``fields`` based on the ``method`` used.

This is a convenience method that requires the least amount of manual
effort. It can be used in most situations, while still having the
option to drop down to more specific methods when necessary, such as
:meth:`request_encode_url`, :meth:`request_encode_body`,
or even the lowest level :meth:`urlopen`.

**Param√®tres :**

- `method`
- `url`
- `fields`
- `headers`

##### request_encode_url

Make a request using :meth:`urlopen` with the ``fields`` encoded in
the url. This is useful for request methods like GET, HEAD, DELETE, etc.

**Param√®tres :**

- `method`
- `url`
- `fields`
- `headers`

##### request_encode_body

Make a request using :meth:`urlopen` with the ``fields`` encoded in
the body. This is useful for request methods like POST, PUT, PATCH, etc.

When ``encode_multipart=True`` (default), then
:func:`urllib3.encode_multipart_formdata` is used to encode
the payload with the appropriate content type. Otherwise
:func:`urllib.parse.urlencode` is used with the
'application/x-www-form-urlencoded' content type.

Multipart encoding must be used when posting files, and it's reasonably
safe to use it in other times too. However, it may break request
signing, such as with OAuth.

Supports an optional ``fields`` parameter of key/value strings AND
key/filetuple. A filetuple is a (filename, data, MIME type) tuple where
the MIME type is optional. For example::

    fields = {
        'foo': 'bar',
        'fakefile': ('foofile.txt', 'contents of foofile'),
        'realfile': ('barfile.txt', open('realfile').read()),
        'typedfile': ('bazfile.bin', open('bazfile').read(),
                      'image/jpeg'),
        'nonamefile': 'contents of nonamefile field',
    }

When uploading a file, providing a filename (the first parameter of the
tuple) is optional but recommended to best mimic behavior of browsers.

Note that if ``headers`` are supplied, the 'Content-Type' header will
be overwritten because it depends on the dynamic random boundary string
which is used to compose the body of the request. The random boundary
string can be explicitly set with the ``multipart_boundary`` parameter.

**Param√®tres :**

- `method`
- `url`
- `fields`
- `headers`
- `encode_multipart`
- `multipart_boundary`

##### __call__

If user tries to call this module directly urllib3 v2.x style raise an error to the user
suggesting they may need urllib3 v2

---

### response

#### Classes

##### DeflateDecoder

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `decompress()`

##### GzipDecoderState

##### GzipDecoder

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `decompress()`

##### MultiDecoder

From RFC7231:
    If one or more encodings have been applied to a representation, the
    sender that applied the encodings MUST generate a Content-Encoding
    header field that lists the content codings in the order in which
    they were applied.

**M√©thodes :**

- `__init__()`
- `flush()`
- `decompress()`

##### HTTPResponse

HTTP Response container.

Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
loaded and decoded on-demand when the ``data`` property is accessed.  This
class is also compatible with the Python standard library's :mod:`io`
module, and can hence be treated as a readable object in the context of that
framework.

Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:

:param preload_content:
    If True, the response's body will be preloaded during construction.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param original_response:
    When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
    object, it's convenient to include the original for debug purposes. It's
    otherwise unused.

:param retries:
    The retries contains the last :class:`~urllib3.util.retry.Retry` that
    was used during the request.

:param enforce_content_length:
    Enforce content length checking. Body returned by server must match
    value of Content-Length header, if present. Otherwise, raise error.

**M√©thodes :**

- `__init__()`
- `get_redirect_location()`
- `release_conn()`
- `drain_conn()`
- `data()`
- `connection()`
- `isclosed()`
- `tell()`
- `_init_length()`
- `_init_decoder()`
- `_decode()`
- `_flush_decoder()`
- `_error_catcher()`
- `_fp_read()`
- `read()`
- `stream()`
- `from_httplib()`
- `getheaders()`
- `getheader()`
- `info()`
- `close()`
- `closed()`
- `fileno()`
- `flush()`
- `readable()`
- `readinto()`
- `supports_chunked_reads()`
- `_update_chunk_length()`
- `_handle_chunk()`
- `read_chunked()`
- `geturl()`
- `__iter__()`

##### BrotliDecoder

**M√©thodes :**

- `__init__()`
- `flush()`

#### Fonctions

##### _get_decoder

**Param√®tres :**

- `mode`

##### __init__

##### __getattr__

**Param√®tres :**

- `name`

##### decompress

**Param√®tres :**

- `data`

##### __init__

##### __getattr__

**Param√®tres :**

- `name`

##### decompress

**Param√®tres :**

- `data`

##### __init__

**Param√®tres :**

- `modes`

##### flush

##### decompress

**Param√®tres :**

- `data`

##### __init__

**Param√®tres :**

- `body`
- `headers`
- `status`
- `version`
- `reason`
- `strict`
- `preload_content`
- `decode_content`
- `original_response`
- `pool`
- `connection`
- `msg`
- `retries`
- `enforce_content_length`
- `request_method`
- `request_url`
- `auto_close`

##### get_redirect_location

Should we redirect and where to?

:returns: Truthy redirect location string if we got a redirect status
    code and valid location. ``None`` if redirect status and no
    location. ``False`` if not a redirect status code.

##### release_conn

##### drain_conn

Read and discard any remaining HTTP response data in the response connection.

Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.

##### data

##### connection

##### isclosed

##### tell

Obtain the number of bytes pulled over the wire so far. May differ from
the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
if bytes are encoded on the wire (e.g, compressed).

##### _init_length

Set initial length value for Response content if available.

**Param√®tres :**

- `request_method`

##### _init_decoder

Set-up the _decoder attribute if necessary.

##### _decode

Decode the data passed in and potentially flush the decoder.

**Param√®tres :**

- `data`
- `decode_content`
- `flush_decoder`

##### _flush_decoder

Flushes the decoder. Should only be called if the decoder is actually
being used.

##### _error_catcher

Catch low-level python exceptions, instead re-raising urllib3
variants, so that low-level exceptions are not leaked in the
high-level api.

On exit, release the connection back to the pool.

##### _fp_read

Read a response with the thought that reading the number of bytes
larger than can fit in a 32-bit int at a time via SSL in some
known cases leads to an overflow error that has to be prevented
if `amt` or `self.length_remaining` indicate that a problem may
happen.

The known cases:
  * 3.8 <= CPython < 3.9.7 because of a bug
    https://github.com/urllib3/urllib3/issues/2513#issuecomment-1152559900.
  * urllib3 injected with pyOpenSSL-backed SSL-support.
  * CPython < 3.10 only when `amt` does not fit 32-bit int.

**Param√®tres :**

- `amt`

##### read

Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
parameters: ``decode_content`` and ``cache_content``.

:param amt:
    How much of the content to read. If specified, caching is skipped
    because it doesn't make sense to cache partial content as the full
    response.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param cache_content:
    If True, will save the returned data such that the same result is
    returned despite of the state of the underlying file object. This
    is useful if you want the ``.data`` property to continue working
    after having ``.read()`` the file object. (Overridden if ``amt`` is
    set.)

**Param√®tres :**

- `amt`
- `decode_content`
- `cache_content`

##### stream

A generator wrapper for the read() method. A call will block until
``amt`` bytes have been read from the connection or until the
connection is closed.

:param amt:
    How much of the content to read. The generator will return up to
    much data per iteration, but may return less. This is particularly
    likely when using compressed data. However, the empty string will
    never be returned.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

**Param√®tres :**

- `amt`
- `decode_content`

##### from_httplib

Given an :class:`http.client.HTTPResponse` instance ``r``, return a
corresponding :class:`urllib3.response.HTTPResponse` object.

Remaining parameters are passed to the HTTPResponse constructor, along
with ``original_response=r``.

**Param√®tres :**

- `ResponseCls`
- `r`

##### getheaders

##### getheader

**Param√®tres :**

- `name`
- `default`

##### info

##### close

##### closed

##### fileno

##### flush

##### readable

##### readinto

**Param√®tres :**

- `b`

##### supports_chunked_reads

Checks if the underlying file-like object looks like a
:class:`http.client.HTTPResponse` object. We do this by testing for
the fp attribute. If it is present we assume it returns raw chunks as
processed by read_chunked().

##### _update_chunk_length

##### _handle_chunk

**Param√®tres :**

- `amt`

##### read_chunked

Similar to :meth:`HTTPResponse.read`, but with an additional
parameter: ``decode_content``.

:param amt:
    How much of the content to read. If specified, caching is skipped
    because it doesn't make sense to cache partial content as the full
    response.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

**Param√®tres :**

- `amt`
- `decode_content`

##### geturl

Returns the URL that was the source of this response.
If the request that generated this response redirected, this method
will return the final redirect location.

##### __iter__

##### __init__

##### flush

---

### .!24290!__init__

---

### .!24295!_collections

---

### .!24300!_version

---

### .!24304!connection

---

### .!24311!connectionpool

---

### .!24315!exceptions

---

### .!24320!fields

---

### .!24325!filepost

---

### .!24331!poolmanager

---

### .!24334!request

---

### .!24339!response

---

### _appengine_environ

This module provides means to detect the App Engine environment.

#### Fonctions

##### is_appengine

##### is_appengine_sandbox

Reports if the app is running in the first generation sandbox.

The second generation runtimes are technically still in a sandbox, but it
is much less restrictive, so generally you shouldn't need to check for it.
see https://cloud.google.com/appengine/docs/standard/runtimes

##### is_local_appengine

##### is_prod_appengine

##### is_prod_appengine_mvms

Deprecated.

---

### appengine

This module provides a pool manager that uses Google App Engine's
`URLFetch Service <https://cloud.google.com/appengine/docs/python/urlfetch>`_.

Example usage::

    from pip._vendor.urllib3 import PoolManager
    from pip._vendor.urllib3.contrib.appengine import AppEngineManager, is_appengine_sandbox

    if is_appengine_sandbox():
        # AppEngineManager uses AppEngine's URLFetch API behind the scenes
        http = AppEngineManager()
    else:
        # PoolManager uses a socket-level API behind the scenes
        http = PoolManager()

    r = http.request('GET', 'https://google.com/')

There are `limitations <https://cloud.google.com/appengine/docs/python/urlfetch/#Python_Quotas_and_limits>`_ to the URLFetch service and it may not be
the best choice for your application. There are three options for using
urllib3 on Google App Engine:

1. You can use :class:`AppEngineManager` with URLFetch. URLFetch is
   cost-effective in many circumstances as long as your usage is within the
   limitations.
2. You can use a normal :class:`~urllib3.PoolManager` by enabling sockets.
   Sockets also have `limitations and restrictions
   <https://cloud.google.com/appengine/docs/python/sockets/   #limitations-and-restrictions>`_ and have a lower free quota than URLFetch.
   To use sockets, be sure to specify the following in your ``app.yaml``::

        env_variables:
            GAE_USE_SOCKETS_HTTPLIB : 'true'

3. If you are using `App Engine Flexible
<https://cloud.google.com/appengine/docs/flexible/>`_, you can use the standard
:class:`PoolManager` without any configuration or special environment variables.

#### Classes

##### AppEnginePlatformWarning

##### AppEnginePlatformError

##### AppEngineManager

Connection manager for Google App Engine sandbox applications.

This manager uses the URLFetch service directly instead of using the
emulated httplib, and is subject to URLFetch limitations as described in
the App Engine documentation `here
<https://cloud.google.com/appengine/docs/python/urlfetch>`_.

Notably it will raise an :class:`AppEnginePlatformError` if:
    * URLFetch is not available.
    * If you attempt to use this on App Engine Flexible, as full socket
      support is available.
    * If a request size is more than 10 megabytes.
    * If a response size is more than 32 megabytes.
    * If you use an unsupported request method such as OPTIONS.

Beyond those cases, it will raise normal urllib3 errors.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `urlopen()`
- `_urlfetch_response_to_http_response()`
- `_get_absolute_timeout()`
- `_get_retries()`

#### Fonctions

##### __init__

**Param√®tres :**

- `headers`
- `retries`
- `validate_certificate`
- `urlfetch_retries`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### urlopen

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`
- `retries`
- `redirect`
- `timeout`

##### _urlfetch_response_to_http_response

**Param√®tres :**

- `urlfetch_resp`

##### _get_absolute_timeout

**Param√®tres :**

- `timeout`

##### _get_retries

**Param√®tres :**

- `retries`
- `redirect`

---

### ntlmpool

NTLM authenticating pool, contributed by erikcederstran

Issue #10, see: http://code.google.com/p/urllib3/issues/detail?id=10

#### Classes

##### NTLMConnectionPool

Implements an NTLM authentication version of an urllib3 connection pool

**M√©thodes :**

- `__init__()`
- `_new_conn()`
- `urlopen()`

#### Fonctions

##### __init__

authurl is a random URL on the server that is protected by NTLM.
user is the Windows user, probably in the DOMAIN\username format.
pw is the password for the user.

**Param√®tres :**

- `user`
- `pw`
- `authurl`

##### _new_conn

##### urlopen

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`
- `retries`
- `redirect`
- `assert_same_host`

---

### pyopenssl

TLS with SNI_-support for Python 2. Follow these instructions if you would
like to verify TLS certificates in Python 2. Note, the default libraries do
*not* do certificate checking; you need to do additional work to validate
certificates yourself.

This needs the following packages installed:

* `pyOpenSSL`_ (tested with 16.0.0)
* `cryptography`_ (minimum 1.3.4, from pyopenssl)
* `idna`_ (minimum 2.0, from cryptography)

However, pyopenssl depends on cryptography, which depends on idna, so while we
use all three directly here we end up having relatively few packages required.

You can install them with the following command:

.. code-block:: bash

    $ python -m pip install pyopenssl cryptography idna

To activate certificate checking, call
:func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code
before you begin making HTTP requests. This can be done in a ``sitecustomize``
module, or at any other time before your application begins using ``urllib3``,
like this:

.. code-block:: python

    try:
        import pip._vendor.urllib3.contrib.pyopenssl as pyopenssl
        pyopenssl.inject_into_urllib3()
    except ImportError:
        pass

Now you can use :mod:`urllib3` as you normally would, and it will support SNI
when the required modules are installed.

Activating this module also has the positive side effect of disabling SSL/TLS
compression in Python 2 (see `CRIME attack`_).

.. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication
.. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)
.. _pyopenssl: https://www.pyopenssl.org
.. _cryptography: https://cryptography.io
.. _idna: https://github.com/kjd/idna

#### Classes

##### WrappedSocket

API-compatibility wrapper for Python OpenSSL's Connection-class.

Note: _makefile_refs, _drop() and _reuse() are needed for the garbage
collector of pypy.

**M√©thodes :**

- `__init__()`
- `fileno()`
- `_decref_socketios()`
- `recv()`
- `recv_into()`
- `settimeout()`
- `_send_until_done()`
- `sendall()`
- `shutdown()`
- `close()`
- `getpeercert()`
- `version()`
- `_reuse()`
- `_drop()`

##### PyOpenSSLContext

I am a wrapper class for the PyOpenSSL ``Context`` object. I am responsible
for translating the interface of the standard library ``SSLContext`` object
to calls into PyOpenSSL.

**M√©thodes :**

- `__init__()`
- `options()`
- `options()`
- `verify_mode()`
- `verify_mode()`
- `set_default_verify_paths()`
- `set_ciphers()`
- `load_verify_locations()`
- `load_cert_chain()`
- `set_alpn_protocols()`
- `wrap_socket()`

##### UnsupportedExtension

#### Fonctions

##### inject_into_urllib3

Monkey-patch urllib3 with PyOpenSSL-backed SSL-support.

##### extract_from_urllib3

Undo monkey-patching by :func:`inject_into_urllib3`.

##### _validate_dependencies_met

Verifies that PyOpenSSL's package-level dependencies have been met.
Throws `ImportError` if they are not met.

##### _dnsname_to_stdlib

Converts a dNSName SubjectAlternativeName field to the form used by the
standard library on the given Python version.

Cryptography produces a dNSName as a unicode string that was idna-decoded
from ASCII bytes. We need to idna-encode that string to get it back, and
then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib
uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).

If the name cannot be idna-encoded then we return None signalling that
the name given should be skipped.

**Param√®tres :**

- `name`

##### get_subj_alt_name

Given an PyOpenSSL certificate, provides all the subject alternative names.

**Param√®tres :**

- `peer_cert`

##### _verify_callback

**Param√®tres :**

- `cnx`
- `x509`
- `err_no`
- `err_depth`
- `return_code`

##### idna_encode

Borrowed wholesale from the Python Cryptography Project. It turns out
that we can't just safely call `idna.encode`: it can explode for
wildcard names. This avoids that problem.

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `connection`
- `socket`
- `suppress_ragged_eofs`

##### fileno

##### _decref_socketios

##### recv

##### recv_into

##### settimeout

**Param√®tres :**

- `timeout`

##### _send_until_done

**Param√®tres :**

- `data`

##### sendall

**Param√®tres :**

- `data`

##### shutdown

##### close

##### getpeercert

**Param√®tres :**

- `binary_form`

##### version

##### _reuse

##### _drop

##### makefile

**Param√®tres :**

- `mode`
- `bufsize`

##### __init__

**Param√®tres :**

- `protocol`

##### options

##### options

**Param√®tres :**

- `value`

##### verify_mode

##### verify_mode

**Param√®tres :**

- `value`

##### set_default_verify_paths

##### set_ciphers

**Param√®tres :**

- `ciphers`

##### load_verify_locations

**Param√®tres :**

- `cafile`
- `capath`
- `cadata`

##### load_cert_chain

**Param√®tres :**

- `certfile`
- `keyfile`
- `password`

##### set_alpn_protocols

**Param√®tres :**

- `protocols`

##### wrap_socket

**Param√®tres :**

- `sock`
- `server_side`
- `do_handshake_on_connect`
- `suppress_ragged_eofs`
- `server_hostname`

---

### securetransport

SecureTranport support for urllib3 via ctypes.

This makes platform-native TLS available to urllib3 users on macOS without the
use of a compiler. This is an important feature because the Python Package
Index is moving to become a TLSv1.2-or-higher server, and the default OpenSSL
that ships with macOS is not capable of doing TLSv1.2. The only way to resolve
this is to give macOS users an alternative solution to the problem, and that
solution is to use SecureTransport.

We use ctypes here because this solution must not require a compiler. That's
because pip is not allowed to require a compiler either.

This is not intended to be a seriously long-term solution to this problem.
The hope is that PEP 543 will eventually solve this issue for us, at which
point we can retire this contrib module. But in the short term, we need to
solve the impending tire fire that is Python on Mac without this kind of
contrib module. So...here we are.

To use this module, simply import and inject it::

    import pip._vendor.urllib3.contrib.securetransport as securetransport
    securetransport.inject_into_urllib3()

Happy TLSing!

This code is a bastardised version of the code found in Will Bond's oscrypto
library. An enormous debt is owed to him for blazing this trail for us. For
that reason, this code should be considered to be covered both by urllib3's
license and by oscrypto's:

.. code-block::

    Copyright (c) 2015-2016 Will Bond <will@wbond.net>

    Permission is hereby granted, free of charge, to any person obtaining a
    copy of this software and associated documentation files (the "Software"),
    to deal in the Software without restriction, including without limitation
    the rights to use, copy, modify, merge, publish, distribute, sublicense,
    and/or sell copies of the Software, and to permit persons to whom the
    Software is furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in
    all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    DEALINGS IN THE SOFTWARE.

#### Classes

##### WrappedSocket

API-compatibility wrapper for Python's OpenSSL wrapped socket object.

Note: _makefile_refs, _drop(), and _reuse() are needed for the garbage
collector of PyPy.

**M√©thodes :**

- `__init__()`
- `_raise_on_error()`
- `_set_ciphers()`
- `_set_alpn_protocols()`
- `_custom_validate()`
- `_evaluate_trust()`
- `handshake()`
- `fileno()`
- `_decref_socketios()`
- `recv()`
- `recv_into()`
- `settimeout()`
- `gettimeout()`
- `send()`
- `sendall()`
- `shutdown()`
- `close()`
- `getpeercert()`
- `version()`
- `_reuse()`
- `_drop()`

##### SecureTransportContext

I am a wrapper class for the SecureTransport library, to translate the
interface of the standard library ``SSLContext`` object to calls into
SecureTransport.

**M√©thodes :**

- `__init__()`
- `check_hostname()`
- `check_hostname()`
- `options()`
- `options()`
- `verify_mode()`
- `verify_mode()`
- `set_default_verify_paths()`
- `load_default_certs()`
- `set_ciphers()`
- `load_verify_locations()`
- `load_cert_chain()`
- `set_alpn_protocols()`
- `wrap_socket()`

#### Fonctions

##### inject_into_urllib3

Monkey-patch urllib3 with SecureTransport-backed SSL-support.

##### extract_from_urllib3

Undo monkey-patching by :func:`inject_into_urllib3`.

##### _read_callback

SecureTransport read callback. This is called by ST to request that data
be returned from the socket.

**Param√®tres :**

- `connection_id`
- `data_buffer`
- `data_length_pointer`

##### _write_callback

SecureTransport write callback. This is called by ST to request that data
actually be sent on the network.

**Param√®tres :**

- `connection_id`
- `data_buffer`
- `data_length_pointer`

##### __init__

**Param√®tres :**

- `socket`

##### _raise_on_error

A context manager that can be used to wrap calls that do I/O from
SecureTransport. If any of the I/O callbacks hit an exception, this
context manager will correctly propagate the exception after the fact.
This avoids silently swallowing those exceptions.

It also correctly forces the socket closed.

##### _set_ciphers

Sets up the allowed ciphers. By default this matches the set in
util.ssl_.DEFAULT_CIPHERS, at least as supported by macOS. This is done
custom and doesn't allow changing at this time, mostly because parsing
OpenSSL cipher strings is going to be a freaking nightmare.

##### _set_alpn_protocols

Sets up the ALPN protocols on the context.

**Param√®tres :**

- `protocols`

##### _custom_validate

Called when we have set custom validation. We do this in two cases:
first, when cert validation is entirely disabled; and second, when
using a custom trust DB.
Raises an SSLError if the connection is not trusted.

**Param√®tres :**

- `verify`
- `trust_bundle`

##### _evaluate_trust

**Param√®tres :**

- `trust_bundle`

##### handshake

Actually performs the TLS handshake. This is run automatically by
wrapped socket, and shouldn't be needed in user code.

**Param√®tres :**

- `server_hostname`
- `verify`
- `trust_bundle`
- `min_version`
- `max_version`
- `client_cert`
- `client_key`
- `client_key_passphrase`
- `alpn_protocols`

##### fileno

##### _decref_socketios

##### recv

**Param√®tres :**

- `bufsiz`

##### recv_into

**Param√®tres :**

- `buffer`
- `nbytes`

##### settimeout

**Param√®tres :**

- `timeout`

##### gettimeout

##### send

**Param√®tres :**

- `data`

##### sendall

**Param√®tres :**

- `data`

##### shutdown

##### close

##### getpeercert

**Param√®tres :**

- `binary_form`

##### version

##### _reuse

##### _drop

##### makefile

**Param√®tres :**

- `mode`
- `bufsize`

##### makefile

**Param√®tres :**

- `mode`
- `buffering`

##### __init__

**Param√®tres :**

- `protocol`

##### check_hostname

SecureTransport cannot have its hostname checking disabled. For more,
see the comment on getpeercert() in this file.

##### check_hostname

SecureTransport cannot have its hostname checking disabled. For more,
see the comment on getpeercert() in this file.

**Param√®tres :**

- `value`

##### options

##### options

**Param√®tres :**

- `value`

##### verify_mode

##### verify_mode

**Param√®tres :**

- `value`

##### set_default_verify_paths

##### load_default_certs

##### set_ciphers

**Param√®tres :**

- `ciphers`

##### load_verify_locations

**Param√®tres :**

- `cafile`
- `capath`
- `cadata`

##### load_cert_chain

**Param√®tres :**

- `certfile`
- `keyfile`
- `password`

##### set_alpn_protocols

Sets the ALPN protocols that will later be set on the context.

Raises a NotImplementedError if ALPN is not supported.

**Param√®tres :**

- `protocols`

##### wrap_socket

**Param√®tres :**

- `sock`
- `server_side`
- `do_handshake_on_connect`
- `suppress_ragged_eofs`
- `server_hostname`

---

### socks

This module contains provisional support for SOCKS proxies from within
urllib3. This module supports SOCKS4, SOCKS4A (an extension of SOCKS4), and
SOCKS5. To enable its functionality, either install PySocks or install this
module with the ``socks`` extra.

The SOCKS implementation supports the full range of urllib3 features. It also
supports the following SOCKS features:

- SOCKS4A (``proxy_url='socks4a://...``)
- SOCKS4 (``proxy_url='socks4://...``)
- SOCKS5 with remote DNS (``proxy_url='socks5h://...``)
- SOCKS5 with local DNS (``proxy_url='socks5://...``)
- Usernames and passwords for the SOCKS proxy

.. note::
   It is recommended to use ``socks5h://`` or ``socks4a://`` schemes in
   your ``proxy_url`` to ensure that DNS resolution is done from the remote
   server instead of client-side when connecting to a domain name.

SOCKS4 supports IPv4 and domain names with the SOCKS4A extension. SOCKS5
supports IPv4, IPv6, and domain names.

When connecting to a SOCKS4 proxy the ``username`` portion of the ``proxy_url``
will be sent as the ``userid`` section of the SOCKS request:

.. code-block:: python

    proxy_url="socks4a://<userid>@proxy-host"

When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion
of the ``proxy_url`` will be sent as the username/password to authenticate
with the proxy:

.. code-block:: python

    proxy_url="socks5h://<username>:<password>@proxy-host"

#### Classes

##### SOCKSConnection

A plain-text HTTP connection that connects via a SOCKS proxy.

**M√©thodes :**

- `__init__()`
- `_new_conn()`

##### SOCKSHTTPSConnection

##### SOCKSHTTPConnectionPool

##### SOCKSHTTPSConnectionPool

##### SOCKSProxyManager

A version of the urllib3 ProxyManager that routes connections via the
defined SOCKS proxy.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

##### _new_conn

Establish a new connection via the SOCKS proxy.

##### __init__

**Param√®tres :**

- `proxy_url`
- `username`
- `password`
- `num_pools`
- `headers`

---

### .!24350!_appengine_environ

---

### .!24354!appengine

---

### .!24360!ntlmpool

---

### .!24365!pyopenssl

---

### .!24368!securetransport

---

### .!24373!socks

---

### bindings

This module uses ctypes to bind a whole bunch of functions and constants from
SecureTransport. The goal here is to provide the low-level API to
SecureTransport. These are essentially the C-level functions and constants, and
they're pretty gross to work with.

This code is a bastardised version of the code found in Will Bond's oscrypto
library. An enormous debt is owed to him for blazing this trail for us. For
that reason, this code should be considered to be covered both by urllib3's
license and by oscrypto's:

    Copyright (c) 2015-2016 Will Bond <will@wbond.net>

    Permission is hereby granted, free of charge, to any person obtaining a
    copy of this software and associated documentation files (the "Software"),
    to deal in the Software without restriction, including without limitation
    the rights to use, copy, modify, merge, publish, distribute, sublicense,
    and/or sell copies of the Software, and to permit persons to whom the
    Software is furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in
    all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    DEALINGS IN THE SOFTWARE.

#### Classes

##### CFConst

A class object that acts as essentially a namespace for CoreFoundation
constants.

##### SecurityConst

A class object that acts as essentially a namespace for Security constants.

#### Fonctions

##### load_cdll

Loads a CDLL by name, falling back to known path on 10.16+

**Param√®tres :**

- `name`
- `macos10_16_path`

---

### low_level

Low-level helpers for the SecureTransport bindings.

These are Python functions that are not directly related to the high-level APIs
but are necessary to get them to work. They include a whole bunch of low-level
CoreFoundation messing about and memory management. The concerns in this module
are almost entirely about trying to avoid memory leaks and providing
appropriate and useful assistance to the higher-level code.

#### Fonctions

##### _cf_data_from_bytes

Given a bytestring, create a CFData object from it. This CFData object must
be CFReleased by the caller.

**Param√®tres :**

- `bytestring`

##### _cf_dictionary_from_tuples

Given a list of Python tuples, create an associated CFDictionary.

**Param√®tres :**

- `tuples`

##### _cfstr

Given a Python binary data, create a CFString.
The string must be CFReleased by the caller.

**Param√®tres :**

- `py_bstr`

##### _create_cfstring_array

Given a list of Python binary data, create an associated CFMutableArray.
The array must be CFReleased by the caller.

Raises an ssl.SSLError on failure.

**Param√®tres :**

- `lst`

##### _cf_string_to_unicode

Creates a Unicode string from a CFString object. Used entirely for error
reporting.

Yes, it annoys me quite a lot that this function is this complex.

**Param√®tres :**

- `value`

##### _assert_no_error

Checks the return code and throws an exception if there is an error to
report

**Param√®tres :**

- `error`
- `exception_class`

##### _cert_array_from_pem

Given a bundle of certs in PEM format, turns them into a CFArray of certs
that can be used to validate a cert chain.

**Param√®tres :**

- `pem_bundle`

##### _is_cert

Returns True if a given CFTypeRef is a certificate.

**Param√®tres :**

- `item`

##### _is_identity

Returns True if a given CFTypeRef is an identity.

**Param√®tres :**

- `item`

##### _temporary_keychain

This function creates a temporary Mac keychain that we can use to work with
credentials. This keychain uses a one-time password and a temporary file to
store the data. We expect to have one keychain per socket. The returned
SecKeychainRef must be freed by the caller, including calling
SecKeychainDelete.

Returns a tuple of the SecKeychainRef and the path to the temporary
directory that contains it.

##### _load_items_from_file

Given a single file, loads all the trust objects from it into arrays and
the keychain.
Returns a tuple of lists: the first list is a list of identities, the
second a list of certs.

**Param√®tres :**

- `keychain`
- `path`

##### _load_client_cert_chain

Load certificates and maybe keys from a number of files. Has the end goal
of returning a CFArray containing one SecIdentityRef, and then zero or more
SecCertificateRef objects, suitable for use as a client certificate trust
chain.

**Param√®tres :**

- `keychain`

##### _build_tls_unknown_ca_alert

Builds a TLS alert record for an unknown CA.

**Param√®tres :**

- `version`

---

### .!24387!bindings

---

### .!24391!low_level

---

### six

Utilities for writing code that runs on Python 2 and 3

#### Classes

##### _LazyDescr

**M√©thodes :**

- `__init__()`
- `__get__()`

##### MovedModule

**M√©thodes :**

- `__init__()`
- `_resolve()`
- `__getattr__()`

##### _LazyModule

**M√©thodes :**

- `__init__()`
- `__dir__()`

##### MovedAttribute

**M√©thodes :**

- `__init__()`
- `_resolve()`

##### _SixMetaPathImporter

A meta path importer to import six.moves and its submodules.

This class implements a PEP302 finder and loader. It should be compatible
with Python 2.5 and all existing versions of Python3

**M√©thodes :**

- `__init__()`
- `_add_module()`
- `_get_module()`
- `find_module()`
- `find_spec()`
- `__get_module()`
- `load_module()`
- `is_package()`
- `get_code()`
- `create_module()`
- `exec_module()`

##### _MovedItems

Lazy loading of moved objects

##### Module_six_moves_urllib_parse

Lazy loading of moved objects in six.moves.urllib_parse

##### Module_six_moves_urllib_error

Lazy loading of moved objects in six.moves.urllib_error

##### Module_six_moves_urllib_request

Lazy loading of moved objects in six.moves.urllib_request

##### Module_six_moves_urllib_response

Lazy loading of moved objects in six.moves.urllib_response

##### Module_six_moves_urllib_robotparser

Lazy loading of moved objects in six.moves.urllib_robotparser

##### Module_six_moves_urllib

Create a six.moves.urllib namespace that resembles the Python 3 namespace

**M√©thodes :**

- `__dir__()`

##### Iterator

**M√©thodes :**

- `next()`

##### metaclass

**M√©thodes :**

- `__new__()`
- `__prepare__()`

##### X

**M√©thodes :**

- `__len__()`

#### Fonctions

##### _add_doc

Add documentation to a function.

**Param√®tres :**

- `func`
- `doc`

##### _import_module

Import module, returning the module after the last dot.

**Param√®tres :**

- `name`

##### add_move

Add an item to six.moves.

**Param√®tres :**

- `move`

##### remove_move

Remove item from six.moves.

**Param√®tres :**

- `name`

##### assertCountEqual

##### assertRaisesRegex

##### assertRegex

##### assertNotRegex

##### with_metaclass

Create a base class with a metaclass.

**Param√®tres :**

- `meta`

##### add_metaclass

Class decorator for creating a class with a metaclass.

**Param√®tres :**

- `metaclass`

##### ensure_binary

Coerce **s** to six.binary_type.

For Python 2:
  - `unicode` -> encoded to `str`
  - `str` -> `str`

For Python 3:
  - `str` -> encoded to `bytes`
  - `bytes` -> `bytes`

**Param√®tres :**

- `s`
- `encoding`
- `errors`

##### ensure_str

Coerce *s* to `str`.

For Python 2:
  - `unicode` -> encoded to `str`
  - `str` -> `str`

For Python 3:
  - `str` -> `str`
  - `bytes` -> decoded to `str`

**Param√®tres :**

- `s`
- `encoding`
- `errors`

##### ensure_text

Coerce *s* to six.text_type.

For Python 2:
  - `unicode` -> `unicode`
  - `str` -> `unicode`

For Python 3:
  - `str` -> `str`
  - `bytes` -> decoded to `str`

**Param√®tres :**

- `s`
- `encoding`
- `errors`

##### python_2_unicode_compatible

A class decorator that defines __unicode__ and __str__ methods under Python 2.
Under Python 3 it does nothing.

To support Python 2 and 3 with a single code base, define a __str__ method
returning text and apply this decorator to the class.

**Param√®tres :**

- `klass`

##### __init__

**Param√®tres :**

- `name`

##### __get__

**Param√®tres :**

- `obj`
- `tp`

##### __init__

**Param√®tres :**

- `name`
- `old`
- `new`

##### _resolve

##### __getattr__

**Param√®tres :**

- `attr`

##### __init__

**Param√®tres :**

- `name`

##### __dir__

##### __init__

**Param√®tres :**

- `name`
- `old_mod`
- `new_mod`
- `old_attr`
- `new_attr`

##### _resolve

##### __init__

**Param√®tres :**

- `six_module_name`

##### _add_module

**Param√®tres :**

- `mod`

##### _get_module

**Param√®tres :**

- `fullname`

##### find_module

**Param√®tres :**

- `fullname`
- `path`

##### find_spec

**Param√®tres :**

- `fullname`
- `path`
- `target`

##### __get_module

**Param√®tres :**

- `fullname`

##### load_module

**Param√®tres :**

- `fullname`

##### is_package

Return true, if the named module is a package.

We need this method to get correct spec objects with
Python 3.4 (see PEP451)

**Param√®tres :**

- `fullname`

##### get_code

Return None

Required, if is_package is implemented

**Param√®tres :**

- `fullname`

##### create_module

**Param√®tres :**

- `spec`

##### exec_module

**Param√®tres :**

- `module`

##### __dir__

##### get_unbound_function

**Param√®tres :**

- `unbound`

##### create_unbound_method

**Param√®tres :**

- `func`
- `cls`

##### get_unbound_function

**Param√®tres :**

- `unbound`

##### create_bound_method

**Param√®tres :**

- `func`
- `obj`

##### create_unbound_method

**Param√®tres :**

- `func`
- `cls`

##### iterkeys

**Param√®tres :**

- `d`

##### itervalues

**Param√®tres :**

- `d`

##### iteritems

**Param√®tres :**

- `d`

##### iterlists

**Param√®tres :**

- `d`

##### iterkeys

**Param√®tres :**

- `d`

##### itervalues

**Param√®tres :**

- `d`

##### iteritems

**Param√®tres :**

- `d`

##### iterlists

**Param√®tres :**

- `d`

##### b

**Param√®tres :**

- `s`

##### u

**Param√®tres :**

- `s`

##### b

**Param√®tres :**

- `s`

##### u

**Param√®tres :**

- `s`

##### byte2int

**Param√®tres :**

- `bs`

##### indexbytes

**Param√®tres :**

- `buf`
- `i`

##### reraise

**Param√®tres :**

- `tp`
- `value`
- `tb`

##### exec_

Execute code in a namespace.

**Param√®tres :**

- `_code_`
- `_globs_`
- `_locs_`

##### raise_from

**Param√®tres :**

- `value`
- `from_value`

##### print_

The new-style print function for Python 2.4 and 2.5.

##### print_

##### _update_wrapper

**Param√®tres :**

- `wrapper`
- `wrapped`
- `assigned`
- `updated`

##### wraps

**Param√®tres :**

- `wrapped`
- `assigned`
- `updated`

##### wrapper

**Param√®tres :**

- `cls`

##### advance_iterator

**Param√®tres :**

- `it`

##### callable

**Param√®tres :**

- `obj`

##### next

##### write

**Param√®tres :**

- `data`

##### __new__

**Param√®tres :**

- `cls`
- `name`
- `this_bases`
- `d`

##### __prepare__

**Param√®tres :**

- `cls`
- `name`
- `this_bases`

##### __len__

---

### .!24402!six

---

### makefile

backports.makefile
~~~~~~~~~~~~~~~~~~

Backports the Python 3 ``socket.makefile`` method for use with anything that
wants to create a "fake" socket object.

#### Fonctions

##### backport_makefile

Backport of ``socket.makefile`` from Python 3.5.

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

---

### weakref_finalize

backports.weakref_finalize
~~~~~~~~~~~~~~~~~~

Backports the Python 3 ``weakref.finalize`` method.

#### Classes

##### weakref_finalize

Class for finalization of weakrefable objects
finalize(obj, func, *args, **kwargs) returns a callable finalizer
object which will be called when obj is garbage collected. The
first time the finalizer is called it evaluates func(*arg, **kwargs)
and returns the result. After this the finalizer is dead, and
calling it just returns None.
When the program exits any remaining finalizers for which the
atexit attribute is true will be run in reverse order of creation.
By default atexit is true.

**M√©thodes :**

- `__init__()`
- `__call__()`
- `detach()`
- `peek()`
- `alive()`
- `atexit()`
- `atexit()`
- `__repr__()`
- `_select_for_exit()`
- `_exitfunc()`

##### _Info

#### Fonctions

##### __init__

**Param√®tres :**

- `obj`
- `func`

##### __call__

If alive then mark as dead and return func(*args, **kwargs);
otherwise return None

**Param√®tres :**

- `_`

##### detach

If alive then mark as dead and return (obj, func, args, kwargs);
otherwise return None

##### peek

If alive then return (obj, func, args, kwargs);
otherwise return None

##### alive

Whether finalizer is alive

##### atexit

Whether finalizer should be called at exit

##### atexit

**Param√®tres :**

- `value`

##### __repr__

##### _select_for_exit

**Param√®tres :**

- `cls`

##### _exitfunc

**Param√®tres :**

- `cls`

---

### .!24413!makefile

---

### .!24418!weakref_finalize

---

### connection

#### Fonctions

##### is_connection_dropped

Returns True if the connection is dropped and should be closed.

:param conn:
    :class:`http.client.HTTPConnection` object.

Note: For platforms like AppEngine, this will always return ``False`` to
let the platform handle connection recycling transparently for us.

**Param√®tres :**

- `conn`

##### create_connection

Connect to *address* and return the socket object.

Convenience function.  Connect to *address* (a 2-tuple ``(host,
port)``) and return the socket object.  Passing the optional
*timeout* parameter will set the timeout on the socket instance
before attempting to connect.  If no *timeout* is supplied, the
global default timeout setting returned by :func:`socket.getdefaulttimeout`
is used.  If *source_address* is set it must be a tuple of (host, port)
for the socket to bind as a source address before making the connection.
An host of '' or port 0 tells the OS to use the default.

**Param√®tres :**

- `address`
- `timeout`
- `source_address`
- `socket_options`

##### _set_socket_options

**Param√®tres :**

- `sock`
- `options`

##### allowed_gai_family

This function is designed to work in the context of
getaddrinfo, where family=socket.AF_UNSPEC is the default and
will perform a DNS search for both IPv6 and IPv4 records.

##### _has_ipv6

Returns True if the system can bind an IPv6 address.

**Param√®tres :**

- `host`

---

### proxy

#### Fonctions

##### connection_requires_http_tunnel

Returns True if the connection requires an HTTP CONNECT through the proxy.

:param URL proxy_url:
    URL of the proxy.
:param ProxyConfig proxy_config:
    Proxy configuration from poolmanager.py
:param str destination_scheme:
    The scheme of the destination. (i.e https, http, etc)

**Param√®tres :**

- `proxy_url`
- `proxy_config`
- `destination_scheme`

##### create_proxy_ssl_context

Generates a default proxy ssl context if one hasn't been provided by the
user.

**Param√®tres :**

- `ssl_version`
- `cert_reqs`
- `ca_certs`
- `ca_cert_dir`
- `ca_cert_data`

---

### queue

#### Classes

##### LifoQueue

**M√©thodes :**

- `_init()`
- `_qsize()`
- `_put()`
- `_get()`

#### Fonctions

##### _init

**Param√®tres :**

- `_`

##### _qsize

**Param√®tres :**

- `len`

##### _put

**Param√®tres :**

- `item`

##### _get

---

### request

#### Fonctions

##### make_headers

Shortcuts for generating request headers.

:param keep_alive:
    If ``True``, adds 'connection: keep-alive' header.

:param accept_encoding:
    Can be a boolean, list, or string.
    ``True`` translates to 'gzip,deflate'.
    List will get joined by comma.
    String will be used as provided.

:param user_agent:
    String representing the user-agent you want, such as
    "python-urllib3/0.6"

:param basic_auth:
    Colon-separated username:password string for 'authorization: basic ...'
    auth header.

:param proxy_basic_auth:
    Colon-separated username:password string for 'proxy-authorization: basic ...'
    auth header.

:param disable_cache:
    If ``True``, adds 'cache-control: no-cache' header.

Example::

    >>> make_headers(keep_alive=True, user_agent="Batman/1.0")
    {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}
    >>> make_headers(accept_encoding=True)
    {'accept-encoding': 'gzip,deflate'}

**Param√®tres :**

- `keep_alive`
- `accept_encoding`
- `user_agent`
- `basic_auth`
- `proxy_basic_auth`
- `disable_cache`

##### set_file_position

If a position is provided, move file to that point.
Otherwise, we'll attempt to record a position for future use.

**Param√®tres :**

- `body`
- `pos`

##### rewind_body

Attempt to rewind body to a certain position.
Primarily used for request redirects and retries.

:param body:
    File-like object that supports seek.

:param int pos:
    Position to seek to in file.

**Param√®tres :**

- `body`
- `body_pos`

---

### .!24457!ssl_

---

### .!24475!url

---

### response

#### Fonctions

##### is_fp_closed

Checks whether a given file-like object is closed.

:param obj:
    The file-like object to check.

**Param√®tres :**

- `obj`

##### assert_header_parsing

Asserts whether all headers have been successfully parsed.
Extracts encountered errors from the result of parsing headers.

Only works on Python 3.

:param http.client.HTTPMessage headers: Headers to verify.

:raises urllib3.exceptions.HeaderParsingError:
    If parsing errors are found.

**Param√®tres :**

- `headers`

##### is_response_to_head

Checks whether the request of a response has been a HEAD-request.
Handles the quirks of AppEngine.

:param http.client.HTTPResponse response:
    Response to check if the originating request
    used 'HEAD' as a method.

**Param√®tres :**

- `response`

---

### .!24480!wait

---

### retry

#### Classes

##### _RetryMeta

**M√©thodes :**

- `DEFAULT_METHOD_WHITELIST()`
- `DEFAULT_METHOD_WHITELIST()`
- `DEFAULT_REDIRECT_HEADERS_BLACKLIST()`
- `DEFAULT_REDIRECT_HEADERS_BLACKLIST()`
- `BACKOFF_MAX()`
- `BACKOFF_MAX()`

##### Retry

Retry configuration.

Each retry attempt will create a new Retry object with updated values, so
they can be safely reused.

Retries can be defined as a default for a pool::

    retries = Retry(connect=5, read=2, redirect=5)
    http = PoolManager(retries=retries)
    response = http.request('GET', 'http://example.com/')

Or per-request (which overrides the default for the pool)::

    response = http.request('GET', 'http://example.com/', retries=Retry(10))

Retries can be disabled by passing ``False``::

    response = http.request('GET', 'http://example.com/', retries=False)

Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless
retries are disabled, in which case the causing exception will be raised.

:param int total:
    Total number of retries to allow. Takes precedence over other counts.

    Set to ``None`` to remove this constraint and fall back on other
    counts.

    Set to ``0`` to fail on the first retry.

    Set to ``False`` to disable and imply ``raise_on_redirect=False``.

:param int connect:
    How many connection-related errors to retry on.

    These are errors raised before the request is sent to the remote server,
    which we assume has not triggered the server to process the request.

    Set to ``0`` to fail on the first retry of this type.

:param int read:
    How many times to retry on read errors.

    These errors are raised after the request was sent to the server, so the
    request may have side-effects.

    Set to ``0`` to fail on the first retry of this type.

:param int redirect:
    How many redirects to perform. Limit this to avoid infinite redirect
    loops.

    A redirect is a HTTP response with a status code 301, 302, 303, 307 or
    308.

    Set to ``0`` to fail on the first retry of this type.

    Set to ``False`` to disable and imply ``raise_on_redirect=False``.

:param int status:
    How many times to retry on bad status codes.

    These are retries made on responses, where status code matches
    ``status_forcelist``.

    Set to ``0`` to fail on the first retry of this type.

:param int other:
    How many times to retry on other errors.

    Other errors are errors that are not connect, read, redirect or status errors.
    These errors might be raised after the request was sent to the server, so the
    request might have side-effects.

    Set to ``0`` to fail on the first retry of this type.

    If ``total`` is not set, it's a good idea to set this to 0 to account
    for unexpected edge cases and avoid infinite retry loops.

:param iterable allowed_methods:
    Set of uppercased HTTP method verbs that we should retry on.

    By default, we only retry on methods which are considered to be
    idempotent (multiple requests with the same parameters end with the
    same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.

    Set to a ``False`` value to retry on any verb.

    .. warning::

        Previously this parameter was named ``method_whitelist``, that
        usage is deprecated in v1.26.0 and will be removed in v2.0.

:param iterable status_forcelist:
    A set of integer HTTP status codes that we should force a retry on.
    A retry is initiated if the request method is in ``allowed_methods``
    and the response status code is in ``status_forcelist``.

    By default, this is disabled with ``None``.

:param float backoff_factor:
    A backoff factor to apply between attempts after the second try
    (most errors are resolved immediately by a second try without a
    delay). urllib3 will sleep for::

        {backoff factor} * (2 ** ({number of total retries} - 1))

    seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep
    for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer
    than :attr:`Retry.DEFAULT_BACKOFF_MAX`.

    By default, backoff is disabled (set to 0).

:param bool raise_on_redirect: Whether, if the number of redirects is
    exhausted, to raise a MaxRetryError, or to return a response with a
    response code in the 3xx range.

:param bool raise_on_status: Similar meaning to ``raise_on_redirect``:
    whether we should raise an exception, or return a response,
    if status falls in ``status_forcelist`` range and retries have
    been exhausted.

:param tuple history: The history of the request encountered during
    each call to :meth:`~Retry.increment`. The list is in the order
    the requests occurred. Each list item is of class :class:`RequestHistory`.

:param bool respect_retry_after_header:
    Whether to respect Retry-After header on status codes defined as
    :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.

:param iterable remove_headers_on_redirect:
    Sequence of headers to remove from the request when a response
    indicating a redirect is returned before firing off the redirected
    request.

**M√©thodes :**

- `__init__()`
- `new()`
- `from_int()`
- `get_backoff_time()`
- `parse_retry_after()`
- `get_retry_after()`
- `sleep_for_retry()`
- `_sleep_backoff()`
- `sleep()`
- `_is_connection_error()`
- `_is_read_error()`
- `_is_method_retryable()`
- `is_retry()`
- `is_exhausted()`
- `increment()`
- `__repr__()`
- `__getattr__()`

#### Fonctions

##### DEFAULT_METHOD_WHITELIST

**Param√®tres :**

- `cls`

##### DEFAULT_METHOD_WHITELIST

**Param√®tres :**

- `cls`
- `value`

##### DEFAULT_REDIRECT_HEADERS_BLACKLIST

**Param√®tres :**

- `cls`

##### DEFAULT_REDIRECT_HEADERS_BLACKLIST

**Param√®tres :**

- `cls`
- `value`

##### BACKOFF_MAX

**Param√®tres :**

- `cls`

##### BACKOFF_MAX

**Param√®tres :**

- `cls`
- `value`

##### __init__

**Param√®tres :**

- `total`
- `connect`
- `read`
- `redirect`
- `status`
- `other`
- `allowed_methods`
- `status_forcelist`
- `backoff_factor`
- `raise_on_redirect`
- `raise_on_status`
- `history`
- `respect_retry_after_header`
- `remove_headers_on_redirect`
- `method_whitelist`

##### new

##### from_int

Backwards-compatibility for the old retries format.

**Param√®tres :**

- `cls`
- `retries`
- `redirect`
- `default`

##### get_backoff_time

Formula for computing the current backoff

:rtype: float

##### parse_retry_after

**Param√®tres :**

- `retry_after`

##### get_retry_after

Get the value of Retry-After in seconds.

**Param√®tres :**

- `response`

##### sleep_for_retry

**Param√®tres :**

- `response`

##### _sleep_backoff

##### sleep

Sleep between retry attempts.

This method will respect a server's ``Retry-After`` response header
and sleep the duration of the time requested. If that is not present, it
will use an exponential backoff. By default, the backoff factor is 0 and
this method will return immediately.

**Param√®tres :**

- `response`

##### _is_connection_error

Errors when we're fairly sure that the server did not receive the
request, so it should be safe to retry.

**Param√®tres :**

- `err`

##### _is_read_error

Errors that occur after the request has been started, so we should
assume that the server began processing it.

**Param√®tres :**

- `err`

##### _is_method_retryable

Checks if a given HTTP method should be retried upon, depending if
it is included in the allowed_methods

**Param√®tres :**

- `method`

##### is_retry

Is this method/status code retryable? (Based on allowlists and control
variables such as the number of total retries to allow, whether to
respect the Retry-After header, whether this header is present, and
whether the returned status code is on the list of status codes to
be retried upon on the presence of the aforementioned header)

**Param√®tres :**

- `method`
- `status_code`
- `has_retry_after`

##### is_exhausted

Are we out of retries?

##### increment

Return a new Retry object with incremented retry counters.

:param response: A response object, or None, if the server did not
    return a response.
:type response: :class:`~urllib3.response.HTTPResponse`
:param Exception error: An error encountered during the request, or
    None if the response was received successfully.

:return: A new ``Retry`` object.

**Param√®tres :**

- `method`
- `url`
- `response`
- `error`
- `_pool`
- `_stacktrace`

##### __repr__

##### __getattr__

**Param√®tres :**

- `item`

---

### ssl_

#### Classes

##### SSLContext

**M√©thodes :**

- `__init__()`
- `load_cert_chain()`
- `load_verify_locations()`
- `set_ciphers()`
- `wrap_socket()`

#### Fonctions

##### _const_compare_digest_backport

Compare two digests of equal length in constant time.

The digests must be of type str/bytes.
Returns True if the digests match, and False otherwise.

**Param√®tres :**

- `a`
- `b`

##### assert_fingerprint

Checks if given fingerprint matches the supplied certificate.

:param cert:
    Certificate as bytes object.
:param fingerprint:
    Fingerprint as string of hexdigits, can be interspersed by colons.

**Param√®tres :**

- `cert`
- `fingerprint`

##### resolve_cert_reqs

Resolves the argument to a numeric constant, which can be passed to
the wrap_socket function/method from the ssl module.
Defaults to :data:`ssl.CERT_REQUIRED`.
If given a string it is assumed to be the name of the constant in the
:mod:`ssl` module or its abbreviation.
(So you can specify `REQUIRED` instead of `CERT_REQUIRED`.
If it's neither `None` nor a string we assume it is already the numeric
constant which can directly be passed to wrap_socket.

**Param√®tres :**

- `candidate`

##### resolve_ssl_version

like resolve_cert_reqs

**Param√®tres :**

- `candidate`

##### create_urllib3_context

All arguments have the same meaning as ``ssl_wrap_socket``.

By default, this function does a lot of the same work that
``ssl.create_default_context`` does on Python 3.4+. It:

- Disables SSLv2, SSLv3, and compression
- Sets a restricted set of server ciphers

If you wish to enable SSLv3, you can do::

    from pip._vendor.urllib3.util import ssl_
    context = ssl_.create_urllib3_context()
    context.options &= ~ssl_.OP_NO_SSLv3

You can do the same to enable compression (substituting ``COMPRESSION``
for ``SSLv3`` in the last line above).

:param ssl_version:
    The desired protocol version to use. This will default to
    PROTOCOL_SSLv23 which will negotiate the highest protocol that both
    the server and your installation of OpenSSL support.
:param cert_reqs:
    Whether to require the certificate verification. This defaults to
    ``ssl.CERT_REQUIRED``.
:param options:
    Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,
    ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``, and ``ssl.OP_NO_TICKET``.
:param ciphers:
    Which cipher suites to allow the server to select.
:returns:
    Constructed SSLContext object with specified options
:rtype: SSLContext

**Param√®tres :**

- `ssl_version`
- `cert_reqs`
- `options`
- `ciphers`

##### ssl_wrap_socket

All arguments except for server_hostname, ssl_context, and ca_cert_dir have
the same meaning as they do when using :func:`ssl.wrap_socket`.

:param server_hostname:
    When SNI is supported, the expected hostname of the certificate
:param ssl_context:
    A pre-made :class:`SSLContext` object. If none is provided, one will
    be created using :func:`create_urllib3_context`.
:param ciphers:
    A string of ciphers we wish the client to support.
:param ca_cert_dir:
    A directory containing CA certificates in multiple separate files, as
    supported by OpenSSL's -CApath flag or the capath argument to
    SSLContext.load_verify_locations().
:param key_password:
    Optional password if the keyfile is encrypted.
:param ca_cert_data:
    Optional string containing CA certificates in PEM format suitable for
    passing as the cadata parameter to SSLContext.load_verify_locations()
:param tls_in_tls:
    Use SSLTransport to wrap the existing socket.

**Param√®tres :**

- `sock`
- `keyfile`
- `certfile`
- `cert_reqs`
- `ca_certs`
- `server_hostname`
- `ssl_version`
- `ciphers`
- `ssl_context`
- `ca_cert_dir`
- `key_password`
- `ca_cert_data`
- `tls_in_tls`

##### is_ipaddress

Detects whether the hostname given is an IPv4 or IPv6 address.
Also detects IPv6 addresses with Zone IDs.

:param str hostname: Hostname to examine.
:return: True if the hostname is an IP address, False otherwise.

**Param√®tres :**

- `hostname`

##### _is_key_file_encrypted

Detects if a key file is encrypted or not.

**Param√®tres :**

- `key_file`

##### _ssl_wrap_socket_impl

**Param√®tres :**

- `sock`
- `ssl_context`
- `tls_in_tls`
- `server_hostname`

##### disable_check_hostname

##### __init__

**Param√®tres :**

- `protocol_version`

##### load_cert_chain

**Param√®tres :**

- `certfile`
- `keyfile`

##### load_verify_locations

**Param√®tres :**

- `cafile`
- `capath`
- `cadata`

##### set_ciphers

**Param√®tres :**

- `cipher_suite`

##### wrap_socket

**Param√®tres :**

- `socket`
- `server_hostname`
- `server_side`

---

### ssl_match_hostname

The match_hostname() function from Python 3.3.3, essential when using SSL.

#### Classes

##### CertificateError

#### Fonctions

##### _dnsname_match

Matching according to RFC 6125, section 6.4.3

http://tools.ietf.org/html/rfc6125#section-6.4.3

**Param√®tres :**

- `dn`
- `hostname`
- `max_wildcards`

##### _to_unicode

**Param√®tres :**

- `obj`

##### _ipaddress_match

Exact matching of IP addresses.

RFC 6125 explicitly doesn't define an algorithm for this
(section 1.7.2 - "Out of Scope").

**Param√®tres :**

- `ipname`
- `host_ip`

##### match_hostname

Verify that *cert* (in decoded format as returned by
SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
rules are followed, but IP addresses are not accepted for *hostname*.

CertificateError is raised on failure. On success, the function
returns nothing.

**Param√®tres :**

- `cert`
- `hostname`

---

### ssltransport

#### Classes

##### SSLTransport

The SSLTransport wraps an existing socket and establishes an SSL connection.

Contrary to Python's implementation of SSLSocket, it allows you to chain
multiple TLS connections together. It's particularly useful if you need to
implement TLS within TLS.

The class supports most of the socket API operations.

**M√©thodes :**

- `_validate_ssl_context_for_tls_in_tls()`
- `__init__()`
- `__enter__()`
- `__exit__()`
- `fileno()`
- `read()`
- `recv()`
- `recv_into()`
- `sendall()`
- `send()`
- `makefile()`
- `unwrap()`
- `close()`
- `getpeercert()`
- `version()`
- `cipher()`
- `selected_alpn_protocol()`
- `selected_npn_protocol()`
- `shared_ciphers()`
- `compression()`
- `settimeout()`
- `gettimeout()`
- `_decref_socketios()`
- `_wrap_ssl_read()`
- `_ssl_io_loop()`

#### Fonctions

##### _validate_ssl_context_for_tls_in_tls

Raises a ProxySchemeUnsupported if the provided ssl_context can't be used
for TLS in TLS.

The only requirement is that the ssl_context provides the 'wrap_bio'
methods.

**Param√®tres :**

- `ssl_context`

##### __init__

Create an SSLTransport around socket using the provided ssl_context.

**Param√®tres :**

- `socket`
- `ssl_context`
- `server_hostname`
- `suppress_ragged_eofs`

##### __enter__

##### __exit__

##### fileno

##### read

**Param√®tres :**

- `len`
- `buffer`

##### recv

**Param√®tres :**

- `len`
- `flags`

##### recv_into

**Param√®tres :**

- `buffer`
- `nbytes`
- `flags`

##### sendall

**Param√®tres :**

- `data`
- `flags`

##### send

**Param√®tres :**

- `data`
- `flags`

##### makefile

Python's httpclient uses makefile and buffered io when reading HTTP
messages and we need to support it.

This is unfortunately a copy and paste of socket.py makefile with small
changes to point to the socket directly.

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `errors`
- `newline`

##### unwrap

##### close

##### getpeercert

**Param√®tres :**

- `binary_form`

##### version

##### cipher

##### selected_alpn_protocol

##### selected_npn_protocol

##### shared_ciphers

##### compression

##### settimeout

**Param√®tres :**

- `value`

##### gettimeout

##### _decref_socketios

##### _wrap_ssl_read

**Param√®tres :**

- `len`
- `buffer`

##### _ssl_io_loop

Performs an I/O loop between incoming/outgoing and the socket.

**Param√®tres :**

- `func`

---

### timeout

#### Classes

##### Timeout

Timeout configuration.

Timeouts can be defined as a default for a pool:

.. code-block:: python

   timeout = Timeout(connect=2.0, read=7.0)
   http = PoolManager(timeout=timeout)
   response = http.request('GET', 'http://example.com/')

Or per-request (which overrides the default for the pool):

.. code-block:: python

   response = http.request('GET', 'http://example.com/', timeout=Timeout(10))

Timeouts can be disabled by setting all the parameters to ``None``:

.. code-block:: python

   no_timeout = Timeout(connect=None, read=None)
   response = http.request('GET', 'http://example.com/, timeout=no_timeout)


:param total:
    This combines the connect and read timeouts into one; the read timeout
    will be set to the time leftover from the connect attempt. In the
    event that both a connect timeout and a total are specified, or a read
    timeout and a total are specified, the shorter timeout will be applied.

    Defaults to None.

:type total: int, float, or None

:param connect:
    The maximum amount of time (in seconds) to wait for a connection
    attempt to a server to succeed. Omitting the parameter will default the
    connect timeout to the system default, probably `the global default
    timeout in socket.py
    <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
    None will set an infinite timeout for connection attempts.

:type connect: int, float, or None

:param read:
    The maximum amount of time (in seconds) to wait between consecutive
    read operations for a response from the server. Omitting the parameter
    will default the read timeout to the system default, probably `the
    global default timeout in socket.py
    <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
    None will set an infinite timeout.

:type read: int, float, or None

.. note::

    Many factors can affect the total amount of time for urllib3 to return
    an HTTP response.

    For example, Python's DNS resolver does not obey the timeout specified
    on the socket. Other factors that can affect total request time include
    high CPU load, high swap, the program running at a low priority level,
    or other behaviors.

    In addition, the read and total timeouts only measure the time between
    read operations on the socket connecting the client and the server,
    not the total amount of time for the request to return a complete
    response. For most requests, the timeout is raised because the server
    has not sent the first byte in the specified time. This is not always
    the case; if a server streams one byte every fifteen seconds, a timeout
    of 20 seconds will not trigger, even though the request will take
    several minutes to complete.

    If your goal is to cut off any request after a set amount of wall clock
    time, consider having a second "watcher" thread to cut off a slow
    request.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `resolve_default_timeout()`
- `_validate_timeout()`
- `from_float()`
- `clone()`
- `start_connect()`
- `get_connect_duration()`
- `connect_timeout()`
- `read_timeout()`

#### Fonctions

##### __init__

**Param√®tres :**

- `total`
- `connect`
- `read`

##### __repr__

##### resolve_default_timeout

**Param√®tres :**

- `cls`
- `timeout`

##### _validate_timeout

Check that a timeout attribute is valid.

:param value: The timeout value to validate
:param name: The name of the timeout attribute to validate. This is
    used to specify in error messages.
:return: The validated and casted version of the given value.
:raises ValueError: If it is a numeric value less than or equal to
    zero, or the type is not an integer, float, or None.

**Param√®tres :**

- `cls`
- `value`
- `name`

##### from_float

Create a new Timeout from a legacy timeout value.

The timeout value used by httplib.py sets the same timeout on the
connect(), and recv() socket requests. This creates a :class:`Timeout`
object that sets the individual timeouts to the ``timeout`` value
passed to this function.

:param timeout: The legacy timeout value.
:type timeout: integer, float, sentinel default object, or None
:return: Timeout object
:rtype: :class:`Timeout`

**Param√®tres :**

- `cls`
- `timeout`

##### clone

Create a copy of the timeout object

Timeout properties are stored per-pool but each request needs a fresh
Timeout object to ensure each one has its own start/stop configured.

:return: a copy of the timeout object
:rtype: :class:`Timeout`

##### start_connect

Start the timeout clock, used during a connect() attempt

:raises urllib3.exceptions.TimeoutStateError: if you attempt
    to start a timer that has been started already.

##### get_connect_duration

Gets the time elapsed since the call to :meth:`start_connect`.

:return: Elapsed time in seconds.
:rtype: float
:raises urllib3.exceptions.TimeoutStateError: if you attempt
    to get duration for a timer that hasn't been started.

##### connect_timeout

Get the value to use when setting a connection timeout.

This will be a positive float or integer, the value None
(never timeout), or the default system timeout.

:return: Connect timeout.
:rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None

##### read_timeout

Get the value for the read timeout.

This assumes some time has elapsed in the connection timeout and
computes the read timeout appropriately.

If self.total is set, the read timeout is dependent on the amount of
time taken by the connect timeout. If the connection time has not been
established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be
raised.

:return: Value to use for the read timeout.
:rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None
:raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`
    has not yet been called on this object.

---

### url

#### Classes

##### Url

Data structure for representing an HTTP URL. Used as a return value for
:func:`parse_url`. Both the scheme and host are normalized as they are
both case-insensitive according to RFC 3986.

**M√©thodes :**

- `__new__()`
- `hostname()`
- `request_uri()`
- `netloc()`
- `url()`
- `__str__()`

#### Fonctions

##### split_first

.. deprecated:: 1.25

Given a string and an iterable of delimiters, split on the first found
delimiter. Return two split parts and the matched delimiter.

If not found, then the first part is the full input string.

Example::

    >>> split_first('foo/bar?baz', '?/=')
    ('foo', 'bar?baz', '/')
    >>> split_first('foo/bar?baz', '123')
    ('foo/bar?baz', '', None)

Scales linearly with number of delims. Not ideal for large number of delims.

**Param√®tres :**

- `s`
- `delims`

##### _encode_invalid_chars

Percent-encodes a URI component without reapplying
onto an already percent-encoded component.

**Param√®tres :**

- `component`
- `allowed_chars`
- `encoding`

##### _remove_path_dot_segments

**Param√®tres :**

- `path`

##### _normalize_host

**Param√®tres :**

- `host`
- `scheme`

##### _idna_encode

**Param√®tres :**

- `name`

##### _encode_target

Percent-encodes a request target so that there are no invalid characters

**Param√®tres :**

- `target`

##### parse_url

Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is
performed to parse incomplete urls. Fields not provided will be None.
This parser is RFC 3986 and RFC 6874 compliant.

The parser logic and helper functions are based heavily on
work done in the ``rfc3986`` module.

:param str url: URL to parse into a :class:`.Url` namedtuple.

Partly backwards-compatible with :mod:`urlparse`.

Example::

    >>> parse_url('http://google.com/mail/')
    Url(scheme='http', host='google.com', port=None, path='/mail/', ...)
    >>> parse_url('google.com:80')
    Url(scheme=None, host='google.com', port=80, path=None, ...)
    >>> parse_url('/foo?bar')
    Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)

**Param√®tres :**

- `url`

##### get_host

Deprecated. Use :func:`parse_url` instead.

**Param√®tres :**

- `url`

##### __new__

**Param√®tres :**

- `cls`
- `scheme`
- `auth`
- `host`
- `port`
- `path`
- `query`
- `fragment`

##### hostname

For backwards-compatibility with urlparse. We're nice like that.

##### request_uri

Absolute path including the query string.

##### netloc

Network location including host and port

##### url

Convert self into a url

This function should more or less round-trip with :func:`.parse_url`. The
returned url may not be exactly the same as the url inputted to
:func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls
with a blank port will have : removed).

Example: ::

    >>> U = parse_url('http://google.com/mail/')
    >>> U.url
    'http://google.com/mail/'
    >>> Url('http', 'username:password', 'host.com', 80,
    ... '/path', 'query', 'fragment').url
    'http://username:password@host.com:80/path?query#fragment'

##### __str__

##### ensure_type

**Param√®tres :**

- `x`

---

### wait

#### Classes

##### NoWayToWaitForSocketError

#### Fonctions

##### select_wait_for_socket

**Param√®tres :**

- `sock`
- `read`
- `write`
- `timeout`

##### poll_wait_for_socket

**Param√®tres :**

- `sock`
- `read`
- `write`
- `timeout`

##### null_wait_for_socket

##### _have_working_poll

##### wait_for_socket

##### wait_for_read

Waits for reading to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired.

**Param√®tres :**

- `sock`
- `timeout`

##### wait_for_write

Waits for writing to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired.

**Param√®tres :**

- `sock`
- `timeout`

##### _retry_on_intr

**Param√®tres :**

- `fn`
- `timeout`

##### _retry_on_intr

**Param√®tres :**

- `fn`
- `timeout`

##### do_poll

**Param√®tres :**

- `t`

---

### .!24424!__init__

---

### .!24428!connection

---

### .!24436!proxy

---

### .!24439!queue

---

### .!24443!request

---

### .!24447!response

---

### .!24453!retry

---

### .!24463!ssl_match_hostname

---

### .!24466!ssltransport

---

### .!24470!timeout

---

### .!24508!util

---

### .!24484!__init__

---

### .!24490!_meta

---

### .!24495!gitignore

---

### .!24500!pathspec

---

### .!24504!pattern

---

### .!24512!__init__

---

### .!24517!gitwildmatch

---

### .!24534!lazy

---

### .!24524!__init__

---

### .!24529!exceptions

---

### .!24537!reference

---

### .!24540!tzfile

---

### .!24545!tzinfo

---

### .!24588!midi

---

### .!24552!surfarray

---

### .!24557!sysfont

---

### .!24561!_camera_vidcapture

---

### .!24566!sndarray

---

### .!24570!version

---

### .!24574!draw_py

---

### .!24578!colordict

---

### .!24585!ftfont

---

### .!24593!cursors

---

### .!24597!__init__

---

### .!24603!sprite

---

### .!24606!macosx

---

### .!24611!camera

---

### .!24614!freetype

---

### .!24618!pkgdata

---

### .!24624!fastevent

---

### .!24627!_camera_opencv

---

### .!24632!locals

---

### .!24637!__init__

---

### .!24642!hook-pygame

---

### .!24648!base_test

---

### .!24653!font_test

---

### .!24657!mixer_test

---

### .!24663!rwobject_test

---

### .!24667!pixelcopy_test

---

### .!24672!video_test

---

### .!24676!scrap_test

---

### .!24680!imageext_tags

---

### .!24686!pixelarray_test

---

### .!24693!draw_test

---

### .!24698!transform_test

---

### .!24703!blit_test

---

### .!24707!bufferproxy_test

---

### .!24714!surfarray_test

---

### .!24717!mouse_test

---

### .!24722!surfarray_tags

---

### .!24726!controller_test

---

### .!24730!event_test

---

### .!24735!imageext_test

---

### .!24739!sprite_test

---

### .!24745!touch_test

---

### .!24748!gfxdraw_test

---

### .!24755!rect_test

---

### .!24761!scrap_tags

---

### .!24766!__init__

---

### .!24770!color_test

---

### .!24776!camera_test

---

### .!24781!surflock_test

---

### .!24786!key_test

---

### .!24790!sysfont_test

---

### .!24796!mixer_tags

---

### .!24799!constants_test

---

### .!24805!mixer_music_tags

---

### .!24809!sndarray_test

---

### .!24814!image_test

---

### .!24818!version_test

---

### .!24823!freetype_test

---

### .!24827!joystick_test

---

### .!24834!docs_test

---

### .!24837!ftfont_tags

---

### .!24846!image__save_gl_surface_test

---

### .!24849!cursors_test

---

### .!24852!display_test

---

### .!24856!ftfont_test

---

### .!24860!mask_test

---

### .!24865!midi_test

---

### .!24870!freetype_tags

---

### .!24875!math_test

---

### .!24878!time_test

---

### .!24885!image_tags

---

### .!24887!threads_test

---

### .!24893!locals_test

---

### .!24896!__main__

---

### .!24900!mixer_music_test

---

### .!24905!sndarray_tags

---

### .!24911!surface_test

---

### .!24933!png

---

### .!24916!run_tests

---

### .!24920!endian

---

### .!24924!test_machinery

---

### .!24929!__init__

---

### .!24939!test_runner

---

### .!24945!arrinter

---

### .!24950!buftools

---

### .!24954!async_sub

---

### .!24962!run_tests__test

---

### .!24965!__init__

---

### .!24972!fake_3_test

---

### .!24977!fake_2_test

---

### .!24982!__init__

---

### .!24988!fake_4_test

---

### .!24995!fake_3_test

---

### .!24999!fake_2_test

---

### .!25004!__init__

---

### .!25010!fake_4_test

---

### .!25014!fake_2_test

---

### .!25019!fake_1_test

---

### .!25024!__init__

---

### .!25030!fake_3_test

---

### .!25035!fake_2_test

---

### .!25039!__init__

---

### .!25043!magic_tag_test

---

### .!25048!fake_2_test

---

### .!25053!__init__

---

### .!25057!invisible_tag_test

---

### .!25063!fake_3_test

---

### .!25069!fake_2_test

---

### .!25073!__init__

---

### .!25078!sleep_test

---

### .!25082!magic_tag_test

---

### .!25087!fake_2_test

---

### .!25091!incomplete_todo_test

---

### .!25096!__init__

---

### .!25100!sleep_test

---

### .!25107!fake_2_test

---

### .!25113!__init__

---

### .!25117!fake_3_test

---

### .!25121!fake_2_test

---

### .!25126!__init__

---

### .!25131!fake_4_test

---

### .!25138!fake_3_test

---

### .!25144!fake_2_test

---

### .!25148!__init__

---

### .!25154!fake_4_test

---

### .!25158!fake_5_test

---

### .!25162!no_assertions__ret_code_of_1__test

---

### .!25167!zero_tests_test

---

### .!25172!fake_6_test

---

### .!25179!__main__

---

### .!25186!__init__

---

### .!25196!mask

---

### .!25204!grid

---

### .!25242!midi

---

### .!25270!blit_blends

---

### .!25191!playmus

---

### .!25200!sound

---

### .!25211!aacircle

---

### .!25213!setmodescale

---

### .!25219!chimp

---

### .!25223!font_viewer

---

### .!25228!liquid

---

### .!25233!audiocapture

---

### .!25239!sound_array_demos

---

### .!25247!scroll

---

### .!25253!cursors

---

### .!25259!moveit

---

### .!25276!sprite_texture

---

### .!25280!testsprite

---

### .!25285!textinput

---

### .!25288!go_over_there

---

### .!25296!vgrade

---

### .!25300!arraydemo

---

### .!25305!stars

---

### .!25311!camera

---

### .!25315!joystick

---

### .!25320!blend_fill

---

### .!25325!fonty

---

### .!25330!headless_no_windows_needed

---

### .!25338!glcube

---

### .!25342!resizing_new

---

### .!25347!aliens

---

### .!25352!freetype_misc

---

### .!25357!scaletest

---

### .!25360!music_drop_fade

---

### .!25367!eventlist

---

### .!25374!video

---

### .!25380!scrap_clipboard

---

### .!25385!pixelarray

---

### .!25391!dropevent

---

### .!25396!__init__

---

### _base_connection

#### Classes

##### ProxyConfig

##### _ResponseOptions

##### BaseHTTPConnection

**M√©thodes :**

- `__init__()`
- `set_tunnel()`
- `connect()`
- `request()`
- `getresponse()`
- `close()`
- `is_closed()`
- `is_connected()`
- `has_connected_to_proxy()`

##### BaseHTTPSConnection

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `host`
- `port`

##### set_tunnel

**Param√®tres :**

- `host`
- `port`
- `headers`
- `scheme`

##### connect

##### request

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`

##### getresponse

##### close

##### is_closed

Whether the connection either is brand new or has been previously closed.
If this property is True then both ``is_connected`` and ``has_connected_to_proxy``
properties must be False.

##### is_connected

Whether the connection is actively connected to any origin (proxy or target)

##### has_connected_to_proxy

Whether the connection has successfully connected to its proxy.
This returns False if no proxy is in use. Used to determine whether
errors are coming from the proxy layer or from tunnelling to the target origin.

##### __init__

**Param√®tres :**

- `host`
- `port`

---

### _collections

#### Classes

##### _Sentinel

##### RecentlyUsedContainer

Provides a thread-safe dict-like container which maintains up to
``maxsize`` keys while throwing away the least-recently-used keys beyond
``maxsize``.

:param maxsize:
    Maximum number of recent elements to retain.

:param dispose_func:
    Every time an item is evicted from the container,
    ``dispose_func(value)`` is called.  Callback which will get called

**M√©thodes :**

- `__init__()`
- `__getitem__()`
- `__setitem__()`
- `__delitem__()`
- `__len__()`
- `__iter__()`
- `clear()`
- `keys()`

##### HTTPHeaderDictItemView

HTTPHeaderDict is unusual for a Mapping[str, str] in that it has two modes of
address.

If we directly try to get an item with a particular name, we will get a string
back that is the concatenated version of all the values:

>>> d['X-Header-Name']
'Value1, Value2, Value3'

However, if we iterate over an HTTPHeaderDict's items, we will optionally combine
these values based on whether combine=True was called when building up the dictionary

>>> d = HTTPHeaderDict({"A": "1", "B": "foo"})
>>> d.add("A", "2", combine=True)
>>> d.add("B", "bar")
>>> list(d.items())
[
    ('A', '1, 2'),
    ('B', 'foo'),
    ('B', 'bar'),
]

This class conforms to the interface required by the MutableMapping ABC while
also giving us the nonstandard iteration behavior we want; items with duplicate
keys, ordered by time of first insertion.

**M√©thodes :**

- `__init__()`
- `__len__()`
- `__iter__()`
- `__contains__()`

##### HTTPHeaderDict

:param headers:
    An iterable of field-value pairs. Must not contain multiple field names
    when compared case-insensitively.

:param kwargs:
    Additional field-value pairs to pass in to ``dict.update``.

A ``dict`` like container for storing HTTP Headers.

Field names are stored and compared case-insensitively in compliance with
RFC 7230. Iteration provides the first case-sensitive key seen for each
case-insensitive pair.

Using ``__setitem__`` syntax overwrites fields that compare equal
case-insensitively in order to maintain ``dict``'s api. For fields that
compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
in a loop.

If multiple fields that are equal case-insensitively are passed to the
constructor or ``.update``, the behavior is undefined and some will be
lost.

>>> headers = HTTPHeaderDict()
>>> headers.add('Set-Cookie', 'foo=bar')
>>> headers.add('set-cookie', 'baz=quxx')
>>> headers['content-length'] = '7'
>>> headers['SET-cookie']
'foo=bar, baz=quxx'
>>> headers['Content-Length']
'7'

**M√©thodes :**

- `__init__()`
- `__setitem__()`
- `__getitem__()`
- `__delitem__()`
- `__contains__()`
- `setdefault()`
- `__eq__()`
- `__ne__()`
- `__len__()`
- `__iter__()`
- `discard()`
- `add()`
- `extend()`
- `getlist()`
- `getlist()`
- `getlist()`
- `_prepare_for_method_change()`
- `__repr__()`
- `_copy_from()`
- `copy()`
- `iteritems()`
- `itermerged()`
- `items()`
- `_has_value_for_header()`
- `__ior__()`
- `__or__()`
- `__ror__()`

##### HasGettableStringKeys

**M√©thodes :**

- `keys()`
- `__getitem__()`

#### Fonctions

##### ensure_can_construct_http_header_dict

**Param√®tres :**

- `potential`

##### __init__

**Param√®tres :**

- `maxsize`
- `dispose_func`

##### __getitem__

**Param√®tres :**

- `key`

##### __setitem__

**Param√®tres :**

- `key`
- `value`

##### __delitem__

**Param√®tres :**

- `key`

##### __len__

##### __iter__

##### clear

##### keys

##### __init__

**Param√®tres :**

- `headers`

##### __len__

##### __iter__

##### __contains__

**Param√®tres :**

- `item`

##### __init__

**Param√®tres :**

- `headers`

##### __setitem__

**Param√®tres :**

- `key`
- `val`

##### __getitem__

**Param√®tres :**

- `key`

##### __delitem__

**Param√®tres :**

- `key`

##### __contains__

**Param√®tres :**

- `key`

##### setdefault

**Param√®tres :**

- `key`
- `default`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __len__

##### __iter__

##### discard

**Param√®tres :**

- `key`

##### add

Adds a (name, value) pair, doesn't overwrite the value if it already
exists.

If this is called with combine=True, instead of adding a new header value
as a distinct item during iteration, this will instead append the value to
any existing header value with a comma. If no existing header value exists
for the key, then the value will simply be added, ignoring the combine parameter.

>>> headers = HTTPHeaderDict(foo='bar')
>>> headers.add('Foo', 'baz')
>>> headers['foo']
'bar, baz'
>>> list(headers.items())
[('foo', 'bar'), ('foo', 'baz')]
>>> headers.add('foo', 'quz', combine=True)
>>> list(headers.items())
[('foo', 'bar, baz, quz')]

**Param√®tres :**

- `key`
- `val`

##### extend

Generic import function for any type of header-like object.
Adapted version of MutableMapping.update in order to insert items
with self.add instead of self.__setitem__

##### getlist

**Param√®tres :**

- `key`

##### getlist

**Param√®tres :**

- `key`
- `default`

##### getlist

Returns a list of all the values for the named field. Returns an
empty list if the key doesn't exist.

**Param√®tres :**

- `key`
- `default`

##### _prepare_for_method_change

Remove content-specific header fields before changing the request
method to GET or HEAD according to RFC 9110, Section 15.4.

##### __repr__

##### _copy_from

**Param√®tres :**

- `other`

##### copy

##### iteritems

Iterate over all header lines, including duplicate ones.

##### itermerged

Iterate over all headers, merging duplicate ones together.

##### items

##### _has_value_for_header

**Param√®tres :**

- `header_name`
- `potential_value`

##### __ior__

**Param√®tres :**

- `other`

##### __or__

**Param√®tres :**

- `other`

##### __ror__

**Param√®tres :**

- `other`

##### keys

##### __getitem__

**Param√®tres :**

- `key`

---

### _request_methods

#### Classes

##### RequestMethods

Convenience mixin for classes who implement a :meth:`urlopen` method, such
as :class:`urllib3.HTTPConnectionPool` and
:class:`urllib3.PoolManager`.

Provides behavior for making common types of HTTP request methods and
decides which type of request field encoding to use.

Specifically,

:meth:`.request_encode_url` is for sending requests whose fields are
encoded in the URL (such as GET, HEAD, DELETE).

:meth:`.request_encode_body` is for sending requests whose fields are
encoded in the *body* of the request using multipart or www-form-urlencoded
(such as for POST, PUT, PATCH).

:meth:`.request` is for making any kind of request, it will look up the
appropriate encoding format and use one of the above two methods to make
the request.

Initializer parameters:

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

**M√©thodes :**

- `__init__()`
- `urlopen()`
- `request()`
- `request_encode_url()`
- `request_encode_body()`

#### Fonctions

##### __init__

**Param√®tres :**

- `headers`

##### urlopen

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`
- `encode_multipart`
- `multipart_boundary`

##### request

Make a request using :meth:`urlopen` with the appropriate encoding of
``fields`` based on the ``method`` used.

This is a convenience method that requires the least amount of manual
effort. It can be used in most situations, while still having the
option to drop down to more specific methods when necessary, such as
:meth:`request_encode_url`, :meth:`request_encode_body`,
or even the lowest level :meth:`urlopen`.

:param method:
    HTTP request method (such as GET, POST, PUT, etc.)

:param url:
    The URL to perform the request on.

:param body:
    Data to send in the request body, either :class:`str`, :class:`bytes`,
    an iterable of :class:`str`/:class:`bytes`, or a file-like object.

:param fields:
    Data to encode and send in the URL or request body, depending on ``method``.

:param headers:
    Dictionary of custom headers to send, such as User-Agent,
    If-None-Match, etc. If None, pool headers are used. If provided,
    these headers completely replace any pool-specific headers.

:param json:
    Data to encode and send as JSON with UTF-encoded in the request body.
    The ``"Content-Type"`` header will be set to ``"application/json"``
    unless specified otherwise.

**Param√®tres :**

- `method`
- `url`
- `body`
- `fields`
- `headers`
- `json`

##### request_encode_url

Make a request using :meth:`urlopen` with the ``fields`` encoded in
the url. This is useful for request methods like GET, HEAD, DELETE, etc.

:param method:
    HTTP request method (such as GET, POST, PUT, etc.)

:param url:
    The URL to perform the request on.

:param fields:
    Data to encode and send in the URL.

:param headers:
    Dictionary of custom headers to send, such as User-Agent,
    If-None-Match, etc. If None, pool headers are used. If provided,
    these headers completely replace any pool-specific headers.

**Param√®tres :**

- `method`
- `url`
- `fields`
- `headers`

##### request_encode_body

Make a request using :meth:`urlopen` with the ``fields`` encoded in
the body. This is useful for request methods like POST, PUT, PATCH, etc.

When ``encode_multipart=True`` (default), then
:func:`urllib3.encode_multipart_formdata` is used to encode
the payload with the appropriate content type. Otherwise
:func:`urllib.parse.urlencode` is used with the
'application/x-www-form-urlencoded' content type.

Multipart encoding must be used when posting files, and it's reasonably
safe to use it in other times too. However, it may break request
signing, such as with OAuth.

Supports an optional ``fields`` parameter of key/value strings AND
key/filetuple. A filetuple is a (filename, data, MIME type) tuple where
the MIME type is optional. For example::

    fields = {
        'foo': 'bar',
        'fakefile': ('foofile.txt', 'contents of foofile'),
        'realfile': ('barfile.txt', open('realfile').read()),
        'typedfile': ('bazfile.bin', open('bazfile').read(),
                      'image/jpeg'),
        'nonamefile': 'contents of nonamefile field',
    }

When uploading a file, providing a filename (the first parameter of the
tuple) is optional but recommended to best mimic behavior of browsers.

Note that if ``headers`` are supplied, the 'Content-Type' header will
be overwritten because it depends on the dynamic random boundary string
which is used to compose the body of the request. The random boundary
string can be explicitly set with the ``multipart_boundary`` parameter.

:param method:
    HTTP request method (such as GET, POST, PUT, etc.)

:param url:
    The URL to perform the request on.

:param fields:
    Data to encode and send in the request body.

:param headers:
    Dictionary of custom headers to send, such as User-Agent,
    If-None-Match, etc. If None, pool headers are used. If provided,
    these headers completely replace any pool-specific headers.

:param encode_multipart:
    If True, encode the ``fields`` using the multipart/form-data MIME
    format.

:param multipart_boundary:
    If not specified, then a random boundary will be generated using
    :func:`urllib3.filepost.choose_boundary`.

**Param√®tres :**

- `method`
- `url`
- `fields`
- `headers`
- `encode_multipart`
- `multipart_boundary`

---

### _version

---

### connection

#### Classes

##### HTTPConnection

Based on :class:`http.client.HTTPConnection` but provides an extra constructor
backwards-compatibility layer between older and newer Pythons.

Additional keyword parameters are used to configure attributes of the connection.
Accepted parameters include:

- ``source_address``: Set the source address for the current connection.
- ``socket_options``: Set specific options on the underlying socket. If not specified, then
  defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
  Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

  For example, if you wish to enable TCP Keep Alive in addition to the defaults,
  you might pass:

  .. code-block:: python

     HTTPConnection.default_socket_options + [
         (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
     ]

  Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).

**M√©thodes :**

- `__init__()`
- `host()`
- `host()`
- `_new_conn()`
- `set_tunnel()`
- `connect()`
- `is_closed()`
- `is_connected()`
- `has_connected_to_proxy()`
- `proxy_is_forwarding()`
- `proxy_is_tunneling()`
- `close()`
- `putrequest()`
- `putheader()`
- `request()`
- `request_chunked()`
- `getresponse()`

##### HTTPSConnection

Many of the parameters to this constructor are passed to the underlying SSL
socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.

**M√©thodes :**

- `__init__()`
- `set_cert()`
- `connect()`
- `_connect_tls_proxy()`

##### _WrappedAndVerifiedSocket

Wrapped socket and whether the connection is
verified after the TLS handshake

##### DummyConnection

Used to detect a failed ConnectionCls import.

##### BaseSSLError

#### Fonctions

##### _ssl_wrap_socket_and_match_hostname

Logic for constructing an SSLContext from all TLS parameters, passing
that down into ssl_wrap_socket, and then doing certificate verification
either via hostname or fingerprint. This function exists to guarantee
that both proxies and targets have the same behavior when connecting via TLS.

**Param√®tres :**

- `sock`

##### _match_hostname

**Param√®tres :**

- `cert`
- `asserted_hostname`
- `hostname_checks_common_name`

##### _wrap_proxy_error

**Param√®tres :**

- `err`
- `proxy_scheme`

##### _get_default_user_agent

##### _url_from_connection

Returns the URL from a given connection. This is mainly used for testing and logging.

**Param√®tres :**

- `conn`
- `path`

##### __init__

**Param√®tres :**

- `host`
- `port`

##### host

Getter method to remove any trailing dots that indicate the hostname is an FQDN.

In general, SSL certificates don't include the trailing dot indicating a
fully-qualified domain name, and thus, they don't validate properly when
checked against a domain name that includes the dot. In addition, some
servers may not expect to receive the trailing dot when provided.

However, the hostname with trailing dot is critical to DNS resolution; doing a
lookup with the trailing dot will properly only resolve the appropriate FQDN,
whereas a lookup without a trailing dot will search the system's search domain
list. Thus, it's important to keep the original host around for use only in
those cases where it's appropriate (i.e., when doing DNS lookup to establish the
actual TCP connection across which we're going to send HTTP requests).

##### host

Setter for the `host` property.

We assume that only urllib3 uses the _dns_host attribute; httplib itself
only uses `host`, and it seems reasonable that other libraries follow suit.

**Param√®tres :**

- `value`

##### _new_conn

Establish a socket connection and set nodelay settings on it.

:return: New socket connection.

##### set_tunnel

**Param√®tres :**

- `host`
- `port`
- `headers`
- `scheme`

##### connect

##### is_closed

##### is_connected

##### has_connected_to_proxy

##### proxy_is_forwarding

Return True if a forwarding proxy is configured, else return False

##### proxy_is_tunneling

Return True if a tunneling proxy is configured, else return False

##### close

##### putrequest

**Param√®tres :**

- `method`
- `url`
- `skip_host`
- `skip_accept_encoding`

##### putheader

**Param√®tres :**

- `header`

##### request

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`

##### request_chunked

Alternative to the common request method, which sends the
body with chunked encoding and not as one block

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`

##### getresponse

Get the response from the server.

If the HTTPConnection is in the correct state, returns an instance of HTTPResponse or of whatever object is returned by the response_class variable.

If a request has not been sent or if a previous response has not be handled, ResponseNotReady is raised. If the HTTP response indicates that the connection should be closed, then it will be closed before the response is returned. When the connection is closed, the underlying socket is closed.

##### __init__

**Param√®tres :**

- `host`
- `port`

##### set_cert

This method should only be called once, before the connection is used.

**Param√®tres :**

- `key_file`
- `cert_file`
- `cert_reqs`
- `key_password`
- `ca_certs`
- `assert_hostname`
- `assert_fingerprint`
- `ca_cert_dir`
- `ca_cert_data`

##### connect

##### _connect_tls_proxy

Establish a TLS connection to the proxy using the provided SSL context.

**Param√®tres :**

- `hostname`
- `sock`

##### _wrap_ipv6

**Param√®tres :**

- `ip`

##### _tunnel

##### _tunnel

---

### connectionpool

#### Classes

##### ConnectionPool

Base class for all connection pools, such as
:class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

.. note::
   ConnectionPool.urlopen() does not normalize or percent-encode target URIs
   which is useful if your target server doesn't support percent-encoded
   target URIs.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__enter__()`
- `__exit__()`
- `close()`

##### HTTPConnectionPool

Thread-safe connection pool for one host.

:param host:
    Host used for this HTTP Connection (e.g. "localhost"), passed into
    :class:`http.client.HTTPConnection`.

:param port:
    Port used for this HTTP Connection (None is equivalent to 80), passed
    into :class:`http.client.HTTPConnection`.

:param timeout:
    Socket timeout in seconds for each individual connection. This can
    be a float or integer, which sets the timeout for the HTTP request,
    or an instance of :class:`urllib3.util.Timeout` which gives you more
    fine-grained control over request timeouts. After the constructor has
    been parsed, this is always a `urllib3.util.Timeout` object.

:param maxsize:
    Number of connections to save that can be reused. More than 1 is useful
    in multithreaded situations. If ``block`` is set to False, more
    connections will be created but they will not be saved once they've
    been used.

:param block:
    If set to True, no more than ``maxsize`` connections will be used at
    a time. When no free connections are available, the call will block
    until a connection has been released. This is a useful side effect for
    particular multithreaded situations where one does not want to use more
    than maxsize connections per host to prevent flooding.

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

:param retries:
    Retry configuration to use by default with requests in this pool.

:param _proxy:
    Parsed proxy URL, should not be used directly, instead, see
    :class:`urllib3.ProxyManager`

:param _proxy_headers:
    A dictionary with proxy headers, should not be used directly,
    instead, see :class:`urllib3.ProxyManager`

:param \**conn_kw:
    Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
    :class:`urllib3.connection.HTTPSConnection` instances.

**M√©thodes :**

- `__init__()`
- `_new_conn()`
- `_get_conn()`
- `_put_conn()`
- `_validate_conn()`
- `_prepare_proxy()`
- `_get_timeout()`
- `_raise_timeout()`
- `_make_request()`
- `close()`
- `is_same_host()`
- `urlopen()`

##### HTTPSConnectionPool

Same as :class:`.HTTPConnectionPool`, but HTTPS.

:class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
``assert_hostname`` and ``host`` in this order to verify connections.
If ``assert_hostname`` is False, no verification is done.

The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
the connection socket into an SSL socket.

**M√©thodes :**

- `__init__()`
- `_prepare_proxy()`
- `_new_conn()`
- `_validate_conn()`

#### Fonctions

##### connection_from_url

Given a url, return an :class:`.ConnectionPool` instance of its host.

This is a shortcut for not having to parse out the scheme, host, and port
of the url before creating an :class:`.ConnectionPool` instance.

:param url:
    Absolute URL string that must include the scheme. Port is optional.

:param \**kw:
    Passes additional parameters to the constructor of the appropriate
    :class:`.ConnectionPool`. Useful for specifying things like
    timeout, maxsize, headers, etc.

Example::

    >>> conn = connection_from_url('http://google.com/')
    >>> r = conn.request('GET', '/')

**Param√®tres :**

- `url`

##### _normalize_host

**Param√®tres :**

- `host`
- `scheme`

##### _normalize_host

**Param√®tres :**

- `host`
- `scheme`

##### _normalize_host

Normalize hosts for comparisons and use with sockets.

**Param√®tres :**

- `host`
- `scheme`

##### _url_from_pool

Returns the URL from a given connection pool. This is mainly used for testing and logging.

**Param√®tres :**

- `pool`
- `path`

##### _close_pool_connections

Drains a queue of connections and closes each one.

**Param√®tres :**

- `pool`

##### __init__

**Param√®tres :**

- `host`
- `port`

##### __str__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### close

Close all pooled connections and disable the pool.

##### __init__

**Param√®tres :**

- `host`
- `port`
- `timeout`
- `maxsize`
- `block`
- `headers`
- `retries`
- `_proxy`
- `_proxy_headers`
- `_proxy_config`

##### _new_conn

Return a fresh :class:`HTTPConnection`.

##### _get_conn

Get a connection. Will return a pooled connection if one is available.

If no connections are available and :prop:`.block` is ``False``, then a
fresh connection is returned.

:param timeout:
    Seconds to wait before giving up and raising
    :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
    :prop:`.block` is ``True``.

**Param√®tres :**

- `timeout`

##### _put_conn

Put a connection back into the pool.

:param conn:
    Connection object for the current host and port as returned by
    :meth:`._new_conn` or :meth:`._get_conn`.

If the pool is already full, the connection is closed and discarded
because we exceeded maxsize. If connections are discarded frequently,
then maxsize should be increased.

If the pool is closed, then the connection will be closed and discarded.

**Param√®tres :**

- `conn`

##### _validate_conn

Called right before a request is made, after the socket is created.

**Param√®tres :**

- `conn`

##### _prepare_proxy

**Param√®tres :**

- `conn`

##### _get_timeout

Helper that always returns a :class:`urllib3.util.Timeout`

**Param√®tres :**

- `timeout`

##### _raise_timeout

Is the error actually a timeout? Will raise a ReadTimeout or pass

**Param√®tres :**

- `err`
- `url`
- `timeout_value`

##### _make_request

Perform a request on a given urllib connection object taken from our
pool.

:param conn:
    a connection from one of our connection pools

:param method:
    HTTP request method (such as GET, POST, PUT, etc.)

:param url:
    The URL to perform the request on.

:param body:
    Data to send in the request body, either :class:`str`, :class:`bytes`,
    an iterable of :class:`str`/:class:`bytes`, or a file-like object.

:param headers:
    Dictionary of custom headers to send, such as User-Agent,
    If-None-Match, etc. If None, pool headers are used. If provided,
    these headers completely replace any pool-specific headers.

:param retries:
    Configure the number of retries to allow before raising a
    :class:`~urllib3.exceptions.MaxRetryError` exception.

    Pass ``None`` to retry until you receive a response. Pass a
    :class:`~urllib3.util.retry.Retry` object for fine-grained control
    over different types of retries.
    Pass an integer number to retry connection errors that many times,
    but no other types of errors. Pass zero to never retry.

    If ``False``, then retries are disabled and any exception is raised
    immediately. Also, instead of raising a MaxRetryError on redirects,
    the redirect response will be returned.

:type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

:param timeout:
    If specified, overrides the default timeout for this one
    request. It may be a float (in seconds) or an instance of
    :class:`urllib3.util.Timeout`.

:param chunked:
    If True, urllib3 will send the body using chunked transfer
    encoding. Otherwise, urllib3 will send the body using the standard
    content-length form. Defaults to False.

:param response_conn:
    Set this to ``None`` if you will handle releasing the connection or
    set the connection to have the response release it.

:param preload_content:
  If True, the response's body will be preloaded during construction.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param enforce_content_length:
    Enforce content length checking. Body returned by server must match
    value of Content-Length header, if present. Otherwise, raise error.

**Param√®tres :**

- `conn`
- `method`
- `url`
- `body`
- `headers`
- `retries`
- `timeout`
- `chunked`
- `response_conn`
- `preload_content`
- `decode_content`
- `enforce_content_length`

##### close

Close all pooled connections and disable the pool.

##### is_same_host

Check if the given ``url`` is a member of the same host as this
connection pool.

**Param√®tres :**

- `url`

##### urlopen

Get a connection from the pool and perform an HTTP request. This is the
lowest level call for making a request, so you'll need to specify all
the raw details.

.. note::

   More commonly, it's appropriate to use a convenience method
   such as :meth:`request`.

.. note::

   `release_conn` will only behave as expected if
   `preload_content=False` because we want to make
   `preload_content=False` the default behaviour someday soon without
   breaking backwards compatibility.

:param method:
    HTTP request method (such as GET, POST, PUT, etc.)

:param url:
    The URL to perform the request on.

:param body:
    Data to send in the request body, either :class:`str`, :class:`bytes`,
    an iterable of :class:`str`/:class:`bytes`, or a file-like object.

:param headers:
    Dictionary of custom headers to send, such as User-Agent,
    If-None-Match, etc. If None, pool headers are used. If provided,
    these headers completely replace any pool-specific headers.

:param retries:
    Configure the number of retries to allow before raising a
    :class:`~urllib3.exceptions.MaxRetryError` exception.

    If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
    :class:`~urllib3.util.retry.Retry` object for fine-grained control
    over different types of retries.
    Pass an integer number to retry connection errors that many times,
    but no other types of errors. Pass zero to never retry.

    If ``False``, then retries are disabled and any exception is raised
    immediately. Also, instead of raising a MaxRetryError on redirects,
    the redirect response will be returned.

:type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

:param redirect:
    If True, automatically handle redirects (status codes 301, 302,
    303, 307, 308). Each redirect counts as a retry. Disabling retries
    will disable redirect, too.

:param assert_same_host:
    If ``True``, will make sure that the host of the pool requests is
    consistent else will raise HostChangedError. When ``False``, you can
    use the pool on an HTTP proxy and request foreign hosts.

:param timeout:
    If specified, overrides the default timeout for this one
    request. It may be a float (in seconds) or an instance of
    :class:`urllib3.util.Timeout`.

:param pool_timeout:
    If set and the pool is set to block=True, then this method will
    block for ``pool_timeout`` seconds and raise EmptyPoolError if no
    connection is available within the time period.

:param bool preload_content:
    If True, the response's body will be preloaded into memory.

:param bool decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param release_conn:
    If False, then the urlopen call will not release the connection
    back into the pool once a response is received (but will release if
    you read the entire contents of the response such as when
    `preload_content=True`). This is useful if you're not preloading
    the response's content immediately. You will need to call
    ``r.release_conn()`` on the response ``r`` to return the connection
    back into the pool. If None, it takes the value of ``preload_content``
    which defaults to ``True``.

:param bool chunked:
    If True, urllib3 will send the body using chunked transfer
    encoding. Otherwise, urllib3 will send the body using the standard
    content-length form. Defaults to False.

:param int body_pos:
    Position to seek to in file-like body in the event of a retry or
    redirect. Typically this won't need to be set because urllib3 will
    auto-populate the value when needed.

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`
- `retries`
- `redirect`
- `assert_same_host`
- `timeout`
- `pool_timeout`
- `release_conn`
- `chunked`
- `body_pos`
- `preload_content`
- `decode_content`

##### __init__

**Param√®tres :**

- `host`
- `port`
- `timeout`
- `maxsize`
- `block`
- `headers`
- `retries`
- `_proxy`
- `_proxy_headers`
- `key_file`
- `cert_file`
- `cert_reqs`
- `key_password`
- `ca_certs`
- `ssl_version`
- `ssl_minimum_version`
- `ssl_maximum_version`
- `assert_hostname`
- `assert_fingerprint`
- `ca_cert_dir`

##### _prepare_proxy

Establishes a tunnel connection through HTTP CONNECT.

**Param√®tres :**

- `conn`

##### _new_conn

Return a fresh :class:`urllib3.connection.HTTPConnection`.

##### _validate_conn

Called right before a request is made, after the socket is created.

**Param√®tres :**

- `conn`

---

### exceptions

#### Classes

##### HTTPError

Base exception used by this module.

##### HTTPWarning

Base warning used by this module.

##### PoolError

Base exception for errors caused within a pool.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### RequestError

Base exception for PoolErrors that have associated URLs.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### SSLError

Raised when SSL certificate fails in an HTTPS connection.

##### ProxyError

Raised when the connection to a proxy fails.

**M√©thodes :**

- `__init__()`

##### DecodeError

Raised when automatic decoding based on Content-Type fails.

##### ProtocolError

Raised when something unexpected happens mid-request/response.

##### MaxRetryError

Raised when the maximum number of retries is exceeded.

:param pool: The connection pool
:type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`
:param str url: The requested Url
:param reason: The underlying error
:type reason: :class:`Exception`

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### HostChangedError

Raised when an existing pool gets a request for a foreign host.

**M√©thodes :**

- `__init__()`

##### TimeoutStateError

Raised when passing an invalid state to a timeout

##### TimeoutError

Raised when a socket timeout error occurs.

Catching this error will catch both :exc:`ReadTimeoutErrors
<ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.

##### ReadTimeoutError

Raised when a socket timeout occurs while receiving data from a server

##### ConnectTimeoutError

Raised when a socket timeout occurs while connecting to a server

##### NewConnectionError

Raised when we fail to establish a new connection. Usually ECONNREFUSED.

**M√©thodes :**

- `__init__()`
- `__reduce__()`
- `pool()`

##### NameResolutionError

Raised when host name resolution fails.

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### EmptyPoolError

Raised when a pool runs out of connections and no more are allowed.

##### FullPoolError

Raised when we try to add a connection to a full pool in blocking mode.

##### ClosedPoolError

Raised when a request enters a pool after the pool has been closed.

##### LocationValueError

Raised when there is something wrong with a given URL input.

##### LocationParseError

Raised when get_host or similar fails to parse the URL input.

**M√©thodes :**

- `__init__()`

##### URLSchemeUnknown

Raised when a URL input has an unsupported scheme.

**M√©thodes :**

- `__init__()`

##### ResponseError

Used as a container for an error reason supplied in a MaxRetryError.

##### SecurityWarning

Warned when performing security reducing actions

##### InsecureRequestWarning

Warned when making an unverified HTTPS request.

##### NotOpenSSLWarning

Warned when using unsupported SSL library

##### SystemTimeWarning

Warned when system time is suspected to be wrong

##### InsecurePlatformWarning

Warned when certain TLS/SSL configuration is not available on a platform.

##### DependencyWarning

Warned when an attempt is made to import a module with missing optional
dependencies.

##### ResponseNotChunked

Response needs to be chunked in order to read it as chunks.

##### BodyNotHttplibCompatible

Body should be :class:`http.client.HTTPResponse` like
(have an fp attribute which returns raw chunks) for read_chunked().

##### IncompleteRead

Response length doesn't match expected Content-Length

Subclass of :class:`http.client.IncompleteRead` to allow int value
for ``partial`` to avoid creating large objects on streamed reads.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### InvalidChunkLength

Invalid chunk length in a chunked response.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### InvalidHeader

The header provided was somehow invalid.

##### ProxySchemeUnknown

ProxyManager does not support the supplied scheme

**M√©thodes :**

- `__init__()`

##### ProxySchemeUnsupported

Fetching HTTPS resources through HTTPS proxies is unsupported

##### HeaderParsingError

Raised by assert_header_parsing, but we convert it to a log.warning statement.

**M√©thodes :**

- `__init__()`

##### UnrewindableBodyError

urllib3 encountered an error when trying to rewind a body

#### Fonctions

##### __init__

**Param√®tres :**

- `pool`
- `message`

##### __reduce__

##### __init__

**Param√®tres :**

- `pool`
- `url`
- `message`

##### __reduce__

##### __init__

**Param√®tres :**

- `message`
- `error`

##### __init__

**Param√®tres :**

- `pool`
- `url`
- `reason`

##### __reduce__

##### __init__

**Param√®tres :**

- `pool`
- `url`
- `retries`

##### __init__

**Param√®tres :**

- `conn`
- `message`

##### __reduce__

##### pool

##### __init__

**Param√®tres :**

- `host`
- `conn`
- `reason`

##### __reduce__

##### __init__

**Param√®tres :**

- `location`

##### __init__

**Param√®tres :**

- `scheme`

##### __init__

**Param√®tres :**

- `partial`
- `expected`

##### __repr__

##### __init__

**Param√®tres :**

- `response`
- `length`

##### __repr__

##### __init__

**Param√®tres :**

- `scheme`

##### __init__

**Param√®tres :**

- `defects`
- `unparsed_data`

---

### fields

#### Classes

##### RequestField

A data container for request body parameters.

:param name:
    The name of this request field. Must be unicode.
:param data:
    The data/value body.
:param filename:
    An optional filename of the request field. Must be unicode.
:param headers:
    An optional dict-like object of headers to initially use for the field.

.. versionchanged:: 2.0.0
    The ``header_formatter`` parameter is deprecated and will
    be removed in urllib3 v2.1.0.

**M√©thodes :**

- `__init__()`
- `from_tuples()`
- `_render_part()`
- `_render_parts()`
- `render_headers()`
- `make_multipart()`

#### Fonctions

##### guess_content_type

Guess the "Content-Type" of a file.

:param filename:
    The filename to guess the "Content-Type" of using :mod:`mimetypes`.
:param default:
    If no "Content-Type" can be guessed, default to `default`.

**Param√®tres :**

- `filename`
- `default`

##### format_header_param_rfc2231

Helper function to format and quote a single header parameter using the
strategy defined in RFC 2231.

Particularly useful for header parameters which might contain
non-ASCII values, like file names. This follows
`RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.

:param name:
    The name of the parameter, a string expected to be ASCII only.
:param value:
    The value of the parameter, provided as ``bytes`` or `str``.
:returns:
    An RFC-2231-formatted unicode string.

.. deprecated:: 2.0.0
    Will be removed in urllib3 v2.1.0. This is not valid for
    ``multipart/form-data`` header parameters.

**Param√®tres :**

- `name`
- `value`

##### format_multipart_header_param

Format and quote a single multipart header parameter.

This follows the `WHATWG HTML Standard`_ as of 2021/06/10, matching
the behavior of current browser and curl versions. Values are
assumed to be UTF-8. The ``\n``, ``\r``, and ``"`` characters are
percent encoded.

.. _WHATWG HTML Standard:
    https://html.spec.whatwg.org/multipage/
    form-control-infrastructure.html#multipart-form-data

:param name:
    The name of the parameter, an ASCII-only ``str``.
:param value:
    The value of the parameter, a ``str`` or UTF-8 encoded
    ``bytes``.
:returns:
    A string ``name="value"`` with the escaped value.

.. versionchanged:: 2.0.0
    Matches the WHATWG HTML Standard as of 2021/06/10. Control
    characters are no longer percent encoded.

.. versionchanged:: 2.0.0
    Renamed from ``format_header_param_html5`` and
    ``format_header_param``. The old names will be removed in
    urllib3 v2.1.0.

**Param√®tres :**

- `name`
- `value`

##### format_header_param_html5

.. deprecated:: 2.0.0
    Renamed to :func:`format_multipart_header_param`. Will be
    removed in urllib3 v2.1.0.

**Param√®tres :**

- `name`
- `value`

##### format_header_param

.. deprecated:: 2.0.0
    Renamed to :func:`format_multipart_header_param`. Will be
    removed in urllib3 v2.1.0.

**Param√®tres :**

- `name`
- `value`

##### __init__

**Param√®tres :**

- `name`
- `data`
- `filename`
- `headers`
- `header_formatter`

##### from_tuples

A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.

Supports constructing :class:`~urllib3.fields.RequestField` from
parameter of key/value strings AND key/filetuple. A filetuple is a
(filename, data, MIME type) tuple where the MIME type is optional.
For example::

    'foo': 'bar',
    'fakefile': ('foofile.txt', 'contents of foofile'),
    'realfile': ('barfile.txt', open('realfile').read()),
    'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),
    'nonamefile': 'contents of nonamefile field',

Field names and filenames must be unicode.

**Param√®tres :**

- `cls`
- `fieldname`
- `value`
- `header_formatter`

##### _render_part

Override this method to change how each multipart header
parameter is formatted. By default, this calls
:func:`format_multipart_header_param`.

:param name:
    The name of the parameter, an ASCII-only ``str``.
:param value:
    The value of the parameter, a ``str`` or UTF-8 encoded
    ``bytes``.

:meta public:

**Param√®tres :**

- `name`
- `value`

##### _render_parts

Helper function to format and quote a single header.

Useful for single headers that are composed of multiple items. E.g.,
'Content-Disposition' fields.

:param header_parts:
    A sequence of (k, v) tuples or a :class:`dict` of (k, v) to format
    as `k1="v1"; k2="v2"; ...`.

**Param√®tres :**

- `header_parts`

##### render_headers

Renders the headers for this request field.

##### make_multipart

Makes this request field into a multipart request field.

This method overrides "Content-Disposition", "Content-Type" and
"Content-Location" headers to the request parameter.

:param content_disposition:
    The 'Content-Disposition' of the request body. Defaults to 'form-data'
:param content_type:
    The 'Content-Type' of the request body.
:param content_location:
    The 'Content-Location' of the request body.

**Param√®tres :**

- `content_disposition`
- `content_type`
- `content_location`

---

### filepost

#### Fonctions

##### choose_boundary

Our embarrassingly-simple replacement for mimetools.choose_boundary.

##### iter_field_objects

Iterate over fields.

Supports list of (k, v) tuples and dicts, and lists of
:class:`~urllib3.fields.RequestField`.

**Param√®tres :**

- `fields`

##### encode_multipart_formdata

Encode a dictionary of ``fields`` using the multipart/form-data MIME format.

:param fields:
    Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).
    Values are processed by :func:`urllib3.fields.RequestField.from_tuples`.

:param boundary:
    If not specified, then a random boundary will be generated using
    :func:`urllib3.filepost.choose_boundary`.

**Param√®tres :**

- `fields`
- `boundary`

---

### poolmanager

#### Classes

##### PoolKey

All known keyword arguments that could be provided to the pool manager, its
pools, or the underlying connections.

All custom key schemes should include the fields in this key at a minimum.

##### PoolManager

Allows for arbitrary requests while transparently keeping track of
necessary connection pools for you.

:param num_pools:
    Number of connection pools to cache before discarding the least
    recently used pool.

:param headers:
    Headers to include with all requests, unless other headers are given
    explicitly.

:param \**connection_pool_kw:
    Additional parameters are used to create fresh
    :class:`urllib3.connectionpool.ConnectionPool` instances.

Example:

.. code-block:: python

    import urllib3

    http = urllib3.PoolManager(num_pools=2)

    resp1 = http.request("GET", "https://google.com/")
    resp2 = http.request("GET", "https://google.com/mail")
    resp3 = http.request("GET", "https://yahoo.com/")

    print(len(http.pools))
    # 2

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `_new_pool()`
- `clear()`
- `connection_from_host()`
- `connection_from_context()`
- `connection_from_pool_key()`
- `connection_from_url()`
- `_merge_pool_kwargs()`
- `_proxy_requires_url_absolute_form()`
- `urlopen()`

##### ProxyManager

Behaves just like :class:`PoolManager`, but sends all requests through
the defined proxy, using the CONNECT method for HTTPS URLs.

:param proxy_url:
    The URL of the proxy to be used.

:param proxy_headers:
    A dictionary containing headers that will be sent to the proxy. In case
    of HTTP they are being sent with each request, while in the
    HTTPS/CONNECT case they are sent only once. Could be used for proxy
    authentication.

:param proxy_ssl_context:
    The proxy SSL context is used to establish the TLS connection to the
    proxy when using HTTPS proxies.

:param use_forwarding_for_https:
    (Defaults to False) If set to True will forward requests to the HTTPS
    proxy to be made on behalf of the client instead of creating a TLS
    tunnel via the CONNECT method. **Enabling this flag means that request
    and response headers and content will be visible from the HTTPS proxy**
    whereas tunneling keeps request and response headers and content
    private.  IP address, target hostname, SNI, and port are always visible
    to an HTTPS proxy even when this flag is disabled.

:param proxy_assert_hostname:
    The hostname of the certificate to verify against.

:param proxy_assert_fingerprint:
    The fingerprint of the certificate to verify against.

Example:

.. code-block:: python

    import urllib3

    proxy = urllib3.ProxyManager("https://localhost:3128/")

    resp1 = proxy.request("GET", "https://google.com/")
    resp2 = proxy.request("GET", "https://httpbin.org/")

    print(len(proxy.pools))
    # 1

    resp3 = proxy.request("GET", "https://httpbin.org/")
    resp4 = proxy.request("GET", "https://twitter.com/")

    print(len(proxy.pools))
    # 3

**M√©thodes :**

- `__init__()`
- `connection_from_host()`
- `_set_proxy_headers()`
- `urlopen()`

#### Fonctions

##### _default_key_normalizer

Create a pool key out of a request context dictionary.

According to RFC 3986, both the scheme and host are case-insensitive.
Therefore, this function normalizes both before constructing the pool
key for an HTTPS request. If you wish to change this behaviour, provide
alternate callables to ``key_fn_by_scheme``.

:param key_class:
    The class to use when constructing the key. This should be a namedtuple
    with the ``scheme`` and ``host`` keys at a minimum.
:type  key_class: namedtuple
:param request_context:
    A dictionary-like object that contain the context for a request.
:type  request_context: dict

:return: A namedtuple that can be used as a connection pool key.
:rtype:  PoolKey

**Param√®tres :**

- `key_class`
- `request_context`

##### proxy_from_url

**Param√®tres :**

- `url`

##### __init__

**Param√®tres :**

- `num_pools`
- `headers`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### _new_pool

Create a new :class:`urllib3.connectionpool.ConnectionPool` based on host, port, scheme, and
any additional pool keyword arguments.

If ``request_context`` is provided, it is provided as keyword arguments
to the pool class used. This method is used to actually create the
connection pools handed out by :meth:`connection_from_url` and
companion methods. It is intended to be overridden for customization.

**Param√®tres :**

- `scheme`
- `host`
- `port`
- `request_context`

##### clear

Empty our store of pools and direct them all to close.

This will not affect in-flight connections, but they will not be
re-used after completion.

##### connection_from_host

Get a :class:`urllib3.connectionpool.ConnectionPool` based on the host, port, and scheme.

If ``port`` isn't given, it will be derived from the ``scheme`` using
``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is
provided, it is merged with the instance's ``connection_pool_kw``
variable and used to create the new connection pool, if one is
needed.

**Param√®tres :**

- `host`
- `port`
- `scheme`
- `pool_kwargs`

##### connection_from_context

Get a :class:`urllib3.connectionpool.ConnectionPool` based on the request context.

``request_context`` must at least contain the ``scheme`` key and its
value must be a key in ``key_fn_by_scheme`` instance variable.

**Param√®tres :**

- `request_context`

##### connection_from_pool_key

Get a :class:`urllib3.connectionpool.ConnectionPool` based on the provided pool key.

``pool_key`` should be a namedtuple that only contains immutable
objects. At a minimum it must have the ``scheme``, ``host``, and
``port`` fields.

**Param√®tres :**

- `pool_key`
- `request_context`

##### connection_from_url

Similar to :func:`urllib3.connectionpool.connection_from_url`.

If ``pool_kwargs`` is not provided and a new pool needs to be
constructed, ``self.connection_pool_kw`` is used to initialize
the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``
is provided, it is used instead. Note that if a new pool does not
need to be created for the request, the provided ``pool_kwargs`` are
not used.

**Param√®tres :**

- `url`
- `pool_kwargs`

##### _merge_pool_kwargs

Merge a dictionary of override values for self.connection_pool_kw.

This does not modify self.connection_pool_kw and returns a new dict.
Any keys in the override dictionary with a value of ``None`` are
removed from the merged dictionary.

**Param√®tres :**

- `override`

##### _proxy_requires_url_absolute_form

Indicates if the proxy requires the complete destination URL in the
request.  Normally this is only needed when not using an HTTP CONNECT
tunnel.

**Param√®tres :**

- `parsed_url`

##### urlopen

Same as :meth:`urllib3.HTTPConnectionPool.urlopen`
with custom cross-host redirect logic and only sends the request-uri
portion of the ``url``.

The given ``url`` parameter must be absolute, such that an appropriate
:class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.

**Param√®tres :**

- `method`
- `url`
- `redirect`

##### __init__

**Param√®tres :**

- `proxy_url`
- `num_pools`
- `headers`
- `proxy_headers`
- `proxy_ssl_context`
- `use_forwarding_for_https`
- `proxy_assert_hostname`
- `proxy_assert_fingerprint`

##### connection_from_host

**Param√®tres :**

- `host`
- `port`
- `scheme`
- `pool_kwargs`

##### _set_proxy_headers

Sets headers needed by proxies: specifically, the Accept and Host
headers. Only sets headers not provided by the user.

**Param√®tres :**

- `url`
- `headers`

##### urlopen

Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.

**Param√®tres :**

- `method`
- `url`
- `redirect`

---

### response

#### Classes

##### ContentDecoder

**M√©thodes :**

- `decompress()`
- `flush()`

##### DeflateDecoder

**M√©thodes :**

- `__init__()`
- `decompress()`
- `flush()`

##### GzipDecoderState

##### GzipDecoder

**M√©thodes :**

- `__init__()`
- `decompress()`
- `flush()`

##### MultiDecoder

From RFC7231:
    If one or more encodings have been applied to a representation, the
    sender that applied the encodings MUST generate a Content-Encoding
    header field that lists the content codings in the order in which
    they were applied.

**M√©thodes :**

- `__init__()`
- `flush()`
- `decompress()`

##### BytesQueueBuffer

Memory-efficient bytes buffer

To return decoded data in read() and still follow the BufferedIOBase API, we need a
buffer to always return the correct amount of bytes.

This buffer should be filled using calls to put()

Our maximum memory usage is determined by the sum of the size of:

 * self.buffer, which contains the full data
 * the largest chunk that we will copy in get()

The worst case scenario is a single chunk, in which case we'll make a full copy of
the data inside get().

**M√©thodes :**

- `__init__()`
- `__len__()`
- `put()`
- `get()`
- `get_all()`

##### BaseHTTPResponse

**M√©thodes :**

- `__init__()`
- `get_redirect_location()`
- `data()`
- `json()`
- `url()`
- `url()`
- `connection()`
- `retries()`
- `retries()`
- `stream()`
- `read()`
- `read1()`
- `read_chunked()`
- `release_conn()`
- `drain_conn()`
- `shutdown()`
- `close()`
- `_init_decoder()`
- `_decode()`
- `_flush_decoder()`
- `readinto()`
- `getheaders()`
- `getheader()`
- `info()`
- `geturl()`

##### HTTPResponse

HTTP Response container.

Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
loaded and decoded on-demand when the ``data`` property is accessed.  This
class is also compatible with the Python standard library's :mod:`io`
module, and can hence be treated as a readable object in the context of that
framework.

Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:

:param preload_content:
    If True, the response's body will be preloaded during construction.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param original_response:
    When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
    object, it's convenient to include the original for debug purposes. It's
    otherwise unused.

:param retries:
    The retries contains the last :class:`~urllib3.util.retry.Retry` that
    was used during the request.

:param enforce_content_length:
    Enforce content length checking. Body returned by server must match
    value of Content-Length header, if present. Otherwise, raise error.

**M√©thodes :**

- `__init__()`
- `release_conn()`
- `drain_conn()`
- `data()`
- `connection()`
- `isclosed()`
- `tell()`
- `_init_length()`
- `_error_catcher()`
- `_fp_read()`
- `_raw_read()`
- `read()`
- `read1()`
- `stream()`
- `readable()`
- `shutdown()`
- `close()`
- `closed()`
- `fileno()`
- `flush()`
- `supports_chunked_reads()`
- `_update_chunk_length()`
- `_handle_chunk()`
- `read_chunked()`
- `url()`
- `url()`
- `__iter__()`

##### BrotliDecoder

**M√©thodes :**

- `__init__()`
- `flush()`

##### ZstdDecoder

**M√©thodes :**

- `__init__()`
- `decompress()`
- `flush()`

##### ZstdDecoder

**M√©thodes :**

- `__init__()`
- `decompress()`
- `flush()`

#### Fonctions

##### _get_decoder

**Param√®tres :**

- `mode`

##### decompress

**Param√®tres :**

- `data`

##### flush

##### __init__

##### decompress

**Param√®tres :**

- `data`

##### flush

##### __init__

##### decompress

**Param√®tres :**

- `data`

##### flush

##### __init__

**Param√®tres :**

- `modes`

##### flush

##### decompress

**Param√®tres :**

- `data`

##### __init__

##### __len__

##### put

**Param√®tres :**

- `data`

##### get

**Param√®tres :**

- `n`

##### get_all

##### __init__

##### get_redirect_location

Should we redirect and where to?

:returns: Truthy redirect location string if we got a redirect status
    code and valid location. ``None`` if redirect status and no
    location. ``False`` if not a redirect status code.

##### data

##### json

Deserializes the body of the HTTP response as a Python object.

The body of the HTTP response must be encoded using UTF-8, as per
`RFC 8529 Section 8.1 <https://www.rfc-editor.org/rfc/rfc8259#section-8.1>`_.

To use a custom JSON decoder pass the result of :attr:`HTTPResponse.data` to
your custom decoder instead.

If the body of the HTTP response is not decodable to UTF-8, a
`UnicodeDecodeError` will be raised. If the body of the HTTP response is not a
valid JSON document, a `json.JSONDecodeError` will be raised.

Read more :ref:`here <json_content>`.

:returns: The body of the HTTP response as a Python object.

##### url

##### url

**Param√®tres :**

- `url`

##### connection

##### retries

##### retries

**Param√®tres :**

- `retries`

##### stream

**Param√®tres :**

- `amt`
- `decode_content`

##### read

**Param√®tres :**

- `amt`
- `decode_content`
- `cache_content`

##### read1

**Param√®tres :**

- `amt`
- `decode_content`

##### read_chunked

**Param√®tres :**

- `amt`
- `decode_content`

##### release_conn

##### drain_conn

##### shutdown

##### close

##### _init_decoder

Set-up the _decoder attribute if necessary.

##### _decode

Decode the data passed in and potentially flush the decoder.

**Param√®tres :**

- `data`
- `decode_content`
- `flush_decoder`

##### _flush_decoder

Flushes the decoder. Should only be called if the decoder is actually
being used.

##### readinto

**Param√®tres :**

- `b`

##### getheaders

##### getheader

**Param√®tres :**

- `name`
- `default`

##### info

##### geturl

##### __init__

**Param√®tres :**

- `body`
- `headers`
- `status`
- `version`
- `version_string`
- `reason`
- `preload_content`
- `decode_content`
- `original_response`
- `pool`
- `connection`
- `msg`
- `retries`
- `enforce_content_length`
- `request_method`
- `request_url`
- `auto_close`
- `sock_shutdown`

##### release_conn

##### drain_conn

Read and discard any remaining HTTP response data in the response connection.

Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.

##### data

##### connection

##### isclosed

##### tell

Obtain the number of bytes pulled over the wire so far. May differ from
the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
if bytes are encoded on the wire (e.g, compressed).

##### _init_length

Set initial length value for Response content if available.

**Param√®tres :**

- `request_method`

##### _error_catcher

Catch low-level python exceptions, instead re-raising urllib3
variants, so that low-level exceptions are not leaked in the
high-level api.

On exit, release the connection back to the pool.

##### _fp_read

Read a response with the thought that reading the number of bytes
larger than can fit in a 32-bit int at a time via SSL in some
known cases leads to an overflow error that has to be prevented
if `amt` or `self.length_remaining` indicate that a problem may
happen.

The known cases:
  * CPython < 3.9.7 because of a bug
    https://github.com/urllib3/urllib3/issues/2513#issuecomment-1152559900.
  * urllib3 injected with pyOpenSSL-backed SSL-support.
  * CPython < 3.10 only when `amt` does not fit 32-bit int.

**Param√®tres :**

- `amt`

##### _raw_read

Reads `amt` of bytes from the socket.

**Param√®tres :**

- `amt`

##### read

Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
parameters: ``decode_content`` and ``cache_content``.

:param amt:
    How much of the content to read. If specified, caching is skipped
    because it doesn't make sense to cache partial content as the full
    response.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

:param cache_content:
    If True, will save the returned data such that the same result is
    returned despite of the state of the underlying file object. This
    is useful if you want the ``.data`` property to continue working
    after having ``.read()`` the file object. (Overridden if ``amt`` is
    set.)

**Param√®tres :**

- `amt`
- `decode_content`
- `cache_content`

##### read1

Similar to ``http.client.HTTPResponse.read1`` and documented
in :meth:`io.BufferedReader.read1`, but with an additional parameter:
``decode_content``.

:param amt:
    How much of the content to read.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

**Param√®tres :**

- `amt`
- `decode_content`

##### stream

A generator wrapper for the read() method. A call will block until
``amt`` bytes have been read from the connection or until the
connection is closed.

:param amt:
    How much of the content to read. The generator will return up to
    much data per iteration, but may return less. This is particularly
    likely when using compressed data. However, the empty string will
    never be returned.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

**Param√®tres :**

- `amt`
- `decode_content`

##### readable

##### shutdown

##### close

##### closed

##### fileno

##### flush

##### supports_chunked_reads

Checks if the underlying file-like object looks like a
:class:`http.client.HTTPResponse` object. We do this by testing for
the fp attribute. If it is present we assume it returns raw chunks as
processed by read_chunked().

##### _update_chunk_length

##### _handle_chunk

**Param√®tres :**

- `amt`

##### read_chunked

Similar to :meth:`HTTPResponse.read`, but with an additional
parameter: ``decode_content``.

:param amt:
    How much of the content to read. If specified, caching is skipped
    because it doesn't make sense to cache partial content as the full
    response.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

**Param√®tres :**

- `amt`
- `decode_content`

##### url

Returns the URL that was the source of this response.
If the request that generated this response redirected, this method
will return the final redirect location.

##### url

**Param√®tres :**

- `url`

##### __iter__

##### __init__

##### flush

##### __init__

##### decompress

**Param√®tres :**

- `data`

##### flush

##### __init__

##### decompress

**Param√®tres :**

- `data`

##### flush

---

### .!25401!__init__

---

### .!25405!_base_connection

---

### .!25411!_collections

---

### .!25415!_request_methods

---

### .!25419!_version

---

### .!25423!connection

---

### .!25428!connectionpool

---

### .!25434!exceptions

---

### .!25439!fields

---

### .!25441!filepost

---

### .!25447!poolmanager

---

### .!25452!response

---

### pyopenssl

Module for using pyOpenSSL as a TLS backend. This module was relevant before
the standard library ``ssl`` module supported SNI, but now that we've dropped
support for Python 2.7 all relevant Python versions support SNI so
**this module is no longer recommended**.

This needs the following packages installed:

* `pyOpenSSL`_ (tested with 16.0.0)
* `cryptography`_ (minimum 1.3.4, from pyopenssl)
* `idna`_ (minimum 2.0)

However, pyOpenSSL depends on cryptography, so while we use all three directly here we
end up having relatively few packages required.

You can install them with the following command:

.. code-block:: bash

    $ python -m pip install pyopenssl cryptography idna

To activate certificate checking, call
:func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code
before you begin making HTTP requests. This can be done in a ``sitecustomize``
module, or at any other time before your application begins using ``urllib3``,
like this:

.. code-block:: python

    try:
        import urllib3.contrib.pyopenssl
        urllib3.contrib.pyopenssl.inject_into_urllib3()
    except ImportError:
        pass

.. _pyopenssl: https://www.pyopenssl.org
.. _cryptography: https://cryptography.io
.. _idna: https://github.com/kjd/idna

#### Classes

##### WrappedSocket

API-compatibility wrapper for Python OpenSSL's Connection-class.

**M√©thodes :**

- `__init__()`
- `fileno()`
- `_decref_socketios()`
- `recv()`
- `recv_into()`
- `settimeout()`
- `_send_until_done()`
- `sendall()`
- `shutdown()`
- `close()`
- `_real_close()`
- `getpeercert()`
- `version()`
- `selected_alpn_protocol()`

##### PyOpenSSLContext

I am a wrapper class for the PyOpenSSL ``Context`` object. I am responsible
for translating the interface of the standard library ``SSLContext`` object
to calls into PyOpenSSL.

**M√©thodes :**

- `__init__()`
- `options()`
- `options()`
- `verify_flags()`
- `verify_flags()`
- `verify_mode()`
- `verify_mode()`
- `set_default_verify_paths()`
- `set_ciphers()`
- `load_verify_locations()`
- `load_cert_chain()`
- `set_alpn_protocols()`
- `wrap_socket()`
- `_set_ctx_options()`
- `minimum_version()`
- `minimum_version()`
- `maximum_version()`
- `maximum_version()`

##### UnsupportedExtension

#### Fonctions

##### inject_into_urllib3

Monkey-patch urllib3 with PyOpenSSL-backed SSL-support.

##### extract_from_urllib3

Undo monkey-patching by :func:`inject_into_urllib3`.

##### _validate_dependencies_met

Verifies that PyOpenSSL's package-level dependencies have been met.
Throws `ImportError` if they are not met.

##### _dnsname_to_stdlib

Converts a dNSName SubjectAlternativeName field to the form used by the
standard library on the given Python version.

Cryptography produces a dNSName as a unicode string that was idna-decoded
from ASCII bytes. We need to idna-encode that string to get it back, and
then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib
uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).

If the name cannot be idna-encoded then we return None signalling that
the name given should be skipped.

**Param√®tres :**

- `name`

##### get_subj_alt_name

Given an PyOpenSSL certificate, provides all the subject alternative names.

**Param√®tres :**

- `peer_cert`

##### _verify_callback

**Param√®tres :**

- `cnx`
- `x509`
- `err_no`
- `err_depth`
- `return_code`

##### idna_encode

Borrowed wholesale from the Python Cryptography Project. It turns out
that we can't just safely call `idna.encode`: it can explode for
wildcard names. This avoids that problem.

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `connection`
- `socket`
- `suppress_ragged_eofs`

##### fileno

##### _decref_socketios

##### recv

##### recv_into

##### settimeout

**Param√®tres :**

- `timeout`

##### _send_until_done

**Param√®tres :**

- `data`

##### sendall

**Param√®tres :**

- `data`

##### shutdown

**Param√®tres :**

- `how`

##### close

##### _real_close

##### getpeercert

**Param√®tres :**

- `binary_form`

##### version

##### selected_alpn_protocol

##### __init__

**Param√®tres :**

- `protocol`

##### options

##### options

**Param√®tres :**

- `value`

##### verify_flags

##### verify_flags

**Param√®tres :**

- `value`

##### verify_mode

##### verify_mode

**Param√®tres :**

- `value`

##### set_default_verify_paths

##### set_ciphers

**Param√®tres :**

- `ciphers`

##### load_verify_locations

**Param√®tres :**

- `cafile`
- `capath`
- `cadata`

##### load_cert_chain

**Param√®tres :**

- `certfile`
- `keyfile`
- `password`

##### set_alpn_protocols

**Param√®tres :**

- `protocols`

##### wrap_socket

**Param√®tres :**

- `sock`
- `server_side`
- `do_handshake_on_connect`
- `suppress_ragged_eofs`
- `server_hostname`

##### _set_ctx_options

##### minimum_version

##### minimum_version

**Param√®tres :**

- `minimum_version`

##### maximum_version

##### maximum_version

**Param√®tres :**

- `maximum_version`

---

### socks

This module contains provisional support for SOCKS proxies from within
urllib3. This module supports SOCKS4, SOCKS4A (an extension of SOCKS4), and
SOCKS5. To enable its functionality, either install PySocks or install this
module with the ``socks`` extra.

The SOCKS implementation supports the full range of urllib3 features. It also
supports the following SOCKS features:

- SOCKS4A (``proxy_url='socks4a://...``)
- SOCKS4 (``proxy_url='socks4://...``)
- SOCKS5 with remote DNS (``proxy_url='socks5h://...``)
- SOCKS5 with local DNS (``proxy_url='socks5://...``)
- Usernames and passwords for the SOCKS proxy

.. note::
   It is recommended to use ``socks5h://`` or ``socks4a://`` schemes in
   your ``proxy_url`` to ensure that DNS resolution is done from the remote
   server instead of client-side when connecting to a domain name.

SOCKS4 supports IPv4 and domain names with the SOCKS4A extension. SOCKS5
supports IPv4, IPv6, and domain names.

When connecting to a SOCKS4 proxy the ``username`` portion of the ``proxy_url``
will be sent as the ``userid`` section of the SOCKS request:

.. code-block:: python

    proxy_url="socks4a://<userid>@proxy-host"

When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion
of the ``proxy_url`` will be sent as the username/password to authenticate
with the proxy:

.. code-block:: python

    proxy_url="socks5h://<username>:<password>@proxy-host"

#### Classes

##### _TYPE_SOCKS_OPTIONS

##### SOCKSConnection

A plain-text HTTP connection that connects via a SOCKS proxy.

**M√©thodes :**

- `__init__()`
- `_new_conn()`

##### SOCKSHTTPSConnection

##### SOCKSHTTPConnectionPool

##### SOCKSHTTPSConnectionPool

##### SOCKSProxyManager

A version of the urllib3 ProxyManager that routes connections via the
defined SOCKS proxy.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `_socks_options`

##### _new_conn

Establish a new connection via the SOCKS proxy.

##### __init__

**Param√®tres :**

- `proxy_url`
- `username`
- `password`
- `num_pools`
- `headers`

---

### .!25465!pyopenssl

---

### .!25471!socks

---

### connection

#### Classes

##### EmscriptenHTTPConnection

**M√©thodes :**

- `__init__()`
- `set_tunnel()`
- `connect()`
- `request()`
- `getresponse()`
- `close()`
- `is_closed()`
- `is_connected()`
- `has_connected_to_proxy()`

##### EmscriptenHTTPSConnection

**M√©thodes :**

- `__init__()`
- `set_cert()`

#### Fonctions

##### __init__

**Param√®tres :**

- `host`
- `port`

##### set_tunnel

**Param√®tres :**

- `host`
- `port`
- `headers`
- `scheme`

##### connect

##### request

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`

##### getresponse

##### close

##### is_closed

Whether the connection either is brand new or has been previously closed.
If this property is True then both ``is_connected`` and ``has_connected_to_proxy``
properties must be False.

##### is_connected

Whether the connection is actively connected to any origin (proxy or target)

##### has_connected_to_proxy

Whether the connection has successfully connected to its proxy.
This returns False if no proxy is in use. Used to determine whether
errors are coming from the proxy layer or from tunnelling to the target origin.

##### __init__

**Param√®tres :**

- `host`
- `port`

##### set_cert

**Param√®tres :**

- `key_file`
- `cert_file`
- `cert_reqs`
- `key_password`
- `ca_certs`
- `assert_hostname`
- `assert_fingerprint`
- `ca_cert_dir`
- `ca_cert_data`

---

### fetch

Support for streaming http requests in emscripten.

A few caveats -

If your browser (or Node.js) has WebAssembly JavaScript Promise Integration enabled
https://github.com/WebAssembly/js-promise-integration/blob/main/proposals/js-promise-integration/Overview.md
*and* you launch pyodide using `pyodide.runPythonAsync`, this will fetch data using the
JavaScript asynchronous fetch api (wrapped via `pyodide.ffi.call_sync`). In this case
timeouts and streaming should just work.

Otherwise, it uses a combination of XMLHttpRequest and a web-worker for streaming.

This approach has several caveats:

Firstly, you can't do streaming http in the main UI thread, because atomics.wait isn't allowed.
Streaming only works if you're running pyodide in a web worker.

Secondly, this uses an extra web worker and SharedArrayBuffer to do the asynchronous fetch
operation, so it requires that you have crossOriginIsolation enabled, by serving over https
(or from localhost) with the two headers below set:

    Cross-Origin-Opener-Policy: same-origin
    Cross-Origin-Embedder-Policy: require-corp

You can tell if cross origin isolation is successfully enabled by looking at the global crossOriginIsolated variable in
JavaScript console. If it isn't, streaming requests will fallback to XMLHttpRequest, i.e. getting the whole
request into a buffer and then returning it. it shows a warning in the JavaScript console in this case.

Finally, the webworker which does the streaming fetch is created on initial import, but will only be started once
control is returned to javascript. Call `await wait_for_streaming_ready()` to wait for streaming fetch.

NB: in this code, there are a lot of JavaScript objects. They are named js_*
to make it clear what type of object they are.

#### Classes

##### _RequestError

**M√©thodes :**

- `__init__()`

##### _StreamingError

##### _TimeoutError

##### _ReadStream

**M√©thodes :**

- `__init__()`
- `__del__()`
- `is_closed()`
- `closed()`
- `close()`
- `readable()`
- `writable()`
- `seekable()`
- `readinto()`

##### _StreamingFetcher

**M√©thodes :**

- `__init__()`
- `send()`

##### _JSPIReadStream

A read stream that uses pyodide.ffi.run_sync to read from a JavaScript fetch
response. This requires support for WebAssembly JavaScript Promise Integration
in the containing browser, and for pyodide to be launched via runPythonAsync.

:param js_read_stream:
    The JavaScript stream reader

:param timeout:
    Timeout in seconds

:param request:
    The request we're handling

:param response:
    The response this stream relates to

:param js_abort_controller:
    A JavaScript AbortController object, used for timeouts

**M√©thodes :**

- `__init__()`
- `__del__()`
- `is_closed()`
- `closed()`
- `close()`
- `readable()`
- `writable()`
- `seekable()`
- `_get_next_buffer()`
- `readinto()`

#### Fonctions

##### _obj_from_dict

**Param√®tres :**

- `dict_val`

##### is_in_browser_main_thread

##### is_cross_origin_isolated

##### is_in_node

##### is_worker_available

##### send_streaming_request

**Param√®tres :**

- `request`

##### _show_timeout_warning

##### _show_streaming_warning

##### send_request

**Param√®tres :**

- `request`

##### send_jspi_request

Send a request using WebAssembly JavaScript Promise Integration
to wrap the asynchronous JavaScript fetch api (experimental).

:param request:
    Request to send

:param streaming:
    Whether to stream the response

:return: The response object
:rtype: EmscriptenResponse

**Param√®tres :**

- `request`
- `streaming`

##### _run_sync_with_timeout

Await a JavaScript promise synchronously with a timeout which is implemented
via the AbortController

:param promise:
    Javascript promise to await

:param timeout:
    Timeout in seconds

:param js_abort_controller:
    A JavaScript AbortController object, used on timeout

:param request:
    The request being handled

:param response:
    The response being handled (if it exists yet)

:raises _TimeoutError: If the request times out
:raises _RequestError: If the request raises a JavaScript exception

:return: The result of awaiting the promise.

**Param√®tres :**

- `promise`
- `timeout`
- `js_abort_controller`
- `request`
- `response`

##### has_jspi

Return true if jspi can be used.

This requires both browser support and also WebAssembly
to be in the correct state - i.e. that the javascript
call into python was async not sync.

:return: True if jspi can be used.
:rtype: bool

##### _is_node_js

Check if we are in Node.js.

:return: True if we are in Node.js.
:rtype: bool

##### streaming_ready

##### __init__

**Param√®tres :**

- `message`

##### __init__

**Param√®tres :**

- `int_buffer`
- `byte_buffer`
- `timeout`
- `worker`
- `connection_id`
- `request`

##### __del__

##### is_closed

##### closed

##### close

##### readable

##### writable

##### seekable

##### readinto

**Param√®tres :**

- `byte_obj`

##### __init__

##### send

**Param√®tres :**

- `request`

##### __init__

**Param√®tres :**

- `js_read_stream`
- `timeout`
- `request`
- `response`
- `js_abort_controller`

##### __del__

##### is_closed

##### closed

##### close

##### readable

##### writable

##### seekable

##### _get_next_buffer

##### readinto

**Param√®tres :**

- `byte_obj`

##### promise_resolver

**Param√®tres :**

- `js_resolve_fn`
- `js_reject_fn`

##### onMsg

**Param√®tres :**

- `e`

##### onErr

**Param√®tres :**

- `e`

---

### request

#### Classes

##### EmscriptenRequest

**M√©thodes :**

- `set_header()`
- `set_body()`

#### Fonctions

##### set_header

**Param√®tres :**

- `name`
- `value`

##### set_body

**Param√®tres :**

- `body`

---

### response

#### Classes

##### EmscriptenResponse

##### EmscriptenHttpResponseWrapper

**M√©thodes :**

- `__init__()`
- `url()`
- `url()`
- `connection()`
- `retries()`
- `retries()`
- `stream()`
- `_init_length()`
- `read()`
- `read_chunked()`
- `release_conn()`
- `drain_conn()`
- `data()`
- `json()`
- `close()`
- `_error_catcher()`

#### Fonctions

##### __init__

**Param√®tres :**

- `internal_response`
- `url`
- `connection`

##### url

##### url

**Param√®tres :**

- `url`

##### connection

##### retries

##### retries

**Param√®tres :**

- `retries`

##### stream

A generator wrapper for the read() method. A call will block until
``amt`` bytes have been read from the connection or until the
connection is closed.

:param amt:
    How much of the content to read. The generator will return up to
    much data per iteration, but may return less. This is particularly
    likely when using compressed data. However, the empty string will
    never be returned.

:param decode_content:
    If True, will attempt to decode the body based on the
    'content-encoding' header.

**Param√®tres :**

- `amt`
- `decode_content`

##### _init_length

**Param√®tres :**

- `request_method`

##### read

**Param√®tres :**

- `amt`
- `decode_content`
- `cache_content`

##### read_chunked

**Param√®tres :**

- `amt`
- `decode_content`

##### release_conn

##### drain_conn

##### data

##### json

Deserializes the body of the HTTP response as a Python object.

The body of the HTTP response must be encoded using UTF-8, as per
`RFC 8529 Section 8.1 <https://www.rfc-editor.org/rfc/rfc8259#section-8.1>`_.

To use a custom JSON decoder pass the result of :attr:`HTTPResponse.data` to
your custom decoder instead.

If the body of the HTTP response is not decodable to UTF-8, a
`UnicodeDecodeError` will be raised. If the body of the HTTP response is not a
valid JSON document, a `json.JSONDecodeError` will be raised.

Read more :ref:`here <json_content>`.

:returns: The body of the HTTP response as a Python object.

##### close

##### _error_catcher

Catch Emscripten specific exceptions thrown by fetch.py,
instead re-raising urllib3 variants, so that low-level exceptions
are not leaked in the high-level api.

On exit, release the connection back to the pool.

---

### .!25477!__init__

---

### .!25480!connection

---

### .!25487!fetch

---

### .!25492!request

---

### .!25495!response

---

### connection

#### Classes

##### _LockedObject

A wrapper class that hides a specific object behind a lock.
The goal here is to provide a simple way to protect access to an object
that cannot safely be simultaneously accessed from multiple threads. The
intended use of this class is simple: take hold of it with a context
manager, which returns the protected object.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### HTTP2Connection

**M√©thodes :**

- `__init__()`
- `_new_h2_conn()`
- `connect()`
- `putrequest()`
- `putheader()`
- `endheaders()`
- `send()`
- `set_tunnel()`
- `getresponse()`
- `request()`
- `close()`

##### HTTP2Response

**M√©thodes :**

- `__init__()`
- `data()`
- `get_redirect_location()`
- `close()`

#### Fonctions

##### _is_legal_header_name

"An implementation that validates fields according to the definitions in Sections
5.1 and 5.5 of [HTTP] only needs an additional check that field names do not
include uppercase characters." (https://httpwg.org/specs/rfc9113.html#n-field-validity)

`http.client._is_legal_header_name` does not validate the field name according to the
HTTP 1.1 spec, so we do that here, in addition to checking for uppercase characters.

This does not allow for the `:` character in the header name, so should not
be used to validate pseudo-headers.

**Param√®tres :**

- `name`

##### _is_illegal_header_value

"A field value MUST NOT contain the zero value (ASCII NUL, 0x00), line feed
(ASCII LF, 0x0a), or carriage return (ASCII CR, 0x0d) at any position. A field
value MUST NOT start or end with an ASCII whitespace character (ASCII SP or HTAB,
0x20 or 0x09)." (https://httpwg.org/specs/rfc9113.html#n-field-validity)

**Param√®tres :**

- `value`

##### __init__

**Param√®tres :**

- `obj`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

**Param√®tres :**

- `host`
- `port`

##### _new_h2_conn

##### connect

##### putrequest

putrequest
This deviates from the HTTPConnection method signature since we never need to override
sending accept-encoding headers or the host header.

**Param√®tres :**

- `method`
- `url`

##### putheader

**Param√®tres :**

- `header`

##### endheaders

**Param√®tres :**

- `message_body`

##### send

Send data to the server.
`data` can be: `str`, `bytes`, an iterable, or file-like objects
that support a .read() method.

**Param√®tres :**

- `data`

##### set_tunnel

**Param√®tres :**

- `host`
- `port`
- `headers`
- `scheme`

##### getresponse

##### request

Send an HTTP/2 request

**Param√®tres :**

- `method`
- `url`
- `body`
- `headers`

##### close

##### __init__

**Param√®tres :**

- `status`
- `headers`
- `request_url`
- `data`
- `decode_content`

##### data

##### get_redirect_location

##### close

---

### probe

#### Classes

##### _HTTP2ProbeCache

**M√©thodes :**

- `__init__()`
- `acquire_and_get()`
- `set_and_release()`
- `_values()`
- `_reset()`

#### Fonctions

##### __init__

##### acquire_and_get

**Param√®tres :**

- `host`
- `port`

##### set_and_release

**Param√®tres :**

- `host`
- `port`
- `supports_http2`

##### _values

This function is for testing purposes only. Gets the current state of the probe cache

##### _reset

This function is for testing purposes only. Reset the cache values

---

### .!25502!__init__

---

### .!25509!connection

---

### .!25512!probe

---

### connection

#### Fonctions

##### is_connection_dropped

Returns True if the connection is dropped and should be closed.
:param conn: :class:`urllib3.connection.HTTPConnection` object.

**Param√®tres :**

- `conn`

##### create_connection

Connect to *address* and return the socket object.

Convenience function.  Connect to *address* (a 2-tuple ``(host,
port)``) and return the socket object.  Passing the optional
*timeout* parameter will set the timeout on the socket instance
before attempting to connect.  If no *timeout* is supplied, the
global default timeout setting returned by :func:`socket.getdefaulttimeout`
is used.  If *source_address* is set it must be a tuple of (host, port)
for the socket to bind as a source address before making the connection.
An host of '' or port 0 tells the OS to use the default.

**Param√®tres :**

- `address`
- `timeout`
- `source_address`
- `socket_options`

##### _set_socket_options

**Param√®tres :**

- `sock`
- `options`

##### allowed_gai_family

This function is designed to work in the context of
getaddrinfo, where family=socket.AF_UNSPEC is the default and
will perform a DNS search for both IPv6 and IPv4 records.

##### _has_ipv6

Returns True if the system can bind an IPv6 address.

**Param√®tres :**

- `host`

---

### proxy

#### Fonctions

##### connection_requires_http_tunnel

Returns True if the connection requires an HTTP CONNECT through the proxy.

:param URL proxy_url:
    URL of the proxy.
:param ProxyConfig proxy_config:
    Proxy configuration from poolmanager.py
:param str destination_scheme:
    The scheme of the destination. (i.e https, http, etc)

**Param√®tres :**

- `proxy_url`
- `proxy_config`
- `destination_scheme`

---

### request

#### Classes

##### _TYPE_FAILEDTELL

##### ChunksAndContentLength

#### Fonctions

##### make_headers

Shortcuts for generating request headers.

:param keep_alive:
    If ``True``, adds 'connection: keep-alive' header.

:param accept_encoding:
    Can be a boolean, list, or string.
    ``True`` translates to 'gzip,deflate'.  If the dependencies for
    Brotli (either the ``brotli`` or ``brotlicffi`` package) and/or Zstandard
    (the ``zstandard`` package) algorithms are installed, then their encodings are
    included in the string ('br' and 'zstd', respectively).
    List will get joined by comma.
    String will be used as provided.

:param user_agent:
    String representing the user-agent you want, such as
    "python-urllib3/0.6"

:param basic_auth:
    Colon-separated username:password string for 'authorization: basic ...'
    auth header.

:param proxy_basic_auth:
    Colon-separated username:password string for 'proxy-authorization: basic ...'
    auth header.

:param disable_cache:
    If ``True``, adds 'cache-control: no-cache' header.

Example:

.. code-block:: python

    import urllib3

    print(urllib3.util.make_headers(keep_alive=True, user_agent="Batman/1.0"))
    # {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}
    print(urllib3.util.make_headers(accept_encoding=True))
    # {'accept-encoding': 'gzip,deflate'}

**Param√®tres :**

- `keep_alive`
- `accept_encoding`
- `user_agent`
- `basic_auth`
- `proxy_basic_auth`
- `disable_cache`

##### set_file_position

If a position is provided, move file to that point.
Otherwise, we'll attempt to record a position for future use.

**Param√®tres :**

- `body`
- `pos`

##### rewind_body

Attempt to rewind body to a certain position.
Primarily used for request redirects and retries.

:param body:
    File-like object that supports seek.

:param int pos:
    Position to seek to in file.

**Param√®tres :**

- `body`
- `body_pos`

##### body_to_chunks

Takes the HTTP request method, body, and blocksize and
transforms them into an iterable of chunks to pass to
socket.sendall() and an optional 'Content-Length' header.

A 'Content-Length' of 'None' indicates the length of the body
can't be determined so should use 'Transfer-Encoding: chunked'
for framing instead.

**Param√®tres :**

- `body`
- `method`
- `blocksize`

##### chunk_readable

---

### response

#### Fonctions

##### is_fp_closed

Checks whether a given file-like object is closed.

:param obj:
    The file-like object to check.

**Param√®tres :**

- `obj`

##### assert_header_parsing

Asserts whether all headers have been successfully parsed.
Extracts encountered errors from the result of parsing headers.

Only works on Python 3.

:param http.client.HTTPMessage headers: Headers to verify.

:raises urllib3.exceptions.HeaderParsingError:
    If parsing errors are found.

**Param√®tres :**

- `headers`

##### is_response_to_head

Checks whether the request of a response has been a HEAD-request.

:param http.client.HTTPResponse response:
    Response to check if the originating request
    used 'HEAD' as a method.

**Param√®tres :**

- `response`

---

### retry

#### Classes

##### RequestHistory

##### Retry

Retry configuration.

Each retry attempt will create a new Retry object with updated values, so
they can be safely reused.

Retries can be defined as a default for a pool:

.. code-block:: python

    retries = Retry(connect=5, read=2, redirect=5)
    http = PoolManager(retries=retries)
    response = http.request("GET", "https://example.com/")

Or per-request (which overrides the default for the pool):

.. code-block:: python

    response = http.request("GET", "https://example.com/", retries=Retry(10))

Retries can be disabled by passing ``False``:

.. code-block:: python

    response = http.request("GET", "https://example.com/", retries=False)

Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless
retries are disabled, in which case the causing exception will be raised.

:param int total:
    Total number of retries to allow. Takes precedence over other counts.

    Set to ``None`` to remove this constraint and fall back on other
    counts.

    Set to ``0`` to fail on the first retry.

    Set to ``False`` to disable and imply ``raise_on_redirect=False``.

:param int connect:
    How many connection-related errors to retry on.

    These are errors raised before the request is sent to the remote server,
    which we assume has not triggered the server to process the request.

    Set to ``0`` to fail on the first retry of this type.

:param int read:
    How many times to retry on read errors.

    These errors are raised after the request was sent to the server, so the
    request may have side-effects.

    Set to ``0`` to fail on the first retry of this type.

:param int redirect:
    How many redirects to perform. Limit this to avoid infinite redirect
    loops.

    A redirect is a HTTP response with a status code 301, 302, 303, 307 or
    308.

    Set to ``0`` to fail on the first retry of this type.

    Set to ``False`` to disable and imply ``raise_on_redirect=False``.

:param int status:
    How many times to retry on bad status codes.

    These are retries made on responses, where status code matches
    ``status_forcelist``.

    Set to ``0`` to fail on the first retry of this type.

:param int other:
    How many times to retry on other errors.

    Other errors are errors that are not connect, read, redirect or status errors.
    These errors might be raised after the request was sent to the server, so the
    request might have side-effects.

    Set to ``0`` to fail on the first retry of this type.

    If ``total`` is not set, it's a good idea to set this to 0 to account
    for unexpected edge cases and avoid infinite retry loops.

:param Collection allowed_methods:
    Set of uppercased HTTP method verbs that we should retry on.

    By default, we only retry on methods which are considered to be
    idempotent (multiple requests with the same parameters end with the
    same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.

    Set to a ``None`` value to retry on any verb.

:param Collection status_forcelist:
    A set of integer HTTP status codes that we should force a retry on.
    A retry is initiated if the request method is in ``allowed_methods``
    and the response status code is in ``status_forcelist``.

    By default, this is disabled with ``None``.

:param float backoff_factor:
    A backoff factor to apply between attempts after the second try
    (most errors are resolved immediately by a second try without a
    delay). urllib3 will sleep for::

        {backoff factor} * (2 ** ({number of previous retries}))

    seconds. If `backoff_jitter` is non-zero, this sleep is extended by::

        random.uniform(0, {backoff jitter})

    seconds. For example, if the backoff_factor is 0.1, then :func:`Retry.sleep` will
    sleep for [0.0s, 0.2s, 0.4s, 0.8s, ...] between retries. No backoff will ever
    be longer than `backoff_max`.

    By default, backoff is disabled (factor set to 0).

:param bool raise_on_redirect: Whether, if the number of redirects is
    exhausted, to raise a MaxRetryError, or to return a response with a
    response code in the 3xx range.

:param bool raise_on_status: Similar meaning to ``raise_on_redirect``:
    whether we should raise an exception, or return a response,
    if status falls in ``status_forcelist`` range and retries have
    been exhausted.

:param tuple history: The history of the request encountered during
    each call to :meth:`~Retry.increment`. The list is in the order
    the requests occurred. Each list item is of class :class:`RequestHistory`.

:param bool respect_retry_after_header:
    Whether to respect Retry-After header on status codes defined as
    :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.

:param Collection remove_headers_on_redirect:
    Sequence of headers to remove from the request when a response
    indicating a redirect is returned before firing off the redirected
    request.

**M√©thodes :**

- `__init__()`
- `new()`
- `from_int()`
- `get_backoff_time()`
- `parse_retry_after()`
- `get_retry_after()`
- `sleep_for_retry()`
- `_sleep_backoff()`
- `sleep()`
- `_is_connection_error()`
- `_is_read_error()`
- `_is_method_retryable()`
- `is_retry()`
- `is_exhausted()`
- `increment()`
- `__repr__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `total`
- `connect`
- `read`
- `redirect`
- `status`
- `other`
- `allowed_methods`
- `status_forcelist`
- `backoff_factor`
- `backoff_max`
- `raise_on_redirect`
- `raise_on_status`
- `history`
- `respect_retry_after_header`
- `remove_headers_on_redirect`
- `backoff_jitter`

##### new

##### from_int

Backwards-compatibility for the old retries format.

**Param√®tres :**

- `cls`
- `retries`
- `redirect`
- `default`

##### get_backoff_time

Formula for computing the current backoff

:rtype: float

##### parse_retry_after

**Param√®tres :**

- `retry_after`

##### get_retry_after

Get the value of Retry-After in seconds.

**Param√®tres :**

- `response`

##### sleep_for_retry

**Param√®tres :**

- `response`

##### _sleep_backoff

##### sleep

Sleep between retry attempts.

This method will respect a server's ``Retry-After`` response header
and sleep the duration of the time requested. If that is not present, it
will use an exponential backoff. By default, the backoff factor is 0 and
this method will return immediately.

**Param√®tres :**

- `response`

##### _is_connection_error

Errors when we're fairly sure that the server did not receive the
request, so it should be safe to retry.

**Param√®tres :**

- `err`

##### _is_read_error

Errors that occur after the request has been started, so we should
assume that the server began processing it.

**Param√®tres :**

- `err`

##### _is_method_retryable

Checks if a given HTTP method should be retried upon, depending if
it is included in the allowed_methods

**Param√®tres :**

- `method`

##### is_retry

Is this method/status code retryable? (Based on allowlists and control
variables such as the number of total retries to allow, whether to
respect the Retry-After header, whether this header is present, and
whether the returned status code is on the list of status codes to
be retried upon on the presence of the aforementioned header)

**Param√®tres :**

- `method`
- `status_code`
- `has_retry_after`

##### is_exhausted

Are we out of retries?

##### increment

Return a new Retry object with incremented retry counters.

:param response: A response object, or None, if the server did not
    return a response.
:type response: :class:`~urllib3.response.BaseHTTPResponse`
:param Exception error: An error encountered during the request, or
    None if the response was received successfully.

:return: A new ``Retry`` object.

**Param√®tres :**

- `method`
- `url`
- `response`
- `error`
- `_pool`
- `_stacktrace`

##### __repr__

---

### .!25549!ssl_

---

### .!25567!url

---

### ssl_

#### Classes

##### _TYPE_PEER_CERT_RET_DICT

#### Fonctions

##### _is_bpo_43522_fixed

Return True for CPython 3.9.3+ or 3.10+ and PyPy 7.3.8+ where
setting SSLContext.hostname_checks_common_name to False works.

Outside of CPython and PyPy we don't know which implementations work
or not so we conservatively use our hostname matching as we know that works
on all implementations.

https://github.com/urllib3/urllib3/issues/2192#issuecomment-821832963
https://foss.heptapod.net/pypy/pypy/-/issues/3539

**Param√®tres :**

- `implementation_name`
- `version_info`
- `pypy_version_info`

##### _is_has_never_check_common_name_reliable

**Param√®tres :**

- `openssl_version`
- `openssl_version_number`
- `implementation_name`
- `version_info`
- `pypy_version_info`

##### assert_fingerprint

Checks if given fingerprint matches the supplied certificate.

:param cert:
    Certificate as bytes object.
:param fingerprint:
    Fingerprint as string of hexdigits, can be interspersed by colons.

**Param√®tres :**

- `cert`
- `fingerprint`

##### resolve_cert_reqs

Resolves the argument to a numeric constant, which can be passed to
the wrap_socket function/method from the ssl module.
Defaults to :data:`ssl.CERT_REQUIRED`.
If given a string it is assumed to be the name of the constant in the
:mod:`ssl` module or its abbreviation.
(So you can specify `REQUIRED` instead of `CERT_REQUIRED`.
If it's neither `None` nor a string we assume it is already the numeric
constant which can directly be passed to wrap_socket.

**Param√®tres :**

- `candidate`

##### resolve_ssl_version

like resolve_cert_reqs

**Param√®tres :**

- `candidate`

##### create_urllib3_context

Creates and configures an :class:`ssl.SSLContext` instance for use with urllib3.

:param ssl_version:
    The desired protocol version to use. This will default to
    PROTOCOL_SSLv23 which will negotiate the highest protocol that both
    the server and your installation of OpenSSL support.

    This parameter is deprecated instead use 'ssl_minimum_version'.
:param ssl_minimum_version:
    The minimum version of TLS to be used. Use the 'ssl.TLSVersion' enum for specifying the value.
:param ssl_maximum_version:
    The maximum version of TLS to be used. Use the 'ssl.TLSVersion' enum for specifying the value.
    Not recommended to set to anything other than 'ssl.TLSVersion.MAXIMUM_SUPPORTED' which is the
    default value.
:param cert_reqs:
    Whether to require the certificate verification. This defaults to
    ``ssl.CERT_REQUIRED``.
:param options:
    Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,
    ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``, and ``ssl.OP_NO_TICKET``.
:param ciphers:
    Which cipher suites to allow the server to select. Defaults to either system configured
    ciphers if OpenSSL 1.1.1+, otherwise uses a secure default set of ciphers.
:param verify_flags:
    The flags for certificate verification operations. These default to
    ``ssl.VERIFY_X509_PARTIAL_CHAIN`` and ``ssl.VERIFY_X509_STRICT`` for Python 3.13+.
:returns:
    Constructed SSLContext object with specified options
:rtype: SSLContext

**Param√®tres :**

- `ssl_version`
- `cert_reqs`
- `options`
- `ciphers`
- `ssl_minimum_version`
- `ssl_maximum_version`
- `verify_flags`

##### ssl_wrap_socket

**Param√®tres :**

- `sock`
- `keyfile`
- `certfile`
- `cert_reqs`
- `ca_certs`
- `server_hostname`
- `ssl_version`
- `ciphers`
- `ssl_context`
- `ca_cert_dir`
- `key_password`
- `ca_cert_data`
- `tls_in_tls`

##### ssl_wrap_socket

**Param√®tres :**

- `sock`
- `keyfile`
- `certfile`
- `cert_reqs`
- `ca_certs`
- `server_hostname`
- `ssl_version`
- `ciphers`
- `ssl_context`
- `ca_cert_dir`
- `key_password`
- `ca_cert_data`
- `tls_in_tls`

##### ssl_wrap_socket

All arguments except for server_hostname, ssl_context, tls_in_tls, ca_cert_data and
ca_cert_dir have the same meaning as they do when using
:func:`ssl.create_default_context`, :meth:`ssl.SSLContext.load_cert_chain`,
:meth:`ssl.SSLContext.set_ciphers` and :meth:`ssl.SSLContext.wrap_socket`.

:param server_hostname:
    When SNI is supported, the expected hostname of the certificate
:param ssl_context:
    A pre-made :class:`SSLContext` object. If none is provided, one will
    be created using :func:`create_urllib3_context`.
:param ciphers:
    A string of ciphers we wish the client to support.
:param ca_cert_dir:
    A directory containing CA certificates in multiple separate files, as
    supported by OpenSSL's -CApath flag or the capath argument to
    SSLContext.load_verify_locations().
:param key_password:
    Optional password if the keyfile is encrypted.
:param ca_cert_data:
    Optional string containing CA certificates in PEM format suitable for
    passing as the cadata parameter to SSLContext.load_verify_locations()
:param tls_in_tls:
    Use SSLTransport to wrap the existing socket.

**Param√®tres :**

- `sock`
- `keyfile`
- `certfile`
- `cert_reqs`
- `ca_certs`
- `server_hostname`
- `ssl_version`
- `ciphers`
- `ssl_context`
- `ca_cert_dir`
- `key_password`
- `ca_cert_data`
- `tls_in_tls`

##### is_ipaddress

Detects whether the hostname given is an IPv4 or IPv6 address.
Also detects IPv6 addresses with Zone IDs.

:param str hostname: Hostname to examine.
:return: True if the hostname is an IP address, False otherwise.

**Param√®tres :**

- `hostname`

##### _is_key_file_encrypted

Detects if a key file is encrypted or not.

**Param√®tres :**

- `key_file`

##### _ssl_wrap_socket_impl

**Param√®tres :**

- `sock`
- `ssl_context`
- `tls_in_tls`
- `server_hostname`

---

### .!25573!util

---

### ssl_match_hostname

The match_hostname() function from Python 3.5, essential when using SSL.

#### Classes

##### CertificateError

#### Fonctions

##### _dnsname_match

Matching according to RFC 6125, section 6.4.3

http://tools.ietf.org/html/rfc6125#section-6.4.3

**Param√®tres :**

- `dn`
- `hostname`
- `max_wildcards`

##### _ipaddress_match

Exact matching of IP addresses.

RFC 9110 section 4.3.5: "A reference identity of IP-ID contains the decoded
bytes of the IP address. An IP version 4 address is 4 octets, and an IP
version 6 address is 16 octets. [...] A reference identity of type IP-ID
matches if the address is identical to an iPAddress value of the
subjectAltName extension of the certificate."

**Param√®tres :**

- `ipname`
- `host_ip`

##### match_hostname

Verify that *cert* (in decoded format as returned by
SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
rules are followed, but IP addresses are not accepted for *hostname*.

CertificateError is raised on failure. On success, the function
returns nothing.

**Param√®tres :**

- `cert`
- `hostname`
- `hostname_checks_common_name`

---

### .!25576!wait

---

### ssltransport

#### Classes

##### SSLTransport

The SSLTransport wraps an existing socket and establishes an SSL connection.

Contrary to Python's implementation of SSLSocket, it allows you to chain
multiple TLS connections together. It's particularly useful if you need to
implement TLS within TLS.

The class supports most of the socket API operations.

**M√©thodes :**

- `_validate_ssl_context_for_tls_in_tls()`
- `__init__()`
- `__enter__()`
- `__exit__()`
- `fileno()`
- `read()`
- `recv()`
- `recv_into()`
- `sendall()`
- `send()`
- `makefile()`
- `unwrap()`
- `close()`
- `getpeercert()`
- `getpeercert()`
- `getpeercert()`
- `version()`
- `cipher()`
- `selected_alpn_protocol()`
- `shared_ciphers()`
- `compression()`
- `settimeout()`
- `gettimeout()`
- `_decref_socketios()`
- `_wrap_ssl_read()`
- `_ssl_io_loop()`
- `_ssl_io_loop()`
- `_ssl_io_loop()`
- `_ssl_io_loop()`

#### Fonctions

##### _validate_ssl_context_for_tls_in_tls

Raises a ProxySchemeUnsupported if the provided ssl_context can't be used
for TLS in TLS.

The only requirement is that the ssl_context provides the 'wrap_bio'
methods.

**Param√®tres :**

- `ssl_context`

##### __init__

Create an SSLTransport around socket using the provided ssl_context.

**Param√®tres :**

- `socket`
- `ssl_context`
- `server_hostname`
- `suppress_ragged_eofs`

##### __enter__

##### __exit__

##### fileno

##### read

**Param√®tres :**

- `len`
- `buffer`

##### recv

**Param√®tres :**

- `buflen`
- `flags`

##### recv_into

**Param√®tres :**

- `buffer`
- `nbytes`
- `flags`

##### sendall

**Param√®tres :**

- `data`
- `flags`

##### send

**Param√®tres :**

- `data`
- `flags`

##### makefile

Python's httpclient uses makefile and buffered io when reading HTTP
messages and we need to support it.

This is unfortunately a copy and paste of socket.py makefile with small
changes to point to the socket directly.

**Param√®tres :**

- `mode`
- `buffering`

##### unwrap

##### close

##### getpeercert

**Param√®tres :**

- `binary_form`

##### getpeercert

**Param√®tres :**

- `binary_form`

##### getpeercert

**Param√®tres :**

- `binary_form`

##### version

##### cipher

##### selected_alpn_protocol

##### shared_ciphers

##### compression

##### settimeout

**Param√®tres :**

- `value`

##### gettimeout

##### _decref_socketios

##### _wrap_ssl_read

**Param√®tres :**

- `len`
- `buffer`

##### _ssl_io_loop

**Param√®tres :**

- `func`

##### _ssl_io_loop

**Param√®tres :**

- `func`
- `arg1`

##### _ssl_io_loop

**Param√®tres :**

- `func`
- `arg1`
- `arg2`

##### _ssl_io_loop

Performs an I/O loop between incoming/outgoing and the socket.

**Param√®tres :**

- `func`
- `arg1`
- `arg2`

---

### timeout

#### Classes

##### _TYPE_DEFAULT

##### Timeout

Timeout configuration.

Timeouts can be defined as a default for a pool:

.. code-block:: python

    import urllib3

    timeout = urllib3.util.Timeout(connect=2.0, read=7.0)

    http = urllib3.PoolManager(timeout=timeout)

    resp = http.request("GET", "https://example.com/")

    print(resp.status)

Or per-request (which overrides the default for the pool):

.. code-block:: python

   response = http.request("GET", "https://example.com/", timeout=Timeout(10))

Timeouts can be disabled by setting all the parameters to ``None``:

.. code-block:: python

   no_timeout = Timeout(connect=None, read=None)
   response = http.request("GET", "https://example.com/", timeout=no_timeout)


:param total:
    This combines the connect and read timeouts into one; the read timeout
    will be set to the time leftover from the connect attempt. In the
    event that both a connect timeout and a total are specified, or a read
    timeout and a total are specified, the shorter timeout will be applied.

    Defaults to None.

:type total: int, float, or None

:param connect:
    The maximum amount of time (in seconds) to wait for a connection
    attempt to a server to succeed. Omitting the parameter will default the
    connect timeout to the system default, probably `the global default
    timeout in socket.py
    <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
    None will set an infinite timeout for connection attempts.

:type connect: int, float, or None

:param read:
    The maximum amount of time (in seconds) to wait between consecutive
    read operations for a response from the server. Omitting the parameter
    will default the read timeout to the system default, probably `the
    global default timeout in socket.py
    <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
    None will set an infinite timeout.

:type read: int, float, or None

.. note::

    Many factors can affect the total amount of time for urllib3 to return
    an HTTP response.

    For example, Python's DNS resolver does not obey the timeout specified
    on the socket. Other factors that can affect total request time include
    high CPU load, high swap, the program running at a low priority level,
    or other behaviors.

    In addition, the read and total timeouts only measure the time between
    read operations on the socket connecting the client and the server,
    not the total amount of time for the request to return a complete
    response. For most requests, the timeout is raised because the server
    has not sent the first byte in the specified time. This is not always
    the case; if a server streams one byte every fifteen seconds, a timeout
    of 20 seconds will not trigger, even though the request will take
    several minutes to complete.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `resolve_default_timeout()`
- `_validate_timeout()`
- `from_float()`
- `clone()`
- `start_connect()`
- `get_connect_duration()`
- `connect_timeout()`
- `read_timeout()`

#### Fonctions

##### __init__

**Param√®tres :**

- `total`
- `connect`
- `read`

##### __repr__

##### resolve_default_timeout

**Param√®tres :**

- `timeout`

##### _validate_timeout

Check that a timeout attribute is valid.

:param value: The timeout value to validate
:param name: The name of the timeout attribute to validate. This is
    used to specify in error messages.
:return: The validated and casted version of the given value.
:raises ValueError: If it is a numeric value less than or equal to
    zero, or the type is not an integer, float, or None.

**Param√®tres :**

- `cls`
- `value`
- `name`

##### from_float

Create a new Timeout from a legacy timeout value.

The timeout value used by httplib.py sets the same timeout on the
connect(), and recv() socket requests. This creates a :class:`Timeout`
object that sets the individual timeouts to the ``timeout`` value
passed to this function.

:param timeout: The legacy timeout value.
:type timeout: integer, float, :attr:`urllib3.util.Timeout.DEFAULT_TIMEOUT`, or None
:return: Timeout object
:rtype: :class:`Timeout`

**Param√®tres :**

- `cls`
- `timeout`

##### clone

Create a copy of the timeout object

Timeout properties are stored per-pool but each request needs a fresh
Timeout object to ensure each one has its own start/stop configured.

:return: a copy of the timeout object
:rtype: :class:`Timeout`

##### start_connect

Start the timeout clock, used during a connect() attempt

:raises urllib3.exceptions.TimeoutStateError: if you attempt
    to start a timer that has been started already.

##### get_connect_duration

Gets the time elapsed since the call to :meth:`start_connect`.

:return: Elapsed time in seconds.
:rtype: float
:raises urllib3.exceptions.TimeoutStateError: if you attempt
    to get duration for a timer that hasn't been started.

##### connect_timeout

Get the value to use when setting a connection timeout.

This will be a positive float or integer, the value None
(never timeout), or the default system timeout.

:return: Connect timeout.
:rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None

##### read_timeout

Get the value for the read timeout.

This assumes some time has elapsed in the connection timeout and
computes the read timeout appropriately.

If self.total is set, the read timeout is dependent on the amount of
time taken by the connect timeout. If the connection time has not been
established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be
raised.

:return: Value to use for the read timeout.
:rtype: int, float or None
:raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`
    has not yet been called on this object.

---

### url

#### Classes

##### Url

Data structure for representing an HTTP URL. Used as a return value for
:func:`parse_url`. Both the scheme and host are normalized as they are
both case-insensitive according to RFC 3986.

**M√©thodes :**

- `__new__()`
- `hostname()`
- `request_uri()`
- `authority()`
- `netloc()`
- `url()`
- `__str__()`

#### Fonctions

##### _encode_invalid_chars

**Param√®tres :**

- `component`
- `allowed_chars`

##### _encode_invalid_chars

**Param√®tres :**

- `component`
- `allowed_chars`

##### _encode_invalid_chars

Percent-encodes a URI component without reapplying
onto an already percent-encoded component.

**Param√®tres :**

- `component`
- `allowed_chars`

##### _remove_path_dot_segments

**Param√®tres :**

- `path`

##### _normalize_host

**Param√®tres :**

- `host`
- `scheme`

##### _normalize_host

**Param√®tres :**

- `host`
- `scheme`

##### _normalize_host

**Param√®tres :**

- `host`
- `scheme`

##### _idna_encode

**Param√®tres :**

- `name`

##### _encode_target

Percent-encodes a request target so that there are no invalid characters

Pre-condition for this function is that 'target' must start with '/'.
If that is the case then _TARGET_RE will always produce a match.

**Param√®tres :**

- `target`

##### parse_url

Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is
performed to parse incomplete urls. Fields not provided will be None.
This parser is RFC 3986 and RFC 6874 compliant.

The parser logic and helper functions are based heavily on
work done in the ``rfc3986`` module.

:param str url: URL to parse into a :class:`.Url` namedtuple.

Partly backwards-compatible with :mod:`urllib.parse`.

Example:

.. code-block:: python

    import urllib3

    print( urllib3.util.parse_url('http://google.com/mail/'))
    # Url(scheme='http', host='google.com', port=None, path='/mail/', ...)

    print( urllib3.util.parse_url('google.com:80'))
    # Url(scheme=None, host='google.com', port=80, path=None, ...)

    print( urllib3.util.parse_url('/foo?bar'))
    # Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)

**Param√®tres :**

- `url`

##### __new__

**Param√®tres :**

- `cls`
- `scheme`
- `auth`
- `host`
- `port`
- `path`
- `query`
- `fragment`

##### hostname

For backwards-compatibility with urlparse. We're nice like that.

##### request_uri

Absolute path including the query string.

##### authority

Authority component as defined in RFC 3986 3.2.
This includes userinfo (auth), host and port.

i.e.
    userinfo@host:port

##### netloc

Network location including host and port.

If you need the equivalent of urllib.parse's ``netloc``,
use the ``authority`` property instead.

##### url

Convert self into a url

This function should more or less round-trip with :func:`.parse_url`. The
returned url may not be exactly the same as the url inputted to
:func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls
with a blank port will have : removed).

Example:

.. code-block:: python

    import urllib3

    U = urllib3.util.parse_url("https://google.com/mail/")

    print(U.url)
    # "https://google.com/mail/"

    print( urllib3.util.Url("https", "username:password",
                            "host.com", 80, "/path", "query", "fragment"
                            ).url
        )
    # "https://username:password@host.com:80/path?query#fragment"

##### __str__

---

### util

#### Fonctions

##### to_bytes

**Param√®tres :**

- `x`
- `encoding`
- `errors`

##### to_str

**Param√®tres :**

- `x`
- `encoding`
- `errors`

##### reraise

**Param√®tres :**

- `tp`
- `value`
- `tb`

---

### wait

#### Fonctions

##### select_wait_for_socket

**Param√®tres :**

- `sock`
- `read`
- `write`
- `timeout`

##### poll_wait_for_socket

**Param√®tres :**

- `sock`
- `read`
- `write`
- `timeout`

##### _have_working_poll

##### wait_for_socket

**Param√®tres :**

- `sock`
- `read`
- `write`
- `timeout`

##### wait_for_read

Waits for reading to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired.

**Param√®tres :**

- `sock`
- `timeout`

##### wait_for_write

Waits for writing to be available on a given socket.
Returns True if the socket is readable, or False if the timeout expired.

**Param√®tres :**

- `sock`
- `timeout`

##### do_poll

**Param√®tres :**

- `t`

---

### .!25518!__init__

---

### .!25525!connection

---

### .!25529!proxy

---

### .!25533!request

---

### .!25538!response

---

### .!25542!retry

---

### .!25553!ssl_match_hostname

---

### .!25558!ssltransport

---

### .!25562!timeout

---

### __main__

---

### cli

#### Classes

##### HelpAction

**M√©thodes :**

- `__call__()`

##### CommandArgumentParser

**M√©thodes :**

- `__init__()`
- `add_command()`

##### HookDispatch

**M√©thodes :**

- `__init__()`
- `__getattr__()`

##### TerminalReporter

**M√©thodes :**

- `__init__()`
- `ensure_newline()`
- `write()`
- `write_line()`
- `rewrite()`
- `write_sep()`
- `section()`
- `line()`

#### Fonctions

##### add_glob_or_file

**Param√®tres :**

- `addoption`

##### make_parser

##### main

##### __call__

**Param√®tres :**

- `parser`
- `namespace`
- `values`
- `option_string`

##### __init__

##### add_command

**Param√®tres :**

- `name`

##### __init__

##### __getattr__

**Param√®tres :**

- `item`

##### __init__

##### ensure_newline

##### write

**Param√®tres :**

- `content`

##### write_line

**Param√®tres :**

- `line`

##### rewrite

**Param√®tres :**

- `line`

##### write_sep

**Param√®tres :**

- `sep`
- `title`

##### section

**Param√®tres :**

- `title`
- `sep`

##### line

**Param√®tres :**

- `msg`

---

### .!25598!cli

---

### compat

---

### .!25605!csv

---

### csv

#### Classes

##### CSVResults

**M√©thodes :**

- `__init__()`
- `render()`

#### Fonctions

##### __init__

**Param√®tres :**

- `columns`
- `sort`
- `logger`

##### render

**Param√®tres :**

- `output_file`
- `groups`

---

### fixture

#### Classes

##### FixtureAlreadyUsed

##### BenchmarkFixture

**M√©thodes :**

- `__init__()`
- `enabled()`
- `_get_precision()`
- `_make_runner()`
- `_make_stats()`
- `_save_cprofile()`
- `__call__()`
- `pedantic()`
- `_raw()`
- `_raw_pedantic()`
- `weave()`
- `_cleanup()`
- `_calibrate_timer()`

#### Fonctions

##### __init__

**Param√®tres :**

- `node`
- `disable_gc`
- `timer`
- `min_rounds`
- `min_time`
- `max_time`
- `warmup`
- `warmup_iterations`
- `calibration_precision`
- `add_stats`
- `logger`
- `warner`
- `disabled`
- `cprofile`
- `cprofile_loops`
- `cprofile_dump`
- `group`

##### enabled

##### _get_precision

**Param√®tres :**

- `timer`

##### _make_runner

**Param√®tres :**

- `function_to_benchmark`
- `args`
- `kwargs`

##### _make_stats

**Param√®tres :**

- `iterations`

##### _save_cprofile

**Param√®tres :**

- `profile`

##### __call__

**Param√®tres :**

- `function_to_benchmark`

##### pedantic

**Param√®tres :**

- `target`
- `args`
- `kwargs`
- `setup`
- `rounds`
- `warmup_rounds`
- `iterations`

##### _raw

**Param√®tres :**

- `function_to_benchmark`

##### _raw_pedantic

**Param√®tres :**

- `target`
- `args`
- `kwargs`
- `setup`
- `rounds`
- `warmup_rounds`
- `iterations`

##### weave

**Param√®tres :**

- `target`

##### _cleanup

##### _calibrate_timer

**Param√®tres :**

- `runner`

##### runner

**Param√®tres :**

- `loops_range`
- `timer`

##### make_arguments

**Param√®tres :**

- `args`
- `kwargs`

##### aspect

**Param√®tres :**

- `function`

##### wrapper

---

### histogram

#### Classes

##### CustomBox

**M√©thodes :**

- `_box_points()`
- `_value_format()`
- `_format()`
- `_tooltip_data()`

##### Style

#### Fonctions

##### make_plot

**Param√®tres :**

- `benchmarks`
- `title`
- `adjustment`

##### make_histogram

**Param√®tres :**

- `output_prefix`
- `name`
- `benchmarks`
- `unit`
- `adjustment`

##### _box_points

**Param√®tres :**

- `serie`
- `_`

##### _value_format

**Param√®tres :**

- `x`

##### _format

**Param√®tres :**

- `x`

##### _tooltip_data

**Param√®tres :**

- `node`
- `value`
- `x`
- `y`
- `classes`
- `xlabel`

---

### hookspec

#### Fonctions

##### pytest_benchmark_scale_unit

To have custom time scaling do something like this:

.. sourcecode:: python

    def pytest_benchmark_scale_unit(config, unit, benchmarks, best, worst, sort):
        if unit == 'seconds':
            prefix = ''
            scale = 1.0
        elif unit == 'operations':
            prefix = 'K'
            scale = 0.001
        else:
            raise RuntimeError("Unexpected measurement unit %r" % unit)

        return prefix, scale

**Param√®tres :**

- `config`
- `unit`
- `benchmarks`
- `best`
- `worst`
- `sort`

##### pytest_benchmark_generate_machine_info

To completely replace the generated machine_info do something like this:

.. sourcecode:: python

    def pytest_benchmark_generate_machine_info(config):
        return {'user': getpass.getuser()}

**Param√®tres :**

- `config`

##### pytest_benchmark_update_machine_info

If benchmarks are compared and machine_info is different then warnings will be shown.

To add the current user to the commit info override the hook in your conftest.py like this:

.. sourcecode:: python

    def pytest_benchmark_update_machine_info(config, machine_info):
        machine_info['user'] = getpass.getuser()

**Param√®tres :**

- `config`
- `machine_info`

##### pytest_benchmark_generate_commit_info

To completely replace the generated commit_info do something like this:

.. sourcecode:: python

    def pytest_benchmark_generate_commit_info(config):
        return {'id': subprocess.check_output(['svnversion']).strip()}

**Param√®tres :**

- `config`

##### pytest_benchmark_update_commit_info

To add something into the commit_info, like the commit message do something like this:

.. sourcecode:: python

    def pytest_benchmark_update_commit_info(config, commit_info):
        commit_info['message'] = subprocess.check_output(['git', 'log', '-1', '--pretty=%B']).strip()

**Param√®tres :**

- `config`
- `commit_info`

##### pytest_benchmark_group_stats

You may perform grouping customization here, in case the builtin grouping doesn't suit you.

Example:

.. sourcecode:: python

    @pytest.mark.hookwrapper
    def pytest_benchmark_group_stats(config, benchmarks, group_by):
        outcome = yield
        if group_by == "special":  # when you use --benchmark-group-by=special
            result = defaultdict(list)
            for bench in benchmarks:
                # `bench.special` doesn't exist, replace with whatever you need
                result[bench.special].append(bench)
            outcome.force_result(result.items())

**Param√®tres :**

- `config`
- `benchmarks`
- `group_by`

##### pytest_benchmark_generate_json

You should read pytest-benchmark's code if you really need to wholly customize the json.

.. warning::

    Improperly customizing this may cause breakage if ``--benchmark-compare`` or ``--benchmark-histogram`` are used.

By default, ``pytest_benchmark_generate_json`` strips benchmarks that have errors from the output. To prevent this,
implement the hook like this:

.. sourcecode:: python

    @pytest.mark.hookwrapper
    def pytest_benchmark_generate_json(config, benchmarks, include_data, machine_info, commit_info):
        for bench in benchmarks:
            bench.has_error = False
        yield

**Param√®tres :**

- `config`
- `benchmarks`
- `include_data`
- `machine_info`
- `commit_info`

##### pytest_benchmark_update_json

Use this to add custom fields in the output JSON.

Example:

.. sourcecode:: python

    def pytest_benchmark_update_json(config, benchmarks, output_json):
        output_json['foo'] = 'bar'

**Param√®tres :**

- `config`
- `benchmarks`
- `output_json`

##### pytest_benchmark_compare_machine_info

You may want to use this hook to implement custom checks or abort execution.
``pytest-benchmark`` builtin hook does this:

.. sourcecode:: python

    def pytest_benchmark_compare_machine_info(config, benchmarksession, machine_info, compared_benchmark):
        if compared_benchmark["machine_info"] != machine_info:
            benchmarksession.logger.warning(
                "Benchmark machine_info is different. Current: %s VS saved: %s." % (
                    format_dict(machine_info),
                    format_dict(compared_benchmark["machine_info"]),
                )
        )

**Param√®tres :**

- `config`
- `benchmarksession`
- `machine_info`
- `compared_benchmark`

---

### logger

#### Classes

##### PytestBenchmarkWarning

##### Logger

**M√©thodes :**

- `__init__()`
- `warning()`
- `error()`
- `info()`
- `debug()`

#### Fonctions

##### __init__

**Param√®tres :**

- `level`
- `config`

##### warning

**Param√®tres :**

- `text`
- `warner`
- `suspend`

##### error

**Param√®tres :**

- `text`

##### info

**Param√®tres :**

- `text`
- `newline`

##### debug

**Param√®tres :**

- `text`
- `newline`

---

### plugin

#### Fonctions

##### pytest_report_header

**Param√®tres :**

- `config`

##### add_display_options

**Param√®tres :**

- `addoption`
- `prefix`

##### add_histogram_options

**Param√®tres :**

- `addoption`
- `prefix`

##### add_csv_options

**Param√®tres :**

- `addoption`
- `prefix`

##### add_global_options

**Param√®tres :**

- `addoption`
- `prefix`

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_addhooks

**Param√®tres :**

- `pluginmanager`

##### pytest_benchmark_compare_machine_info

**Param√®tres :**

- `config`
- `benchmarksession`
- `machine_info`
- `compared_benchmark`

##### pytest_collection_modifyitems

**Param√®tres :**

- `config`
- `items`

##### pytest_benchmark_group_stats

**Param√®tres :**

- `config`
- `benchmarks`
- `group_by`

##### pytest_sessionfinish

**Param√®tres :**

- `session`
- `exitstatus`

##### pytest_terminal_summary

**Param√®tres :**

- `terminalreporter`

##### get_cpu_info

##### pytest_benchmark_scale_unit

**Param√®tres :**

- `config`
- `unit`
- `benchmarks`
- `best`
- `worst`
- `sort`

##### pytest_benchmark_generate_machine_info

##### pytest_benchmark_generate_commit_info

**Param√®tres :**

- `config`

##### pytest_benchmark_generate_json

**Param√®tres :**

- `config`
- `benchmarks`
- `include_data`
- `machine_info`
- `commit_info`

##### benchmark

**Param√®tres :**

- `request`

##### benchmark_weave

**Param√®tres :**

- `benchmark`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_makereport

**Param√®tres :**

- `item`
- `call`

##### pytest_configure

**Param√®tres :**

- `config`

---

### session

#### Classes

##### PerformanceRegression

##### BenchmarkSession

**M√©thodes :**

- `__init__()`
- `get_machine_info()`
- `prepare_benchmarks()`
- `save_json()`
- `handle_saving()`
- `handle_loading()`
- `finish()`
- `display()`
- `check_regressions()`
- `display_cprofile()`

#### Fonctions

##### __init__

**Param√®tres :**

- `config`

##### get_machine_info

##### prepare_benchmarks

##### save_json

**Param√®tres :**

- `output_json`

##### handle_saving

##### handle_loading

##### finish

##### display

**Param√®tres :**

- `tr`

##### check_regressions

##### display_cprofile

**Param√®tres :**

- `tr`

---

### stats

#### Classes

##### Stats

**M√©thodes :**

- `__init__()`
- `__bool__()`
- `__nonzero__()`
- `as_dict()`
- `update()`
- `sorted_data()`
- `total()`
- `min()`
- `max()`
- `mean()`
- `stddev()`
- `stddev_outliers()`
- `rounds()`
- `median()`
- `ld15iqr()`
- `hd15iqr()`
- `q1()`
- `q3()`
- `iqr()`
- `iqr_outliers()`
- `outliers()`
- `ops()`

##### Metadata

**M√©thodes :**

- `__init__()`
- `__bool__()`
- `__nonzero__()`
- `get()`
- `__getitem__()`
- `has_error()`
- `as_dict()`
- `update()`

#### Fonctions

##### normalize_stats

**Param√®tres :**

- `stats`

##### __init__

##### __bool__

##### __nonzero__

##### as_dict

##### update

**Param√®tres :**

- `duration`

##### sorted_data

##### total

##### min

##### max

##### mean

##### stddev

##### stddev_outliers

Count of StdDev outliers: what's beyond (Mean - StdDev, Mean - StdDev)

##### rounds

##### median

##### ld15iqr

Tukey-style Lowest Datum within 1.5 IQR under Q1.

##### hd15iqr

Tukey-style Highest Datum within 1.5 IQR over Q3.

##### q1

##### q3

##### iqr

##### iqr_outliers

Count of Tukey outliers: what's beyond (Q1 - 1.5IQR, Q3 + 1.5IQR)

##### outliers

##### ops

##### __init__

**Param√®tres :**

- `fixture`
- `iterations`
- `options`

##### __bool__

##### __nonzero__

##### get

**Param√®tres :**

- `key`
- `default`

##### __getitem__

**Param√®tres :**

- `key`

##### has_error

##### as_dict

**Param√®tres :**

- `include_data`
- `flat`
- `stats`
- `cprofile`

##### update

**Param√®tres :**

- `duration`

---

### table

#### Classes

##### TableResults

**M√©thodes :**

- `__init__()`
- `display()`

#### Fonctions

##### compute_baseline_scale

**Param√®tres :**

- `baseline`
- `value`
- `width`

##### __init__

**Param√®tres :**

- `columns`
- `sort`
- `histogram`
- `name_format`
- `logger`
- `scale_unit`

##### display

**Param√®tres :**

- `tr`
- `groups`
- `progress_reporter`

---

### timers

#### Fonctions

##### compute_timer_precision

**Param√®tres :**

- `timer`

##### monotonic

---

### utils

#### Classes

##### SecondsDecimal

**M√©thodes :**

- `__float__()`
- `__str__()`
- `as_string()`

##### NameWrapper

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`

##### Fallback

**M√©thodes :**

- `__init__()`
- `__call__()`
- `register()`

##### RegressionCheck

**M√©thodes :**

- `__init__()`
- `fails()`

##### PercentageRegressionCheck

**M√©thodes :**

- `compute()`

##### DifferenceRegressionCheck

**M√©thodes :**

- `compute()`

##### cached_property

**M√©thodes :**

- `__init__()`
- `__get__()`

##### SafeJSONEncoder

**M√©thodes :**

- `default()`

#### Fonctions

##### get_tag

**Param√®tres :**

- `project_name`

##### get_machine_id

##### get_project_name

##### get_project_name_git

##### get_project_name_hg

##### in_any_parent

**Param√®tres :**

- `name`
- `path`

##### subprocess_output

**Param√®tres :**

- `cmd`

##### get_commit_info

**Param√®tres :**

- `project_name`

##### get_current_time

##### first_or_value

**Param√®tres :**

- `obj`
- `value`

##### short_filename

**Param√®tres :**

- `path`
- `machine_id`

##### load_timer

**Param√®tres :**

- `string`

##### parse_compare_fail

**Param√®tres :**

- `string`
- `rex`

##### parse_cprofile_loops

**Param√®tres :**

- `string`

##### parse_warmup

**Param√®tres :**

- `string`

##### name_formatter_short

**Param√®tres :**

- `bench`

##### name_formatter_normal

**Param√®tres :**

- `bench`

##### name_formatter_long

**Param√®tres :**

- `bench`

##### name_formatter_trial

**Param√®tres :**

- `bench`

##### parse_name_format

**Param√®tres :**

- `string`

##### parse_timer

**Param√®tres :**

- `string`

##### parse_sort

**Param√®tres :**

- `string`

##### parse_columns

**Param√®tres :**

- `string`

##### parse_rounds

**Param√®tres :**

- `string`

##### parse_seconds

**Param√®tres :**

- `string`

##### parse_save

**Param√®tres :**

- `string`

##### _parse_hosts

**Param√®tres :**

- `storage_url`
- `netrc_file`

##### parse_elasticsearch_storage

**Param√®tres :**

- `string`
- `default_index`
- `default_doctype`
- `netrc_file`

##### load_storage

**Param√®tres :**

- `storage`

##### time_unit

**Param√®tres :**

- `value`

##### operations_unit

**Param√®tres :**

- `value`

##### format_time

**Param√®tres :**

- `value`

##### funcname

**Param√®tres :**

- `f`

##### clonefunc

Deep clone the given function to create a new one.

By default, the PyPy JIT specializes the assembler based on f.__code__:
clonefunc makes sure that you will get a new function with a **different**
__code__, so that PyPy will produce independent assembler. This is useful
e.g. for benchmarks and microbenchmarks, so you can make sure to compare
apples to apples.

Use it with caution: if abused, this might easily produce an explosion of
produced assembler.

**Param√®tres :**

- `f`

##### consistent_dumps

**Param√®tres :**

- `value`

##### safe_dumps

**Param√®tres :**

- `obj`

##### report_progress

**Param√®tres :**

- `iterable`
- `terminal_reporter`
- `format_string`

##### report_noprogress

**Param√®tres :**

- `iterable`

##### report_online_progress

**Param√®tres :**

- `progress_reporter`
- `tr`
- `line`

##### slugify

**Param√®tres :**

- `name`

##### get_cprofile_functions

Convert pstats structure to list of sorted dicts about each function.

**Param√®tres :**

- `stats`

##### __float__

##### __str__

##### as_string

##### __init__

**Param√®tres :**

- `target`

##### __str__

##### __repr__

##### __init__

**Param√®tres :**

- `fallback`
- `exceptions`

##### __call__

##### register

**Param√®tres :**

- `other`

##### __init__

**Param√®tres :**

- `field`
- `threshold`

##### fails

**Param√®tres :**

- `current`
- `compared`

##### compute

**Param√®tres :**

- `current`
- `compared`

##### compute

**Param√®tres :**

- `current`
- `compared`

##### __init__

**Param√®tres :**

- `func`

##### __get__

**Param√®tres :**

- `obj`
- `cls`

##### default

**Param√®tres :**

- `o`

##### progress_reporting_wrapper

---

### .!25587!__init__

---

### .!25592!__main__

---

### .!25602!compat

---

### .!25609!fixture

---

### .!25613!histogram

---

### .!25619!hookspec

---

### .!25624!logger

---

### .!25630!plugin

---

### .!25634!session

---

### .!25640!stats

---

### .!25647!table

---

### .!25652!timers

---

### .!25656!utils

---

### elasticsearch

#### Classes

##### BenchmarkJSONSerializer

**M√©thodes :**

- `default()`

##### ElasticsearchStorage

**M√©thodes :**

- `__init__()`
- `__str__()`
- `location()`
- `query()`
- `load()`
- `_search()`
- `_benchmark_from_es_record()`
- `_run_info_from_es_record()`
- `_group_by_commit_and_time()`
- `load_benchmarks()`
- `save()`
- `_create_index()`

#### Fonctions

##### _mask_hosts

**Param√®tres :**

- `hosts`

##### default

**Param√®tres :**

- `data`

##### __init__

**Param√®tres :**

- `hosts`
- `index`
- `doctype`
- `project_name`
- `logger`
- `default_machine_id`

##### __str__

##### location

##### query

Returns sorted records names (ids) that corresponds with project.

##### load

Yield key and content of records that corresponds with project name.

**Param√®tres :**

- `id_prefix`

##### _search

**Param√®tres :**

- `project`
- `id_prefix`

##### _benchmark_from_es_record

**Param√®tres :**

- `source_es_record`

##### _run_info_from_es_record

**Param√®tres :**

- `source_es_record`

##### _group_by_commit_and_time

**Param√®tres :**

- `hits`

##### load_benchmarks

Yield benchmarks that corresponds with project. Put path and
source (uncommon part of path) to benchmark dict.

##### save

**Param√®tres :**

- `output_json`
- `save`

##### _create_index

---

### file

#### Classes

##### FileStorage

**M√©thodes :**

- `__init__()`
- `__str__()`
- `location()`
- `get()`
- `_next_num()`
- `save()`
- `query()`
- `load()`
- `load_benchmarks()`

#### Fonctions

##### __init__

**Param√®tres :**

- `path`
- `logger`
- `default_machine_id`

##### __str__

##### location

##### get

**Param√®tres :**

- `name`

##### _next_num

##### save

**Param√®tres :**

- `output_json`
- `save`

##### query

##### load

##### load_benchmarks

---

### .!25666!elasticsearch

---

### .!25671!file

---

### .!25676!__init__

---

### __main__

---

### api

API for the command-line I{pyflakes} tool.

#### Fonctions

##### check

Check the Python source given by C{codeString} for flakes.

@param codeString: The Python source to check.
@type codeString: C{str}

@param filename: The name of the file the source came from, used to report
    errors.
@type filename: C{str}

@param reporter: A L{Reporter} instance, where errors and warnings will be
    reported.

@return: The number of warnings emitted.
@rtype: C{int}

**Param√®tres :**

- `codeString`
- `filename`
- `reporter`

##### checkPath

Check the given path, printing out any warnings detected.

@param reporter: A L{Reporter} instance, where errors and warnings will be
    reported.

@return: the number of warnings printed

**Param√®tres :**

- `filename`
- `reporter`

##### isPythonFile

Return True if filename points to a Python file.

**Param√®tres :**

- `filename`

##### iterSourceCode

Iterate over all Python source files in C{paths}.

@param paths: A list of paths.  Directories will be recursed into and
    any .py files found will be yielded.  Any non-directories will be
    yielded as-is.

**Param√®tres :**

- `paths`

##### checkRecursive

Recursively check all source files in C{paths}.

@param paths: A list of paths to Python source files and directories
    containing Python source files.
@param reporter: A L{Reporter} where all of the warnings and errors
    will be reported to.
@return: The number of warnings found.

**Param√®tres :**

- `paths`
- `reporter`

##### _exitOnSignal

Handles a signal with sys.exit.

Some of these signals (SIGPIPE, for example) don't exist or are invalid on
Windows. So, ignore errors that might arise.

**Param√®tres :**

- `sigName`
- `message`

##### _get_version

Retrieve and format package version along with python version & OS used

##### main

Entry point for the script "pyflakes".

**Param√®tres :**

- `prog`
- `args`

##### handler

**Param√®tres :**

- `sig`
- `f`

---

### .!25829!api

---

### checker

Main module.

Implement the central Checker class.
Also, it models the Bindings and Scopes.

#### Classes

##### _FieldsOrder

Fix order of AST node fields.

**M√©thodes :**

- `_get_fields()`
- `__missing__()`

##### Binding

Represents the binding of a value to a name.

The checker uses this to keep track of which names have been bound and
which names have not. See L{Assignment} for a special type of binding that
is checked with stricter rules.

@ivar used: pair of (L{Scope}, node) indicating the scope and
            the node that this binding was last used.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `__repr__()`
- `redefines()`

##### Definition

A binding that defines a function or a class.

**M√©thodes :**

- `redefines()`

##### Builtin

A definition created for all Python builtins.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### UnhandledKeyType

A dictionary key of a type that we cannot or do not check for duplicates.

##### VariableKey

A dictionary key which is a variable.

@ivar item: The variable AST object.

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `__hash__()`

##### Importation

A binding created by an import statement.

@ivar fullName: The complete name given to the import statement,
    possibly including multiple dotted components.
@type fullName: C{str}

**M√©thodes :**

- `__init__()`
- `redefines()`
- `_has_alias()`
- `source_statement()`
- `__str__()`

##### SubmoduleImportation

A binding created by a submodule import statement.

A submodule import is a special case where the root module is implicitly
imported, without an 'as' clause, and the submodule is also imported.
Python does not restrict which attributes of the root module may be used.

This class is only used when the submodule import is without an 'as' clause.

pyflakes handles this case by registering the root module name in the scope,
allowing any attribute of the root module to be accessed.

RedefinedWhileUnused is suppressed in `redefines` unless the submodule
name is also the same, to avoid false positives.

**M√©thodes :**

- `__init__()`
- `redefines()`
- `__str__()`
- `source_statement()`

##### ImportationFrom

**M√©thodes :**

- `__init__()`
- `__str__()`
- `source_statement()`

##### StarImportation

A binding created by a 'from x import *' statement.

**M√©thodes :**

- `__init__()`
- `source_statement()`
- `__str__()`

##### FutureImportation

A binding created by a from `__future__` import statement.

`__future__` imports are implicitly used.

**M√©thodes :**

- `__init__()`

##### Argument

Represents binding a name as an argument.

##### Assignment

Represents binding a name with an explicit assignment.

The checker will raise warnings for any Assignment that isn't used. Also,
the checker does not consider assignments in tuple/list unpacking to be
Assignments, rather it treats them as simple Bindings.

##### NamedExprAssignment

Represents binding a name with an assignment expression.

##### Annotation

Represents binding a name to a type without an associated value.

As long as this name is not assigned a value in another binding, it is considered
undefined for most purposes. One notable exception is using the name as a type
annotation.

**M√©thodes :**

- `redefines()`

##### FunctionDefinition

##### ClassDefinition

##### ExportBinding

A binding created by an C{__all__} assignment.  If the names in the list
can be determined statically, they will be treated as names for export and
additional checking applied to them.

The only recognized C{__all__} assignment via list/tuple concatenation is in the
following format:

    __all__ = ['a'] + ['b'] + ['c']

Names which are imported and not otherwise used but appear in the value of
C{__all__} will not have an unused import warning reported for them.

**M√©thodes :**

- `__init__()`

##### Scope

**M√©thodes :**

- `__repr__()`

##### ClassScope

**M√©thodes :**

- `__init__()`

##### FunctionScope

I represent a name scope for a function.

@ivar globals: Names declared 'global' in this function.

**M√©thodes :**

- `__init__()`
- `unused_assignments()`
- `unused_annotations()`

##### TypeScope

##### GeneratorScope

##### ModuleScope

Scope for a module.

##### DoctestScope

Scope for a doctest.

##### DetectClassScopedMagic

##### AnnotationState

##### Checker

I check the cleanliness and sanity of Python code.

**M√©thodes :**

- `__init__()`
- `deferFunction()`
- `_run_deferred()`
- `_in_doctest()`
- `futuresAllowed()`
- `futuresAllowed()`
- `annotationsFutureEnabled()`
- `annotationsFutureEnabled()`
- `scope()`
- `in_scope()`
- `checkDeadScopes()`
- `report()`
- `getParent()`
- `getCommonAncestor()`
- `descendantOf()`
- `_getAncestor()`
- `getScopeNode()`
- `differentForks()`
- `addBinding()`
- `_unknown_handler()`
- `getNodeHandler()`
- `handleNodeLoad()`
- `handleNodeStore()`
- `handleNodeDelete()`
- `_enter_annotation()`
- `_in_postponed_annotation()`
- `handleChildren()`
- `isLiteralTupleUnpacking()`
- `isDocstring()`
- `getDocstring()`
- `handleNode()`
- `handleDoctests()`
- `handleStringAnnotation()`
- `handle_annotation_always_deferred()`
- `handleAnnotation()`
- `ignore()`
- `SUBSCRIPT()`
- `_handle_string_dot_format()`
- `CALL()`
- `_handle_percent_format()`
- `BINOP()`
- `CONSTANT()`
- `RAISE()`
- `JOINEDSTR()`
- `TEMPLATESTR()`
- `DICT()`
- `IF()`
- `ASSERT()`
- `GLOBAL()`
- `GENERATOREXP()`
- `NAME()`
- `CONTINUE()`
- `RETURN()`
- `YIELD()`
- `FUNCTIONDEF()`
- `LAMBDA()`
- `ARGUMENTS()`
- `ARG()`
- `CLASSDEF()`
- `AUGASSIGN()`
- `TUPLE()`
- `IMPORT()`
- `IMPORTFROM()`
- `TRY()`
- `EXCEPTHANDLER()`
- `ANNASSIGN()`
- `COMPARE()`
- `_match_target()`
- `_type_param_scope()`
- `TYPEVAR()`
- `TYPEALIAS()`

#### Fonctions

##### getAlternatives

**Param√®tres :**

- `n`

##### _is_singleton

**Param√®tres :**

- `node`

##### _is_tuple_constant

**Param√®tres :**

- `node`

##### _is_constant

**Param√®tres :**

- `node`

##### _is_const_non_singleton

**Param√®tres :**

- `node`

##### _is_name_or_attr

**Param√®tres :**

- `node`
- `name`

##### _must_match

**Param√®tres :**

- `regex`
- `string`
- `pos`

##### parse_percent_format

Parses the string component of a `'...' % ...` format call

Copied from https://github.com/asottile/pyupgrade at v1.20.1

**Param√®tres :**

- `s`

##### iter_child_nodes

Yield all direct child nodes of *node*, that is, all fields that
are nodes and all items of fields that are lists of nodes.

:param node:          AST node to be iterated upon
:param omit:          String or tuple of strings denoting the
                      attributes of the node to be omitted from
                      further parsing
:param _fields_order: Order of AST node fields

**Param√®tres :**

- `node`
- `omit`
- `_fields_order`

##### convert_to_value

**Param√®tres :**

- `item`

##### is_notimplemented_name_node

**Param√®tres :**

- `node`

##### getNodeName

**Param√®tres :**

- `node`

##### _is_typing_helper

Internal helper to determine whether or not something is a member of a
typing module. This is used as part of working out whether we are within a
type annotation context.

Note: you probably don't want to use this function directly. Instead see the
utils below which wrap it (`_is_typing` and `_is_any_typing_member`).

**Param√®tres :**

- `node`
- `is_name_match_fn`
- `scope_stack`

##### _is_typing

Determine whether `node` represents the member of a typing module specified
by `typing_attr`.

This is used as part of working out whether we are within a type annotation
context.

**Param√®tres :**

- `node`
- `typing_attr`
- `scope_stack`

##### _is_any_typing_member

Determine whether `node` represents any member of a typing module.

This is used as part of working out whether we are within a type annotation
context.

**Param√®tres :**

- `node`
- `scope_stack`

##### is_typing_overload

**Param√®tres :**

- `value`
- `scope_stack`

##### in_annotation

**Param√®tres :**

- `func`

##### in_string_annotation

**Param√®tres :**

- `func`

##### _parse_inner

##### _get_fields

**Param√®tres :**

- `node_class`

##### __missing__

**Param√®tres :**

- `node_class`

##### __init__

**Param√®tres :**

- `name`
- `source`

##### __str__

##### __repr__

##### redefines

**Param√®tres :**

- `other`

##### redefines

**Param√®tres :**

- `other`

##### __init__

**Param√®tres :**

- `name`

##### __repr__

##### __init__

**Param√®tres :**

- `item`

##### __eq__

**Param√®tres :**

- `compare`

##### __hash__

##### __init__

**Param√®tres :**

- `name`
- `source`
- `full_name`

##### redefines

**Param√®tres :**

- `other`

##### _has_alias

Return whether importation needs an as clause.

##### source_statement

Generate a source statement equivalent to the import.

##### __str__

Return import full name with alias.

##### __init__

**Param√®tres :**

- `name`
- `source`

##### redefines

**Param√®tres :**

- `other`

##### __str__

##### source_statement

##### __init__

**Param√®tres :**

- `name`
- `source`
- `module`
- `real_name`

##### __str__

Return import full name with alias.

##### source_statement

##### __init__

**Param√®tres :**

- `name`
- `source`

##### source_statement

##### __str__

##### __init__

**Param√®tres :**

- `name`
- `source`
- `scope`

##### redefines

An Annotation doesn't define any name, so it cannot redefine one.

**Param√®tres :**

- `other`

##### __init__

**Param√®tres :**

- `name`
- `source`
- `scope`

##### __repr__

##### __init__

##### __init__

##### unused_assignments

Return a generator for the assignments which have not been used.

##### unused_annotations

Return a generator for the annotations which have not been used.

##### _bare_name_is_attr

**Param√®tres :**

- `name`

##### _module_scope_is_typing

**Param√®tres :**

- `name`

##### in_annotation_func

##### in_annotation_func

##### __init__

**Param√®tres :**

- `tree`
- `filename`
- `builtins`
- `withDoctest`
- `file_tokens`

##### deferFunction

Schedule a function handler to be called just before completion.

This is used for handling function bodies, which must be deferred
because code later in the file might modify the global scope. When
`callable` is called, the scope at the time this is called will be
restored, however it will contain any new bindings added to it.

**Param√®tres :**

- `callable`

##### _run_deferred

##### _in_doctest

##### futuresAllowed

##### futuresAllowed

**Param√®tres :**

- `value`

##### annotationsFutureEnabled

##### annotationsFutureEnabled

**Param√®tres :**

- `value`

##### scope

##### in_scope

**Param√®tres :**

- `cls`

##### checkDeadScopes

Look at scopes which have been fully examined and report names in them
which were imported but unused.

##### report

**Param√®tres :**

- `messageClass`

##### getParent

**Param√®tres :**

- `node`

##### getCommonAncestor

**Param√®tres :**

- `lnode`
- `rnode`
- `stop`

##### descendantOf

**Param√®tres :**

- `node`
- `ancestors`
- `stop`

##### _getAncestor

**Param√®tres :**

- `node`
- `ancestor_type`

##### getScopeNode

**Param√®tres :**

- `node`

##### differentForks

True, if lnode and rnode are located on different forks of IF/TRY

**Param√®tres :**

- `lnode`
- `rnode`

##### addBinding

Called when a binding is altered.

- `node` is the statement responsible for the change
- `value` is the new value, a Binding instance

**Param√®tres :**

- `node`
- `value`

##### _unknown_handler

**Param√®tres :**

- `node`

##### getNodeHandler

**Param√®tres :**

- `node_class`

##### handleNodeLoad

**Param√®tres :**

- `node`
- `parent`

##### handleNodeStore

**Param√®tres :**

- `node`

##### handleNodeDelete

**Param√®tres :**

- `node`

##### _enter_annotation

**Param√®tres :**

- `ann_type`

##### _in_postponed_annotation

##### handleChildren

**Param√®tres :**

- `tree`
- `omit`

##### isLiteralTupleUnpacking

**Param√®tres :**

- `node`

##### isDocstring

Determine if the given node is a docstring, as long as it is at the
correct place in the node tree.

**Param√®tres :**

- `node`

##### getDocstring

**Param√®tres :**

- `node`

##### handleNode

**Param√®tres :**

- `node`
- `parent`

##### handleDoctests

**Param√®tres :**

- `node`

##### handleStringAnnotation

**Param√®tres :**

- `s`
- `node`
- `ref_lineno`
- `ref_col_offset`
- `err`

##### handle_annotation_always_deferred

**Param√®tres :**

- `annotation`
- `parent`

##### handleAnnotation

**Param√®tres :**

- `annotation`
- `node`

##### ignore

**Param√®tres :**

- `node`

##### SUBSCRIPT

**Param√®tres :**

- `node`

##### _handle_string_dot_format

**Param√®tres :**

- `node`

##### CALL

**Param√®tres :**

- `node`

##### _handle_percent_format

**Param√®tres :**

- `node`

##### BINOP

**Param√®tres :**

- `node`

##### CONSTANT

**Param√®tres :**

- `node`

##### RAISE

**Param√®tres :**

- `node`

##### JOINEDSTR

**Param√®tres :**

- `node`

##### TEMPLATESTR

**Param√®tres :**

- `node`

##### DICT

**Param√®tres :**

- `node`

##### IF

**Param√®tres :**

- `node`

##### ASSERT

**Param√®tres :**

- `node`

##### GLOBAL

Keep track of globals declarations.

**Param√®tres :**

- `node`

##### GENERATOREXP

**Param√®tres :**

- `node`

##### NAME

Handle occurrence of Name (which can be a load/store/delete access.)

**Param√®tres :**

- `node`

##### CONTINUE

**Param√®tres :**

- `node`

##### RETURN

**Param√®tres :**

- `node`

##### YIELD

**Param√®tres :**

- `node`

##### FUNCTIONDEF

**Param√®tres :**

- `node`

##### LAMBDA

**Param√®tres :**

- `node`

##### ARGUMENTS

**Param√®tres :**

- `node`

##### ARG

**Param√®tres :**

- `node`

##### CLASSDEF

Check names used in a class definition, including its decorators, base
classes, and the body of its definition.  Additionally, add its name to
the current scope.

**Param√®tres :**

- `node`

##### AUGASSIGN

**Param√®tres :**

- `node`

##### TUPLE

**Param√®tres :**

- `node`

##### IMPORT

**Param√®tres :**

- `node`

##### IMPORTFROM

**Param√®tres :**

- `node`

##### TRY

**Param√®tres :**

- `node`

##### EXCEPTHANDLER

**Param√®tres :**

- `node`

##### ANNASSIGN

**Param√®tres :**

- `node`

##### COMPARE

**Param√®tres :**

- `node`

##### _match_target

**Param√®tres :**

- `node`

##### _type_param_scope

**Param√®tres :**

- `node`

##### TYPEVAR

**Param√®tres :**

- `node`

##### TYPEALIAS

**Param√®tres :**

- `node`

##### _add_to_names

**Param√®tres :**

- `container`

##### on_conditional_branch

Return `True` if node is part of a conditional body.

##### _add_key

Returns True if there is an error which should early-exit

**Param√®tres :**

- `fmtkey`

##### runFunction

---

### messages

Provide the class Message and its subclasses.

#### Classes

##### Message

**M√©thodes :**

- `__init__()`
- `__str__()`

##### UnusedImport

**M√©thodes :**

- `__init__()`

##### RedefinedWhileUnused

**M√©thodes :**

- `__init__()`

##### ImportShadowedByLoopVar

**M√©thodes :**

- `__init__()`

##### ImportStarNotPermitted

**M√©thodes :**

- `__init__()`

##### ImportStarUsed

**M√©thodes :**

- `__init__()`

##### ImportStarUsage

**M√©thodes :**

- `__init__()`

##### UndefinedName

**M√©thodes :**

- `__init__()`

##### DoctestSyntaxError

**M√©thodes :**

- `__init__()`

##### UndefinedExport

**M√©thodes :**

- `__init__()`

##### UndefinedLocal

**M√©thodes :**

- `__init__()`

##### DuplicateArgument

**M√©thodes :**

- `__init__()`

##### MultiValueRepeatedKeyLiteral

**M√©thodes :**

- `__init__()`

##### MultiValueRepeatedKeyVariable

**M√©thodes :**

- `__init__()`

##### LateFutureImport

##### FutureFeatureNotDefined

An undefined __future__ feature name was imported.

**M√©thodes :**

- `__init__()`

##### UnusedVariable

Indicates that a variable has been explicitly assigned to but not actually
used.

**M√©thodes :**

- `__init__()`

##### UnusedAnnotation

Indicates that a variable has been explicitly annotated to but not actually
used.

**M√©thodes :**

- `__init__()`

##### UnusedIndirectAssignment

A `global` or `nonlocal` statement where the name is never reassigned

**M√©thodes :**

- `__init__()`

##### ReturnOutsideFunction

Indicates a return statement outside of a function/method.

##### YieldOutsideFunction

Indicates a yield or yield from statement outside of a function/method.

##### ContinueOutsideLoop

Indicates a continue statement outside of a while or for loop.

##### BreakOutsideLoop

Indicates a break statement outside of a while or for loop.

##### DefaultExceptNotLast

Indicates an except: block as not the last exception handler.

##### TwoStarredExpressions

Two or more starred expressions in an assignment (a, *b, *c = d).

##### TooManyExpressionsInStarredAssignment

Too many expressions in an assignment with star-unpacking

##### IfTuple

Conditional test is a non-empty tuple literal, which are always True.

##### AssertTuple

Assertion test is a non-empty tuple literal, which are always True.

##### ForwardAnnotationSyntaxError

**M√©thodes :**

- `__init__()`

##### RaiseNotImplemented

##### InvalidPrintSyntax

##### IsLiteral

##### FStringMissingPlaceholders

##### TStringMissingPlaceholders

##### StringDotFormatExtraPositionalArguments

**M√©thodes :**

- `__init__()`

##### StringDotFormatExtraNamedArguments

**M√©thodes :**

- `__init__()`

##### StringDotFormatMissingArgument

**M√©thodes :**

- `__init__()`

##### StringDotFormatMixingAutomatic

##### StringDotFormatInvalidFormat

**M√©thodes :**

- `__init__()`

##### PercentFormatInvalidFormat

**M√©thodes :**

- `__init__()`

##### PercentFormatMixedPositionalAndNamed

##### PercentFormatUnsupportedFormatCharacter

**M√©thodes :**

- `__init__()`

##### PercentFormatPositionalCountMismatch

**M√©thodes :**

- `__init__()`

##### PercentFormatExtraNamedArguments

**M√©thodes :**

- `__init__()`

##### PercentFormatMissingArgument

**M√©thodes :**

- `__init__()`

##### PercentFormatExpectedMapping

##### PercentFormatExpectedSequence

##### PercentFormatStarRequiresSequence

#### Fonctions

##### __init__

**Param√®tres :**

- `filename`
- `loc`

##### __str__

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`
- `orig_loc`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`
- `orig_loc`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `modname`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `modname`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`
- `from_list`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `position`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`
- `orig_loc`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `key`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `key`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `names`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `names`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `name`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `annotation`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `extra_positions`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `extra_keywords`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `missing_arguments`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `error`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `error`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `c`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `n_placeholders`
- `n_substitutions`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `extra_keywords`

##### __init__

**Param√®tres :**

- `filename`
- `loc`
- `missing_arguments`

---

### reporter

Provide the Reporter class.

#### Classes

##### Reporter

Formats the results of pyflakes checks to users.

**M√©thodes :**

- `__init__()`
- `unexpectedError()`
- `syntaxError()`
- `flake()`

#### Fonctions

##### _makeDefaultReporter

Make a reporter that can be used when no reporter is specified.

##### __init__

Construct a L{Reporter}.

@param warningStream: A file-like object where warnings will be
    written to.  The stream's C{write} method must accept unicode.
    C{sys.stdout} is a good value.
@param errorStream: A file-like object where error output will be
    written to.  The stream's C{write} method must accept unicode.
    C{sys.stderr} is a good value.

**Param√®tres :**

- `warningStream`
- `errorStream`

##### unexpectedError

An unexpected error occurred trying to process C{filename}.

@param filename: The path to a file that we could not process.
@ptype filename: C{unicode}
@param msg: A message explaining the problem.
@ptype msg: C{unicode}

**Param√®tres :**

- `filename`
- `msg`

##### syntaxError

There was a syntax error in C{filename}.

@param filename: The path to the file with the syntax error.
@ptype filename: C{unicode}
@param msg: An explanation of the syntax error.
@ptype msg: C{unicode}
@param lineno: The line number where the syntax error occurred.
@ptype lineno: C{int}
@param offset: The column on which the syntax error occurred, or None.
@ptype offset: C{int}
@param text: The source code containing the syntax error.
@ptype text: C{unicode}

**Param√®tres :**

- `filename`
- `msg`
- `lineno`
- `offset`
- `text`

##### flake

pyflakes found something wrong with the code.

@param: A L{pyflakes.messages.Message}.

**Param√®tres :**

- `message`

---

### .!25819!__init__

---

### .!25823!__main__

---

### .!25834!checker

---

### .!25838!messages

---

### .!25842!reporter

---

### pyflakes

Implementation of the command-line I{pyflakes} tool.

---

### .!25855!pyflakes

---

### harness

#### Classes

##### TestCase

**M√©thodes :**

- `flakes()`

#### Fonctions

##### flakes

**Param√®tres :**

- `input`

---

### test_api

Tests for L{pyflakes.scripts.pyflakes}.

#### Classes

##### Node

Mock an AST node.

**M√©thodes :**

- `__init__()`

##### SysStreamCapturing

Context manager capturing sys.stdin, sys.stdout and sys.stderr.

The file handles are replaced with a StringIO object.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### LoggingReporter

Implementation of Reporter that just appends any error to a list.

**M√©thodes :**

- `__init__()`
- `flake()`
- `unexpectedError()`
- `syntaxError()`

##### TestIterSourceCode

Tests for L{iterSourceCode}.

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `makeEmptyFile()`
- `test_emptyDirectory()`
- `test_singleFile()`
- `test_onlyPythonSource()`
- `test_recurses()`
- `test_shebang()`
- `test_multipleDirectories()`
- `test_explicitFiles()`

##### TestReporter

Tests for L{Reporter}.

**M√©thodes :**

- `test_syntaxError()`
- `test_syntaxErrorNoOffset()`
- `test_syntaxErrorNoText()`
- `test_multiLineSyntaxError()`
- `test_unexpectedError()`
- `test_flake()`

##### CheckTests

Tests for L{check} and L{checkPath} which check a file for flakes.

**M√©thodes :**

- `makeTempFile()`
- `assertHasErrors()`
- `getErrors()`
- `test_legacyScript()`
- `test_missingTrailingNewline()`
- `test_checkPathNonExisting()`
- `test_multilineSyntaxError()`
- `test_eofSyntaxError()`
- `test_eofSyntaxErrorWithTab()`
- `test_nonDefaultFollowsDefaultSyntaxError()`
- `test_nonKeywordAfterKeywordSyntaxError()`
- `test_invalidEscape()`
- `test_permissionDenied()`
- `test_pyflakesWarning()`
- `test_encodedFileUTF8()`
- `test_CRLFLineEndings()`
- `test_misencodedFileUTF8()`
- `test_misencodedFileUTF16()`
- `test_checkRecursive()`
- `test_stdinReportsErrors()`

##### IntegrationTests

Tests of the pyflakes script that actually spawn the script.

**M√©thodes :**

- `setUp()`
- `tearDown()`
- `getPyflakesBinary()`
- `runPyflakes()`
- `test_goodFile()`
- `test_fileWithFlakes()`
- `test_errors_io()`
- `test_errors_syntax()`
- `test_readFromStdin()`

##### TestMain

Tests of the pyflakes main function.

**M√©thodes :**

- `runPyflakes()`

#### Fonctions

##### withStderrTo

Call C{f} with C{sys.stderr} redirected to C{stderr}.

**Param√®tres :**

- `stderr`
- `f`

##### __init__

**Param√®tres :**

- `lineno`
- `col_offset`

##### __init__

**Param√®tres :**

- `stdin`

##### __enter__

##### __exit__

##### __init__

Construct a C{LoggingReporter}.

@param log: A list to append log messages to.

**Param√®tres :**

- `log`

##### flake

**Param√®tres :**

- `message`

##### unexpectedError

**Param√®tres :**

- `filename`
- `message`

##### syntaxError

**Param√®tres :**

- `filename`
- `msg`
- `lineno`
- `offset`
- `line`

##### setUp

##### tearDown

##### makeEmptyFile

##### test_emptyDirectory

There are no Python files in an empty directory.

##### test_singleFile

If the directory contains one Python file, C{iterSourceCode} will find
it.

##### test_onlyPythonSource

Files that are not Python source files are not included.

##### test_recurses

If the Python files are hidden deep down in child directories, we will
find them.

##### test_shebang

Find Python files that don't end with `.py`, but contain a Python
shebang.

##### test_multipleDirectories

L{iterSourceCode} can be given multiple directories.  It will recurse
into each of them.

##### test_explicitFiles

If one of the paths given to L{iterSourceCode} is not a directory but
a file, it will include that in its output.

##### test_syntaxError

C{syntaxError} reports that there was a syntax error in the source
file.  It reports to the error stream and includes the filename, line
number, error message, actual line of source and a caret pointing to
where the error is.

##### test_syntaxErrorNoOffset

C{syntaxError} doesn't include a caret pointing to the error if
C{offset} is passed as C{None}.

##### test_syntaxErrorNoText

C{syntaxError} doesn't include text or nonsensical offsets if C{text} is C{None}.

This typically happens when reporting syntax errors from stdin.

##### test_multiLineSyntaxError

If there's a multi-line syntax error, then we only report the last
line.  The offset is adjusted so that it is relative to the start of
the last line.

##### test_unexpectedError

C{unexpectedError} reports an error processing a source file.

##### test_flake

C{flake} reports a code warning from Pyflakes.  It is exactly the
str() of a L{pyflakes.messages.Message}.

##### makeTempFile

Make a temporary file containing C{content} and return a path to it.

**Param√®tres :**

- `content`

##### assertHasErrors

Assert that C{path} causes errors.

@param path: A path to a file to check.
@param errorList: A list of errors expected to be printed to stderr.

**Param√®tres :**

- `path`
- `errorList`

##### getErrors

Get any warnings or errors reported by pyflakes for the file at C{path}.

@param path: The path to a Python file on disk that pyflakes will check.
@return: C{(count, log)}, where C{count} is the number of warnings or
    errors generated, and log is a list of those warnings, presented
    as structured data.  See L{LoggingReporter} for more details.

**Param√®tres :**

- `path`

##### test_legacyScript

##### test_missingTrailingNewline

Source which doesn't end with a newline shouldn't cause any
exception to be raised nor an error indicator to be returned by
L{check}.

##### test_checkPathNonExisting

L{checkPath} handles non-existing files.

##### test_multilineSyntaxError

Source which includes a syntax error which results in the raised
L{SyntaxError.text} containing multiple lines of source are reported
with only the last line of that source.

##### test_eofSyntaxError

The error reported for source files which end prematurely causing a
syntax error reflects the cause for the syntax error.

##### test_eofSyntaxErrorWithTab

The error reported for source files which end prematurely causing a
syntax error reflects the cause for the syntax error.

##### test_nonDefaultFollowsDefaultSyntaxError

Source which has a non-default argument following a default argument
should include the line number of the syntax error.  However these
exceptions do not include an offset.

##### test_nonKeywordAfterKeywordSyntaxError

Source which has a non-keyword argument after a keyword argument should
include the line number of the syntax error.  However these exceptions
do not include an offset.

##### test_invalidEscape

The invalid escape syntax raises ValueError in Python 2

##### test_permissionDenied

If the source file is not readable, this is reported on standard
error.

##### test_pyflakesWarning

If the source file has a pyflakes warning, this is reported as a
'flake'.

##### test_encodedFileUTF8

If source file declares the correct encoding, no error is reported.

##### test_CRLFLineEndings

Source files with Windows CR LF line endings are parsed successfully.

##### test_misencodedFileUTF8

If a source file contains bytes which cannot be decoded, this is
reported on stderr.

##### test_misencodedFileUTF16

If a source file contains bytes which cannot be decoded, this is
reported on stderr.

##### test_checkRecursive

L{checkRecursive} descends into each directory, finding Python files
and reporting problems.

##### test_stdinReportsErrors

L{check} reports syntax errors from stdin

##### setUp

##### tearDown

##### getPyflakesBinary

Return the path to the pyflakes binary.

##### runPyflakes

Launch a subprocess running C{pyflakes}.

@param paths: Command-line arguments to pass to pyflakes.
@param stdin: Text to use as stdin.
@return: C{(returncode, stdout, stderr)} of the completed pyflakes
    process.

**Param√®tres :**

- `paths`
- `stdin`

##### test_goodFile

When a Python source file is all good, the return code is zero and no
messages are printed to either stdout or stderr.

##### test_fileWithFlakes

When a Python source file has warnings, the return code is non-zero
and the warnings are printed to stdout.

##### test_errors_io

When pyflakes finds errors with the files it's given, (if they don't
exist, say), then the return code is non-zero and the errors are
printed to stderr.

##### test_errors_syntax

When pyflakes finds errors with the files it's given, (if they don't
exist, say), then the return code is non-zero and the errors are
printed to stderr.

##### test_readFromStdin

If no arguments are passed to C{pyflakes} then it reads from stdin.

##### runPyflakes

**Param√®tres :**

- `paths`
- `stdin`

##### evaluate

**Param√®tres :**

- `source`

---

### test_builtin

Tests for detecting redefinition of builtins.

#### Classes

##### TestBuiltins

**M√©thodes :**

- `test_builtin_unbound_local()`
- `test_global_shadowing_builtin()`

#### Fonctions

##### test_builtin_unbound_local

##### test_global_shadowing_builtin

---

### test_code_segment

#### Classes

##### TestCodeSegments

Tests for segments of a module

**M√©thodes :**

- `test_function_segment()`
- `test_class_segment()`
- `test_scope_class()`
- `test_scope_function()`
- `test_scope_async_function()`

#### Fonctions

##### test_function_segment

##### test_class_segment

##### test_scope_class

##### test_scope_function

##### test_scope_async_function

---

### test_dict

Tests for dict duplicate keys Pyflakes behavior.

#### Classes

##### Test

**M√©thodes :**

- `test_duplicate_keys()`
- `test_duplicate_keys_bytes_vs_unicode_py3()`
- `test_duplicate_values_bytes_vs_unicode_py3()`
- `test_multiple_duplicate_keys()`
- `test_duplicate_keys_in_function()`
- `test_duplicate_keys_in_lambda()`
- `test_duplicate_keys_tuples()`
- `test_duplicate_keys_tuples_int_and_float()`
- `test_duplicate_keys_ints()`
- `test_duplicate_keys_bools()`
- `test_duplicate_keys_bools_false()`
- `test_duplicate_keys_none()`
- `test_duplicate_variable_keys()`
- `test_duplicate_variable_values()`
- `test_duplicate_variable_values_same_value()`
- `test_duplicate_key_float_and_int()`
- `test_no_duplicate_key_error_same_value()`
- `test_no_duplicate_key_errors()`
- `test_no_duplicate_keys_tuples_same_first_element()`
- `test_no_duplicate_key_errors_func_call()`
- `test_no_duplicate_key_errors_bool_or_none()`
- `test_no_duplicate_key_errors_ints()`
- `test_no_duplicate_key_errors_vars()`
- `test_no_duplicate_key_errors_tuples()`
- `test_no_duplicate_key_errors_instance_attributes()`

#### Fonctions

##### test_duplicate_keys

##### test_duplicate_keys_bytes_vs_unicode_py3

##### test_duplicate_values_bytes_vs_unicode_py3

##### test_multiple_duplicate_keys

##### test_duplicate_keys_in_function

##### test_duplicate_keys_in_lambda

##### test_duplicate_keys_tuples

##### test_duplicate_keys_tuples_int_and_float

##### test_duplicate_keys_ints

##### test_duplicate_keys_bools

##### test_duplicate_keys_bools_false

##### test_duplicate_keys_none

##### test_duplicate_variable_keys

##### test_duplicate_variable_values

##### test_duplicate_variable_values_same_value

##### test_duplicate_key_float_and_int

These do look like different values, but when it comes to their use as
keys, they compare as equal and so are actually duplicates.
The literal dict {1: 1, 1.0: 1} actually becomes {1.0: 1}.

##### test_no_duplicate_key_error_same_value

##### test_no_duplicate_key_errors

##### test_no_duplicate_keys_tuples_same_first_element

##### test_no_duplicate_key_errors_func_call

##### test_no_duplicate_key_errors_bool_or_none

##### test_no_duplicate_key_errors_ints

##### test_no_duplicate_key_errors_vars

##### test_no_duplicate_key_errors_tuples

##### test_no_duplicate_key_errors_instance_attributes

---

### test_doctests

#### Classes

##### _DoctestMixin

**M√©thodes :**

- `doctestify()`
- `flakes()`

##### Test

**M√©thodes :**

- `test_scope_class()`
- `test_nested_doctest_ignored()`
- `test_global_module_scope_pollution()`
- `test_global_undefined()`
- `test_nested_class()`
- `test_ignore_nested_function()`
- `test_inaccessible_scope_class()`
- `test_importBeforeDoctest()`
- `test_importBeforeAndInDoctest()`
- `test_importInDoctestAndAfter()`
- `test_offsetInDoctests()`
- `test_offsetInLambdasInDoctests()`
- `test_offsetAfterDoctests()`
- `test_syntaxErrorInDoctest()`
- `test_indentationErrorInDoctest()`
- `test_offsetWithMultiLineArgs()`
- `test_doctestCanReferToFunction()`
- `test_doctestCanReferToClass()`
- `test_noOffsetSyntaxErrorInDoctest()`
- `test_singleUnderscoreInDoctest()`
- `test_globalUnderscoreInDoctest()`

##### TestOther

Run TestOther with each test wrapped in a doctest.

##### TestImports

Run TestImports with each test wrapped in a doctest.

##### TestUndefinedNames

Run TestUndefinedNames with each test wrapped in a doctest.

#### Fonctions

##### doctestify

**Param√®tres :**

- `input`

##### flakes

**Param√®tres :**

- `input`

##### test_scope_class

Check that a doctest is given a DoctestScope.

##### test_nested_doctest_ignored

Check that nested doctests are ignored.

##### test_global_module_scope_pollution

Check that global in doctest does not pollute module scope.

##### test_global_undefined

##### test_nested_class

Doctest within nested class are processed.

##### test_ignore_nested_function

Doctest module does not process doctest in nested functions.

##### test_inaccessible_scope_class

Doctest may not access class scope.

##### test_importBeforeDoctest

##### test_importBeforeAndInDoctest

##### test_importInDoctestAndAfter

##### test_offsetInDoctests

##### test_offsetInLambdasInDoctests

##### test_offsetAfterDoctests

##### test_syntaxErrorInDoctest

##### test_indentationErrorInDoctest

##### test_offsetWithMultiLineArgs

##### test_doctestCanReferToFunction

##### test_doctestCanReferToClass

##### test_noOffsetSyntaxErrorInDoctest

##### test_singleUnderscoreInDoctest

##### test_globalUnderscoreInDoctest

---

### test_imports

#### Classes

##### TestImportationObject

**M√©thodes :**

- `test_import_basic()`
- `test_import_as()`
- `test_import_submodule()`
- `test_import_submodule_as()`
- `test_import_submodule_as_source_name()`
- `test_importfrom_relative()`
- `test_importfrom_relative_parent()`
- `test_importfrom_relative_with_module()`
- `test_importfrom_relative_with_module_as()`
- `test_importfrom_member()`
- `test_importfrom_submodule_member()`
- `test_importfrom_member_as()`
- `test_importfrom_submodule_member_as()`
- `test_importfrom_star()`
- `test_importfrom_star_relative()`
- `test_importfrom_future()`
- `test_unusedImport_underscore()`

##### Test

**M√©thodes :**

- `test_unusedImport()`
- `test_unusedImport_relative()`
- `test_aliasedImport()`
- `test_aliasedImportShadowModule()`
- `test_usedImport()`
- `test_usedImport_relative()`
- `test_redefinedWhileUnused()`
- `test_redefinedIf()`
- `test_redefinedIfElse()`
- `test_redefinedTry()`
- `test_redefinedTryExcept()`
- `test_redefinedTryNested()`
- `test_redefinedTryExceptMulti()`
- `test_redefinedTryElse()`
- `test_redefinedTryExceptElse()`
- `test_redefinedTryExceptFinally()`
- `test_redefinedTryExceptElseFinally()`
- `test_redefinedByFunction()`
- `test_redefinedInNestedFunction()`
- `test_redefinedInNestedFunctionTwice()`
- `test_redefinedButUsedLater()`
- `test_redefinedByClass()`
- `test_redefinedBySubclass()`
- `test_redefinedInClass()`
- `test_importInClass()`
- `test_usedInFunction()`
- `test_shadowedByParameter()`
- `test_newAssignment()`
- `test_usedInGetattr()`
- `test_usedInSlice()`
- `test_usedInIfBody()`
- `test_usedInIfConditional()`
- `test_usedInElifConditional()`
- `test_usedInElse()`
- `test_usedInCall()`
- `test_usedInClass()`
- `test_usedInClassBase()`
- `test_notUsedInNestedScope()`
- `test_usedInFor()`
- `test_usedInForElse()`
- `test_redefinedByFor()`
- `test_shadowedByFor()`
- `test_shadowedByForDeep()`
- `test_usedInReturn()`
- `test_usedInOperators()`
- `test_usedInAssert()`
- `test_usedInSubscript()`
- `test_usedInLogic()`
- `test_usedInList()`
- `test_usedInTuple()`
- `test_usedInTry()`
- `test_usedInExcept()`
- `test_redefinedByExcept()`
- `test_usedInRaise()`
- `test_usedInYield()`
- `test_usedInDict()`
- `test_usedInParameterDefault()`
- `test_usedInAttributeAssign()`
- `test_usedInKeywordArg()`
- `test_usedInAssignment()`
- `test_usedInListComp()`
- `test_usedInTryFinally()`
- `test_usedInWhile()`
- `test_usedInGlobal()`
- `test_usedAndGlobal()`
- `test_assignedToGlobal()`
- `test_usedInExec()`
- `test_usedInLambda()`
- `test_shadowedByLambda()`
- `test_usedInSliceObj()`
- `test_unusedInNestedScope()`
- `test_methodsDontUseClassScope()`
- `test_nestedFunctionsNestScope()`
- `test_nestedClassAndFunctionScope()`
- `test_importStar()`
- `test_importStar_relative()`
- `test_localImportStar()`
- `test_packageImport()`
- `test_unusedPackageImport()`
- `test_duplicateSubmoduleImport()`
- `test_differentSubmoduleImport()`
- `test_used_package_with_submodule_import()`
- `test_used_package_with_submodule_import_of_alias()`
- `test_unused_package_with_submodule_import()`
- `test_assignRHSFirst()`
- `test_tryingMultipleImports()`
- `test_nonGlobalDoesNotRedefine()`
- `test_functionsRunLater()`
- `test_functionNamesAreBoundNow()`
- `test_ignoreNonImportRedefinitions()`
- `test_importingForImportError()`
- `test_importedInClass()`
- `test_importUsedInMethodDefinition()`
- `test_futureImport()`
- `test_futureImportFirst()`
- `test_futureImportUsed()`
- `test_futureImportUndefined()`
- `test_futureImportStar()`

##### TestSpecialAll

Tests for suppression of unused import warnings by C{__all__}.

**M√©thodes :**

- `test_ignoredInFunction()`
- `test_ignoredInClass()`
- `test_ignored_when_not_directly_assigned()`
- `test_warningSuppressed()`
- `test_augmentedAssignment()`
- `test_list_concatenation_assignment()`
- `test_tuple_concatenation_assignment()`
- `test_all_with_attributes()`
- `test_all_with_names()`
- `test_all_with_attributes_added()`
- `test_all_mixed_attributes_and_strings()`
- `test_unboundExported()`
- `test_importStarExported()`
- `test_importStarNotExported()`
- `test_usedInGenExp()`
- `test_redefinedByGenExp()`
- `test_usedAsDecorator()`
- `test_usedAsClassDecorator()`

#### Fonctions

##### test_import_basic

##### test_import_as

##### test_import_submodule

##### test_import_submodule_as

##### test_import_submodule_as_source_name

##### test_importfrom_relative

##### test_importfrom_relative_parent

##### test_importfrom_relative_with_module

##### test_importfrom_relative_with_module_as

##### test_importfrom_member

##### test_importfrom_submodule_member

##### test_importfrom_member_as

##### test_importfrom_submodule_member_as

##### test_importfrom_star

##### test_importfrom_star_relative

##### test_importfrom_future

##### test_unusedImport_underscore

The magic underscore var should be reported as unused when used as an
import alias.

##### test_unusedImport

##### test_unusedImport_relative

##### test_aliasedImport

##### test_aliasedImportShadowModule

Imported aliases can shadow the source of the import.

##### test_usedImport

##### test_usedImport_relative

##### test_redefinedWhileUnused

##### test_redefinedIf

Test that importing a module twice within an if
block does raise a warning.

##### test_redefinedIfElse

Test that importing a module twice in if
and else blocks does not raise a warning.

##### test_redefinedTry

Test that importing a module twice in a try block
does raise a warning.

##### test_redefinedTryExcept

Test that importing a module twice in a try
and except block does not raise a warning.

##### test_redefinedTryNested

Test that importing a module twice using a nested
try/except and if blocks does not issue a warning.

##### test_redefinedTryExceptMulti

##### test_redefinedTryElse

##### test_redefinedTryExceptElse

##### test_redefinedTryExceptFinally

##### test_redefinedTryExceptElseFinally

##### test_redefinedByFunction

##### test_redefinedInNestedFunction

Test that shadowing a global name with a nested function definition
generates a warning.

##### test_redefinedInNestedFunctionTwice

Test that shadowing a global name with a nested function definition
generates a warning.

##### test_redefinedButUsedLater

Test that a global import which is redefined locally,
but used later in another scope does not generate a warning.

##### test_redefinedByClass

##### test_redefinedBySubclass

If an imported name is redefined by a class statement which also uses
that name in the bases list, no warning is emitted.

##### test_redefinedInClass

Test that shadowing a global with a class attribute does not produce a
warning.

##### test_importInClass

Test that import within class is a locally scoped attribute.

##### test_usedInFunction

##### test_shadowedByParameter

##### test_newAssignment

##### test_usedInGetattr

##### test_usedInSlice

##### test_usedInIfBody

##### test_usedInIfConditional

##### test_usedInElifConditional

##### test_usedInElse

##### test_usedInCall

##### test_usedInClass

##### test_usedInClassBase

##### test_notUsedInNestedScope

##### test_usedInFor

##### test_usedInForElse

##### test_redefinedByFor

##### test_shadowedByFor

Test that shadowing a global name with a for loop variable generates a
warning.

##### test_shadowedByForDeep

Test that shadowing a global name with a for loop variable nested in a
tuple unpack generates a warning.

##### test_usedInReturn

##### test_usedInOperators

##### test_usedInAssert

##### test_usedInSubscript

##### test_usedInLogic

##### test_usedInList

##### test_usedInTuple

##### test_usedInTry

##### test_usedInExcept

##### test_redefinedByExcept

##### test_usedInRaise

##### test_usedInYield

##### test_usedInDict

##### test_usedInParameterDefault

##### test_usedInAttributeAssign

##### test_usedInKeywordArg

##### test_usedInAssignment

##### test_usedInListComp

##### test_usedInTryFinally

##### test_usedInWhile

##### test_usedInGlobal

A 'global' statement shadowing an unused import should not prevent it
from being reported.

##### test_usedAndGlobal

A 'global' statement shadowing a used import should not cause it to be
reported as unused.

##### test_assignedToGlobal

Binding an import to a declared global should not cause it to be
reported as unused.

##### test_usedInExec

##### test_usedInLambda

##### test_shadowedByLambda

##### test_usedInSliceObj

##### test_unusedInNestedScope

##### test_methodsDontUseClassScope

##### test_nestedFunctionsNestScope

##### test_nestedClassAndFunctionScope

##### test_importStar

Use of import * at module level is reported.

##### test_importStar_relative

Use of import * from a relative import is reported.

##### test_localImportStar

import * is only allowed at module level.

##### test_packageImport

If a dotted name is imported and used, no warning is reported.

##### test_unusedPackageImport

If a dotted name is imported and not used, an unused import warning is
reported.

##### test_duplicateSubmoduleImport

If a submodule of a package is imported twice, an unused import warning
and a redefined while unused warning are reported.

##### test_differentSubmoduleImport

If two different submodules of a package are imported, no duplicate
import warning is reported for the package.

##### test_used_package_with_submodule_import

Usage of package marks submodule imports as used.

##### test_used_package_with_submodule_import_of_alias

Usage of package by alias marks submodule imports as used.

##### test_unused_package_with_submodule_import

When a package and its submodule are imported, only report once.

##### test_assignRHSFirst

##### test_tryingMultipleImports

##### test_nonGlobalDoesNotRedefine

##### test_functionsRunLater

##### test_functionNamesAreBoundNow

##### test_ignoreNonImportRedefinitions

##### test_importingForImportError

##### test_importedInClass

Imports in class scope can be used through self.

##### test_importUsedInMethodDefinition

Method named 'foo' with default args referring to module named 'foo'.

##### test_futureImport

__future__ is special.

##### test_futureImportFirst

__future__ imports must come before anything else.

##### test_futureImportUsed

__future__ is special, but names are injected in the namespace.

##### test_futureImportUndefined

Importing undefined names from __future__ fails.

##### test_futureImportStar

Importing '*' from __future__ fails.

##### test_ignoredInFunction

An C{__all__} definition does not suppress unused import warnings in a
function scope.

##### test_ignoredInClass

An C{__all__} definition in a class does not suppress unused import warnings.

##### test_ignored_when_not_directly_assigned

##### test_warningSuppressed

If a name is imported and unused but is named in C{__all__}, no warning
is reported.

##### test_augmentedAssignment

The C{__all__} variable is defined incrementally.

##### test_list_concatenation_assignment

The C{__all__} variable is defined through list concatenation.

##### test_tuple_concatenation_assignment

The C{__all__} variable is defined through tuple concatenation.

##### test_all_with_attributes

##### test_all_with_names

##### test_all_with_attributes_added

##### test_all_mixed_attributes_and_strings

##### test_unboundExported

If C{__all__} includes a name which is not bound, a warning is emitted.

##### test_importStarExported

Report undefined if import * is used

##### test_importStarNotExported

Report unused import when not needed to satisfy __all__.

##### test_usedInGenExp

Using a global in a generator expression results in no warnings.

##### test_redefinedByGenExp

Re-using a global name as the loop variable for a generator
expression results in a redefinition warning.

##### test_usedAsDecorator

Using a global name in a decorator statement results in no warnings,
but using an undefined name in a decorator statement results in an
undefined name warning.

##### test_usedAsClassDecorator

Using an imported name as a class decorator results in no warnings,
but using an undefined name as a class decorator results in an
undefined name warning.

---

### test_is_literal

#### Classes

##### Test

**M√©thodes :**

- `test_is_str()`
- `test_is_bytes()`
- `test_is_unicode()`
- `test_is_int()`
- `test_is_true()`
- `test_is_false()`
- `test_is_not_str()`
- `test_is_not_bytes()`
- `test_is_not_unicode()`
- `test_is_not_int()`
- `test_is_not_true()`
- `test_is_not_false()`
- `test_left_is_str()`
- `test_left_is_bytes()`
- `test_left_is_unicode()`
- `test_left_is_int()`
- `test_left_is_true()`
- `test_left_is_false()`
- `test_left_is_not_str()`
- `test_left_is_not_bytes()`
- `test_left_is_not_unicode()`
- `test_left_is_not_int()`
- `test_left_is_not_true()`
- `test_left_is_not_false()`
- `test_chained_operators_is_true()`
- `test_chained_operators_is_str()`
- `test_chained_operators_is_true_end()`
- `test_chained_operators_is_str_end()`
- `test_is_tuple_constant()`
- `test_is_tuple_constant_containing_constants()`
- `test_is_tuple_containing_variables_ok()`

#### Fonctions

##### test_is_str

##### test_is_bytes

##### test_is_unicode

##### test_is_int

##### test_is_true

##### test_is_false

##### test_is_not_str

##### test_is_not_bytes

##### test_is_not_unicode

##### test_is_not_int

##### test_is_not_true

##### test_is_not_false

##### test_left_is_str

##### test_left_is_bytes

##### test_left_is_unicode

##### test_left_is_int

##### test_left_is_true

##### test_left_is_false

##### test_left_is_not_str

##### test_left_is_not_bytes

##### test_left_is_not_unicode

##### test_left_is_not_int

##### test_left_is_not_true

##### test_left_is_not_false

##### test_chained_operators_is_true

##### test_chained_operators_is_str

##### test_chained_operators_is_true_end

##### test_chained_operators_is_str_end

##### test_is_tuple_constant

##### test_is_tuple_constant_containing_constants

##### test_is_tuple_containing_variables_ok

---

### test_match

#### Classes

##### TestMatch

**M√©thodes :**

- `test_match_bindings()`
- `test_match_pattern_matched_class()`
- `test_match_placeholder()`
- `test_match_singleton()`
- `test_match_or_pattern()`
- `test_match_star()`
- `test_match_double_star()`
- `test_defined_in_different_branches()`

#### Fonctions

##### test_match_bindings

##### test_match_pattern_matched_class

##### test_match_placeholder

##### test_match_singleton

##### test_match_or_pattern

##### test_match_star

##### test_match_double_star

##### test_defined_in_different_branches

---

### test_other

Tests for various Pyflakes behavior.

#### Classes

##### Test

**M√©thodes :**

- `test_duplicateArgs()`
- `test_localReferencedBeforeAssignment()`
- `test_redefinedInGenerator()`
- `test_redefinedInSetComprehension()`
- `test_redefinedInDictComprehension()`
- `test_redefinedFunction()`
- `test_redefined_function_shadows_variable()`
- `test_redefinedUnderscoreFunction()`
- `test_redefinedUnderscoreImportation()`
- `test_redefinedClassFunction()`
- `test_redefinedIfElseFunction()`
- `test_redefinedIfFunction()`
- `test_redefinedTryExceptFunction()`
- `test_redefinedTryFunction()`
- `test_redefinedIfElseInListComp()`
- `test_functionDecorator()`
- `test_classFunctionDecorator()`
- `test_modernProperty()`
- `test_unaryPlus()`
- `test_undefinedBaseClass()`
- `test_classNameUndefinedInClassBody()`
- `test_classNameDefinedPreviously()`
- `test_classRedefinition()`
- `test_functionRedefinedAsClass()`
- `test_classRedefinedAsFunction()`
- `test_classWithReturn()`
- `test_moduleWithReturn()`
- `test_classWithYield()`
- `test_moduleWithYield()`
- `test_classWithYieldFrom()`
- `test_moduleWithYieldFrom()`
- `test_continueOutsideLoop()`
- `test_continueInsideLoop()`
- `test_breakOutsideLoop()`
- `test_breakInsideLoop()`
- `test_defaultExceptLast()`
- `test_defaultExceptNotLast()`
- `test_starredAssignmentNoError()`
- `test_starredAssignmentErrors()`
- `test_doubleAssignment()`
- `test_doubleAssignmentConditionally()`
- `test_doubleAssignmentWithUse()`
- `test_comparison()`
- `test_identity()`
- `test_containment()`
- `test_loopControl()`
- `test_ellipsis()`
- `test_extendedSlice()`
- `test_varAugmentedAssignment()`
- `test_attrAugmentedAssignment()`
- `test_globalDeclaredInDifferentScope()`
- `test_unused_global_statement()`
- `test_unused_nonlocal_statement()`
- `test_unused_global_statement_not_marked_as_used_by_nested_scope()`
- `test_global_nonlocal_in_class_bodies()`
- `test_unused_global_in_class()`
- `test_unused_nonlocal_in_clas()`
- `test_function_arguments()`
- `test_function_arguments_python3()`

##### TestUnusedAssignment

Tests for warning about unused assignments.

**M√©thodes :**

- `test_unusedVariable()`
- `test_unusedUnderscoreVariable()`
- `test_unusedVariableAsLocals()`
- `test_unusedVariableNoLocals()`
- `test_unusedReassignedVariable()`
- `test_variableUsedInLoop()`
- `test_assignToGlobal()`
- `test_assignToNonlocal()`
- `test_assignToMember()`
- `test_assignInForLoop()`
- `test_assignInListComprehension()`
- `test_generatorExpression()`
- `test_assignmentInsideLoop()`
- `test_tupleUnpacking()`
- `test_listUnpacking()`
- `test_closedOver()`
- `test_doubleClosedOver()`
- `test_tracebackhideSpecialVariable()`
- `test_debuggerskipSpecialVariable()`
- `test_ifexp()`
- `test_if_tuple()`
- `test_withStatementNoNames()`
- `test_withStatementSingleName()`
- `test_withStatementAttributeName()`
- `test_withStatementSubscript()`
- `test_withStatementSubscriptUndefined()`
- `test_withStatementTupleNames()`
- `test_withStatementListNames()`
- `test_withStatementComplicatedTarget()`
- `test_withStatementSingleNameUndefined()`
- `test_withStatementTupleNamesUndefined()`
- `test_withStatementSingleNameRedefined()`
- `test_withStatementTupleNamesRedefined()`
- `test_withStatementUndefinedInside()`
- `test_withStatementNameDefinedInBody()`
- `test_withStatementUndefinedInExpression()`
- `test_dictComprehension()`
- `test_setComprehensionAndLiteral()`
- `test_exceptionUsedInExcept()`
- `test_exceptionUnusedInExcept()`
- `test_exception_unused_in_except_star()`
- `test_exceptionUnusedInExceptInFunction()`
- `test_exceptWithoutNameInFunction()`
- `test_exceptWithoutNameInFunctionTuple()`
- `test_augmentedAssignmentImportedFunctionCall()`
- `test_assert_without_message()`
- `test_assert_with_message()`
- `test_assert_tuple()`
- `test_assert_tuple_empty()`
- `test_assert_static()`
- `test_yieldFromUndefined()`
- `test_f_string()`
- `test_t_string()`
- `test_assign_expr()`
- `test_assign_expr_after_annotation()`
- `test_assign_expr_generator_scope()`
- `test_assign_expr_generator_scope_reassigns_parameter()`
- `test_assign_expr_nested()`

##### TestStringFormatting

**M√©thodes :**

- `test_f_string_without_placeholders()`
- `test_t_string_missing_placeholders()`
- `test_invalid_dot_format_calls()`
- `test_invalid_percent_format_calls()`
- `test_ok_percent_format_cannot_determine_element_count()`

##### TestAsyncStatements

**M√©thodes :**

- `test_asyncDef()`
- `test_asyncDefAwait()`
- `test_asyncDefUndefined()`
- `test_asyncFor()`
- `test_asyncForUnderscoreLoopVar()`
- `test_loopControlInAsyncFor()`
- `test_loopControlInAsyncForElse()`
- `test_asyncWith()`
- `test_asyncWithItem()`
- `test_matmul()`
- `test_formatstring()`
- `test_raise_notimplemented()`

##### TestIncompatiblePrintOperator

Tests for warning about invalid use of print function.

**M√©thodes :**

- `test_valid_print()`
- `test_invalid_print_when_imported_from_future()`
- `test_print_augmented_assign()`
- `test_print_function_assignment()`
- `test_print_in_lambda()`
- `test_print_returned_in_function()`
- `test_print_as_condition_test()`

#### Fonctions

##### test_duplicateArgs

##### test_localReferencedBeforeAssignment

##### test_redefinedInGenerator

Test that reusing a variable in a generator does not raise
a warning.

##### test_redefinedInSetComprehension

Test that reusing a variable in a set comprehension does not raise
a warning.

##### test_redefinedInDictComprehension

Test that reusing a variable in a dict comprehension does not raise
a warning.

##### test_redefinedFunction

Test that shadowing a function definition with another one raises a
warning.

##### test_redefined_function_shadows_variable

##### test_redefinedUnderscoreFunction

Test that shadowing a function definition named with underscore doesn't
raise anything.

##### test_redefinedUnderscoreImportation

Test that shadowing an underscore importation raises a warning.

##### test_redefinedClassFunction

Test that shadowing a function definition in a class suite with another
one raises a warning.

##### test_redefinedIfElseFunction

Test that shadowing a function definition twice in an if
and else block does not raise a warning.

##### test_redefinedIfFunction

Test that shadowing a function definition within an if block
raises a warning.

##### test_redefinedTryExceptFunction

Test that shadowing a function definition twice in try
and except block does not raise a warning.

##### test_redefinedTryFunction

Test that shadowing a function definition within a try block
raises a warning.

##### test_redefinedIfElseInListComp

Test that shadowing a variable in a list comprehension in
an if and else block does not raise a warning.

##### test_functionDecorator

Test that shadowing a function definition with a decorated version of
that function does not raise a warning.

##### test_classFunctionDecorator

Test that shadowing a function definition in a class suite with a
decorated version of that function does not raise a warning.

##### test_modernProperty

##### test_unaryPlus

Don't die on unary +.

##### test_undefinedBaseClass

If a name in the base list of a class definition is undefined, a
warning is emitted.

##### test_classNameUndefinedInClassBody

If a class name is used in the body of that class's definition and
the name is not already defined, a warning is emitted.

##### test_classNameDefinedPreviously

If a class name is used in the body of that class's definition and
the name was previously defined in some other way, no warning is
emitted.

##### test_classRedefinition

If a class is defined twice in the same module, a warning is emitted.

##### test_functionRedefinedAsClass

If a function is redefined as a class, a warning is emitted.

##### test_classRedefinedAsFunction

If a class is redefined as a function, a warning is emitted.

##### test_classWithReturn

If a return is used inside a class, a warning is emitted.

##### test_moduleWithReturn

If a return is used at the module level, a warning is emitted.

##### test_classWithYield

If a yield is used inside a class, a warning is emitted.

##### test_moduleWithYield

If a yield is used at the module level, a warning is emitted.

##### test_classWithYieldFrom

If a yield from is used inside a class, a warning is emitted.

##### test_moduleWithYieldFrom

If a yield from is used at the module level, a warning is emitted.

##### test_continueOutsideLoop

##### test_continueInsideLoop

##### test_breakOutsideLoop

##### test_breakInsideLoop

##### test_defaultExceptLast

A default except block should be last.

YES:

try:
    ...
except Exception:
    ...
except:
    ...

NO:

try:
    ...
except:
    ...
except Exception:
    ...

##### test_defaultExceptNotLast

##### test_starredAssignmentNoError

Python 3 extended iterable unpacking

##### test_starredAssignmentErrors

SyntaxErrors (not encoded in the ast) surrounding Python 3 extended
iterable unpacking

##### test_doubleAssignment

If a variable is re-assigned to without being used, no warning is
emitted.

##### test_doubleAssignmentConditionally

If a variable is re-assigned within a conditional, no warning is
emitted.

##### test_doubleAssignmentWithUse

If a variable is re-assigned to after being used, no warning is
emitted.

##### test_comparison

If a defined name is used on either side of any of the six comparison
operators, no warning is emitted.

##### test_identity

If a defined name is used on either side of an identity test, no
warning is emitted.

##### test_containment

If a defined name is used on either side of a containment test, no
warning is emitted.

##### test_loopControl

break and continue statements are supported.

##### test_ellipsis

Ellipsis in a slice is supported.

##### test_extendedSlice

Extended slices are supported.

##### test_varAugmentedAssignment

Augmented assignment of a variable is supported.
We don't care about var refs.

##### test_attrAugmentedAssignment

Augmented assignment of attributes is supported.
We don't care about attr refs.

##### test_globalDeclaredInDifferentScope

A 'global' can be declared in one scope and reused in another.

##### test_unused_global_statement

##### test_unused_nonlocal_statement

##### test_unused_global_statement_not_marked_as_used_by_nested_scope

##### test_global_nonlocal_in_class_bodies

##### test_unused_global_in_class

##### test_unused_nonlocal_in_clas

##### test_function_arguments

Test to traverse ARG and ARGUMENT handler

##### test_function_arguments_python3

##### test_unusedVariable

Warn when a variable in a function is assigned a value that's never
used.

##### test_unusedUnderscoreVariable

Don't warn when the magic "_" (underscore) variable is unused.
See issue #202.

##### test_unusedVariableAsLocals

Using locals() it is perfectly valid to have unused variables

##### test_unusedVariableNoLocals

Using locals() in wrong scope should not matter

##### test_unusedReassignedVariable

Shadowing a used variable can still raise an UnusedVariable warning.

##### test_variableUsedInLoop

Shadowing a used variable cannot raise an UnusedVariable warning in the
context of a loop.

##### test_assignToGlobal

Assigning to a global and then not using that global is perfectly
acceptable. Do not mistake it for an unused local variable.

##### test_assignToNonlocal

Assigning to a nonlocal and then not using that binding is perfectly
acceptable. Do not mistake it for an unused local variable.

##### test_assignToMember

Assigning to a member of another object and then not using that member
variable is perfectly acceptable. Do not mistake it for an unused
local variable.

##### test_assignInForLoop

Don't warn when a variable in a for loop is assigned to but not used.

##### test_assignInListComprehension

Don't warn when a variable in a list comprehension is
assigned to but not used.

##### test_generatorExpression

Don't warn when a variable in a generator expression is
assigned to but not used.

##### test_assignmentInsideLoop

Don't warn when a variable assignment occurs lexically after its use.

##### test_tupleUnpacking

Don't warn when a variable included in tuple unpacking is unused. It's
very common for variables in a tuple unpacking assignment to be unused
in good Python code, so warning will only create false positives.

##### test_listUnpacking

Don't warn when a variable included in list unpacking is unused.

##### test_closedOver

Don't warn when the assignment is used in an inner function.

##### test_doubleClosedOver

Don't warn when the assignment is used in an inner function, even if
that inner function itself is in an inner function.

##### test_tracebackhideSpecialVariable

Do not warn about unused local variable __tracebackhide__, which is
a special variable for py.test.

##### test_debuggerskipSpecialVariable

Do not warn about unused local variable __debuggerskip__, which is
a special variable for IPython.

##### test_ifexp

Test C{foo if bar else baz} statements.

##### test_if_tuple

Test C{if (foo,)} conditions.

##### test_withStatementNoNames

No warnings are emitted for using inside or after a nameless C{with}
statement a name defined beforehand.

##### test_withStatementSingleName

No warnings are emitted for using a name defined by a C{with} statement
within the suite or afterwards.

##### test_withStatementAttributeName

No warnings are emitted for using an attribute as the target of a
C{with} statement.

##### test_withStatementSubscript

No warnings are emitted for using a subscript as the target of a
C{with} statement.

##### test_withStatementSubscriptUndefined

An undefined name warning is emitted if the subscript used as the
target of a C{with} statement is not defined.

##### test_withStatementTupleNames

No warnings are emitted for using any of the tuple of names defined by
a C{with} statement within the suite or afterwards.

##### test_withStatementListNames

No warnings are emitted for using any of the list of names defined by a
C{with} statement within the suite or afterwards.

##### test_withStatementComplicatedTarget

If the target of a C{with} statement uses any or all of the valid forms
for that part of the grammar (See
U{http://docs.python.org/reference/compound_stmts.html#the-with-statement}),
the names involved are checked both for definedness and any bindings
created are respected in the suite of the statement and afterwards.

##### test_withStatementSingleNameUndefined

An undefined name warning is emitted if the name first defined by a
C{with} statement is used before the C{with} statement.

##### test_withStatementTupleNamesUndefined

An undefined name warning is emitted if a name first defined by the
tuple-unpacking form of the C{with} statement is used before the
C{with} statement.

##### test_withStatementSingleNameRedefined

A redefined name warning is emitted if a name bound by an import is
rebound by the name defined by a C{with} statement.

##### test_withStatementTupleNamesRedefined

A redefined name warning is emitted if a name bound by an import is
rebound by one of the names defined by the tuple-unpacking form of a
C{with} statement.

##### test_withStatementUndefinedInside

An undefined name warning is emitted if a name is used inside the
body of a C{with} statement without first being bound.

##### test_withStatementNameDefinedInBody

A name defined in the body of a C{with} statement can be used after
the body ends without warning.

##### test_withStatementUndefinedInExpression

An undefined name warning is emitted if a name in the I{test}
expression of a C{with} statement is undefined.

##### test_dictComprehension

Dict comprehensions are properly handled.

##### test_setComprehensionAndLiteral

Set comprehensions are properly handled.

##### test_exceptionUsedInExcept

##### test_exceptionUnusedInExcept

##### test_exception_unused_in_except_star

##### test_exceptionUnusedInExceptInFunction

##### test_exceptWithoutNameInFunction

Don't issue false warning when an unnamed exception is used.
Previously, there would be a false warning, but only when the
try..except was in a function

##### test_exceptWithoutNameInFunctionTuple

Don't issue false warning when an unnamed exception is used.
This example catches a tuple of exception types.

##### test_augmentedAssignmentImportedFunctionCall

Consider a function that is called on the right part of an
augassign operation to be used.

##### test_assert_without_message

An assert without a message is not an error.

##### test_assert_with_message

An assert with a message is not an error.

##### test_assert_tuple

An assert of a non-empty tuple is always True.

##### test_assert_tuple_empty

An assert of an empty tuple is always False.

##### test_assert_static

An assert of a static value is not an error.

##### test_yieldFromUndefined

Test C{yield from} statement

##### test_f_string

Test PEP 498 f-strings are treated as a usage.

##### test_t_string

##### test_assign_expr

Test PEP 572 assignment expressions are treated as usage / write.

##### test_assign_expr_after_annotation

##### test_assign_expr_generator_scope

Test assignment expressions in generator expressions.

##### test_assign_expr_generator_scope_reassigns_parameter

##### test_assign_expr_nested

Test assignment expressions in nested expressions.

##### test_f_string_without_placeholders

##### test_t_string_missing_placeholders

##### test_invalid_dot_format_calls

##### test_invalid_percent_format_calls

##### test_ok_percent_format_cannot_determine_element_count

##### test_asyncDef

##### test_asyncDefAwait

##### test_asyncDefUndefined

##### test_asyncFor

##### test_asyncForUnderscoreLoopVar

##### test_loopControlInAsyncFor

##### test_loopControlInAsyncForElse

##### test_asyncWith

##### test_asyncWithItem

##### test_matmul

##### test_formatstring

##### test_raise_notimplemented

##### test_valid_print

##### test_invalid_print_when_imported_from_future

##### test_print_augmented_assign

##### test_print_function_assignment

A valid assignment, tested for catching false positives.

##### test_print_in_lambda

##### test_print_returned_in_function

##### test_print_as_condition_test

---

### test_type_annotations

Tests for behaviour related to type annotations.

#### Classes

##### TestTypeAnnotations

**M√©thodes :**

- `test_typingOverload()`
- `test_typingExtensionsOverload()`
- `test_typingOverloadAsync()`
- `test_overload_with_multiple_decorators()`
- `test_overload_in_class()`
- `test_aliased_import()`
- `test_not_a_typing_overload()`
- `test_variable_annotations()`
- `test_variable_annotation_references_self_name_undefined()`
- `test_TypeAlias_annotations()`
- `test_annotating_an_import()`
- `test_unused_annotation()`
- `test_unused_annotation_in_outer_scope_reassigned_in_local_scope()`
- `test_unassigned_annotation_is_undefined()`
- `test_annotated_async_def()`
- `test_postponed_annotations()`
- `test_annotations_do_not_define_names_with_future_annotations()`
- `test_postponed_annotations_py314()`
- `test_type_annotation_clobbers_all()`
- `test_return_annotation_is_class_scope_variable()`
- `test_return_annotation_is_function_body_variable()`
- `test_positional_only_argument_annotations()`
- `test_partially_quoted_type_annotation()`
- `test_partially_quoted_type_assignment()`
- `test_nested_partially_quoted_type_assignment()`
- `test_quoted_type_cast()`
- `test_type_cast_literal_str_to_str()`
- `test_quoted_type_cast_renamed_import()`
- `test_quoted_TypeVar_constraints()`
- `test_quoted_TypeVar_bound()`
- `test_literal_type_typing()`
- `test_literal_type_typing_extensions()`
- `test_annotated_type_typing_missing_forward_type()`
- `test_annotated_type_typing_missing_forward_type_multiple_args()`
- `test_annotated_type_typing_with_string_args()`
- `test_annotated_type_typing_with_string_args_in_union()`
- `test_literal_type_some_other_module()`
- `test_literal_union_type_typing()`
- `test_deferred_twice_annotation()`
- `test_partial_string_annotations_with_future_annotations()`
- `test_forward_annotations_for_classes_in_scope()`
- `test_idomiatic_typing_guards()`
- `test_typing_guard_for_protocol()`
- `test_typednames_correct_forward_ref()`
- `test_namedtypes_classes()`
- `test_variadic_generics()`
- `test_type_statements()`
- `test_type_parameters_functions()`
- `test_type_parameters_do_not_escape_function_scopes()`
- `test_type_parameters_classes()`
- `test_type_parameters_do_not_escape_class_scopes()`
- `test_type_parameters_TypeVarTuple()`
- `test_type_parameters_ParamSpec()`
- `test_type_parameter_defaults()`

#### Fonctions

##### test_typingOverload

Allow intentional redefinitions via @typing.overload

##### test_typingExtensionsOverload

Allow intentional redefinitions via @typing_extensions.overload

##### test_typingOverloadAsync

Allow intentional redefinitions via @typing.overload (async)

##### test_overload_with_multiple_decorators

##### test_overload_in_class

##### test_aliased_import

Detect when typing is imported as another name

##### test_not_a_typing_overload

regression test for @typing.overload detection bug in 2.1.0

##### test_variable_annotations

##### test_variable_annotation_references_self_name_undefined

##### test_TypeAlias_annotations

##### test_annotating_an_import

##### test_unused_annotation

##### test_unused_annotation_in_outer_scope_reassigned_in_local_scope

##### test_unassigned_annotation_is_undefined

##### test_annotated_async_def

##### test_postponed_annotations

##### test_annotations_do_not_define_names_with_future_annotations

##### test_postponed_annotations_py314

##### test_type_annotation_clobbers_all

##### test_return_annotation_is_class_scope_variable

##### test_return_annotation_is_function_body_variable

##### test_positional_only_argument_annotations

##### test_partially_quoted_type_annotation

##### test_partially_quoted_type_assignment

##### test_nested_partially_quoted_type_assignment

##### test_quoted_type_cast

##### test_type_cast_literal_str_to_str

##### test_quoted_type_cast_renamed_import

##### test_quoted_TypeVar_constraints

##### test_quoted_TypeVar_bound

##### test_literal_type_typing

##### test_literal_type_typing_extensions

##### test_annotated_type_typing_missing_forward_type

##### test_annotated_type_typing_missing_forward_type_multiple_args

##### test_annotated_type_typing_with_string_args

##### test_annotated_type_typing_with_string_args_in_union

##### test_literal_type_some_other_module

err on the side of false-negatives for types named Literal

##### test_literal_union_type_typing

##### test_deferred_twice_annotation

##### test_partial_string_annotations_with_future_annotations

##### test_forward_annotations_for_classes_in_scope

##### test_idomiatic_typing_guards

##### test_typing_guard_for_protocol

##### test_typednames_correct_forward_ref

##### test_namedtypes_classes

##### test_variadic_generics

##### test_type_statements

##### test_type_parameters_functions

##### test_type_parameters_do_not_escape_function_scopes

##### test_type_parameters_classes

##### test_type_parameters_do_not_escape_class_scopes

##### test_type_parameters_TypeVarTuple

##### test_type_parameters_ParamSpec

##### test_type_parameter_defaults

##### undefined_names_before_py314

---

### test_undefined_names

#### Classes

##### Test

**M√©thodes :**

- `test_undefined()`
- `test_definedInListComp()`
- `test_undefinedInListComp()`
- `test_undefinedExceptionName()`
- `test_namesDeclaredInExceptBlocks()`
- `test_undefinedExceptionNameObscuringLocalVariable()`
- `test_undefinedExceptionNameObscuringLocalVariable2()`
- `test_undefinedExceptionNameObscuringLocalVariableFalsePositive1()`
- `test_delExceptionInExcept()`
- `test_undefinedExceptionNameObscuringLocalVariableFalsePositive2()`
- `test_undefinedExceptionNameObscuringGlobalVariable()`
- `test_undefinedExceptionNameObscuringGlobalVariable2()`
- `test_undefinedExceptionNameObscuringGlobalVariableFalsePositive1()`
- `test_undefinedExceptionNameObscuringGlobalVariableFalsePositive2()`
- `test_functionsNeedGlobalScope()`
- `test_builtins()`
- `test_builtinWindowsError()`
- `test_moduleAnnotations()`
- `test_magicGlobalsFile()`
- `test_magicGlobalsBuiltins()`
- `test_magicGlobalsName()`
- `test_magicGlobalsPath()`
- `test_magicModuleInClassScope()`
- `test_magicQualnameInClassScope()`
- `test_globalImportStar()`
- `test_definedByGlobal()`
- `test_definedByGlobalMultipleNames()`
- `test_globalInGlobalScope()`
- `test_global_reset_name_only()`
- `test_unused_global()`
- `test_del()`
- `test_delGlobal()`
- `test_delUndefined()`
- `test_delConditional()`
- `test_delConditionalNested()`
- `test_delWhile()`
- `test_delWhileTestUsage()`
- `test_delWhileNested()`
- `test_globalFromNestedScope()`
- `test_laterRedefinedGlobalFromNestedScope()`
- `test_laterRedefinedGlobalFromNestedScope2()`
- `test_intermediateClassScopeIgnored()`
- `test_doubleNestingReportsClosestName()`
- `test_laterRedefinedGlobalFromNestedScope3()`
- `test_undefinedAugmentedAssignment()`
- `test_nestedClass()`
- `test_badNestedClass()`
- `test_definedAsStarArgs()`
- `test_definedAsStarUnpack()`
- `test_usedAsStarUnpack()`
- `test_unusedAsStarUnpack()`
- `test_keywordOnlyArgs()`
- `test_keywordOnlyArgsUndefined()`
- `test_annotationUndefined()`
- `test_metaClassUndefined()`
- `test_definedInGenExp()`
- `test_undefinedInGenExpNested()`
- `test_undefinedWithErrorHandler()`
- `test_definedInClass()`
- `test_definedInClassNested()`
- `test_undefinedInLoop()`
- `test_definedFromLambdaInDictionaryComprehension()`
- `test_definedFromLambdaInGenerator()`
- `test_undefinedFromLambdaInDictionaryComprehension()`
- `test_undefinedFromLambdaInComprehension()`
- `test_dunderClass()`

##### NameTests

Tests for some extra cases of name handling.

**M√©thodes :**

- `test_impossibleContext()`

#### Fonctions

##### test_undefined

##### test_definedInListComp

##### test_undefinedInListComp

##### test_undefinedExceptionName

Exception names can't be used after the except: block.

The exc variable is unused inside the exception handler.

##### test_namesDeclaredInExceptBlocks

Locals declared in except: blocks can be used after the block.

This shows the example in test_undefinedExceptionName is
different.

##### test_undefinedExceptionNameObscuringLocalVariable

Exception names obscure locals, can't be used after.

Last line will raise UnboundLocalError on Python 3 after exiting
the except: block. Note next two examples for false positives to
watch out for.

##### test_undefinedExceptionNameObscuringLocalVariable2

Exception names are unbound after the `except:` block.

Last line will raise UnboundLocalError.
The exc variable is unused inside the exception handler.

##### test_undefinedExceptionNameObscuringLocalVariableFalsePositive1

Exception names obscure locals, can't be used after. Unless.

Last line will never raise UnboundLocalError because it's only
entered if no exception was raised.

##### test_delExceptionInExcept

The exception name can be deleted in the except: block.

##### test_undefinedExceptionNameObscuringLocalVariableFalsePositive2

Exception names obscure locals, can't be used after. Unless.

Last line will never raise UnboundLocalError because `error` is
only falsy if the `except:` block has not been entered.

##### test_undefinedExceptionNameObscuringGlobalVariable

Exception names obscure globals, can't be used after.

Last line will raise UnboundLocalError because the existence of that
exception name creates a local scope placeholder for it, obscuring any
globals, etc.

##### test_undefinedExceptionNameObscuringGlobalVariable2

Exception names obscure globals, can't be used after.

Last line will raise NameError on Python 3 because the name is
locally unbound after the `except:` block, even if it's
nonlocal. We should issue an error in this case because code
only working correctly if an exception isn't raised, is invalid.
Unless it's explicitly silenced, see false positives below.

##### test_undefinedExceptionNameObscuringGlobalVariableFalsePositive1

Exception names obscure globals, can't be used after. Unless.

Last line will never raise NameError because it's only entered
if no exception was raised.

##### test_undefinedExceptionNameObscuringGlobalVariableFalsePositive2

Exception names obscure globals, can't be used after. Unless.

Last line will never raise NameError because `error` is only
falsy if the `except:` block has not been entered.

##### test_functionsNeedGlobalScope

##### test_builtins

##### test_builtinWindowsError

C{WindowsError} is sometimes a builtin name, so no warning is emitted
for using it.

##### test_moduleAnnotations

Use of the C{__annotations__} in module scope should not emit
an undefined name warning when version is greater than or equal to 3.6.

##### test_magicGlobalsFile

Use of the C{__file__} magic global should not emit an undefined name
warning.

##### test_magicGlobalsBuiltins

Use of the C{__builtins__} magic global should not emit an undefined
name warning.

##### test_magicGlobalsName

Use of the C{__name__} magic global should not emit an undefined name
warning.

##### test_magicGlobalsPath

Use of the C{__path__} magic global should not emit an undefined name
warning, if you refer to it from a file called __init__.py.

##### test_magicModuleInClassScope

Use of the C{__module__} magic builtin should not emit an undefined
name warning if used in class scope.

##### test_magicQualnameInClassScope

Use of the C{__qualname__} magic builtin should not emit an undefined
name warning if used in class scope.

##### test_globalImportStar

Can't find undefined names with import *.

##### test_definedByGlobal

"global" can make an otherwise undefined name in another function
defined.

##### test_definedByGlobalMultipleNames

"global" can accept multiple names.

##### test_globalInGlobalScope

A global statement in the global scope is ignored.

##### test_global_reset_name_only

A global statement does not prevent other names being undefined.

##### test_unused_global

An unused global statement does not define the name.

##### test_del

Del deletes bindings.

##### test_delGlobal

Del a global binding from a function.

##### test_delUndefined

Del an undefined name.

##### test_delConditional

Ignores conditional bindings deletion.

##### test_delConditionalNested

Ignored conditional bindings deletion even if they are nested in other
blocks.

##### test_delWhile

Ignore bindings deletion if called inside the body of a while
statement.

##### test_delWhileTestUsage

Ignore bindings deletion if called inside the body of a while
statement and name is used inside while's test part.

##### test_delWhileNested

Ignore bindings deletions if node is part of while's test, even when
del is in a nested block.

##### test_globalFromNestedScope

Global names are available from nested scopes.

##### test_laterRedefinedGlobalFromNestedScope

Test that referencing a local name that shadows a global, before it is
defined, generates a warning.

##### test_laterRedefinedGlobalFromNestedScope2

Test that referencing a local name in a nested scope that shadows a
global declared in an enclosing scope, before it is defined, generates
a warning.

##### test_intermediateClassScopeIgnored

If a name defined in an enclosing scope is shadowed by a local variable
and the name is used locally before it is bound, an unbound local
warning is emitted, even if there is a class scope between the enclosing
scope and the local scope.

##### test_doubleNestingReportsClosestName

Test that referencing a local name in a nested scope that shadows a
variable declared in two different outer scopes before it is defined
in the innermost scope generates an UnboundLocal warning which
refers to the nearest shadowed name.

##### test_laterRedefinedGlobalFromNestedScope3

Test that referencing a local name in a nested scope that shadows a
global, before it is defined, generates a warning.

##### test_undefinedAugmentedAssignment

##### test_nestedClass

Nested classes can access enclosing scope.

##### test_badNestedClass

Free variables in nested classes must bind at class creation.

##### test_definedAsStarArgs

Star and double-star arg names are defined.

##### test_definedAsStarUnpack

Star names in unpack are defined.

##### test_usedAsStarUnpack

Star names in unpack are used if RHS is not a tuple/list literal.

##### test_unusedAsStarUnpack

Star names in unpack are unused if RHS is a tuple/list literal.

##### test_keywordOnlyArgs

Keyword-only arg names are defined.

##### test_keywordOnlyArgsUndefined

Typo in kwonly name.

##### test_annotationUndefined

Undefined annotations.

##### test_metaClassUndefined

##### test_definedInGenExp

Using the loop variable of a generator expression results in no
warnings.

##### test_undefinedInGenExpNested

The loop variables of generator expressions nested together are
not defined in the other generator.

##### test_undefinedWithErrorHandler

Some compatibility code checks explicitly for NameError.
It should not trigger warnings.

##### test_definedInClass

Defined name for generator expressions and dict/set comprehension.

##### test_definedInClassNested

Defined name for nested generator expressions in a class.

##### test_undefinedInLoop

The loop variable is defined after the expression is computed.

##### test_definedFromLambdaInDictionaryComprehension

Defined name referenced from a lambda function within a dict/set
comprehension.

##### test_definedFromLambdaInGenerator

Defined name referenced from a lambda function within a generator
expression.

##### test_undefinedFromLambdaInDictionaryComprehension

Undefined name referenced from a lambda function within a dict/set
comprehension.

##### test_undefinedFromLambdaInComprehension

Undefined name referenced from a lambda function within a generator
expression.

##### test_dunderClass

##### test_impossibleContext

A Name node with an unrecognized context results in a RuntimeError being
raised.

---

### .!25867!harness

---

### .!25870!test_api

---

### .!25875!test_builtin

---

### .!25880!test_dict

---

### .!25886!test_code_segment

---

### .!25890!test_doctests

---

### .!25896!test_imports

---

### .!25901!test_match

---

### .!25906!test_is_literal

---

### .!25912!test_other

---

### .!25918!test_type_annotations

---

### .!25923!test_undefined_names

---

### .!25939!auth

---

### .!25955!web

---

### .!25977!gen

---

### .!25989!log

---

### .!25995!util

---

### .!26088!wsgi

---

### .!25934!options

---

### .!25945!concurrent

---

### .!25951!escape

---

### .!25961!queues

---

### .!25966!httpclient

---

### .!25970!_locale_data

---

### .!25983!iostream

---

### .!26000!locks

---

### .!26004!httpserver

---

### .!26009!__init__

---

### .!26014!netutil

---

### .!26021!httputil

---

### .!26025!ioloop

---

### .!26031!routing

---

### .!26034!tcpserver

---

### .!26040!template

---

### .!26045!locale

---

### .!26049!curl_httpclient

---

### .!26054!process

---

### .!26058!autoreload

---

### .!26064!testing

---

### .!26067!simple_httpclient

---

### .!26075!http1connection

---

### .!26078!tcpclient

---

### .!26084!websocket

---

### .!26120!util

---

### .!26093!httpclient_test

---

### .!26098!queues_test

---

### .!26102!auth_test

---

### .!26107!httpserver_test

---

### .!26112!process_test

---

### .!26117!twisted_test

---

### .!26125!circlerefs_test

---

### .!26130!gen_test

---

### .!26134!concurrent_test

---

### .!26141!web_test

---

### .!26145!routing_test

---

### .!26150!locks_test

---

### .!26154!template_test

---

### .!26160!autoreload_test

---

### .!26165!wsgi_test

---

### .!26174!curl_httpclient_test

---

### .!26180!ioloop_test

---

### .!26185!simple_httpclient_test

---

### .!26190!httputil_test

---

### .!26195!websocket_test

---

### .!26199!util_test

---

### .!26203!log_test

---

### .!26208!tcpclient_test

---

### .!26212!netutil_test

---

### .!26217!options_test

---

### .!26222!import_test

---

### .!26226!http1connection_test

---

### .!26233!testing_test

---

### .!26237!tcpserver_test

---

### .!26242!locale_test

---

### .!26246!resolve_test_helper

---

### .!26251!asyncio_test

---

### .!26256!__main__

---

### .!26260!iostream_test

---

### .!26264!runtests

---

### .!26269!escape_test

---

### .!26276!asyncio

---

### .!26289!caresresolver

---

### .!26293!twisted

---

### .!26309!_re

---

### .!26300!__init__

---

### .!26303!_parser

---

### .!26313!_types

---

### .!26343!tz

---

### .!26324!__init__

---

### .!26331!decoder

---

### .!26334!encoder

---

### .!26338!ordered

---

### .!26384!nap

---

### .!26391!stop

---

### .!26402!wait

---

### .!26359!__init__

---

### .!26363!_utils

---

### .!26369!after

---

### .!26373!before

---

### .!26377!before_sleep

---

### .!26387!retry

---

### .!26395!tornadoweb

---

### .!26406!__init__

---

### .!26411!retry

---

### .!26425!buf

---

### .!26422!__init__

---

### .!26430!mman

---

### .!26434!util

---

### .!26446!lib

---

### .!26451!test_buf

---

### .!26455!test_mman

---

### .!26460!test_tutorial

---

### .!26466!test_util

---

### __main__

Module allowing for ``python -m flake8 ...``.

---

### _compat

---

### checker

Checker Manager and Checker classes.

#### Classes

##### Manager

Manage the parallelism and checker instances for each plugin and file.

This class will be responsible for the following:

- Determining the parallelism of Flake8, e.g.:

  * Do we use :mod:`multiprocessing` or is it unavailable?

  * Do we automatically decide on the number of jobs to use or did the
    user provide that?

- Falling back to a serial way of processing files if we run into an
  OSError related to :mod:`multiprocessing`

- Organizing the results of each checker so we can group the output
  together and make our output deterministic.

**M√©thodes :**

- `__init__()`
- `_process_statistics()`
- `_job_count()`
- `_handle_results()`
- `report()`
- `run_parallel()`
- `run_serial()`
- `run()`
- `start()`
- `stop()`

##### FileChecker

Manage running checks for a file and aggregate the results.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `_make_processor()`
- `report()`
- `run_check()`
- `_extract_syntax_information()`
- `run_ast_checks()`
- `run_logical_checks()`
- `run_physical_checks()`
- `process_tokens()`
- `run_checks()`
- `handle_newline()`
- `check_physical_eol()`

#### Fonctions

##### _mp_prefork

**Param√®tres :**

- `plugins`
- `options`

##### _mp_init

**Param√®tres :**

- `argv`

##### _mp_run

**Param√®tres :**

- `filename`

##### _try_initialize_processpool

Return a new process pool instance if we are able to create one.

**Param√®tres :**

- `job_count`
- `argv`

##### find_offset

Find the offset tuple for a single offset.

**Param√®tres :**

- `offset`
- `mapping`

##### __init__

Initialize our Manager instance.

**Param√®tres :**

- `style_guide`
- `plugins`
- `argv`

##### _process_statistics

##### _job_count

##### _handle_results

**Param√®tres :**

- `filename`
- `results`

##### report

Report all of the errors found in the managed file checkers.

This iterates over each of the checkers and reports the errors sorted
by line number.

:returns:
    A tuple of the total results found and the results reported.

##### run_parallel

Run the checkers in parallel.

##### run_serial

Run the checkers in serial.

##### run

Run all the checkers.

This will intelligently decide whether to run the checks in parallel
or whether to run them in serial.

If running the checks in parallel causes a problem (e.g.,
:issue:`117`) this also implements fallback to serial processing.

##### start

Start checking files.

:param paths:
    Path names to check. This is passed directly to
    :meth:`~Manager.make_checkers`.

##### stop

Stop checking files.

##### __init__

Initialize our file checker.

##### __repr__

Provide helpful debugging representation.

##### _make_processor

##### report

Report an error by storing it in the results list.

**Param√®tres :**

- `error_code`
- `line_number`
- `column`
- `text`

##### run_check

Run the check in a single plugin.

**Param√®tres :**

- `plugin`

##### _extract_syntax_information

**Param√®tres :**

- `exception`

##### run_ast_checks

Run all checks expecting an abstract syntax tree.

##### run_logical_checks

Run all checks expecting a logical line.

##### run_physical_checks

Run all checks for a given physical line.

A single physical check may return multiple errors.

**Param√®tres :**

- `physical_line`

##### process_tokens

Process tokens and trigger checks.

Instead of using this directly, you should use
:meth:`flake8.checker.FileChecker.run_checks`.

##### run_checks

Run checks against the file.

##### handle_newline

Handle the logic when encountering a newline token.

**Param√®tres :**

- `token_type`

##### check_physical_eol

Run physical checks if and only if it is at the end of the line.

**Param√®tres :**

- `token`
- `prev_physical`

---

### defaults

Constants that define defaults.

---

### discover_files

Functions related to discovering paths.

#### Fonctions

##### _filenames_from

Generate filenames from an argument.

:param arg:
    Parameter from the command-line.
:param predicate:
    Predicate to use to filter out filenames. If the predicate
    returns ``True`` we will exclude the filename, otherwise we
    will yield it. By default, we include every filename
    generated.
:returns:
    Generator of paths

**Param√®tres :**

- `arg`

##### expand_paths

Expand out ``paths`` from commandline to the lintable files.

##### is_excluded

**Param√®tres :**

- `arg`

---

### exceptions

Exception classes for all of Flake8.

#### Classes

##### Flake8Exception

Plain Flake8 exception.

##### EarlyQuit

Except raised when encountering a KeyboardInterrupt.

##### ExecutionError

Exception raised during execution of Flake8.

##### FailedToLoadPlugin

Exception raised when a plugin fails to load.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### PluginRequestedUnknownParameters

The plugin requested unknown parameters.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### PluginExecutionFailed

The plugin failed during execution.

**M√©thodes :**

- `__init__()`
- `__str__()`

#### Fonctions

##### __init__

Initialize our FailedToLoadPlugin exception.

**Param√®tres :**

- `plugin_name`
- `exception`

##### __str__

Format our exception message.

##### __init__

Pop certain keyword arguments for initialization.

**Param√®tres :**

- `plugin_name`
- `exception`

##### __str__

Format our exception message.

##### __init__

Utilize keyword arguments for message generation.

**Param√®tres :**

- `filename`
- `plugin_name`
- `exception`

##### __str__

Format our exception message.

---

### processor

Module containing our file processor that tokenizes a file for checks.

#### Classes

##### FileProcessor

Processes a file and holds state.

This processes a file by generating tokens, logical and physical lines,
and AST trees. This also provides a way of passing state about the file
to checks expecting that state. Any public attribute on this object can
be requested by a plugin. The known public attributes are:

- :attr:`blank_before`
- :attr:`blank_lines`
- :attr:`checker_state`
- :attr:`indent_char`
- :attr:`indent_level`
- :attr:`line_number`
- :attr:`logical_line`
- :attr:`max_line_length`
- :attr:`max_doc_length`
- :attr:`multiline`
- :attr:`noqa`
- :attr:`previous_indent_level`
- :attr:`previous_logical`
- :attr:`previous_unindented_logical_line`
- :attr:`tokens`
- :attr:`file_tokens`
- :attr:`total_lines`
- :attr:`verbose`

**M√©thodes :**

- `__init__()`
- `file_tokens()`
- `fstring_start()`
- `tstring_start()`
- `multiline_string()`
- `reset_blank_before()`
- `delete_first_token()`
- `visited_new_blank_line()`
- `update_state()`
- `update_checker_state_for()`
- `next_logical_line()`
- `build_logical_line_tokens()`
- `build_ast()`
- `build_logical_line()`
- `keyword_arguments_for()`
- `generate_tokens()`
- `_noqa_line_range()`
- `_noqa_line_mapping()`
- `noqa_line_for()`
- `next_line()`
- `read_lines()`
- `read_lines_from_filename()`
- `read_lines_from_stdin()`
- `should_ignore_file()`
- `strip_utf_bom()`

#### Fonctions

##### is_eol_token

Check if the token is an end-of-line token.

**Param√®tres :**

- `token`

##### is_multiline_string

Check if this is a multiline string.

**Param√®tres :**

- `token`

##### token_is_newline

Check if the token type is a newline token type.

**Param√®tres :**

- `token`

##### count_parentheses

Count the number of parentheses.

**Param√®tres :**

- `current_parentheses_count`
- `token_text`

##### expand_indent

Return the amount of indentation.

Tabs are expanded to the next multiple of 8.

>>> expand_indent('    ')
4
>>> expand_indent('\t')
8
>>> expand_indent('       \t')
8
>>> expand_indent('        \t')
16

**Param√®tres :**

- `line`

##### mutate_string

Replace contents with 'xxx' to prevent syntax matching.

>>> mutate_string('"abc"')
'"xxx"'
>>> mutate_string("'''abc'''")
"'''xxx'''"
>>> mutate_string("r'abc'")
"r'xxx'"

**Param√®tres :**

- `text`

##### __init__

Initialize our file processor.

:param filename: Name of the file to process

**Param√®tres :**

- `filename`
- `options`
- `lines`

##### file_tokens

Return the complete set of tokens for a file.

##### fstring_start

Signal the beginning of an fstring.

**Param√®tres :**

- `lineno`

##### tstring_start

Signal the beginning of an tstring.

**Param√®tres :**

- `lineno`

##### multiline_string

Iterate through the lines of a multiline string.

**Param√®tres :**

- `token`

##### reset_blank_before

Reset the blank_before attribute to zero.

##### delete_first_token

Delete the first token in the list of tokens.

##### visited_new_blank_line

Note that we visited a new blank line.

##### update_state

Update the indent level based on the logical line mapping.

**Param√®tres :**

- `mapping`

##### update_checker_state_for

Update the checker_state attribute for the plugin.

**Param√®tres :**

- `plugin`

##### next_logical_line

Record the previous logical line.

This also resets the tokens list and the blank_lines count.

##### build_logical_line_tokens

Build the mapping, comments, and logical line lists.

##### build_ast

Build an abstract syntax tree from the list of lines.

##### build_logical_line

Build a logical line from the current tokens list.

##### keyword_arguments_for

Generate the keyword arguments for a list of parameters.

**Param√®tres :**

- `parameters`
- `arguments`

##### generate_tokens

Tokenize the file and yield the tokens.

##### _noqa_line_range

**Param√®tres :**

- `min_line`
- `max_line`

##### _noqa_line_mapping

Map from line number to the line we'll search for `noqa` in.

##### noqa_line_for

Retrieve the line which will be used to determine noqa.

**Param√®tres :**

- `line_number`

##### next_line

Get the next line from the list.

##### read_lines

Read the lines for this file checker.

##### read_lines_from_filename

Read the lines for a file.

##### read_lines_from_stdin

Read the lines from standard in.

##### should_ignore_file

Check if ``flake8: noqa`` is in the file to be ignored.

:returns:
    True if a line matches :attr:`defaults.NOQA_FILE`,
    otherwise False

##### strip_utf_bom

Strip the UTF bom from the lines of the file.

---

### statistics

Statistic collection logic for Flake8.

#### Classes

##### Statistics

Manager of aggregated statistics for a run of Flake8.

**M√©thodes :**

- `__init__()`
- `error_codes()`
- `record()`
- `statistics_for()`

##### Key

Simple key structure for the Statistics dictionary.

To make things clearer, easier to read, and more understandable, we use a
namedtuple here for all Keys in the underlying dictionary for the
Statistics object.

**M√©thodes :**

- `create_from()`
- `matches()`

##### Statistic

Simple wrapper around the logic of each statistic.

Instead of maintaining a simple but potentially hard to reason about
tuple, we create a class which has attributes and a couple
convenience methods on it.

**M√©thodes :**

- `__init__()`
- `create_from()`
- `increment()`

#### Fonctions

##### __init__

Initialize the underlying dictionary for our statistics.

##### error_codes

Return all unique error codes stored.

:returns:
    Sorted list of error codes.

##### record

Add the fact that the error was seen in the file.

:param error:
    The Violation instance containing the information about the
    violation.

**Param√®tres :**

- `error`

##### statistics_for

Generate statistics for the prefix and filename.

If you have a :class:`Statistics` object that has recorded errors,
you can generate the statistics for a prefix (e.g., ``E``, ``E1``,
``W50``, ``W503``) with the optional filter of a filename as well.

.. code-block:: python

    >>> stats = Statistics()
    >>> stats.statistics_for('E12',
                             filename='src/flake8/statistics.py')
    <generator ...>
    >>> stats.statistics_for('W')
    <generator ...>

:param prefix:
    The error class or specific error code to find statistics for.
:param filename:
    (Optional) The filename to further filter results by.
:returns:
    Generator of instances of :class:`Statistic`

**Param√®tres :**

- `prefix`
- `filename`

##### create_from

Create a Key from :class:`flake8.violation.Violation`.

**Param√®tres :**

- `cls`
- `error`

##### matches

Determine if this key matches some constraints.

:param prefix:
    The error code prefix that this key's error code should start with.
:param filename:
    The filename that we potentially want to match on. This can be
    None to only match on error prefix.
:returns:
    True if the Key's code starts with the prefix and either filename
    is None, or the Key's filename matches the value passed in.

**Param√®tres :**

- `prefix`
- `filename`

##### __init__

Initialize our Statistic.

**Param√®tres :**

- `error_code`
- `filename`
- `message`
- `count`

##### create_from

Create a Statistic from a :class:`flake8.violation.Violation`.

**Param√®tres :**

- `cls`
- `error`

##### increment

Increment the number of times we've seen this error in this file.

---

### style_guide

Implementation of the StyleGuide used by Flake8.

#### Classes

##### Selected

Enum representing an explicitly or implicitly selected code.

##### Ignored

Enum representing an explicitly or implicitly ignored code.

##### Decision

Enum representing whether a code should be ignored or selected.

##### DecisionEngine

A class for managing the decision process around violations.

This contains the logic for whether a violation should be reported or
ignored.

**M√©thodes :**

- `__init__()`
- `was_selected()`
- `was_ignored()`
- `make_decision()`
- `decision_for()`

##### StyleGuideManager

Manage multiple style guides for a single run.

**M√©thodes :**

- `__init__()`
- `populate_style_guides_with()`
- `_style_guide_for()`
- `processing_file()`
- `handle_error()`

##### StyleGuide

Manage a Flake8 user's style guide.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `copy()`
- `processing_file()`
- `applies_to()`
- `should_report_error()`
- `handle_error()`

#### Fonctions

##### _explicitly_chosen

##### _select_ignore

##### __init__

Initialize the engine.

**Param√®tres :**

- `options`

##### was_selected

Determine if the code has been selected by the user.

:param code: The code for the check that has been run.
:returns:
    Selected.Implicitly if the selected list is empty,
    Selected.Explicitly if the selected list is not empty and a match
    was found,
    Ignored.Implicitly if the selected list is not empty but no match
    was found.

**Param√®tres :**

- `code`

##### was_ignored

Determine if the code has been ignored by the user.

:param code:
    The code for the check that has been run.
:returns:
    Selected.Implicitly if the ignored list is empty,
    Ignored.Explicitly if the ignored list is not empty and a match was
    found,
    Selected.Implicitly if the ignored list is not empty but no match
    was found.

**Param√®tres :**

- `code`

##### make_decision

Decide if code should be ignored or selected.

**Param√®tres :**

- `code`

##### decision_for

Return the decision for a specific code.

This method caches the decisions for codes to avoid retracing the same
logic over and over again. We only care about the select and ignore
rules as specified by the user in their configuration files and
command-line flags.

This method does not look at whether the specific line is being
ignored in the file itself.

:param code: The code for the check that has been run.

**Param√®tres :**

- `code`

##### __init__

Initialize our StyleGuide.

.. todo:: Add parameter documentation.

**Param√®tres :**

- `options`
- `formatter`
- `decider`

##### populate_style_guides_with

Generate style guides from the per-file-ignores option.

:param options:
    The original options parsed from the CLI and config file.
:returns:
    A copy of the default style guide with overridden values.

**Param√®tres :**

- `options`

##### _style_guide_for

Find the StyleGuide for the filename in particular.

**Param√®tres :**

- `filename`

##### processing_file

Record the fact that we're processing the file's results.

**Param√®tres :**

- `filename`

##### handle_error

Handle an error reported by a check.

:param code:
    The error code found, e.g., E123.
:param filename:
    The file in which the error was found.
:param line_number:
    The line number (where counting starts at 1) at which the error
    occurs.
:param column_number:
    The column number (where counting starts at 1) at which the error
    occurs.
:param text:
    The text of the error message.
:param physical_line:
    The actual physical line causing the error.
:returns:
    1 if the error was reported. 0 if it was ignored. This is to allow
    for counting of the number of errors found that were not ignored.

**Param√®tres :**

- `code`
- `filename`
- `line_number`
- `column_number`
- `text`
- `physical_line`

##### __init__

Initialize our StyleGuide.

.. todo:: Add parameter documentation.

**Param√®tres :**

- `options`
- `formatter`
- `stats`
- `filename`
- `decider`

##### __repr__

Make it easier to debug which StyleGuide we're using.

##### copy

Create a copy of this style guide with different values.

**Param√®tres :**

- `filename`
- `extend_ignore_with`

##### processing_file

Record the fact that we're processing the file's results.

**Param√®tres :**

- `filename`

##### applies_to

Check if this StyleGuide applies to the file.

:param filename:
    The name of the file with violations that we're potentially
    applying this StyleGuide to.
:returns:
    True if this applies, False otherwise

**Param√®tres :**

- `filename`

##### should_report_error

Determine if the error code should be reported or ignored.

This method only cares about the select and ignore rules as specified
by the user in their configuration files and command-line flags.

This method does not look at whether the specific line is being
ignored in the file itself.

:param code:
    The code for the check that has been run.

**Param√®tres :**

- `code`

##### handle_error

Handle an error reported by a check.

:param code:
    The error code found, e.g., E123.
:param filename:
    The file in which the error was found.
:param line_number:
    The line number (where counting starts at 1) at which the error
    occurs.
:param column_number:
    The column number (where counting starts at 1) at which the error
    occurs.
:param text:
    The text of the error message.
:param physical_line:
    The actual physical line causing the error.
:returns:
    1 if the error was reported. 0 if it was ignored. This is to allow
    for counting of the number of errors found that were not ignored.

**Param√®tres :**

- `code`
- `filename`
- `line_number`
- `column_number`
- `text`
- `physical_line`

---

### utils

Utility methods for flake8.

#### Classes

##### _Token

##### State

#### Fonctions

##### parse_comma_separated_list

Parse a comma-separated list.

:param value:
    String to be parsed and normalized.
:param regexp:
    Compiled regular expression used to split the value when it is a
    string.
:returns:
    List of values with whitespace stripped.

**Param√®tres :**

- `value`
- `regexp`

##### _tokenize_files_to_codes_mapping

**Param√®tres :**

- `value`

##### parse_files_to_codes_mapping

Parse a files-to-codes mapping.

A files-to-codes mapping a sequence of values specified as
`filenames list:codes list ...`.  Each of the lists may be separated by
either comma or whitespace tokens.

:param value: String to be parsed and normalized.

**Param√®tres :**

- `value_`

##### normalize_paths

Normalize a list of paths relative to a parent directory.

:returns:
    The normalized paths.

**Param√®tres :**

- `paths`
- `parent`

##### normalize_path

Normalize a single-path.

:returns:
    The normalized path.

**Param√®tres :**

- `path`
- `parent`

##### stdin_get_value

Get and cache it so plugins can use it.

##### stdin_get_lines

Return lines of stdin split according to file splitting.

##### is_using_stdin

Determine if we're going to read from stdin.

:param paths:
    The paths that we're going to check.
:returns:
    True if stdin (-) is in the path, otherwise False

**Param√®tres :**

- `paths`

##### fnmatch

Wrap :func:`fnmatch.fnmatch` to add some functionality.

:param filename:
    Name of the file we're trying to match.
:param patterns:
    Patterns we're using to try to match the filename.
:param default:
    The default value if patterns is empty
:returns:
    True if a pattern matches the filename, False if it doesn't.
    ``True`` if patterns is empty.

**Param√®tres :**

- `filename`
- `patterns`

##### matches_filename

Use fnmatch to discern if a path exists in patterns.

:param path:
    The path to the file under question
:param patterns:
    The patterns to match the path against.
:param log_message:
    The message used for logging purposes.
:returns:
    True if path matches patterns, False otherwise

**Param√®tres :**

- `path`
- `patterns`
- `log_message`
- `logger`

##### get_python_version

Find and format the python implementation and version.

:returns:
    Implementation name, version, and platform as a string.

##### normalize_pypi_name

Normalize a distribution name according to PEP 503.

**Param√®tres :**

- `s`

##### _reset

##### _unexpected_token

---

### violation

Contains the Violation error class used internally.

#### Classes

##### Violation

Class representing a violation reported by Flake8.

**M√©thodes :**

- `is_inline_ignored()`

#### Fonctions

##### _find_noqa

**Param√®tres :**

- `physical_line`

##### is_inline_ignored

Determine if a comment has been added to ignore this line.

:param disable_noqa:
    Whether or not users have provided ``--disable-noqa``.
:returns:
    True if error is ignored in-line, False otherwise.

**Param√®tres :**

- `disable_noqa`

---

### .!26471!__init__

---

### .!26475!__main__

---

### .!26481!_compat

---

### .!26486!checker

---

### .!26490!defaults

---

### .!26496!discover_files

---

### .!26501!exceptions

---

### .!26507!processor

---

### .!26512!statistics

---

### .!26517!style_guide

---

### .!26522!utils

---

### .!26529!violation

---

### legacy

Module containing shims around Flake8 2.x behaviour.

Previously, users would import :func:`get_style_guide` from ``flake8.engine``.
In 3.0 we no longer have an "engine" module but we maintain the API from it.

#### Classes

##### Report

Public facing object that mimic's Flake8 2.0's API.

.. note::

    There are important changes in how this object behaves compared to
    the object provided in Flake8 2.x.

.. warning::

    This should not be instantiated by users.

.. versionchanged:: 3.0.0

**M√©thodes :**

- `__init__()`
- `total_errors()`
- `get_statistics()`

##### StyleGuide

Public facing object that mimic's Flake8 2.0's StyleGuide.

.. note::

    There are important changes in how this object behaves compared to
    the StyleGuide object provided in Flake8 2.x.

.. warning::

    This object should not be instantiated directly by users.

.. versionchanged:: 3.0.0

**M√©thodes :**

- `__init__()`
- `options()`
- `paths()`
- `check_files()`
- `excluded()`
- `init_report()`
- `input_file()`

#### Fonctions

##### get_style_guide

Provision a StyleGuide for use.

:param \*\*kwargs:
    Keyword arguments that provide some options for the StyleGuide.
:returns:
    An initialized StyleGuide

##### __init__

Initialize the Report for the user.

.. warning:: This should not be instantiated by users.

**Param√®tres :**

- `application`

##### total_errors

Return the total number of errors.

##### get_statistics

Get the list of occurrences of a violation.

:returns:
    List of occurrences of a violation formatted as:
    {Count} {Error Code} {Message}, e.g.,
    ``8 E531 Some error message about the error``

**Param√®tres :**

- `violation`

##### __init__

Initialize our StyleGuide.

**Param√®tres :**

- `application`

##### options

Return application's options.

An instance of :class:`argparse.Namespace` containing parsed options.

##### paths

Return the extra arguments passed as paths.

##### check_files

Run collected checks on the files provided.

This will check the files passed in and return a :class:`Report`
instance.

:param paths:
    List of filenames (or paths) to check.
:returns:
    Object that mimic's Flake8 2.0's Reporter class.

**Param√®tres :**

- `paths`

##### excluded

Determine if a file is excluded.

:param filename:
    Path to the file to check if it is excluded.
:param parent:
    Name of the parent directory containing the file.
:returns:
    True if the filename is excluded, False otherwise.

**Param√®tres :**

- `filename`
- `parent`

##### init_report

Set up a formatter for this run of Flake8.

**Param√®tres :**

- `reporter`

##### input_file

Run collected checks on a single file.

This will check the file passed in and return a :class:`Report`
instance.

:param filename:
    The path to the file to check.
:param lines:
    Ignored since Flake8 3.0.
:param expected:
    Ignored since Flake8 3.0.
:param line_offset:
    Ignored since Flake8 3.0.
:returns:
    Object that mimic's Flake8 2.0's Reporter class.

**Param√®tres :**

- `filename`
- `lines`
- `expected`
- `line_offset`

##### excluded

**Param√®tres :**

- `path`

---

### .!26533!__init__

---

### .!26538!legacy

---

### _windows_color

ctypes hackery to enable color processing on windows.

See: https://github.com/pre-commit/pre-commit/blob/cb40e96/pre_commit/color.py

#### Fonctions

##### _enable

##### bool_errcheck

**Param√®tres :**

- `result`
- `func`
- `args`

---

### .!26556!base

---

### base

The base class and interface for all formatting plugins.

#### Classes

##### BaseFormatter

Class defining the formatter interface.

.. attribute:: options

    The options parsed from both configuration files and the command-line.

.. attribute:: filename

    If specified by the user, the path to store the results of the run.

.. attribute:: output_fd

    Initialized when the :meth:`start` is called. This will be a file
    object opened for writing.

.. attribute:: newline

    The string to add to the end of a line. This is only used when the
    output filename has been specified.

**M√©thodes :**

- `__init__()`
- `after_init()`
- `beginning()`
- `finished()`
- `start()`
- `handle()`
- `format()`
- `show_statistics()`
- `show_benchmarks()`
- `show_source()`
- `_write()`
- `write()`
- `stop()`

#### Fonctions

##### __init__

Initialize with the options parsed from config and cli.

This also calls a hook, :meth:`after_init`, so subclasses do not need
to call super to call this method.

:param options:
    User specified configuration parsed from both configuration files
    and the command-line interface.

**Param√®tres :**

- `options`

##### after_init

Initialize the formatter further.

##### beginning

Notify the formatter that we're starting to process a file.

:param filename:
    The name of the file that Flake8 is beginning to report results
    from.

**Param√®tres :**

- `filename`

##### finished

Notify the formatter that we've finished processing a file.

:param filename:
    The name of the file that Flake8 has finished reporting results
    from.

**Param√®tres :**

- `filename`

##### start

Prepare the formatter to receive input.

This defaults to initializing :attr:`output_fd` if :attr:`filename`

##### handle

Handle an error reported by Flake8.

This defaults to calling :meth:`format`, :meth:`show_source`, and
then :meth:`write`. To extend how errors are handled, override this
method.

:param error:
    This will be an instance of
    :class:`~flake8.violation.Violation`.

**Param√®tres :**

- `error`

##### format

Format an error reported by Flake8.

This method **must** be implemented by subclasses.

:param error:
    This will be an instance of
    :class:`~flake8.violation.Violation`.
:returns:
    The formatted error string.

**Param√®tres :**

- `error`

##### show_statistics

Format and print the statistics.

**Param√®tres :**

- `statistics`

##### show_benchmarks

Format and print the benchmarks.

**Param√®tres :**

- `benchmarks`

##### show_source

Show the physical line generating the error.

This also adds an indicator for the particular part of the line that
is reported as generating the problem.

:param error:
    This will be an instance of
    :class:`~flake8.violation.Violation`.
:returns:
    The formatted error string if the user wants to show the source.
    If the user does not want to show the source, this will return
    ``None``.

**Param√®tres :**

- `error`

##### _write

Handle logic of whether to use an output file or print().

**Param√®tres :**

- `output`

##### write

Write the line either to the output file or stdout.

This handles deciding whether to write to a file or print to standard
out for subclasses. Override this if you want behaviour that differs
from the default.

:param line:
    The formatted string to print or write.
:param source:
    The source code that has been formatted and associated with the
    line of output.

**Param√®tres :**

- `line`
- `source`

##### stop

Clean up after reporting is finished.

---

### default

Default formatting class for Flake8.

#### Classes

##### SimpleFormatter

Simple abstraction for Default and Pylint formatter commonality.

Sub-classes of this need to define an ``error_format`` attribute in order
to succeed. The ``format`` method relies on that attribute and expects the
``error_format`` string to use the old-style formatting strings with named
parameters:

* code
* text
* path
* row
* col

**M√©thodes :**

- `format()`

##### Default

Default formatter for Flake8.

This also handles backwards compatibility for people specifying a custom
format string.

**M√©thodes :**

- `after_init()`

##### Pylint

Pylint formatter for Flake8.

##### FilenameOnly

Only print filenames, e.g., flake8 -q.

**M√©thodes :**

- `after_init()`
- `show_source()`
- `format()`

##### Nothing

Print absolutely nothing.

**M√©thodes :**

- `format()`
- `show_source()`

#### Fonctions

##### format

Format and write error out.

If an output filename is specified, write formatted errors to that
file. Otherwise, print the formatted error to standard out.

**Param√®tres :**

- `error`

##### after_init

Check for a custom format string.

##### after_init

Initialize our set of filenames.

##### show_source

Do not include the source code.

**Param√®tres :**

- `error`

##### format

Ensure we only print each error once.

**Param√®tres :**

- `error`

##### format

Do nothing.

**Param√®tres :**

- `error`

##### show_source

Do not print the source.

**Param√®tres :**

- `error`

---

### .!26543!__init__

---

### .!26549!_windows_color

---

### .!26560!default

---

### application

Module containing the application logic for Flake8.

#### Classes

##### Application

Abstract our application into a class.

**M√©thodes :**

- `__init__()`
- `exit_code()`
- `make_formatter()`
- `make_guide()`
- `make_file_checker_manager()`
- `run_checks()`
- `report_benchmarks()`
- `report_errors()`
- `report_statistics()`
- `initialize()`
- `report()`
- `_run()`
- `run()`

#### Fonctions

##### __init__

Initialize our application.

##### exit_code

Return the program exit code.

##### make_formatter

Initialize a formatter based on the parsed options.

##### make_guide

Initialize our StyleGuide.

##### make_file_checker_manager

Initialize our FileChecker Manager.

**Param√®tres :**

- `argv`

##### run_checks

Run the actual checks with the FileChecker Manager.

This method encapsulates the logic to make a
:class:`~flake8.checker.Manger` instance run the checks it is
managing.

##### report_benchmarks

Aggregate, calculate, and report benchmarks for this run.

##### report_errors

Report all the errors found by flake8 3.0.

This also updates the :attr:`result_count` attribute with the total
number of errors, warnings, and other messages found.

##### report_statistics

Aggregate and report statistics from this run.

##### initialize

Initialize the application to be run.

This finds the plugins, registers their options, and parses the
command-line arguments.

**Param√®tres :**

- `argv`

##### report

Report errors, statistics, and benchmarks.

##### _run

**Param√®tres :**

- `argv`

##### run

Run our application.

This method will also handle KeyboardInterrupt exceptions for the
entirety of the flake8 application. If it sees a KeyboardInterrupt it
will forcibly clean up the :class:`~flake8.checker.Manager`.

**Param√®tres :**

- `argv`

---

### .!26575!cli

---

### cli

Command-line implementation of flake8.

#### Fonctions

##### main

Execute the main bit of the application.

This handles the creation of an instance of :class:`Application`, runs it,
and then exits the application.

:param argv:
    The arguments to be passed to the application for parsing.

**Param√®tres :**

- `argv`

---

### debug

Module containing the logic for our debugging logic.

#### Fonctions

##### information

Generate the information to be printed for the bug report.

**Param√®tres :**

- `version`
- `plugins`

---

### options

Contains the logic for all of the default options for Flake8.

#### Classes

##### JobsArgument

Type callback for the --jobs argument.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__str__()`

#### Fonctions

##### stage1_arg_parser

Register the preliminary options on our OptionManager.

The preliminary options include:

- ``-v``/``--verbose``
- ``--output-file``
- ``--append-config``
- ``--config``
- ``--isolated``
- ``--enable-extensions``

##### register_default_options

Register the default options on our OptionManager.

The default options include:

- ``-q``/``--quiet``
- ``--color``
- ``--count``
- ``--exclude``
- ``--extend-exclude``
- ``--filename``
- ``--format``
- ``--hang-closing``
- ``--ignore``
- ``--extend-ignore``
- ``--per-file-ignores``
- ``--max-line-length``
- ``--max-doc-length``
- ``--indent-size``
- ``--select``
- ``--extend-select``
- ``--disable-noqa``
- ``--show-source``
- ``--statistics``
- ``--exit-zero``
- ``-j``/``--jobs``
- ``--tee``
- ``--benchmark``
- ``--bug-report``

**Param√®tres :**

- `option_manager`

##### __init__

Parse and validate the --jobs argument.

:param arg: The argument passed by argparse for validation

**Param√®tres :**

- `arg`

##### __repr__

Representation for debugging.

##### __str__

Format our JobsArgument class.

---

### .!26566!__init__

---

### .!26570!application

---

### .!26581!debug

---

### .!26585!options

---

### aggregator

Aggregation function for CLI specified options and config file options.

This holds the logic that uses the collected and merged config files and
applies the user-specified command-line configuration on top of it.

#### Fonctions

##### aggregate_options

Aggregate and merge CLI and config file options.

**Param√®tres :**

- `manager`
- `cfg`
- `cfg_dir`
- `argv`

---

### config

Config handling logic for Flake8.

#### Fonctions

##### _stat_key

**Param√®tres :**

- `s`

##### _find_config_file

**Param√®tres :**

- `path`

##### load_config

Load the configuration given the user options.

- in ``isolated`` mode, return an empty configuration
- if a config file is given in ``config`` use that, otherwise attempt to
  discover a configuration using ``tox.ini`` / ``setup.cfg`` / ``.flake8``
- finally, load any ``extra`` configuration files

**Param√®tres :**

- `config`
- `extra`

##### parse_config

Parse and normalize the typed configuration options.

**Param√®tres :**

- `option_manager`
- `cfg`
- `cfg_dir`

---

### manager

Option handling and Option management logic.

#### Classes

##### Option

Our wrapper around an argparse argument parsers to add features.

**M√©thodes :**

- `__init__()`
- `filtered_option_kwargs()`
- `__repr__()`
- `normalize()`
- `to_argparse()`

##### OptionManager

Manage Options and OptionParser while adding post-processing.

**M√©thodes :**

- `__init__()`
- `register_plugins()`
- `add_option()`
- `extend_default_ignore()`
- `extend_default_select()`
- `parse_args()`

#### Fonctions

##### _flake8_normalize

**Param√®tres :**

- `value`

##### __init__

Initialize an Option instance.

The following are all passed directly through to argparse.

:param short_option_name:
    The short name of the option (e.g., ``-x``). This will be the
    first argument passed to ``ArgumentParser.add_argument``
:param long_option_name:
    The long name of the option (e.g., ``--xtra-long-option``). This
    will be the second argument passed to
    ``ArgumentParser.add_argument``
:param default:
    Default value of the option.
:param dest:
    Attribute name to store parsed option value as.
:param nargs:
    Number of arguments to parse for this option.
:param const:
    Constant value to store on a common destination. Usually used in
    conjunction with ``action="store_const"``.
:param choices:
    Possible values for the option.
:param help:
    Help text displayed in the usage information.
:param metavar:
    Name to use instead of the long option name for help text.
:param required:
    Whether this option is required or not.

The following options may be passed directly through to :mod:`argparse`
but may need some massaging.

:param type:
    A callable to normalize the type (as is the case in
    :mod:`argparse`).
:param action:
    Any action allowed by :mod:`argparse`.

The following parameters are for Flake8's option handling alone.

:param parse_from_config:
    Whether or not this option should be parsed out of config files.
:param comma_separated_list:
    Whether the option is a comma separated list when parsing from a
    config file.
:param normalize_paths:
    Whether the option is expecting a path or list of paths and should
    attempt to normalize the paths to absolute paths.

**Param√®tres :**

- `short_option_name`
- `long_option_name`
- `action`
- `default`
- `type`
- `dest`
- `nargs`
- `const`
- `choices`
- `help`
- `metavar`
- `required`
- `parse_from_config`
- `comma_separated_list`
- `normalize_paths`

##### filtered_option_kwargs

Return any actually-specified arguments.

##### __repr__

##### normalize

Normalize the value based on the option configuration.

**Param√®tres :**

- `value`

##### to_argparse

Convert a Flake8 Option to argparse ``add_argument`` arguments.

##### __init__

Initialize an instance of an OptionManager.

##### register_plugins

Register the plugin options (if needed).

**Param√®tres :**

- `plugins`

##### add_option

Create and register a new option.

See parameters for :class:`~flake8.options.manager.Option` for
acceptable arguments to this method.

.. note::

    ``short_option_name`` and ``long_option_name`` may be specified
    positionally as they are with argparse normally.

##### extend_default_ignore

Extend the default ignore list with the error codes provided.

:param error_codes:
    List of strings that are the error/warning codes with which to
    extend the default ignore list.

**Param√®tres :**

- `error_codes`

##### extend_default_select

Extend the default select list with the error codes provided.

:param error_codes:
    List of strings that are the error/warning codes with which
    to extend the default select list.

**Param√®tres :**

- `error_codes`

##### parse_args

Proxy to calling the OptionParser's parse_args method.

**Param√®tres :**

- `args`
- `values`

##### _set_group

**Param√®tres :**

- `name`

---

### parse_args

Procedure for parsing args, config, loading plugins.

#### Fonctions

##### parse_args

Procedure for parsing args, config, loading plugins.

**Param√®tres :**

- `argv`

---

### .!26591!__init__

---

### .!26595!aggregator

---

### .!26602!config

---

### .!26607!manager

---

### .!26612!parse_args

---

### finder

Functions related to finding and loading plugins.

#### Classes

##### Plugin

A plugin before loading.

##### LoadedPlugin

Represents a plugin after being imported.

**M√©thodes :**

- `entry_name()`
- `display_name()`

##### Checkers

Classified plugins needed for checking.

##### Plugins

Classified plugins.

**M√©thodes :**

- `all_plugins()`
- `versions_str()`

##### PluginOptions

Options related to plugin loading.

**M√©thodes :**

- `blank()`

#### Fonctions

##### _parse_option

**Param√®tres :**

- `cfg`
- `cfg_opt_name`
- `opt`

##### parse_plugin_options

Parse plugin loading related options.

**Param√®tres :**

- `cfg`
- `cfg_dir`

##### _flake8_plugins

**Param√®tres :**

- `eps`
- `name`
- `version`

##### _find_importlib_plugins

##### _find_local_plugins

**Param√®tres :**

- `cfg`

##### _check_required_plugins

**Param√®tres :**

- `plugins`
- `expected`

##### find_plugins

Discovers all plugins (but does not load them).

**Param√®tres :**

- `cfg`
- `opts`

##### _parameters_for

Return the parameters for the plugin.

This will inspect the plugin and return either the function parameters
if the plugin is a function or the parameters for ``__init__`` after
``self`` if the plugin is a class.

:returns:
    A dictionary mapping the parameter name to whether or not it is
    required (a.k.a., is positional only/does not have a default).

**Param√®tres :**

- `func`

##### _load_plugin

**Param√®tres :**

- `plugin`

##### _import_plugins

**Param√®tres :**

- `plugins`
- `opts`

##### _classify_plugins

**Param√®tres :**

- `plugins`
- `opts`

##### load_plugins

Load and classify all flake8 plugins.

- first: extends ``sys.path`` with ``paths`` (to import local plugins)
- next: converts the ``Plugin``s to ``LoadedPlugins``
- finally: classifies plugins into their specific types

**Param√®tres :**

- `plugins`
- `opts`

##### entry_name

Return the name given in the packaging metadata.

##### display_name

Return the name for use in user-facing / error messages.

##### all_plugins

Return an iterator over all :class:`LoadedPlugin`s.

##### versions_str

Return a user-displayed list of plugin versions.

##### blank

Make a blank PluginOptions, mostly used for tests.

**Param√®tres :**

- `cls`

---

### pycodestyle

Generated using ./bin/gen-pycodestyle-plugin.

#### Fonctions

##### pycodestyle_logical

Run pycodestyle logical checks.

**Param√®tres :**

- `blank_before`
- `blank_lines`
- `checker_state`
- `hang_closing`
- `indent_char`
- `indent_level`
- `indent_size`
- `line_number`
- `lines`
- `logical_line`
- `max_doc_length`
- `noqa`
- `previous_indent_level`
- `previous_logical`
- `previous_unindented_logical_line`
- `tokens`
- `verbose`

##### pycodestyle_physical

Run pycodestyle physical checks.

**Param√®tres :**

- `indent_char`
- `line_number`
- `lines`
- `max_line_length`
- `multiline`
- `noqa`
- `physical_line`
- `total_lines`

---

### pyflakes

Plugin built-in to Flake8 to treat pyflakes as a plugin.

#### Classes

##### FlakesChecker

Subclass the Pyflakes checker to conform with the flake8 API.

**M√©thodes :**

- `__init__()`
- `add_options()`
- `parse_options()`
- `run()`

#### Fonctions

##### __init__

Initialize the PyFlakes plugin with an AST tree and filename.

**Param√®tres :**

- `tree`
- `filename`

##### add_options

Register options for PyFlakes on the Flake8 OptionManager.

**Param√®tres :**

- `cls`
- `parser`

##### parse_options

Parse option values from Flake8's OptionManager.

**Param√®tres :**

- `cls`
- `options`

##### run

Run the plugin.

---

### reporter

Functions for constructing the requested report plugin.

#### Fonctions

##### make

Make the formatter from the requested user options.

- if :option:`flake8 --quiet` is specified, return the ``quiet-filename``
  formatter.
- if :option:`flake8 --quiet` is specified at least twice, return the
  ``quiet-nothing`` formatter.
- otherwise attempt to return the formatter by name.
- failing that, assume it is a format string and return the ``default``
  formatter.

**Param√®tres :**

- `reporters`
- `options`

---

### .!26617!__init__

---

### .!26620!finder

---

### .!26626!pycodestyle

---

### .!26632!pyflakes

---

### .!26637!reporter

---

### .!26646!__init__

---

### .!26653!pygram

---

### .!26658!pytree

---

### .!26669!pgen

---

### .!26664!token

---

### .!26672!__init__

---

### .!26678!literals

---

### .!26684!grammar

---

### .!26687!conv

---

### .!26693!parse

---

### .!26698!driver

---

### .!26703!tokenize

---

### .!26714!__init__

---

### __main__

Entry point for cli, enables execution with `python -m dotenv`

---

### cli

#### Fonctions

##### enumerate_env

Return a path for the ${pwd}/.env file.

If pwd does not exist, return None.

##### cli

This script is used to set, get or unset values from a .env file.

**Param√®tres :**

- `ctx`
- `file`
- `quote`
- `export`

##### stream_file

Open a file and yield the corresponding (decoded) stream.

Exits with error code 2 if the file cannot be opened.

**Param√®tres :**

- `path`

##### list

Display all the stored key/value.

**Param√®tres :**

- `ctx`
- `format`

##### set

Store the given key/value.

**Param√®tres :**

- `ctx`
- `key`
- `value`

##### get

Retrieve the value for the given key.

**Param√®tres :**

- `ctx`
- `key`

##### unset

Removes the given key.

**Param√®tres :**

- `ctx`
- `key`

##### run

Run command with environment variables present.

**Param√®tres :**

- `ctx`
- `override`
- `commandline`

##### run_command

Replace the current process with the specified command.

Replaces the current process with the specified command and the variables from `env`
added in the current environment variables.

Parameters
----------
command: List[str]
    The command and it's parameters
env: Dict
    The additional environment variables

Returns
-------
None
    This function does not return any value. It replaces the current process with the new one.

**Param√®tres :**

- `command`
- `env`

---

### ipython

#### Classes

##### IPythonDotEnv

**M√©thodes :**

- `dotenv()`

#### Fonctions

##### load_ipython_extension

Register the %dotenv magic.

**Param√®tres :**

- `ipython`

##### dotenv

**Param√®tres :**

- `line`

---

### main

#### Classes

##### DotEnv

**M√©thodes :**

- `__init__()`
- `_get_stream()`
- `dict()`
- `parse()`
- `set_as_environment_variables()`
- `get()`

#### Fonctions

##### with_warn_for_invalid_lines

**Param√®tres :**

- `mappings`

##### get_key

Get the value of a given key from the given .env.

Returns `None` if the key isn't found or doesn't have a value.

**Param√®tres :**

- `dotenv_path`
- `key_to_get`
- `encoding`

##### rewrite

**Param√®tres :**

- `path`
- `encoding`

##### set_key

Adds or Updates a key/value to the given .env

If the .env path given doesn't exist, fails instead of risking creating
an orphan .env somewhere in the filesystem

**Param√®tres :**

- `dotenv_path`
- `key_to_set`
- `value_to_set`
- `quote_mode`
- `export`
- `encoding`

##### unset_key

Removes a given key from the given `.env` file.

If the .env path given doesn't exist, fails.
If the given key doesn't exist in the .env, fails.

**Param√®tres :**

- `dotenv_path`
- `key_to_unset`
- `quote_mode`
- `encoding`

##### resolve_variables

**Param√®tres :**

- `values`
- `override`

##### _walk_to_root

Yield directories starting from the given directory up to the root

**Param√®tres :**

- `path`

##### find_dotenv

Search in increasingly higher folders for the given file

Returns path to the file if found, or an empty string otherwise

**Param√®tres :**

- `filename`
- `raise_error_if_not_found`
- `usecwd`

##### load_dotenv

Parse a .env file and then load all the variables found as environment variables.

Parameters:
    dotenv_path: Absolute or relative path to .env file.
    stream: Text stream (such as `io.StringIO`) with .env content, used if
        `dotenv_path` is `None`.
    verbose: Whether to output a warning the .env file is missing.
    override: Whether to override the system environment variables with the variables
        from the `.env` file.
    encoding: Encoding to be used to read the file.
Returns:
    Bool: True if at least one environment variable is set else False

If both `dotenv_path` and `stream` are `None`, `find_dotenv()` is used to find the
.env file with it's default parameters. If you need to change the default parameters
of `find_dotenv()`, you can explicitly call `find_dotenv()` and pass the result
to this function as `dotenv_path`.

**Param√®tres :**

- `dotenv_path`
- `stream`
- `verbose`
- `override`
- `interpolate`
- `encoding`

##### dotenv_values

Parse a .env file and return its content as a dict.

The returned dict will have `None` values for keys without values in the .env file.
For example, `foo=bar` results in `{"foo": "bar"}` whereas `foo` alone results in
`{"foo": None}`

Parameters:
    dotenv_path: Absolute or relative path to the .env file.
    stream: `StringIO` object with .env content, used if `dotenv_path` is `None`.
    verbose: Whether to output a warning if the .env file is missing.
    encoding: Encoding to be used to read the file.

If both `dotenv_path` and `stream` are `None`, `find_dotenv()` is used to find the
.env file.

**Param√®tres :**

- `dotenv_path`
- `stream`
- `verbose`
- `interpolate`
- `encoding`

##### __init__

**Param√®tres :**

- `dotenv_path`
- `stream`
- `verbose`
- `encoding`
- `interpolate`
- `override`

##### _get_stream

##### dict

Return dotenv as dict

##### parse

##### set_as_environment_variables

Load the current dotenv as system environment variable.

##### get

**Param√®tres :**

- `key`

##### _is_interactive

Decide whether this is running in a REPL or IPython notebook

##### _is_debugger

---

### parser

#### Classes

##### Original

##### Binding

##### Position

**M√©thodes :**

- `__init__()`
- `start()`
- `set()`
- `advance()`

##### Error

##### Reader

**M√©thodes :**

- `__init__()`
- `has_next()`
- `set_mark()`
- `get_marked()`
- `peek()`
- `read()`
- `read_regex()`

#### Fonctions

##### make_regex

**Param√®tres :**

- `string`
- `extra_flags`

##### decode_escapes

**Param√®tres :**

- `regex`
- `string`

##### parse_key

**Param√®tres :**

- `reader`

##### parse_unquoted_value

**Param√®tres :**

- `reader`

##### parse_value

**Param√®tres :**

- `reader`

##### parse_binding

**Param√®tres :**

- `reader`

##### parse_stream

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `chars`
- `line`

##### start

**Param√®tres :**

- `cls`

##### set

**Param√®tres :**

- `other`

##### advance

**Param√®tres :**

- `string`

##### __init__

**Param√®tres :**

- `stream`

##### has_next

##### set_mark

##### get_marked

##### peek

**Param√®tres :**

- `count`

##### read

**Param√®tres :**

- `count`

##### read_regex

**Param√®tres :**

- `regex`

##### decode_match

**Param√®tres :**

- `match`

---

### variables

#### Classes

##### Atom

**M√©thodes :**

- `__ne__()`
- `resolve()`

##### Literal

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__eq__()`
- `__hash__()`
- `resolve()`

##### Variable

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__eq__()`
- `__hash__()`
- `resolve()`

#### Fonctions

##### parse_variables

**Param√®tres :**

- `value`

##### __ne__

**Param√®tres :**

- `other`

##### resolve

**Param√®tres :**

- `env`

##### __init__

**Param√®tres :**

- `value`

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### resolve

**Param√®tres :**

- `env`

##### __init__

**Param√®tres :**

- `name`
- `default`

##### __repr__

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### resolve

**Param√®tres :**

- `env`

---

### version

---

### .!26720!__init__

---

### .!26724!__init__

---

### .!26730!middlewares

---

### .!26737!__main__

---

### scanner

#### Classes

##### ScannerError

##### SimpleKey

**M√©thodes :**

- `__init__()`

##### Scanner

**M√©thodes :**

- `__init__()`
- `check_token()`
- `peek_token()`
- `get_token()`
- `need_more_tokens()`
- `fetch_more_tokens()`
- `next_possible_simple_key()`
- `stale_possible_simple_keys()`
- `save_possible_simple_key()`
- `remove_possible_simple_key()`
- `unwind_indent()`
- `add_indent()`
- `fetch_stream_start()`
- `fetch_stream_end()`
- `fetch_directive()`
- `fetch_document_start()`
- `fetch_document_end()`
- `fetch_document_indicator()`
- `fetch_flow_sequence_start()`
- `fetch_flow_mapping_start()`
- `fetch_flow_collection_start()`
- `fetch_flow_sequence_end()`
- `fetch_flow_mapping_end()`
- `fetch_flow_collection_end()`
- `fetch_flow_entry()`
- `fetch_block_entry()`
- `fetch_key()`
- `fetch_value()`
- `fetch_alias()`
- `fetch_anchor()`
- `fetch_tag()`
- `fetch_literal()`
- `fetch_folded()`
- `fetch_block_scalar()`
- `fetch_single()`
- `fetch_double()`
- `fetch_flow_scalar()`
- `fetch_plain()`
- `check_directive()`
- `check_document_start()`
- `check_document_end()`
- `check_block_entry()`
- `check_key()`
- `check_value()`
- `check_plain()`
- `scan_to_next_token()`
- `scan_directive()`
- `scan_directive_name()`
- `scan_yaml_directive_value()`
- `scan_yaml_directive_number()`
- `scan_tag_directive_value()`
- `scan_tag_directive_handle()`
- `scan_tag_directive_prefix()`
- `scan_directive_ignored_line()`
- `scan_anchor()`
- `scan_tag()`
- `scan_block_scalar()`
- `scan_block_scalar_indicators()`
- `scan_block_scalar_ignored_line()`
- `scan_block_scalar_indentation()`
- `scan_block_scalar_breaks()`
- `scan_flow_scalar()`
- `scan_flow_scalar_non_spaces()`
- `scan_flow_scalar_spaces()`
- `scan_flow_scalar_breaks()`
- `scan_plain()`
- `scan_plain_spaces()`
- `scan_tag_handle()`
- `scan_tag_uri()`
- `scan_uri_escapes()`
- `scan_line_break()`

#### Fonctions

##### __init__

**Param√®tres :**

- `token_number`
- `required`
- `index`
- `line`
- `column`
- `mark`

##### __init__

Initialize the scanner.

##### check_token

##### peek_token

##### get_token

##### need_more_tokens

##### fetch_more_tokens

##### next_possible_simple_key

##### stale_possible_simple_keys

##### save_possible_simple_key

##### remove_possible_simple_key

##### unwind_indent

**Param√®tres :**

- `column`

##### add_indent

**Param√®tres :**

- `column`

##### fetch_stream_start

##### fetch_stream_end

##### fetch_directive

##### fetch_document_start

##### fetch_document_end

##### fetch_document_indicator

**Param√®tres :**

- `TokenClass`

##### fetch_flow_sequence_start

##### fetch_flow_mapping_start

##### fetch_flow_collection_start

**Param√®tres :**

- `TokenClass`

##### fetch_flow_sequence_end

##### fetch_flow_mapping_end

##### fetch_flow_collection_end

**Param√®tres :**

- `TokenClass`

##### fetch_flow_entry

##### fetch_block_entry

##### fetch_key

##### fetch_value

##### fetch_alias

##### fetch_anchor

##### fetch_tag

##### fetch_literal

##### fetch_folded

##### fetch_block_scalar

**Param√®tres :**

- `style`

##### fetch_single

##### fetch_double

##### fetch_flow_scalar

**Param√®tres :**

- `style`

##### fetch_plain

##### check_directive

##### check_document_start

##### check_document_end

##### check_block_entry

##### check_key

##### check_value

##### check_plain

##### scan_to_next_token

##### scan_directive

##### scan_directive_name

**Param√®tres :**

- `start_mark`

##### scan_yaml_directive_value

**Param√®tres :**

- `start_mark`

##### scan_yaml_directive_number

**Param√®tres :**

- `start_mark`

##### scan_tag_directive_value

**Param√®tres :**

- `start_mark`

##### scan_tag_directive_handle

**Param√®tres :**

- `start_mark`

##### scan_tag_directive_prefix

**Param√®tres :**

- `start_mark`

##### scan_directive_ignored_line

**Param√®tres :**

- `start_mark`

##### scan_anchor

**Param√®tres :**

- `TokenClass`

##### scan_tag

##### scan_block_scalar

**Param√®tres :**

- `style`

##### scan_block_scalar_indicators

**Param√®tres :**

- `start_mark`

##### scan_block_scalar_ignored_line

**Param√®tres :**

- `start_mark`

##### scan_block_scalar_indentation

##### scan_block_scalar_breaks

**Param√®tres :**

- `indent`

##### scan_flow_scalar

**Param√®tres :**

- `style`

##### scan_flow_scalar_non_spaces

**Param√®tres :**

- `double`
- `start_mark`

##### scan_flow_scalar_spaces

**Param√®tres :**

- `double`
- `start_mark`

##### scan_flow_scalar_breaks

**Param√®tres :**

- `double`
- `start_mark`

##### scan_plain

##### scan_plain_spaces

**Param√®tres :**

- `indent`
- `start_mark`

##### scan_tag_handle

**Param√®tres :**

- `name`
- `start_mark`

##### scan_tag_uri

**Param√®tres :**

- `name`
- `start_mark`

##### scan_uri_escapes

**Param√®tres :**

- `name`
- `start_mark`

##### scan_line_break

---

### error

#### Classes

##### Mark

**M√©thodes :**

- `__init__()`
- `get_snippet()`
- `__str__()`

##### YAMLError

##### MarkedYAMLError

**M√©thodes :**

- `__init__()`
- `__str__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `name`
- `index`
- `line`
- `column`
- `buffer`
- `pointer`

##### get_snippet

**Param√®tres :**

- `indent`
- `max_length`

##### __str__

##### __init__

**Param√®tres :**

- `context`
- `context_mark`
- `problem`
- `problem_mark`
- `note`

##### __str__

---

### constructor

#### Classes

##### ConstructorError

##### BaseConstructor

**M√©thodes :**

- `__init__()`
- `check_data()`
- `check_state_key()`
- `get_data()`
- `get_single_data()`
- `construct_document()`
- `construct_object()`
- `construct_scalar()`
- `construct_sequence()`
- `construct_mapping()`
- `construct_pairs()`
- `add_constructor()`
- `add_multi_constructor()`

##### SafeConstructor

**M√©thodes :**

- `construct_scalar()`
- `flatten_mapping()`
- `construct_mapping()`
- `construct_yaml_null()`
- `construct_yaml_bool()`
- `construct_yaml_int()`
- `construct_yaml_float()`
- `construct_yaml_binary()`
- `construct_yaml_timestamp()`
- `construct_yaml_omap()`
- `construct_yaml_pairs()`
- `construct_yaml_set()`
- `construct_yaml_str()`
- `construct_yaml_seq()`
- `construct_yaml_map()`
- `construct_yaml_object()`
- `construct_undefined()`

##### FullConstructor

**M√©thodes :**

- `get_state_keys_blacklist()`
- `get_state_keys_blacklist_regexp()`
- `construct_python_str()`
- `construct_python_unicode()`
- `construct_python_bytes()`
- `construct_python_long()`
- `construct_python_complex()`
- `construct_python_tuple()`
- `find_python_module()`
- `find_python_name()`
- `construct_python_name()`
- `construct_python_module()`
- `make_python_instance()`
- `set_python_instance_state()`
- `construct_python_object()`
- `construct_python_object_apply()`
- `construct_python_object_new()`

##### UnsafeConstructor

**M√©thodes :**

- `find_python_module()`
- `find_python_name()`
- `make_python_instance()`
- `set_python_instance_state()`

##### Constructor

#### Fonctions

##### __init__

##### check_data

##### check_state_key

Block special attributes/methods from being set in a newly created
object, to prevent user-controlled methods from being called during
deserialization

**Param√®tres :**

- `key`

##### get_data

##### get_single_data

##### construct_document

**Param√®tres :**

- `node`

##### construct_object

**Param√®tres :**

- `node`
- `deep`

##### construct_scalar

**Param√®tres :**

- `node`

##### construct_sequence

**Param√®tres :**

- `node`
- `deep`

##### construct_mapping

**Param√®tres :**

- `node`
- `deep`

##### construct_pairs

**Param√®tres :**

- `node`
- `deep`

##### add_constructor

**Param√®tres :**

- `cls`
- `tag`
- `constructor`

##### add_multi_constructor

**Param√®tres :**

- `cls`
- `tag_prefix`
- `multi_constructor`

##### construct_scalar

**Param√®tres :**

- `node`

##### flatten_mapping

**Param√®tres :**

- `node`

##### construct_mapping

**Param√®tres :**

- `node`
- `deep`

##### construct_yaml_null

**Param√®tres :**

- `node`

##### construct_yaml_bool

**Param√®tres :**

- `node`

##### construct_yaml_int

**Param√®tres :**

- `node`

##### construct_yaml_float

**Param√®tres :**

- `node`

##### construct_yaml_binary

**Param√®tres :**

- `node`

##### construct_yaml_timestamp

**Param√®tres :**

- `node`

##### construct_yaml_omap

**Param√®tres :**

- `node`

##### construct_yaml_pairs

**Param√®tres :**

- `node`

##### construct_yaml_set

**Param√®tres :**

- `node`

##### construct_yaml_str

**Param√®tres :**

- `node`

##### construct_yaml_seq

**Param√®tres :**

- `node`

##### construct_yaml_map

**Param√®tres :**

- `node`

##### construct_yaml_object

**Param√®tres :**

- `node`
- `cls`

##### construct_undefined

**Param√®tres :**

- `node`

##### get_state_keys_blacklist

##### get_state_keys_blacklist_regexp

##### construct_python_str

**Param√®tres :**

- `node`

##### construct_python_unicode

**Param√®tres :**

- `node`

##### construct_python_bytes

**Param√®tres :**

- `node`

##### construct_python_long

**Param√®tres :**

- `node`

##### construct_python_complex

**Param√®tres :**

- `node`

##### construct_python_tuple

**Param√®tres :**

- `node`

##### find_python_module

**Param√®tres :**

- `name`
- `mark`
- `unsafe`

##### find_python_name

**Param√®tres :**

- `name`
- `mark`
- `unsafe`

##### construct_python_name

**Param√®tres :**

- `suffix`
- `node`

##### construct_python_module

**Param√®tres :**

- `suffix`
- `node`

##### make_python_instance

**Param√®tres :**

- `suffix`
- `node`
- `args`
- `kwds`
- `newobj`
- `unsafe`

##### set_python_instance_state

**Param√®tres :**

- `instance`
- `state`
- `unsafe`

##### construct_python_object

**Param√®tres :**

- `suffix`
- `node`

##### construct_python_object_apply

**Param√®tres :**

- `suffix`
- `node`
- `newobj`

##### construct_python_object_new

**Param√®tres :**

- `suffix`
- `node`

##### find_python_module

**Param√®tres :**

- `name`
- `mark`

##### find_python_name

**Param√®tres :**

- `name`
- `mark`

##### make_python_instance

**Param√®tres :**

- `suffix`
- `node`
- `args`
- `kwds`
- `newobj`

##### set_python_instance_state

**Param√®tres :**

- `instance`
- `state`

---

### composer

#### Classes

##### ComposerError

##### Composer

**M√©thodes :**

- `__init__()`
- `check_node()`
- `get_node()`
- `get_single_node()`
- `compose_document()`
- `compose_node()`
- `compose_scalar_node()`
- `compose_sequence_node()`
- `compose_mapping_node()`

#### Fonctions

##### __init__

##### check_node

##### get_node

##### get_single_node

##### compose_document

##### compose_node

**Param√®tres :**

- `parent`
- `index`

##### compose_scalar_node

**Param√®tres :**

- `anchor`

##### compose_sequence_node

**Param√®tres :**

- `anchor`

##### compose_mapping_node

**Param√®tres :**

- `anchor`

---

### events

#### Classes

##### Event

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### NodeEvent

**M√©thodes :**

- `__init__()`

##### CollectionStartEvent

**M√©thodes :**

- `__init__()`

##### CollectionEndEvent

##### StreamStartEvent

**M√©thodes :**

- `__init__()`

##### StreamEndEvent

##### DocumentStartEvent

**M√©thodes :**

- `__init__()`

##### DocumentEndEvent

**M√©thodes :**

- `__init__()`

##### AliasEvent

##### ScalarEvent

**M√©thodes :**

- `__init__()`

##### SequenceStartEvent

##### SequenceEndEvent

##### MappingStartEvent

##### MappingEndEvent

#### Fonctions

##### __init__

**Param√®tres :**

- `start_mark`
- `end_mark`

##### __repr__

##### __init__

**Param√®tres :**

- `anchor`
- `start_mark`
- `end_mark`

##### __init__

**Param√®tres :**

- `anchor`
- `tag`
- `implicit`
- `start_mark`
- `end_mark`
- `flow_style`

##### __init__

**Param√®tres :**

- `start_mark`
- `end_mark`
- `encoding`

##### __init__

**Param√®tres :**

- `start_mark`
- `end_mark`
- `explicit`
- `version`
- `tags`

##### __init__

**Param√®tres :**

- `start_mark`
- `end_mark`
- `explicit`

##### __init__

**Param√®tres :**

- `anchor`
- `tag`
- `implicit`
- `value`
- `start_mark`
- `end_mark`
- `style`

---

### representer

#### Classes

##### RepresenterError

##### BaseRepresenter

**M√©thodes :**

- `__init__()`
- `represent()`
- `represent_data()`
- `add_representer()`
- `add_multi_representer()`
- `represent_scalar()`
- `represent_sequence()`
- `represent_mapping()`
- `ignore_aliases()`

##### SafeRepresenter

**M√©thodes :**

- `ignore_aliases()`
- `represent_none()`
- `represent_str()`
- `represent_binary()`
- `represent_bool()`
- `represent_int()`
- `represent_float()`
- `represent_list()`
- `represent_dict()`
- `represent_set()`
- `represent_date()`
- `represent_datetime()`
- `represent_yaml_object()`
- `represent_undefined()`

##### Representer

**M√©thodes :**

- `represent_complex()`
- `represent_tuple()`
- `represent_name()`
- `represent_module()`
- `represent_object()`
- `represent_ordered_dict()`

#### Fonctions

##### __init__

**Param√®tres :**

- `default_style`
- `default_flow_style`
- `sort_keys`

##### represent

**Param√®tres :**

- `data`

##### represent_data

**Param√®tres :**

- `data`

##### add_representer

**Param√®tres :**

- `cls`
- `data_type`
- `representer`

##### add_multi_representer

**Param√®tres :**

- `cls`
- `data_type`
- `representer`

##### represent_scalar

**Param√®tres :**

- `tag`
- `value`
- `style`

##### represent_sequence

**Param√®tres :**

- `tag`
- `sequence`
- `flow_style`

##### represent_mapping

**Param√®tres :**

- `tag`
- `mapping`
- `flow_style`

##### ignore_aliases

**Param√®tres :**

- `data`

##### ignore_aliases

**Param√®tres :**

- `data`

##### represent_none

**Param√®tres :**

- `data`

##### represent_str

**Param√®tres :**

- `data`

##### represent_binary

**Param√®tres :**

- `data`

##### represent_bool

**Param√®tres :**

- `data`

##### represent_int

**Param√®tres :**

- `data`

##### represent_float

**Param√®tres :**

- `data`

##### represent_list

**Param√®tres :**

- `data`

##### represent_dict

**Param√®tres :**

- `data`

##### represent_set

**Param√®tres :**

- `data`

##### represent_date

**Param√®tres :**

- `data`

##### represent_datetime

**Param√®tres :**

- `data`

##### represent_yaml_object

**Param√®tres :**

- `tag`
- `data`
- `cls`
- `flow_style`

##### represent_undefined

**Param√®tres :**

- `data`

##### represent_complex

**Param√®tres :**

- `data`

##### represent_tuple

**Param√®tres :**

- `data`

##### represent_name

**Param√®tres :**

- `data`

##### represent_module

**Param√®tres :**

- `data`

##### represent_object

**Param√®tres :**

- `data`

##### represent_ordered_dict

**Param√®tres :**

- `data`

---

### tokens

#### Classes

##### Token

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### DirectiveToken

**M√©thodes :**

- `__init__()`

##### DocumentStartToken

##### DocumentEndToken

##### StreamStartToken

**M√©thodes :**

- `__init__()`

##### StreamEndToken

##### BlockSequenceStartToken

##### BlockMappingStartToken

##### BlockEndToken

##### FlowSequenceStartToken

##### FlowMappingStartToken

##### FlowSequenceEndToken

##### FlowMappingEndToken

##### KeyToken

##### ValueToken

##### BlockEntryToken

##### FlowEntryToken

##### AliasToken

**M√©thodes :**

- `__init__()`

##### AnchorToken

**M√©thodes :**

- `__init__()`

##### TagToken

**M√©thodes :**

- `__init__()`

##### ScalarToken

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `start_mark`
- `end_mark`

##### __repr__

##### __init__

**Param√®tres :**

- `name`
- `value`
- `start_mark`
- `end_mark`

##### __init__

**Param√®tres :**

- `start_mark`
- `end_mark`
- `encoding`

##### __init__

**Param√®tres :**

- `value`
- `start_mark`
- `end_mark`

##### __init__

**Param√®tres :**

- `value`
- `start_mark`
- `end_mark`

##### __init__

**Param√®tres :**

- `value`
- `start_mark`
- `end_mark`

##### __init__

**Param√®tres :**

- `value`
- `plain`
- `start_mark`
- `end_mark`
- `style`

---

### dumper

#### Classes

##### BaseDumper

**M√©thodes :**

- `__init__()`

##### SafeDumper

**M√©thodes :**

- `__init__()`

##### Dumper

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `stream`
- `default_style`
- `default_flow_style`
- `canonical`
- `indent`
- `width`
- `allow_unicode`
- `line_break`
- `encoding`
- `explicit_start`
- `explicit_end`
- `version`
- `tags`
- `sort_keys`

##### __init__

**Param√®tres :**

- `stream`
- `default_style`
- `default_flow_style`
- `canonical`
- `indent`
- `width`
- `allow_unicode`
- `line_break`
- `encoding`
- `explicit_start`
- `explicit_end`
- `version`
- `tags`
- `sort_keys`

##### __init__

**Param√®tres :**

- `stream`
- `default_style`
- `default_flow_style`
- `canonical`
- `indent`
- `width`
- `allow_unicode`
- `line_break`
- `encoding`
- `explicit_start`
- `explicit_end`
- `version`
- `tags`
- `sort_keys`

---

### cyaml

#### Classes

##### CBaseLoader

**M√©thodes :**

- `__init__()`

##### CSafeLoader

**M√©thodes :**

- `__init__()`

##### CFullLoader

**M√©thodes :**

- `__init__()`

##### CUnsafeLoader

**M√©thodes :**

- `__init__()`

##### CLoader

**M√©thodes :**

- `__init__()`

##### CBaseDumper

**M√©thodes :**

- `__init__()`

##### CSafeDumper

**M√©thodes :**

- `__init__()`

##### CDumper

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`
- `default_style`
- `default_flow_style`
- `canonical`
- `indent`
- `width`
- `allow_unicode`
- `line_break`
- `encoding`
- `explicit_start`
- `explicit_end`
- `version`
- `tags`
- `sort_keys`

##### __init__

**Param√®tres :**

- `stream`
- `default_style`
- `default_flow_style`
- `canonical`
- `indent`
- `width`
- `allow_unicode`
- `line_break`
- `encoding`
- `explicit_start`
- `explicit_end`
- `version`
- `tags`
- `sort_keys`

##### __init__

**Param√®tres :**

- `stream`
- `default_style`
- `default_flow_style`
- `canonical`
- `indent`
- `width`
- `allow_unicode`
- `line_break`
- `encoding`
- `explicit_start`
- `explicit_end`
- `version`
- `tags`
- `sort_keys`

---

### parser

#### Classes

##### ParserError

##### Parser

**M√©thodes :**

- `__init__()`
- `dispose()`
- `check_event()`
- `peek_event()`
- `get_event()`
- `parse_stream_start()`
- `parse_implicit_document_start()`
- `parse_document_start()`
- `parse_document_end()`
- `parse_document_content()`
- `process_directives()`
- `parse_block_node()`
- `parse_flow_node()`
- `parse_block_node_or_indentless_sequence()`
- `parse_node()`
- `parse_block_sequence_first_entry()`
- `parse_block_sequence_entry()`
- `parse_indentless_sequence_entry()`
- `parse_block_mapping_first_key()`
- `parse_block_mapping_key()`
- `parse_block_mapping_value()`
- `parse_flow_sequence_first_entry()`
- `parse_flow_sequence_entry()`
- `parse_flow_sequence_entry_mapping_key()`
- `parse_flow_sequence_entry_mapping_value()`
- `parse_flow_sequence_entry_mapping_end()`
- `parse_flow_mapping_first_key()`
- `parse_flow_mapping_key()`
- `parse_flow_mapping_value()`
- `parse_flow_mapping_empty_value()`
- `process_empty_scalar()`

#### Fonctions

##### __init__

##### dispose

##### check_event

##### peek_event

##### get_event

##### parse_stream_start

##### parse_implicit_document_start

##### parse_document_start

##### parse_document_end

##### parse_document_content

##### process_directives

##### parse_block_node

##### parse_flow_node

##### parse_block_node_or_indentless_sequence

##### parse_node

**Param√®tres :**

- `block`
- `indentless_sequence`

##### parse_block_sequence_first_entry

##### parse_block_sequence_entry

##### parse_indentless_sequence_entry

##### parse_block_mapping_first_key

##### parse_block_mapping_key

##### parse_block_mapping_value

##### parse_flow_sequence_first_entry

##### parse_flow_sequence_entry

**Param√®tres :**

- `first`

##### parse_flow_sequence_entry_mapping_key

##### parse_flow_sequence_entry_mapping_value

##### parse_flow_sequence_entry_mapping_end

##### parse_flow_mapping_first_key

##### parse_flow_mapping_key

**Param√®tres :**

- `first`

##### parse_flow_mapping_value

##### parse_flow_mapping_empty_value

##### process_empty_scalar

**Param√®tres :**

- `mark`

---

### reader

#### Classes

##### ReaderError

**M√©thodes :**

- `__init__()`
- `__str__()`

##### Reader

**M√©thodes :**

- `__init__()`
- `peek()`
- `prefix()`
- `forward()`
- `get_mark()`
- `determine_encoding()`
- `check_printable()`
- `update()`
- `update_raw()`

#### Fonctions

##### __init__

**Param√®tres :**

- `name`
- `position`
- `character`
- `encoding`
- `reason`

##### __str__

##### __init__

**Param√®tres :**

- `stream`

##### peek

**Param√®tres :**

- `index`

##### prefix

**Param√®tres :**

- `length`

##### forward

**Param√®tres :**

- `length`

##### get_mark

##### determine_encoding

##### check_printable

**Param√®tres :**

- `data`

##### update

**Param√®tres :**

- `length`

##### update_raw

**Param√®tres :**

- `size`

---

### loader

#### Classes

##### BaseLoader

**M√©thodes :**

- `__init__()`

##### FullLoader

**M√©thodes :**

- `__init__()`

##### SafeLoader

**M√©thodes :**

- `__init__()`

##### Loader

**M√©thodes :**

- `__init__()`

##### UnsafeLoader

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

##### __init__

**Param√®tres :**

- `stream`

---

### resolver

#### Classes

##### ResolverError

##### BaseResolver

**M√©thodes :**

- `__init__()`
- `add_implicit_resolver()`
- `add_path_resolver()`
- `descend_resolver()`
- `ascend_resolver()`
- `check_resolver_prefix()`
- `resolve()`

##### Resolver

#### Fonctions

##### __init__

##### add_implicit_resolver

**Param√®tres :**

- `cls`
- `tag`
- `regexp`
- `first`

##### add_path_resolver

**Param√®tres :**

- `cls`
- `tag`
- `path`
- `kind`

##### descend_resolver

**Param√®tres :**

- `current_node`
- `current_index`

##### ascend_resolver

##### check_resolver_prefix

**Param√®tres :**

- `depth`
- `path`
- `kind`
- `current_node`
- `current_index`

##### resolve

**Param√®tres :**

- `kind`
- `value`
- `implicit`

---

### serializer

#### Classes

##### SerializerError

##### Serializer

**M√©thodes :**

- `__init__()`
- `open()`
- `close()`
- `serialize()`
- `anchor_node()`
- `generate_anchor()`
- `serialize_node()`

#### Fonctions

##### __init__

**Param√®tres :**

- `encoding`
- `explicit_start`
- `explicit_end`
- `version`
- `tags`

##### open

##### close

##### serialize

**Param√®tres :**

- `node`

##### anchor_node

**Param√®tres :**

- `node`

##### generate_anchor

**Param√®tres :**

- `node`

##### serialize_node

**Param√®tres :**

- `node`
- `parent`
- `index`

---

### nodes

#### Classes

##### Node

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### ScalarNode

**M√©thodes :**

- `__init__()`

##### CollectionNode

**M√©thodes :**

- `__init__()`

##### SequenceNode

##### MappingNode

#### Fonctions

##### __init__

**Param√®tres :**

- `tag`
- `value`
- `start_mark`
- `end_mark`

##### __repr__

##### __init__

**Param√®tres :**

- `tag`
- `value`
- `start_mark`
- `end_mark`
- `style`

##### __init__

**Param√®tres :**

- `tag`
- `value`
- `start_mark`
- `end_mark`
- `flow_style`

---

### emitter

#### Classes

##### EmitterError

##### ScalarAnalysis

**M√©thodes :**

- `__init__()`

##### Emitter

**M√©thodes :**

- `__init__()`
- `dispose()`
- `emit()`
- `need_more_events()`
- `need_events()`
- `increase_indent()`
- `expect_stream_start()`
- `expect_nothing()`
- `expect_first_document_start()`
- `expect_document_start()`
- `expect_document_end()`
- `expect_document_root()`
- `expect_node()`
- `expect_alias()`
- `expect_scalar()`
- `expect_flow_sequence()`
- `expect_first_flow_sequence_item()`
- `expect_flow_sequence_item()`
- `expect_flow_mapping()`
- `expect_first_flow_mapping_key()`
- `expect_flow_mapping_key()`
- `expect_flow_mapping_simple_value()`
- `expect_flow_mapping_value()`
- `expect_block_sequence()`
- `expect_first_block_sequence_item()`
- `expect_block_sequence_item()`
- `expect_block_mapping()`
- `expect_first_block_mapping_key()`
- `expect_block_mapping_key()`
- `expect_block_mapping_simple_value()`
- `expect_block_mapping_value()`
- `check_empty_sequence()`
- `check_empty_mapping()`
- `check_empty_document()`
- `check_simple_key()`
- `process_anchor()`
- `process_tag()`
- `choose_scalar_style()`
- `process_scalar()`
- `prepare_version()`
- `prepare_tag_handle()`
- `prepare_tag_prefix()`
- `prepare_tag()`
- `prepare_anchor()`
- `analyze_scalar()`
- `flush_stream()`
- `write_stream_start()`
- `write_stream_end()`
- `write_indicator()`
- `write_indent()`
- `write_line_break()`
- `write_version_directive()`
- `write_tag_directive()`
- `write_single_quoted()`
- `write_double_quoted()`
- `determine_block_hints()`
- `write_folded()`
- `write_literal()`
- `write_plain()`

#### Fonctions

##### __init__

**Param√®tres :**

- `scalar`
- `empty`
- `multiline`
- `allow_flow_plain`
- `allow_block_plain`
- `allow_single_quoted`
- `allow_double_quoted`
- `allow_block`

##### __init__

**Param√®tres :**

- `stream`
- `canonical`
- `indent`
- `width`
- `allow_unicode`
- `line_break`

##### dispose

##### emit

**Param√®tres :**

- `event`

##### need_more_events

##### need_events

**Param√®tres :**

- `count`

##### increase_indent

**Param√®tres :**

- `flow`
- `indentless`

##### expect_stream_start

##### expect_nothing

##### expect_first_document_start

##### expect_document_start

**Param√®tres :**

- `first`

##### expect_document_end

##### expect_document_root

##### expect_node

**Param√®tres :**

- `root`
- `sequence`
- `mapping`
- `simple_key`

##### expect_alias

##### expect_scalar

##### expect_flow_sequence

##### expect_first_flow_sequence_item

##### expect_flow_sequence_item

##### expect_flow_mapping

##### expect_first_flow_mapping_key

##### expect_flow_mapping_key

##### expect_flow_mapping_simple_value

##### expect_flow_mapping_value

##### expect_block_sequence

##### expect_first_block_sequence_item

##### expect_block_sequence_item

**Param√®tres :**

- `first`

##### expect_block_mapping

##### expect_first_block_mapping_key

##### expect_block_mapping_key

**Param√®tres :**

- `first`

##### expect_block_mapping_simple_value

##### expect_block_mapping_value

##### check_empty_sequence

##### check_empty_mapping

##### check_empty_document

##### check_simple_key

##### process_anchor

**Param√®tres :**

- `indicator`

##### process_tag

##### choose_scalar_style

##### process_scalar

##### prepare_version

**Param√®tres :**

- `version`

##### prepare_tag_handle

**Param√®tres :**

- `handle`

##### prepare_tag_prefix

**Param√®tres :**

- `prefix`

##### prepare_tag

**Param√®tres :**

- `tag`

##### prepare_anchor

**Param√®tres :**

- `anchor`

##### analyze_scalar

**Param√®tres :**

- `scalar`

##### flush_stream

##### write_stream_start

##### write_stream_end

##### write_indicator

**Param√®tres :**

- `indicator`
- `need_whitespace`
- `whitespace`
- `indention`

##### write_indent

##### write_line_break

**Param√®tres :**

- `data`

##### write_version_directive

**Param√®tres :**

- `version_text`

##### write_tag_directive

**Param√®tres :**

- `handle_text`
- `prefix_text`

##### write_single_quoted

**Param√®tres :**

- `text`
- `split`

##### write_double_quoted

**Param√®tres :**

- `text`
- `split`

##### determine_block_hints

**Param√®tres :**

- `text`

##### write_folded

**Param√®tres :**

- `text`

##### write_literal

**Param√®tres :**

- `text`

##### write_plain

**Param√®tres :**

- `text`
- `split`

---

### .!26743!scanner

---

### .!26748!error

---

### .!26751!constructor

---

### .!26755!composer

---

### .!26760!events

---

### .!26765!__init__

---

### .!26768!representer

---

### .!26772!tokens

---

### .!26777!dumper

---

### .!26782!cyaml

---

### .!26786!parser

---

### .!26790!reader

---

### .!26795!loader

---

### .!26799!resolver

---

### .!26803!serializer

---

### .!26810!nodes

---

### .!26813!emitter

---

### .!26817!__init__

---

### .!26823!__init__

---

### .!26829!__init__

---

### .!26837!__init__

---

### .!26842!__init__

---

### .!26848!__init__

---

### .!26852!__init__

---

### .!26858!__init__

---

### .!26863!context

---

### .!26868!contextvars_context

---

### .!26872!__init__

---

### .!26879!__init__

---

### .!26884!__init__

---

### .!26889!instrument

---

### .!26895!observation

---

### .!26901!__init__

---

### .!26906!composite

---

### .!26912!textmap

---

### .!26921!span

---

### .!26918!__init__

---

### .!26927!status

---

### .!26931!__init__

---

### .!26935!tracecontext

---

### .!26961!re

---

### .!26941!_decorator

---

### .!26946!_importlib_metadata

---

### .!26951!_once

---

### .!26955!_providers

---

### .!26965!types

---

### .!26971!__init__

---

### __main__

pygments.__main__
~~~~~~~~~~~~~~~~~

Main entry point for ``python -m pygments``.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### cmdline

pygments.cmdline
~~~~~~~~~~~~~~~~

Command line interface.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### HelpFormatter

**M√©thodes :**

- `__init__()`

#### Fonctions

##### _parse_options

**Param√®tres :**

- `o_strs`

##### _parse_filters

**Param√®tres :**

- `f_strs`

##### _print_help

**Param√®tres :**

- `what`
- `name`

##### _print_list

**Param√®tres :**

- `what`

##### _print_list_as_json

**Param√®tres :**

- `requested_items`

##### main_inner

**Param√®tres :**

- `parser`
- `argns`

##### main

Main command line entry point.

**Param√®tres :**

- `args`

##### is_only_option

**Param√®tres :**

- `opt`

##### __init__

**Param√®tres :**

- `prog`
- `indent_increment`
- `max_help_position`
- `width`

---

### .!27056!util

---

### console

pygments.console
~~~~~~~~~~~~~~~~

Format colored console output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### reset_color

##### colorize

**Param√®tres :**

- `color_key`
- `text`

##### ansiformat

Format ``text`` with a color and/or some attributes::

    color       normal color
    *color*     bold color
    _color_     underlined color
    +color+     blinking color

**Param√®tres :**

- `attr`
- `text`

---

### filter

pygments.filter
~~~~~~~~~~~~~~~

Module that implements the default filter.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Filter

Default filter. Subclass this class or use the `simplefilter`
decorator to create own filters.

**M√©thodes :**

- `__init__()`
- `filter()`

##### FunctionFilter

Abstract class used by `simplefilter` to create simple
function filters on the fly. The `simplefilter` decorator
automatically creates subclasses of this class for
functions passed to it.

**M√©thodes :**

- `__init__()`
- `filter()`

#### Fonctions

##### apply_filters

Use this method to apply an iterable of filters to
a stream. If lexer is given it's forwarded to the
filter, otherwise the filter receives `None`.

**Param√®tres :**

- `stream`
- `filters`
- `lexer`

##### simplefilter

Decorator that converts a function into a filter::

    @simplefilter
    def lowercase(self, lexer, stream, options):
        for ttype, value in stream:
            yield ttype, value.lower()

**Param√®tres :**

- `f`

##### _apply

**Param√®tres :**

- `filter_`
- `stream`

##### __init__

##### filter

**Param√®tres :**

- `lexer`
- `stream`

##### __init__

##### filter

**Param√®tres :**

- `lexer`
- `stream`

---

### formatter

pygments.formatter
~~~~~~~~~~~~~~~~~~

Base formatter class.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Formatter

Converts a token stream to text.

Formatters should have attributes to help selecting them. These
are similar to the corresponding :class:`~pygments.lexer.Lexer`
attributes.

.. autoattribute:: name
   :no-value:

.. autoattribute:: aliases
   :no-value:

.. autoattribute:: filenames
   :no-value:

You can pass options as keyword arguments to the constructor.
All formatters accept these basic options:

``style``
    The style to use, can be a string or a Style subclass
    (default: "default"). Not used by e.g. the
    TerminalFormatter.
``full``
    Tells the formatter to output a "full" document, i.e.
    a complete self-contained document. This doesn't have
    any effect for some formatters (default: false).
``title``
    If ``full`` is true, the title that should be used to
    caption the document (default: '').
``encoding``
    If given, must be an encoding name. This will be used to
    convert the Unicode token strings to byte strings in the
    output. If it is "" or None, Unicode strings will be written
    to the output file, which most file-like objects do not
    support (default: None).
``outencoding``
    Overrides ``encoding`` if given.

**M√©thodes :**

- `__init__()`
- `get_style_defs()`
- `format()`
- `__class_getitem__()`

#### Fonctions

##### _lookup_style

**Param√®tres :**

- `style`

##### __init__

As with lexers, this constructor takes arbitrary optional arguments,
and if you override it, you should first process your own options, then
call the base class implementation.

##### get_style_defs

This method must return statements or declarations suitable to define
the current style for subsequent highlighted text (e.g. CSS classes
in the `HTMLFormatter`).

The optional argument `arg` can be used to modify the generation and
is formatter dependent (it is standardized because it can be given on
the command line).

This method is called by the ``-S`` :doc:`command-line option <cmdline>`,
the `arg` is then given by the ``-a`` option.

**Param√®tres :**

- `arg`

##### format

This method must format the tokens from the `tokensource` iterable and
write the formatted version to the file object `outfile`.

Formatter options can control how exactly the tokens are converted.

**Param√®tres :**

- `tokensource`
- `outfile`

##### __class_getitem__

**Param√®tres :**

- `cls`
- `name`

---

### lexer

pygments.lexer
~~~~~~~~~~~~~~

Base lexer classes.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LexerMeta

This metaclass automagically converts ``analyse_text`` methods into
static methods which always return float values.

**M√©thodes :**

- `__new__()`

##### Lexer

Lexer for a specific language.

See also :doc:`lexerdevelopment`, a high-level guide to writing
lexers.

Lexer classes have attributes used for choosing the most appropriate
lexer based on various criteria.

.. autoattribute:: name
   :no-value:
.. autoattribute:: aliases
   :no-value:
.. autoattribute:: filenames
   :no-value:
.. autoattribute:: alias_filenames
.. autoattribute:: mimetypes
   :no-value:
.. autoattribute:: priority

Lexers included in Pygments should have two additional attributes:

.. autoattribute:: url
   :no-value:
.. autoattribute:: version_added
   :no-value:

Lexers included in Pygments may have additional attributes:

.. autoattribute:: _example
   :no-value:

You can pass options to the constructor. The basic options recognized
by all lexers and processed by the base `Lexer` class are:

``stripnl``
    Strip leading and trailing newlines from the input (default: True).
``stripall``
    Strip all leading and trailing whitespace from the input
    (default: False).
``ensurenl``
    Make sure that the input ends with a newline (default: True).  This
    is required for some lexers that consume input linewise.

    .. versionadded:: 1.3

``tabsize``
    If given and greater than 0, expand tabs in the input (default: 0).
``encoding``
    If given, must be an encoding name. This encoding will be used to
    convert the input string to Unicode, if it is not already a Unicode
    string (default: ``'guess'``, which uses a simple UTF-8 / Locale /
    Latin1 detection.  Can also be ``'chardet'`` to use the chardet
    library, if it is installed.
``inencoding``
    Overrides the ``encoding`` if given.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `add_filter()`
- `analyse_text()`
- `_preprocess_lexer_input()`
- `get_tokens()`
- `get_tokens_unprocessed()`

##### DelegatingLexer

This lexer takes two lexer as arguments. A root lexer and
a language lexer. First everything is scanned using the language
lexer, afterwards all ``Other`` tokens are lexed using the root
lexer.

The lexers from the ``template`` lexer package use this base lexer.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### include

Indicates that a state should include rules from another state.

##### _inherit

Indicates the a state should inherit from its superclass.

**M√©thodes :**

- `__repr__()`

##### combined

Indicates a state combined from multiple states.

**M√©thodes :**

- `__new__()`
- `__init__()`

##### _PseudoMatch

A pseudo match object constructed from a string.

**M√©thodes :**

- `__init__()`
- `start()`
- `end()`
- `group()`
- `groups()`
- `groupdict()`

##### _This

Special singleton used for indicating the caller class.
Used by ``using``.

##### default

Indicates a state or state action (e.g. #pop) to apply.
For example default('#pop') is equivalent to ('', Token, '#pop')
Note that state tuples may be used as well.

.. versionadded:: 2.0

**M√©thodes :**

- `__init__()`

##### words

Indicates a list of literal words that is transformed into an optimized
regex that matches any of the words.

.. versionadded:: 2.0

**M√©thodes :**

- `__init__()`
- `get()`

##### RegexLexerMeta

Metaclass for RegexLexer, creates the self._tokens attribute from
self.tokens on the first instantiation.

**M√©thodes :**

- `_process_regex()`
- `_process_token()`
- `_process_new_state()`
- `_process_state()`
- `process_tokendef()`
- `get_tokendefs()`
- `__call__()`

##### RegexLexer

Base for simple stateful regular expression-based lexers.
Simplifies the lexing process so that you need only
provide a list of states and regular expressions.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### LexerContext

A helper object that holds lexer position data.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### ExtendedRegexLexer

A RegexLexer that uses a context object to store its state.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### ProfilingRegexLexerMeta

Metaclass for ProfilingRegexLexer, collects regex timing info.

**M√©thodes :**

- `_process_regex()`

##### ProfilingRegexLexer

Drop-in replacement for RegexLexer that does profiling of its regexes.

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### bygroups

Callback that yields multiple actions for each group in the match.

##### using

Callback that processes the match with a different lexer.

The keyword arguments are forwarded to the lexer, except `state` which
is handled separately.

`state` specifies the state that the new lexer will start in, and can
be an enumerable such as ('root', 'inline', 'string') or a simple
string which is assumed to be on top of the root state.

Note: For that to work, `_other` must not be an `ExtendedRegexLexer`.

**Param√®tres :**

- `_other`

##### do_insertions

Helper for lexers which must combine the results of several
sublexers.

``insertions`` is a list of ``(index, itokens)`` pairs.
Each ``itokens`` iterable should be inserted at position
``index`` into the token stream given by the ``tokens``
argument.

The result is a combined token stream.

TODO: clean up the code here.

**Param√®tres :**

- `insertions`
- `tokens`

##### __new__

**Param√®tres :**

- `mcs`
- `name`
- `bases`
- `d`

##### __init__

This constructor takes arbitrary options as keyword arguments.
Every subclass must first process its own options and then call
the `Lexer` constructor, since it processes the basic
options like `stripnl`.

An example looks like this:

.. sourcecode:: python

   def __init__(self, **options):
       self.compress = options.get('compress', '')
       Lexer.__init__(self, **options)

As these options must all be specifiable as strings (due to the
command line usage), there are various utility functions
available to help with that, see `Utilities`_.

##### __repr__

##### add_filter

Add a new stream filter to this lexer.

**Param√®tres :**

- `filter_`

##### analyse_text

A static method which is called for lexer guessing.

It should analyse the text and return a float in the range
from ``0.0`` to ``1.0``.  If it returns ``0.0``, the lexer
will not be selected as the most probable one, if it returns
``1.0``, it will be selected immediately.  This is used by
`guess_lexer`.

The `LexerMeta` metaclass automatically wraps this function so
that it works like a static method (no ``self`` or ``cls``
parameter) and the return value is automatically converted to
`float`. If the return value is an object that is boolean `False`
it's the same as if the return values was ``0.0``.

**Param√®tres :**

- `text`

##### _preprocess_lexer_input

Apply preprocessing such as decoding the input, removing BOM and normalizing newlines.

**Param√®tres :**

- `text`

##### get_tokens

This method is the basic interface of a lexer. It is called by
the `highlight()` function. It must process the text and return an
iterable of ``(tokentype, value)`` pairs from `text`.

Normally, you don't need to override this method. The default
implementation processes the options recognized by all lexers
(`stripnl`, `stripall` and so on), and then yields all tokens
from `get_tokens_unprocessed()`, with the ``index`` dropped.

If `unfiltered` is set to `True`, the filtering mechanism is
bypassed even if filters are defined.

**Param√®tres :**

- `text`
- `unfiltered`

##### get_tokens_unprocessed

This method should process the text and return an iterable of
``(index, tokentype, value)`` tuples where ``index`` is the starting
position of the token within the input text.

It must be overridden by subclasses. It is recommended to
implement it as a generator to maximize effectiveness.

**Param√®tres :**

- `text`

##### __init__

**Param√®tres :**

- `_root_lexer`
- `_language_lexer`
- `_needle`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __repr__

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### __init__

**Param√®tres :**

- `start`
- `text`

##### start

**Param√®tres :**

- `arg`

##### end

**Param√®tres :**

- `arg`

##### group

**Param√®tres :**

- `arg`

##### groups

##### groupdict

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### __init__

**Param√®tres :**

- `state`

##### __init__

**Param√®tres :**

- `words`
- `prefix`
- `suffix`

##### get

##### _process_regex

Preprocess the regular expression component of a token definition.

**Param√®tres :**

- `cls`
- `regex`
- `rflags`
- `state`

##### _process_token

Preprocess the token component of a token definition.

**Param√®tres :**

- `cls`
- `token`

##### _process_new_state

Preprocess the state transition action of a token definition.

**Param√®tres :**

- `cls`
- `new_state`
- `unprocessed`
- `processed`

##### _process_state

Preprocess a single state definition.

**Param√®tres :**

- `cls`
- `unprocessed`
- `processed`
- `state`

##### process_tokendef

Preprocess a dictionary of token definitions.

**Param√®tres :**

- `cls`
- `name`
- `tokendefs`

##### get_tokendefs

Merge tokens from superclasses in MRO order, returning a single tokendef
dictionary.

Any state that is not defined by a subclass will be inherited
automatically.  States that *are* defined by subclasses will, by
default, override that state in the superclass.  If a subclass wishes to
inherit definitions from a superclass, it can use the special value
"inherit", which will cause the superclass' state definition to be
included at that point in the state.

**Param√®tres :**

- `cls`

##### __call__

Instantiate cls after preprocessing its token definitions.

**Param√®tres :**

- `cls`

##### get_tokens_unprocessed

Split ``text`` into (tokentype, text) pairs.

``stack`` is the initial stack (default: ``['root']``)

**Param√®tres :**

- `text`
- `stack`

##### __init__

**Param√®tres :**

- `text`
- `pos`
- `stack`
- `end`

##### __repr__

##### get_tokens_unprocessed

Split ``text`` into (tokentype, text) pairs.
If ``context`` is given, use this lexer context instead.

**Param√®tres :**

- `text`
- `context`

##### _process_regex

**Param√®tres :**

- `cls`
- `regex`
- `rflags`
- `state`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

##### streamer

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### match_func

**Param√®tres :**

- `text`
- `pos`
- `endpos`

---

### modeline

pygments.modeline
~~~~~~~~~~~~~~~~~

A simple modeline parser (based on pymodeline).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### get_filetype_from_line

**Param√®tres :**

- `l`

##### get_filetype_from_buffer

Scan the buffer for modelines and return filetype if one is found.

**Param√®tres :**

- `buf`
- `max_lines`

---

### plugin

pygments.plugin
~~~~~~~~~~~~~~~

Pygments plugin interface.

lexer plugins::

    [pygments.lexers]
    yourlexer = yourmodule:YourLexer

formatter plugins::

    [pygments.formatters]
    yourformatter = yourformatter:YourFormatter
    /.ext = yourformatter:YourFormatter

As you can see, you can define extensions for the formatter
with a leading slash.

syntax plugins::

    [pygments.styles]
    yourstyle = yourstyle:YourStyle

filter plugin::

    [pygments.filter]
    yourfilter = yourfilter:YourFilter


:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### iter_entry_points

**Param√®tres :**

- `group_name`

##### find_plugin_lexers

##### find_plugin_formatters

##### find_plugin_styles

##### find_plugin_filters

---

### regexopt

pygments.regexopt
~~~~~~~~~~~~~~~~~

An algorithm that generates optimized regexes for matching long lists of
literal strings.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### make_charset

**Param√®tres :**

- `letters`

##### regex_opt_inner

Return a regex that matches any string in the sorted list of strings.

**Param√®tres :**

- `strings`
- `open_paren`

##### regex_opt

Return a compiled regex that matches any string in the given list.

The strings to match must be literal strings, not regexes.  They will be
regex-escaped.

*prefix* and *suffix* are pre- and appended to the final regex.

**Param√®tres :**

- `strings`
- `prefix`
- `suffix`

---

### scanner

pygments.scanner
~~~~~~~~~~~~~~~~

This library implements a regex based scanner. Some languages
like Pascal are easy to parse but have some keywords that
depend on the context. Because of this it's impossible to lex
that just by using a regular expression lexer like the
`RegexLexer`.

Have a look at the `DelphiLexer` to get an idea of how to use
this scanner.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### EndOfText

Raise if end of text is reached and the user
tried to call a match function.

##### Scanner

Simple scanner

All method patterns are regular expression strings (not
compiled expressions!)

**M√©thodes :**

- `__init__()`
- `eos()`
- `check()`
- `test()`
- `scan()`
- `get_char()`
- `__repr__()`

#### Fonctions

##### __init__

:param text:    The text which should be scanned
:param flags:   default regular expression flags

**Param√®tres :**

- `text`
- `flags`

##### eos

`True` if the scanner reached the end of text.

##### check

Apply `pattern` on the current position and return
the match object. (Doesn't touch pos). Use this for
lookahead.

**Param√®tres :**

- `pattern`

##### test

Apply a pattern on the current position and check
if it patches. Doesn't touch pos.

**Param√®tres :**

- `pattern`

##### scan

Scan the text for the given pattern and update pos/match
and related fields. The return value is a boolean that
indicates if the pattern matched. The matched value is
stored on the instance as ``match``, the last value is
stored as ``last``. ``start_pos`` is the position of the
pointer before the pattern was matched, ``pos`` is the
end position.

**Param√®tres :**

- `pattern`

##### get_char

Scan exactly one char.

##### __repr__

---

### sphinxext

pygments.sphinxext
~~~~~~~~~~~~~~~~~~

Sphinx extension to generate automatic documentation of lexers,
formatters and filters.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PygmentsDoc

A directive to collect all lexers/formatters/filters and generate
autoclass directives for them.

**M√©thodes :**

- `run()`
- `document_lexers_overview()`
- `document_lexers()`
- `document_formatters()`
- `document_filters()`

#### Fonctions

##### setup

**Param√®tres :**

- `app`

##### run

##### document_lexers_overview

Generate a tabular overview of all lexers.

The columns are the lexer name, the extensions handled by this lexer
(or "None"), the aliases and a link to the lexer class.

##### document_lexers

##### document_formatters

##### document_filters

##### format_link

**Param√®tres :**

- `name`
- `url`

##### write_row

Format a table row

##### write_seperator

Write a table separator row

---

### style

pygments.style
~~~~~~~~~~~~~~

Basic style object.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### StyleMeta

**M√©thodes :**

- `__new__()`
- `style_for_token()`
- `list_styles()`
- `styles_token()`
- `__iter__()`
- `__len__()`

##### Style

#### Fonctions

##### __new__

**Param√®tres :**

- `mcs`
- `name`
- `bases`
- `dct`

##### style_for_token

**Param√®tres :**

- `cls`
- `token`

##### list_styles

**Param√®tres :**

- `cls`

##### styles_token

**Param√®tres :**

- `cls`
- `ttype`

##### __iter__

**Param√®tres :**

- `cls`

##### __len__

**Param√®tres :**

- `cls`

##### colorformat

**Param√®tres :**

- `text`

---

### token

pygments.token
~~~~~~~~~~~~~~

Basic token types and the standard tokens.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### _TokenType

**M√©thodes :**

- `split()`
- `__init__()`
- `__contains__()`
- `__getattr__()`
- `__repr__()`
- `__copy__()`
- `__deepcopy__()`

#### Fonctions

##### is_token_subtype

Return True if ``ttype`` is a subtype of ``other``.

exists for backwards compatibility. use ``ttype in other`` now.

**Param√®tres :**

- `ttype`
- `other`

##### string_to_tokentype

Convert a string into a token type::

    >>> string_to_token('String.Double')
    Token.Literal.String.Double
    >>> string_to_token('Token.Literal.Number')
    Token.Literal.Number
    >>> string_to_token('')
    Token

Tokens that are already tokens are returned unchanged:

    >>> string_to_token(String)
    Token.Literal.String

**Param√®tres :**

- `s`

##### split

##### __init__

##### __contains__

**Param√®tres :**

- `val`

##### __getattr__

**Param√®tres :**

- `val`

##### __repr__

##### __copy__

##### __deepcopy__

**Param√®tres :**

- `memo`

---

### unistring

pygments.unistring
~~~~~~~~~~~~~~~~~~

Strings of all Unicode characters of a certain category.
Used for matching in Unicode-aware languages. Run to regenerate.

Inspired by chartypes_create.py from the MoinMoin project.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### combine

##### allexcept

##### _handle_runs

**Param√®tres :**

- `char_list`

---

### util

pygments.util
~~~~~~~~~~~~~

Utility functions.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ClassNotFound

Raised if one of the lookup functions didn't find a matching class.

##### OptionError

This exception will be raised by all option processing functions if
the type or value of the argument is not correct.

##### Future

Generic class to defer some work.

Handled specially in RegexLexerMeta, to support regex string construction at
first use.

**M√©thodes :**

- `get()`

##### UnclosingTextIOWrapper

**M√©thodes :**

- `close()`

#### Fonctions

##### get_choice_opt

If the key `optname` from the dictionary is not in the sequence
`allowed`, raise an error, otherwise return it.

**Param√®tres :**

- `options`
- `optname`
- `allowed`
- `default`
- `normcase`

##### get_bool_opt

Intuitively, this is `options.get(optname, default)`, but restricted to
Boolean value. The Booleans can be represented as string, in order to accept
Boolean value from the command line arguments. If the key `optname` is
present in the dictionary `options` and is not associated with a Boolean,
raise an `OptionError`. If it is absent, `default` is returned instead.

The valid string values for ``True`` are ``1``, ``yes``, ``true`` and
``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``
(matched case-insensitively).

**Param√®tres :**

- `options`
- `optname`
- `default`

##### get_int_opt

As :func:`get_bool_opt`, but interpret the value as an integer.

**Param√®tres :**

- `options`
- `optname`
- `default`

##### get_list_opt

If the key `optname` from the dictionary `options` is a string,
split it at whitespace and return it. If it is already a list
or a tuple, it is returned as a list.

**Param√®tres :**

- `options`
- `optname`
- `default`

##### docstring_headline

**Param√®tres :**

- `obj`

##### make_analysator

Return a static text analyser function that returns float values.

**Param√®tres :**

- `f`

##### shebang_matches

Check if the given regular expression matches the last part of the
shebang if one exists.

    >>> from pygments.util import shebang_matches
    >>> shebang_matches('#!/usr/bin/env python', r'python(2\.\d)?')
    True
    >>> shebang_matches('#!/usr/bin/python2.4', r'python(2\.\d)?')
    True
    >>> shebang_matches('#!/usr/bin/python-ruby', r'python(2\.\d)?')
    False
    >>> shebang_matches('#!/usr/bin/python/ruby', r'python(2\.\d)?')
    False
    >>> shebang_matches('#!/usr/bin/startsomethingwith python',
    ...                 r'python(2\.\d)?')
    True

It also checks for common windows executable file extensions::

    >>> shebang_matches('#!C:\\Python2.4\\Python.exe', r'python(2\.\d)?')
    True

Parameters (``'-f'`` or ``'--foo'`` are ignored so ``'perl'`` does
the same as ``'perl -e'``)

Note that this method automatically searches the whole string (eg:
the regular expression is wrapped in ``'^$'``)

**Param√®tres :**

- `text`
- `regex`

##### doctype_matches

Check if the doctype matches a regular expression (if present).

Note that this method only checks the first part of a DOCTYPE.
eg: 'html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"'

**Param√®tres :**

- `text`
- `regex`

##### html_doctype_matches

Check if the file looks like it has a html doctype.

**Param√®tres :**

- `text`

##### looks_like_xml

Check if a doctype exists or if we have some tags.

**Param√®tres :**

- `text`

##### surrogatepair

Given a unicode character code with length greater than 16 bits,
return the two 16 bit surrogate pair.

**Param√®tres :**

- `c`

##### format_lines

Formats a sequence of strings for output.

**Param√®tres :**

- `var_name`
- `seq`
- `raw`
- `indent_level`

##### duplicates_removed

Returns a list with duplicates removed from the iterable `it`.

Order is preserved.

**Param√®tres :**

- `it`
- `already_seen`

##### guess_decode

Decode *text* with guessed encoding.

First try UTF-8; this should fail for non-UTF-8 encodings.
Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Param√®tres :**

- `text`

##### guess_decode_from_terminal

Decode *text* coming from terminal *term*.

First try the terminal encoding, if given.
Then try UTF-8.  Then try the preferred locale encoding.
Fall back to latin-1, which always works.

**Param√®tres :**

- `text`
- `term`

##### terminal_encoding

Return our best guess of encoding for the given *term*.

**Param√®tres :**

- `term`

##### text_analyse

**Param√®tres :**

- `text`

##### get

##### close

---

### .!26977!__init__

---

### .!26981!__main__

---

### .!26988!cmdline

---

### .!26993!console

---

### .!26999!filter

---

### .!27004!formatter

---

### .!27009!lexer

---

### .!27013!modeline

---

### .!27020!plugin

---

### .!27026!regexopt

---

### .!27032!scanner

---

### .!27036!sphinxext

---

### .!27042!style

---

### .!27044!token

---

### .!27051!unistring

---

### .!27061!__init__

---

### _mapping

---

### bbcode

pygments.formatters.bbcode
~~~~~~~~~~~~~~~~~~~~~~~~~~

BBcode formatter.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BBCodeFormatter

Format tokens with BBcodes. These formatting codes are used by many
bulletin boards, so you can highlight your sourcecode with pygments before
posting it there.

This formatter has no support for background colors and borders, as there
are no common BBcode tags for that.

Some board systems (e.g. phpBB) don't support colors in their [code] tag,
so you can't use the highlighting together with that tag.
Text in a [code] tag usually is shown with a monospace font (which this
formatter can do with the ``monofont`` option) and no spaces (which you
need for indentation) are removed.

Additional options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`codetag`
    If set to true, put the output into ``[code]`` tags (default:
    ``false``)

`monofont`
    If set to true, add a tag to show the code with a monospace font
    (default: ``false``).

**M√©thodes :**

- `__init__()`
- `_make_styles()`
- `format_unencoded()`

#### Fonctions

##### __init__

##### _make_styles

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

---

### groff

pygments.formatters.groff
~~~~~~~~~~~~~~~~~~~~~~~~~

Formatter for groff output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GroffFormatter

Format tokens with groff escapes to change their color and font style.

.. versionadded:: 2.11

Additional options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`monospaced`
    If set to true, monospace font will be used (default: ``true``).

`linenos`
    If set to true, print the line numbers (default: ``false``).

`wrap`
    Wrap lines to the specified number of characters. Disabled if set to 0
    (default: ``0``).

**M√©thodes :**

- `__init__()`
- `_make_styles()`
- `_define_colors()`
- `_write_lineno()`
- `_wrap_line()`
- `_escape_chars()`
- `format_unencoded()`

#### Fonctions

##### __init__

##### _make_styles

##### _define_colors

**Param√®tres :**

- `outfile`

##### _write_lineno

**Param√®tres :**

- `outfile`

##### _wrap_line

**Param√®tres :**

- `line`

##### _escape_chars

**Param√®tres :**

- `text`

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

---

### html

pygments.formatters.html
~~~~~~~~~~~~~~~~~~~~~~~~

Formatter for HTML output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### HtmlFormatter

Format tokens as HTML 4 ``<span>`` tags. By default, the content is enclosed
in a ``<pre>`` tag, itself wrapped in a ``<div>`` tag (but see the `nowrap` option).
The ``<div>``'s CSS class can be set by the `cssclass` option.

If the `linenos` option is set to ``"table"``, the ``<pre>`` is
additionally wrapped inside a ``<table>`` which has one row and two
cells: one containing the line numbers and one containing the code.
Example:

.. sourcecode:: html

    <div class="highlight" >
    <table><tr>
      <td class="linenos" title="click to toggle"
        onclick="with (this.firstChild.style)
                 { display = (display == '') ? 'none' : '' }">
        <pre>1
        2</pre>
      </td>
      <td class="code">
        <pre><span class="Ke">def </span><span class="NaFu">foo</span>(bar):
          <span class="Ke">pass</span>
        </pre>
      </td>
    </tr></table></div>

(whitespace added to improve clarity).

A list of lines can be specified using the `hl_lines` option to make these
lines highlighted (as of Pygments 0.11).

With the `full` option, a complete HTML 4 document is output, including
the style definitions inside a ``<style>`` tag, or in a separate file if
the `cssfile` option is given.

When `tagsfile` is set to the path of a ctags index file, it is used to
generate hyperlinks from names to their definition.  You must enable
`lineanchors` and run ctags with the `-n` option for this to work.  The
`python-ctags` module from PyPI must be installed to use this feature;
otherwise a `RuntimeError` will be raised.

The `get_style_defs(arg='')` method of a `HtmlFormatter` returns a string
containing CSS rules for the CSS classes used by the formatter. The
argument `arg` can be used to specify additional CSS selectors that
are prepended to the classes. A call `fmter.get_style_defs('td .code')`
would result in the following CSS classes:

.. sourcecode:: css

    td .code .kw { font-weight: bold; color: #00FF00 }
    td .code .cm { color: #999999 }
    ...

If you have Pygments 0.6 or higher, you can also pass a list or tuple to the
`get_style_defs()` method to request multiple prefixes for the tokens:

.. sourcecode:: python

    formatter.get_style_defs(['div.syntax pre', 'pre.syntax'])

The output would then look like this:

.. sourcecode:: css

    div.syntax pre .kw,
    pre.syntax .kw { font-weight: bold; color: #00FF00 }
    div.syntax pre .cm,
    pre.syntax .cm { color: #999999 }
    ...

Additional options accepted:

`nowrap`
    If set to ``True``, don't add a ``<pre>`` and a ``<div>`` tag
    around the tokens. This disables most other options (default: ``False``).

`full`
    Tells the formatter to output a "full" document, i.e. a complete
    self-contained document (default: ``False``).

`title`
    If `full` is true, the title that should be used to caption the
    document (default: ``''``).

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``). This option has no effect if the `cssfile`
    and `noclobber_cssfile` option are given and the file specified in
    `cssfile` exists.

`noclasses`
    If set to true, token ``<span>`` tags (as well as line number elements)
    will not use CSS classes, but inline styles. This is not recommended
    for larger pieces of code since it increases output size by quite a bit
    (default: ``False``).

`classprefix`
    Since the token types use relatively short class names, they may clash
    with some of your own class names. In this case you can use the
    `classprefix` option to give a string to prepend to all Pygments-generated
    CSS class names for token types.
    Note that this option also affects the output of `get_style_defs()`.

`cssclass`
    CSS class for the wrapping ``<div>`` tag (default: ``'highlight'``).
    If you set this option, the default selector for `get_style_defs()`
    will be this class.

    .. versionadded:: 0.9
       If you select the ``'table'`` line numbers, the wrapping table will
       have a CSS class of this string plus ``'table'``, the default is
       accordingly ``'highlighttable'``.

`cssstyles`
    Inline CSS styles for the wrapping ``<div>`` tag (default: ``''``).

`prestyles`
    Inline CSS styles for the ``<pre>`` tag (default: ``''``).

    .. versionadded:: 0.11

`cssfile`
    If the `full` option is true and this option is given, it must be the
    name of an external file. If the filename does not include an absolute
    path, the file's path will be assumed to be relative to the main output
    file's path, if the latter can be found. The stylesheet is then written
    to this file instead of the HTML file.

    .. versionadded:: 0.6

`noclobber_cssfile`
    If `cssfile` is given and the specified file exists, the css file will
    not be overwritten. This allows the use of the `full` option in
    combination with a user specified css file. Default is ``False``.

    .. versionadded:: 1.1

`linenos`
    If set to ``'table'``, output line numbers as a table with two cells,
    one containing the line numbers, the other the whole code.  This is
    copy-and-paste-friendly, but may cause alignment problems with some
    browsers or fonts.  If set to ``'inline'``, the line numbers will be
    integrated in the ``<pre>`` tag that contains the code (that setting
    is *new in Pygments 0.8*).

    For compatibility with Pygments 0.7 and earlier, every true value
    except ``'inline'`` means the same as ``'table'`` (in particular, that
    means also ``True``).

    The default value is ``False``, which means no line numbers at all.

    **Note:** with the default ("table") line number mechanism, the line
    numbers and code can have different line heights in Internet Explorer
    unless you give the enclosing ``<pre>`` tags an explicit ``line-height``
    CSS property (you get the default line spacing with ``line-height:
    125%``).

`hl_lines`
    Specify a list of lines to be highlighted. The line numbers are always
    relative to the input (i.e. the first line is line 1) and are
    independent of `linenostart`.

    .. versionadded:: 0.11

`linenostart`
    The line number for the first line (default: ``1``).

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

`linenospecial`
    If set to a number n > 0, every nth line number is given the CSS
    class ``"special"`` (default: ``0``).

`nobackground`
    If set to ``True``, the formatter won't output the background color
    for the wrapping element (this automatically defaults to ``False``
    when there is no wrapping element [eg: no argument for the
    `get_syntax_defs` method given]) (default: ``False``).

    .. versionadded:: 0.6

`lineseparator`
    This string is output between lines of code. It defaults to ``"\n"``,
    which is enough to break a line inside ``<pre>`` tags, but you can
    e.g. set it to ``"<br>"`` to get HTML line breaks.

    .. versionadded:: 0.7

`lineanchors`
    If set to a nonempty string, e.g. ``foo``, the formatter will wrap each
    output line in an anchor tag with an ``id`` (and `name`) of ``foo-linenumber``.
    This allows easy linking to certain lines.

    .. versionadded:: 0.9

`linespans`
    If set to a nonempty string, e.g. ``foo``, the formatter will wrap each
    output line in a span tag with an ``id`` of ``foo-linenumber``.
    This allows easy access to lines via javascript.

    .. versionadded:: 1.6

`anchorlinenos`
    If set to `True`, will wrap line numbers in <a> tags. Used in
    combination with `linenos` and `lineanchors`.

`tagsfile`
    If set to the path of a ctags file, wrap names in anchor tags that
    link to their definitions. `lineanchors` should be used, and the
    tags file should specify line numbers (see the `-n` option to ctags).
    The tags file is assumed to be encoded in UTF-8.

    .. versionadded:: 1.6

`tagurlformat`
    A string formatting pattern used to generate links to ctags definitions.
    Available variables are `%(path)s`, `%(fname)s` and `%(fext)s`.
    Defaults to an empty string, resulting in just `#prefix-number` links.

    .. versionadded:: 1.6

`filename`
    A string used to generate a filename when rendering ``<pre>`` blocks,
    for example if displaying source code. If `linenos` is set to
    ``'table'`` then the filename will be rendered in an initial row
    containing a single `<th>` which spans both columns.

    .. versionadded:: 2.1

`wrapcode`
    Wrap the code inside ``<pre>`` blocks using ``<code>``, as recommended
    by the HTML5 specification.

    .. versionadded:: 2.4

`debug_token_types`
    Add ``title`` attributes to all token ``<span>`` tags that show the
    name of the token.

    .. versionadded:: 2.10


**Subclassing the HTML formatter**

.. versionadded:: 0.7

The HTML formatter is now built in a way that allows easy subclassing, thus
customizing the output HTML code. The `format()` method calls
`self._format_lines()` which returns a generator that yields tuples of ``(1,
line)``, where the ``1`` indicates that the ``line`` is a line of the
formatted source code.

If the `nowrap` option is set, the generator is the iterated over and the
resulting HTML is output.

Otherwise, `format()` calls `self.wrap()`, which wraps the generator with
other generators. These may add some HTML code to the one generated by
`_format_lines()`, either by modifying the lines generated by the latter,
then yielding them again with ``(1, line)``, and/or by yielding other HTML
code before or after the lines, with ``(0, html)``. The distinction between
source lines and other code makes it possible to wrap the generator multiple
times.

The default `wrap()` implementation adds a ``<div>`` and a ``<pre>`` tag.

A custom `HtmlFormatter` subclass could look like this:

.. sourcecode:: python

    class CodeHtmlFormatter(HtmlFormatter):

        def wrap(self, source, *, include_div):
            return self._wrap_code(source)

        def _wrap_code(self, source):
            yield 0, '<code>'
            for i, t in source:
                if i == 1:
                    # it's a line of formatted code
                    t += '<br>'
                yield i, t
            yield 0, '</code>'

This results in wrapping the formatted lines with a ``<code>`` tag, where the
source lines are broken using ``<br>`` tags.

After calling `wrap()`, the `format()` method also adds the "line numbers"
and/or "full document" wrappers if the respective options are set. Then, all
HTML yielded by the wrapped generator is output.

**M√©thodes :**

- `__init__()`
- `_get_css_class()`
- `_get_css_classes()`
- `_get_css_inline_styles()`
- `_create_stylesheet()`
- `get_style_defs()`
- `get_token_style_defs()`
- `get_background_style_defs()`
- `get_linenos_style_defs()`
- `get_css_prefix()`
- `_pre_style()`
- `_linenos_style()`
- `_linenos_special_style()`
- `_decodeifneeded()`
- `_wrap_full()`
- `_wrap_tablelinenos()`
- `_wrap_inlinelinenos()`
- `_wrap_lineanchors()`
- `_wrap_linespans()`
- `_wrap_div()`
- `_wrap_pre()`
- `_wrap_code()`
- `_translate_parts()`
- `_format_lines()`
- `_lookup_ctag()`
- `_highlight_lines()`
- `wrap()`
- `format_unencoded()`

#### Fonctions

##### escape_html

Escape &, <, > as well as single and double quotes for HTML.

**Param√®tres :**

- `text`
- `table`

##### webify

**Param√®tres :**

- `color`

##### _get_ttype_class

**Param√®tres :**

- `ttype`

##### __init__

##### _get_css_class

Return the css class of this token type prefixed with
the classprefix option.

**Param√®tres :**

- `ttype`

##### _get_css_classes

Return the CSS classes of this token type prefixed with the classprefix option.

**Param√®tres :**

- `ttype`

##### _get_css_inline_styles

Return the inline CSS styles for this token type.

**Param√®tres :**

- `ttype`

##### _create_stylesheet

##### get_style_defs

Return CSS style definitions for the classes produced by the current
highlighting style. ``arg`` can be a string or list of selectors to
insert before the token type classes.

**Param√®tres :**

- `arg`

##### get_token_style_defs

**Param√®tres :**

- `arg`

##### get_background_style_defs

**Param√®tres :**

- `arg`

##### get_linenos_style_defs

##### get_css_prefix

**Param√®tres :**

- `arg`

##### _pre_style

##### _linenos_style

##### _linenos_special_style

##### _decodeifneeded

**Param√®tres :**

- `value`

##### _wrap_full

**Param√®tres :**

- `inner`
- `outfile`

##### _wrap_tablelinenos

**Param√®tres :**

- `inner`

##### _wrap_inlinelinenos

**Param√®tres :**

- `inner`

##### _wrap_lineanchors

**Param√®tres :**

- `inner`

##### _wrap_linespans

**Param√®tres :**

- `inner`

##### _wrap_div

**Param√®tres :**

- `inner`

##### _wrap_pre

**Param√®tres :**

- `inner`

##### _wrap_code

**Param√®tres :**

- `inner`

##### _translate_parts

HTML-escape a value and split it by newlines.

**Param√®tres :**

- `value`

##### _format_lines

Just format the tokens, without any wrapping tags.
Yield individual lines.

**Param√®tres :**

- `tokensource`

##### _lookup_ctag

**Param√®tres :**

- `token`

##### _highlight_lines

Highlighted the lines specified in the `hl_lines` option by
post-processing the token stream coming from `_format_lines`.

**Param√®tres :**

- `tokensource`

##### wrap

Wrap the ``source``, which is a generator yielding
individual lines, in custom generators. See docstring
for `format`. Can be overridden.

**Param√®tres :**

- `source`

##### format_unencoded

The formatting process uses several nested generators; which of
them are used is determined by the user's options.

Each generator should take at least one argument, ``inner``,
and wrap the pieces of text generated by this.

Always yield 2-tuples: (code, text). If "code" is 1, the text
is part of the original tokensource being highlighted, if it's
0, the text is some piece of wrapping. This makes it possible to
use several different wrappers that process the original source
linewise, e.g. line number generators.

**Param√®tres :**

- `tokensource`
- `outfile`

##### prefix

**Param√®tres :**

- `cls`

---

### img

pygments.formatters.img
~~~~~~~~~~~~~~~~~~~~~~~

Formatter for Pixmap output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PilNotAvailable

When Python imaging library is not available

##### FontNotFound

When there are no usable fonts specified

##### FontManager

Manages a set of fonts: normal, italic, bold, etc...

**M√©thodes :**

- `__init__()`
- `_get_nix_font_path()`
- `_create_nix()`
- `_get_mac_font_path()`
- `_create_mac()`
- `_lookup_win()`
- `_create_win()`
- `get_char_size()`
- `get_text_size()`
- `get_font()`
- `get_style()`

##### ImageFormatter

Create a PNG image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 0.10

Additional options accepted:

`image_format`
    An image format to output to that is recognised by PIL, these include:

    * "PNG" (default)
    * "JPEG"
    * "BMP"
    * "GIF"

`line_pad`
    The extra spacing (in pixels) between each line of text.

    Default: 2

`font_name`
    The font name to be used as the base font from which others, such as
    bold and italic fonts will be generated.  This really should be a
    monospace font to look sane.
    If a filename or a file-like object is specified, the user must
    provide different styles of the font.

    Default: "Courier New" on Windows, "Menlo" on Mac OS, and
             "DejaVu Sans Mono" on \*nix

`font_size`
    The font size in points to be used.

    Default: 14

`image_pad`
    The padding, in pixels to be used at each edge of the resulting image.

    Default: 10

`line_numbers`
    Whether line numbers should be shown: True/False

    Default: True

`line_number_start`
    The line number of the first line.

    Default: 1

`line_number_step`
    The step used when printing line numbers.

    Default: 1

`line_number_bg`
    The background colour (in "#123456" format) of the line number bar, or
    None to use the style background color.

    Default: "#eed"

`line_number_fg`
    The text color of the line numbers (in "#123456"-like format).

    Default: "#886"

`line_number_chars`
    The number of columns of line numbers allowable in the line number
    margin.

    Default: 2

`line_number_bold`
    Whether line numbers will be bold: True/False

    Default: False

`line_number_italic`
    Whether line numbers will be italicized: True/False

    Default: False

`line_number_separator`
    Whether a line will be drawn between the line number area and the
    source code area: True/False

    Default: True

`line_number_pad`
    The horizontal padding (in pixels) between the line number margin, and
    the source code area.

    Default: 6

`hl_lines`
    Specify a list of lines to be highlighted.

    .. versionadded:: 1.2

    Default: empty list

`hl_color`
    Specify the color for highlighting lines.

    .. versionadded:: 1.2

    Default: highlight color of the selected style

**M√©thodes :**

- `__init__()`
- `get_style_defs()`
- `_get_line_height()`
- `_get_line_y()`
- `_get_char_width()`
- `_get_char_x()`
- `_get_text_pos()`
- `_get_linenumber_pos()`
- `_get_text_color()`
- `_get_text_bg_color()`
- `_get_style_font()`
- `_get_image_size()`
- `_draw_linenumber()`
- `_draw_text()`
- `_create_drawables()`
- `_draw_line_numbers()`
- `_paint_line_number_bg()`
- `format()`

##### GifImageFormatter

Create a GIF image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 1.0

##### JpgImageFormatter

Create a JPEG image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 1.0

##### BmpImageFormatter

Create a bitmap image from source code. This uses the Python Imaging Library to
generate a pixmap from the source code.

.. versionadded:: 1.0

#### Fonctions

##### __init__

**Param√®tres :**

- `font_name`
- `font_size`

##### _get_nix_font_path

**Param√®tres :**

- `name`
- `style`

##### _create_nix

##### _get_mac_font_path

**Param√®tres :**

- `font_map`
- `name`
- `style`

##### _create_mac

##### _lookup_win

**Param√®tres :**

- `key`
- `basename`
- `styles`
- `fail`

##### _create_win

##### get_char_size

Get the character size.

##### get_text_size

Get the text size (width, height).

**Param√®tres :**

- `text`

##### get_font

Get the font based on bold and italic flags.

**Param√®tres :**

- `bold`
- `oblique`

##### get_style

Get the specified style of the font if it is a variable font.
If not found, return the normal font.

**Param√®tres :**

- `style`

##### __init__

See the class docstring for explanation of options.

##### get_style_defs

**Param√®tres :**

- `arg`

##### _get_line_height

Get the height of a line.

##### _get_line_y

Get the Y coordinate of a line number.

**Param√®tres :**

- `lineno`

##### _get_char_width

Get the width of a character.

##### _get_char_x

Get the X coordinate of a character position.

**Param√®tres :**

- `linelength`

##### _get_text_pos

Get the actual position for a character and line position.

**Param√®tres :**

- `linelength`
- `lineno`

##### _get_linenumber_pos

Get the actual position for the start of a line number.

**Param√®tres :**

- `lineno`

##### _get_text_color

Get the correct color for the token from the style.

**Param√®tres :**

- `style`

##### _get_text_bg_color

Get the correct background color for the token from the style.

**Param√®tres :**

- `style`

##### _get_style_font

Get the correct font for the style.

**Param√®tres :**

- `style`

##### _get_image_size

Get the required image size.

**Param√®tres :**

- `maxlinelength`
- `maxlineno`

##### _draw_linenumber

Remember a line number drawable to paint later.

**Param√®tres :**

- `posno`
- `lineno`

##### _draw_text

Remember a single drawable tuple to paint later.

**Param√®tres :**

- `pos`
- `text`
- `font`
- `text_fg`
- `text_bg`

##### _create_drawables

Create drawables for the token content.

**Param√®tres :**

- `tokensource`

##### _draw_line_numbers

Create drawables for the line numbers.

##### _paint_line_number_bg

Paint the line number background on the image.

**Param√®tres :**

- `im`

##### format

Format ``tokensource``, an iterable of ``(tokentype, tokenstring)``
tuples and write it into ``outfile``.

This implementation calculates where it should draw each token on the
pixmap, then calculates the required pixmap size and draws the items.

**Param√®tres :**

- `tokensource`
- `outfile`

---

### irc

pygments.formatters.irc
~~~~~~~~~~~~~~~~~~~~~~~

Formatter for IRC output

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### IRCFormatter

Format tokens with IRC color sequences

The `get_style_defs()` method doesn't do anything special since there is
no support for common styles.

Options accepted:

`bg`
    Set to ``"light"`` or ``"dark"`` depending on the terminal's background
    (default: ``"light"``).

`colorscheme`
    A dictionary mapping token types to (lightbg, darkbg) color names or
    ``None`` (default: ``None`` = use builtin colorscheme).

`linenos`
    Set to ``True`` to have line numbers in the output as well
    (default: ``False`` = no line numbers).

**M√©thodes :**

- `__init__()`
- `_write_lineno()`
- `format_unencoded()`

#### Fonctions

##### ircformat

**Param√®tres :**

- `color`
- `text`

##### __init__

##### _write_lineno

**Param√®tres :**

- `outfile`

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

---

### .!27087!html

---

### .!27090!img

---

### latex

pygments.formatters.latex
~~~~~~~~~~~~~~~~~~~~~~~~~

Formatter for LaTeX fancyvrb output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LatexFormatter

Format tokens as LaTeX code. This needs the `fancyvrb` and `color`
standard packages.

Without the `full` option, code is formatted as one ``Verbatim``
environment, like this:

.. sourcecode:: latex

    \begin{Verbatim}[commandchars=\\\{\}]
    \PY{k}{def }\PY{n+nf}{foo}(\PY{n}{bar}):
        \PY{k}{pass}
    \end{Verbatim}

Wrapping can be disabled using the `nowrap` option.

The special command used here (``\PY``) and all the other macros it needs
are output by the `get_style_defs` method.

With the `full` option, a complete LaTeX document is output, including
the command definitions in the preamble.

The `get_style_defs()` method of a `LatexFormatter` returns a string
containing ``\def`` commands defining the macros needed inside the
``Verbatim`` environments.

Additional options accepted:

`nowrap`
    If set to ``True``, don't wrap the tokens at all, not even inside a
    ``\begin{Verbatim}`` environment. This disables most other options
    (default: ``False``).

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`full`
    Tells the formatter to output a "full" document, i.e. a complete
    self-contained document (default: ``False``).

`title`
    If `full` is true, the title that should be used to caption the
    document (default: ``''``).

`docclass`
    If the `full` option is enabled, this is the document class to use
    (default: ``'article'``).

`preamble`
    If the `full` option is enabled, this can be further preamble commands,
    e.g. ``\usepackage`` (default: ``''``).

`linenos`
    If set to ``True``, output line numbers (default: ``False``).

`linenostart`
    The line number for the first line (default: ``1``).

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

`verboptions`
    Additional options given to the Verbatim environment (see the *fancyvrb*
    docs for possible values) (default: ``''``).

`commandprefix`
    The LaTeX commands used to produce colored output are constructed
    using this prefix and some letters (default: ``'PY'``).

    .. versionadded:: 0.7
    .. versionchanged:: 0.10
       The default is now ``'PY'`` instead of ``'C'``.

`texcomments`
    If set to ``True``, enables LaTeX comment lines.  That is, LaTex markup
    in comment tokens is not escaped so that LaTeX can render it (default:
    ``False``).

    .. versionadded:: 1.2

`mathescape`
    If set to ``True``, enables LaTeX math mode escape in comments. That
    is, ``'$...$'`` inside a comment will trigger math mode (default:
    ``False``).

    .. versionadded:: 1.2

`escapeinside`
    If set to a string of length 2, enables escaping to LaTeX. Text
    delimited by these 2 characters is read as LaTeX code and
    typeset accordingly. It has no effect in string literals. It has
    no effect in comments if `texcomments` or `mathescape` is
    set. (default: ``''``).

    .. versionadded:: 2.0

`envname`
    Allows you to pick an alternative environment name replacing Verbatim.
    The alternate environment still has to support Verbatim's option syntax.
    (default: ``'Verbatim'``).

    .. versionadded:: 2.0

**M√©thodes :**

- `__init__()`
- `_create_stylesheet()`
- `get_style_defs()`
- `format_unencoded()`

##### LatexEmbeddedLexer

This lexer takes one lexer as argument, the lexer for the language
being formatted, and the left and right delimiters for escaped text.

First everything is scanned using the language lexer to obtain
strings and comments. All other consecutive tokens are merged and
the resulting text is scanned for escaped segments, which are given
the Token.Escape type. Finally text that is not escaped is scanned
again with the language lexer.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`
- `_find_safe_escape_tokens()`
- `_filter_to()`
- `_find_escape_tokens()`

#### Fonctions

##### escape_tex

**Param√®tres :**

- `text`
- `commandprefix`

##### _get_ttype_name

**Param√®tres :**

- `ttype`

##### __init__

##### _create_stylesheet

##### get_style_defs

Return the command sequences needed to define the commands
used to format text in the verbatim environment. ``arg`` is ignored.

**Param√®tres :**

- `arg`

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

##### __init__

**Param√®tres :**

- `left`
- `right`
- `lang`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### _find_safe_escape_tokens

find escape tokens that are not in strings or comments 

**Param√®tres :**

- `text`

##### _filter_to

Keep only the tokens that match `pred`, merge the others together 

**Param√®tres :**

- `it`
- `pred`

##### _find_escape_tokens

Find escape tokens within text, give token=None otherwise 

**Param√®tres :**

- `text`

##### rgbcolor

**Param√®tres :**

- `col`

---

### .!27096!irc

---

### .!27116!rtf

---

### other

pygments.formatters.other
~~~~~~~~~~~~~~~~~~~~~~~~~

Other formatters: NullFormatter, RawTokenFormatter.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NullFormatter

Output the text unchanged without any formatting.

**M√©thodes :**

- `format()`

##### RawTokenFormatter

Format tokens as a raw representation for storing token streams.

The format is ``tokentype<TAB>repr(tokenstring)\n``. The output can later
be converted to a token stream with the `RawTokenLexer`, described in the
:doc:`lexer list <lexers>`.

Only two options are accepted:

`compress`
    If set to ``'gz'`` or ``'bz2'``, compress the output with the given
    compression algorithm after encoding (default: ``''``).
`error_color`
    If set to a color name, highlight error tokens using that color.  If
    set but with no value, defaults to ``'red'``.

    .. versionadded:: 0.11

**M√©thodes :**

- `__init__()`
- `format()`

##### TestcaseFormatter

Format tokens as appropriate for a new testcase.

.. versionadded:: 2.0

**M√©thodes :**

- `__init__()`
- `format()`

#### Fonctions

##### format

**Param√®tres :**

- `tokensource`
- `outfile`

##### __init__

##### format

**Param√®tres :**

- `tokensource`
- `outfile`

##### __init__

##### format

**Param√®tres :**

- `tokensource`
- `outfile`

##### write

**Param√®tres :**

- `text`

##### flush

---

### .!27121!svg

---

### pangomarkup

pygments.formatters.pangomarkup
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Formatter for Pango markup output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PangoMarkupFormatter

Format tokens as Pango Markup code. It can then be rendered to an SVG.

.. versionadded:: 2.9

**M√©thodes :**

- `__init__()`
- `format_unencoded()`

#### Fonctions

##### escape_special_chars

Escape & and < for Pango Markup.

**Param√®tres :**

- `text`
- `table`

##### __init__

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

---

### rtf

pygments.formatters.rtf
~~~~~~~~~~~~~~~~~~~~~~~

A formatter that generates RTF files.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RtfFormatter

Format tokens as RTF markup. This formatter automatically outputs full RTF
documents with color information and other useful stuff. Perfect for Copy and
Paste into Microsoft(R) Word(R) documents.

Please note that ``encoding`` and ``outencoding`` options are ignored.
The RTF format is ASCII natively, but handles unicode characters correctly
thanks to escape sequences.

.. versionadded:: 0.6

Additional options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`fontface`
    The used font family, for example ``Bitstream Vera Sans``. Defaults to
    some generic font which is supposed to have fixed width.

`fontsize`
    Size of the font used. Size is specified in half points. The
    default is 24 half-points, giving a size 12 font.

    .. versionadded:: 2.0

`linenos`
    Turn on line numbering (default: ``False``).

    .. versionadded:: 2.18

`lineno_fontsize`
    Font size for line numbers. Size is specified in half points
    (default: `fontsize`). 

    .. versionadded:: 2.18

`lineno_padding`
    Number of spaces between the (inline) line numbers and the
    source code (default: ``2``).

    .. versionadded:: 2.18

`linenostart`
    The line number for the first line (default: ``1``).

    .. versionadded:: 2.18

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

    .. versionadded:: 2.18

`lineno_color`
    Color for line numbers specified as a hex triplet, e.g. ``'5e5e5e'``. 
    Defaults to the style's line number color if it is a hex triplet, 
    otherwise ansi bright black.

    .. versionadded:: 2.18

`hl_lines`
    Specify a list of lines to be highlighted, as line numbers separated by
    spaces, e.g. ``'3 7 8'``. The line numbers are relative to the input 
    (i.e. the first line is line 1) unless `hl_linenostart` is set.

    .. versionadded:: 2.18

`hl_color`
    Color for highlighting the lines specified in `hl_lines`, specified as 
    a hex triplet (default: style's `highlight_color`).

    .. versionadded:: 2.18

`hl_linenostart`
    If set to ``True`` line numbers in `hl_lines` are specified
    relative to `linenostart` (default ``False``).

    .. versionadded:: 2.18

**M√©thodes :**

- `__init__()`
- `_escape()`
- `_escape_text()`
- `hex_to_rtf_color()`
- `_split_tokens_on_newlines()`
- `_create_color_mapping()`
- `_lineno_template()`
- `_hl_open_str()`
- `_rtf_header()`
- `format_unencoded()`

#### Fonctions

##### __init__

Additional options accepted:

``fontface``
    Name of the font used. Could for example be ``'Courier New'``
    to further specify the default which is ``'\fmodern'``. The RTF
    specification claims that ``\fmodern`` are "Fixed-pitch serif
    and sans serif fonts". Hope every RTF implementation thinks
    the same about modern...

##### _escape

**Param√®tres :**

- `text`

##### _escape_text

**Param√®tres :**

- `text`

##### hex_to_rtf_color

**Param√®tres :**

- `hex_color`

##### _split_tokens_on_newlines

Split tokens containing newline characters into multiple token
each representing a line of the input file. Needed for numbering
lines of e.g. multiline comments.

**Param√®tres :**

- `tokensource`

##### _create_color_mapping

Create a mapping of style hex colors to index/offset in
the RTF color table.

##### _lineno_template

##### _hl_open_str

##### _rtf_header

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

---

### svg

pygments.formatters.svg
~~~~~~~~~~~~~~~~~~~~~~~

Formatter for SVG output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SvgFormatter

Format tokens as an SVG graphics file.  This formatter is still experimental.
Each line of code is a ``<text>`` element with explicit ``x`` and ``y``
coordinates containing ``<tspan>`` elements with the individual token styles.

By default, this formatter outputs a full SVG document including doctype
declaration and the ``<svg>`` root element.

.. versionadded:: 0.9

Additional options accepted:

`nowrap`
    Don't wrap the SVG ``<text>`` elements in ``<svg><g>`` elements and
    don't add a XML declaration and a doctype.  If true, the `fontfamily`
    and `fontsize` options are ignored.  Defaults to ``False``.

`fontfamily`
    The value to give the wrapping ``<g>`` element's ``font-family``
    attribute, defaults to ``"monospace"``.

`fontsize`
    The value to give the wrapping ``<g>`` element's ``font-size``
    attribute, defaults to ``"14px"``.

`linenos`
    If ``True``, add line numbers (default: ``False``).

`linenostart`
    The line number for the first line (default: ``1``).

`linenostep`
    If set to a number n > 1, only every nth line number is printed.

`linenowidth`
    Maximum width devoted to line numbers (default: ``3*ystep``, sufficient
    for up to 4-digit line numbers. Increase width for longer code blocks).

`xoffset`
    Starting offset in X direction, defaults to ``0``.

`yoffset`
    Starting offset in Y direction, defaults to the font size if it is given
    in pixels, or ``20`` else.  (This is necessary since text coordinates
    refer to the text baseline, not the top edge.)

`ystep`
    Offset to add to the Y coordinate for each subsequent line.  This should
    roughly be the text size plus 5.  It defaults to that value if the text
    size is given in pixels, or ``25`` else.

`spacehack`
    Convert spaces in the source to ``&#160;``, which are non-breaking
    spaces.  SVG provides the ``xml:space`` attribute to control how
    whitespace inside tags is handled, in theory, the ``preserve`` value
    could be used to keep all whitespace as-is.  However, many current SVG
    viewers don't obey that rule, so this option is provided as a workaround
    and defaults to ``True``.

**M√©thodes :**

- `__init__()`
- `format_unencoded()`
- `_get_style()`

#### Fonctions

##### escape_html

Escape &, <, > as well as single and double quotes for HTML.

**Param√®tres :**

- `text`

##### __init__

##### format_unencoded

Format ``tokensource``, an iterable of ``(tokentype, tokenstring)``
tuples and write it into ``outfile``.

For our implementation we put all lines in their own 'line group'.

**Param√®tres :**

- `tokensource`
- `outfile`

##### _get_style

**Param√®tres :**

- `tokentype`

---

### terminal

pygments.formatters.terminal
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Formatter for terminal output with ANSI sequences.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TerminalFormatter

Format tokens with ANSI color sequences, for output in a text console.
Color sequences are terminated at newlines, so that paging the output
works correctly.

The `get_style_defs()` method doesn't do anything special since there is
no support for common styles.

Options accepted:

`bg`
    Set to ``"light"`` or ``"dark"`` depending on the terminal's background
    (default: ``"light"``).

`colorscheme`
    A dictionary mapping token types to (lightbg, darkbg) color names or
    ``None`` (default: ``None`` = use builtin colorscheme).

`linenos`
    Set to ``True`` to have line numbers on the terminal output as well
    (default: ``False`` = no line numbers).

**M√©thodes :**

- `__init__()`
- `format()`
- `_write_lineno()`
- `_get_color()`
- `format_unencoded()`

#### Fonctions

##### __init__

##### format

**Param√®tres :**

- `tokensource`
- `outfile`

##### _write_lineno

**Param√®tres :**

- `outfile`

##### _get_color

**Param√®tres :**

- `ttype`

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

---

### terminal256

pygments.formatters.terminal256
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Formatter for 256-color terminal output with ANSI sequences.

RGB-to-XTERM color conversion routines adapted from xterm256-conv
tool (http://frexx.de/xterm-256-notes/data/xterm256-conv2.tar.bz2)
by Wolfgang Frisch.

Formatter version 1.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### EscapeSequence

**M√©thodes :**

- `__init__()`
- `escape()`
- `color_string()`
- `true_color_string()`
- `reset_string()`

##### Terminal256Formatter

Format tokens with ANSI color sequences, for output in a 256-color
terminal or console.  Like in `TerminalFormatter` color sequences
are terminated at newlines, so that paging the output works correctly.

The formatter takes colors from a style defined by the `style` option
and converts them to nearest ANSI 256-color escape sequences. Bold and
underline attributes from the style are preserved (and displayed).

.. versionadded:: 0.9

.. versionchanged:: 2.2
   If the used style defines foreground colors in the form ``#ansi*``, then
   `Terminal256Formatter` will map these to non extended foreground color.
   See :ref:`AnsiTerminalStyle` for more information.

.. versionchanged:: 2.4
   The ANSI color names have been updated with names that are easier to
   understand and align with colornames of other projects and terminals.
   See :ref:`this table <new-ansi-color-names>` for more information.


Options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

`linenos`
    Set to ``True`` to have line numbers on the terminal output as well
    (default: ``False`` = no line numbers).

**M√©thodes :**

- `__init__()`
- `_build_color_table()`
- `_closest_color()`
- `_color_index()`
- `_setup_styles()`
- `_write_lineno()`
- `format()`
- `format_unencoded()`

##### TerminalTrueColorFormatter

Format tokens with ANSI color sequences, for output in a true-color
terminal or console.  Like in `TerminalFormatter` color sequences
are terminated at newlines, so that paging the output works correctly.

.. versionadded:: 2.1

Options accepted:

`style`
    The style to use, can be a string or a Style subclass (default:
    ``'default'``).

**M√©thodes :**

- `_build_color_table()`
- `_color_tuple()`
- `_setup_styles()`

#### Fonctions

##### __init__

**Param√®tres :**

- `fg`
- `bg`
- `bold`
- `underline`
- `italic`

##### escape

**Param√®tres :**

- `attrs`

##### color_string

##### true_color_string

##### reset_string

##### __init__

##### _build_color_table

##### _closest_color

**Param√®tres :**

- `r`
- `g`
- `b`

##### _color_index

**Param√®tres :**

- `color`

##### _setup_styles

##### _write_lineno

**Param√®tres :**

- `outfile`

##### format

**Param√®tres :**

- `tokensource`
- `outfile`

##### format_unencoded

**Param√®tres :**

- `tokensource`
- `outfile`

##### _build_color_table

##### _color_tuple

**Param√®tres :**

- `color`

##### _setup_styles

---

### .!27067!__init__

---

### .!27073!_mapping

---

### .!27076!bbcode

---

### .!27082!groff

---

### .!27101!latex

---

### .!27107!other

---

### .!27110!pangomarkup

---

### .!27127!terminal

---

### .!27131!terminal256

---

### _ada_builtins

pygments.lexers._ada_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Ada builtins.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _asy_builtins

pygments.lexers._asy_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file contains the asy-function names and asy-variable names of
Asymptote.

Do not edit the ASYFUNCNAME and ASYVARNAME sets by hand.
TODO: perl/python script in Asymptote SVN similar to asy-list.pl but only
for function and variable names.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _cl_builtins

pygments.lexers._cl_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ANSI Common Lisp builtins.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _cocoa_builtins

pygments.lexers._cocoa_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file defines a set of types used across Cocoa frameworks from Apple.
There is a list of @interfaces, @protocols and some other (structs, unions)

File may be also used as standalone generator for above.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _csound_builtins

pygments.lexers._csound_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _css_builtins

pygments.lexers._css_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file is autogenerated by scripts/get_css_properties.py

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _googlesql_builtins

pygments.lexers._googlesql_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Autogenerated data files for the GoogleSQL lexer.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _julia_builtins

pygments.lexers._julia_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Julia builtins.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _lasso_builtins

pygments.lexers._lasso_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Built-in Lasso types, traits, methods, and members.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _lilypond_builtins

pygments.lexers._lilypond_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

LilyPond builtins.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _lua_builtins

pygments.lexers._lua_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file contains the names and modules of lua functions
It is able to re-generate itself, but for adding new functions you
probably have to add some callbacks (see function module_callbacks).

Do not edit the MODULES dict by hand.

Run with `python -I` to regenerate.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### module_callbacks

##### get_newest_version

##### get_lua_functions

**Param√®tres :**

- `version`

##### get_function_module

**Param√®tres :**

- `name`

##### regenerate

**Param√®tres :**

- `filename`
- `modules`

##### run

##### is_in_coroutine_module

**Param√®tres :**

- `name`

##### is_in_modules_module

**Param√®tres :**

- `name`

##### is_in_string_module

**Param√®tres :**

- `name`

##### is_in_table_module

**Param√®tres :**

- `name`

##### is_in_math_module

**Param√®tres :**

- `name`

##### is_in_io_module

**Param√®tres :**

- `name`

##### is_in_os_module

**Param√®tres :**

- `name`

##### is_in_debug_module

**Param√®tres :**

- `name`

---

### _luau_builtins

pygments.lexers._luau_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Includes the builtins for Luau and Roblox.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _mapping

---

### _mql_builtins

pygments.lexers._mql_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Builtins for the MqlLexer.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _mysql_builtins

pygments.lexers._mysql_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Self-updating data files for the MySQL lexer.

Run with `python -I` to update.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### update_myself

##### parse_lex_keywords

Parse keywords in lex.h.

**Param√®tres :**

- `f`

##### parse_lex_optimizer_hints

Parse optimizer hints in lex.h.

**Param√®tres :**

- `f`

##### parse_lex_functions

Parse MySQL function names from lex.h.

**Param√®tres :**

- `f`

##### parse_item_create_functions

Parse MySQL function names from item_create.cc.

**Param√®tres :**

- `f`

##### update_content

Overwrite this file with content parsed from MySQL's source code.

**Param√®tres :**

- `field_name`
- `content`

---

### _openedge_builtins

pygments.lexers._openedge_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Builtin list for the OpenEdgeLexer.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _php_builtins

pygments.lexers._php_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file loads the function names and their modules from the
php webpage and generates itself.

Run with `python -I` to regenerate.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### get_php_functions

##### get_php_references

##### regenerate

**Param√®tres :**

- `filename`
- `modules`

##### run

---

### _postgres_builtins

pygments.lexers._postgres_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Self-updating data files for PostgreSQL lexer.

Run with `python -I` to update itself.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### update_myself

##### parse_keywords

**Param√®tres :**

- `f`

##### parse_datatypes

**Param√®tres :**

- `f`

##### parse_pseudos

**Param√®tres :**

- `f`

##### update_consts

**Param√®tres :**

- `filename`
- `constname`
- `content`

---

### _qlik_builtins

pygments.lexers._qlik_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Qlik builtins.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _scheme_builtins

pygments.lexers._scheme_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Scheme builtins.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _scilab_builtins

pygments.lexers._scilab_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Builtin list for the ScilabLexer.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### extract_completion

**Param√®tres :**

- `var_type`

---

### _sourcemod_builtins

pygments.lexers._sourcemod_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file contains the names of SourceMod functions.

Do not edit the FUNCTIONS list by hand.

Run with `python -I` to regenerate.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Opener

#### Fonctions

##### get_version

##### get_sm_functions

##### regenerate

**Param√®tres :**

- `filename`
- `natives`

##### run

---

### _sql_builtins

pygments.lexers._sql_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Data files for the SQL lexer.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _stan_builtins

pygments.lexers._stan_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file contains the names of functions for Stan used by
``pygments.lexers.math.StanLexer. This is for Stan language version 2.29.0.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _stata_builtins

pygments.lexers._stata_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Builtins for Stata

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _tsql_builtins

pygments.lexers._tsql_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

These are manually translated lists from https://msdn.microsoft.com.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _usd_builtins

pygments.lexers._usd_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A collection of known USD-related keywords, attributes, and types.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _vbscript_builtins

pygments.lexers._vbscript_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

These are manually translated lists from
http://www.indusoft.com/pdf/VBScript%20Reference.pdf.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### _vim_builtins

pygments.lexers._vim_builtins
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This file is autogenerated by scripts/get_vimkw.py

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Fonctions

##### _getauto

##### _getcommand

##### _getoption

---

### actionscript

pygments.lexers.actionscript
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for ActionScript and MXML.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ActionScriptLexer

For ActionScript source code.

**M√©thodes :**

- `analyse_text()`

##### ActionScript3Lexer

For ActionScript 3 source code.

**M√©thodes :**

- `analyse_text()`

##### MxmlLexer

For MXML markup.
Nested AS3 in <script> tags is highlighted by the appropriate lexer.

#### Fonctions

##### analyse_text

This is only used to disambiguate between ActionScript and
ActionScript3. We return 0 here; the ActionScript3 lexer will match
AS3 variable definitions and that will hopefully suffice.

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### ada

pygments.lexers.ada
~~~~~~~~~~~~~~~~~~~

Lexers for Ada family languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AdaLexer

For Ada source code.

---

### agile

pygments.lexers.agile
~~~~~~~~~~~~~~~~~~~~~

Just export lexer classes previously contained in this module.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### algebra

pygments.lexers.algebra
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for computer algebra systems.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GAPLexer

For GAP source code.

**M√©thodes :**

- `analyse_text()`

##### GAPConsoleLexer

For GAP console sessions. Modeled after JuliaConsoleLexer.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `analyse_text()`

##### MathematicaLexer

Lexer for Mathematica source code.

**M√©thodes :**

- `_multi_escape()`

##### MuPADLexer

A MuPAD lexer.
Contributed by Christopher Creutzig <christopher@creutzig.de>.

##### BCLexer

A BC lexer.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### _multi_escape

**Param√®tres :**

- `entries`

---

### ambient

pygments.lexers.ambient
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for AmbientTalk language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AmbientTalkLexer

Lexer for AmbientTalk source code.

---

### amdgpu

pygments.lexers.amdgpu
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the AMDGPU ISA assembly.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AMDGPULexer

For AMD GPU assembly.

---

### ampl

pygments.lexers.ampl
~~~~~~~~~~~~~~~~~~~~

Lexers for the AMPL language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AmplLexer

For AMPL source code.

---

### apdlexer

pygments.lexers.apdlexer
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for ANSYS Parametric Design Language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### apdlexer

For APDL source code.

---

### apl

pygments.lexers.apl
~~~~~~~~~~~~~~~~~~~

Lexers for APL.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### APLLexer

A simple APL lexer.

---

### archetype

pygments.lexers.archetype
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Archetype-related syntaxes, including ODIN, ADL and cADL.

For uses of this syntax, see the openEHR archetypes <http://www.openEHR.org/ckm>

Contributed by Thomas Beale <https://github.com/wolandscat>,
<https://bitbucket.org/thomas_beale>.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AtomsLexer

Lexer for Values used in ADL and ODIN.

.. versionadded:: 2.1

##### OdinLexer

Lexer for ODIN syntax.

##### CadlLexer

Lexer for cADL syntax.

##### AdlLexer

Lexer for ADL syntax.

---

### arrow

pygments.lexers.arrow
~~~~~~~~~~~~~~~~~~~~~

Lexer for Arrow.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ArrowLexer

Lexer for Arrow

---

### arturo

pygments.lexers.arturo
~~~~~~~~~~~~~~~~~~~~~~

Lexer for the Arturo language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ArturoLexer

For Arturo source code.

See `Arturo's Github <https://github.com/arturo-lang/arturo>`_
and `Arturo's Website <https://arturo-lang.io/>`_.

**M√©thodes :**

- `__init__()`
- `handle_annotated_strings()`

#### Fonctions

##### __init__

##### handle_annotated_strings

Adds syntax from another languages inside annotated strings

match args:
    1:open_string,
    2:exclamation_mark,
    3:lang_name,
    4:space_or_newline,
    5:code,
    6:close_string

**Param√®tres :**

- `match`

---

### asc

pygments.lexers.asc
~~~~~~~~~~~~~~~~~~~

Lexer for various ASCII armored files.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AscLexer

Lexer for ASCII armored files, containing `-----BEGIN/END ...-----` wrapped
base64 data.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### asm

pygments.lexers.asm
~~~~~~~~~~~~~~~~~~~

Lexers for assembly languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GasLexer

For Gas (AT&T) assembly code.

**M√©thodes :**

- `analyse_text()`

##### ObjdumpLexer

For the output of ``objdump -dr``.

##### DObjdumpLexer

For the output of ``objdump -Sr`` on compiled D files.

**M√©thodes :**

- `__init__()`

##### CppObjdumpLexer

For the output of ``objdump -Sr`` on compiled C++ files.

**M√©thodes :**

- `__init__()`

##### CObjdumpLexer

For the output of ``objdump -Sr`` on compiled C files.

**M√©thodes :**

- `__init__()`

##### HsailLexer

For HSAIL assembly code.

##### LlvmLexer

For LLVM assembly code.

##### LlvmMirBodyLexer

For LLVM MIR examples without the YAML wrapper.

##### LlvmMirLexer

Lexer for the overall LLVM MIR document format.

MIR is a human readable serialization format that's used to represent LLVM's
machine specific intermediate representation. It allows LLVM's developers to
see the state of the compilation process at various points, as well as test
individual pieces of the compiler.

##### NasmLexer

For Nasm (Intel) assembly code.

**M√©thodes :**

- `analyse_text()`

##### NasmObjdumpLexer

For the output of ``objdump -d -M intel``.

##### TasmLexer

For Tasm (Turbo Assembler) assembly code.

**M√©thodes :**

- `analyse_text()`

##### Ca65Lexer

For ca65 assembler sources.

**M√©thodes :**

- `analyse_text()`

##### Dasm16Lexer

For DCPU-16 Assembly.

**M√©thodes :**

- `guess_identifier()`

#### Fonctions

##### _objdump_lexer_tokens

Common objdump lexer tokens to wrap an ASM lexer.

**Param√®tres :**

- `asm_lexer`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### guess_identifier

**Param√®tres :**

- `lexer`
- `match`

---

### asn1

pygments.lexers.asn1
~~~~~~~~~~~~~~~~~~~~

Pygments lexers for ASN.1.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Asn1Lexer

Lexer for ASN.1 module definition

#### Fonctions

##### word_sequences

**Param√®tres :**

- `tokens`

---

### automation

pygments.lexers.automation
~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for automation scripting languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AutohotkeyLexer

For autohotkey source code.

##### AutoItLexer

For AutoIt files.

AutoIt is a freeware BASIC-like scripting language
designed for automating the Windows GUI and general scripting

---

### bare

pygments.lexers.bare
~~~~~~~~~~~~~~~~~~~~

Lexer for the BARE schema.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BareLexer

For BARE schema source.

---

### basic

pygments.lexers.basic
~~~~~~~~~~~~~~~~~~~~~

Lexers for BASIC like languages (other than VB.net).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BlitzMaxLexer

For BlitzMax source code.

##### BlitzBasicLexer

For BlitzBasic source code.

##### MonkeyLexer

For Monkey source code.

##### CbmBasicV2Lexer

For CBM BASIC V2 sources.

**M√©thodes :**

- `analyse_text()`

##### QBasicLexer

For QBasic source code.

**M√©thodes :**

- `analyse_text()`

##### VBScriptLexer

VBScript is scripting language that is modeled on Visual Basic.

##### BBCBasicLexer

BBC Basic was supplied on the BBC Micro, and later Acorn RISC OS.
It is also used by BBC Basic For Windows.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### bdd

pygments.lexers.bdd
~~~~~~~~~~~~~~~~~~~

Lexer for BDD(Behavior-driven development).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BddLexer

Lexer for BDD(Behavior-driven development), which highlights not only
keywords, but also comments, punctuations, strings, numbers, and variables.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### berry

pygments.lexers.berry
~~~~~~~~~~~~~~~~~~~~~

Lexer for Berry.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BerryLexer

For Berry source code.

---

### bibtex

pygments.lexers.bibtex
~~~~~~~~~~~~~~~~~~~~~~

Lexers for BibTeX bibliography data and styles

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BibTeXLexer

A lexer for BibTeX bibliography data format.

**M√©thodes :**

- `open_brace_callback()`
- `close_brace_callback()`

##### BSTLexer

A lexer for BibTeX bibliography styles.

#### Fonctions

##### open_brace_callback

**Param√®tres :**

- `match`
- `ctx`

##### close_brace_callback

**Param√®tres :**

- `match`
- `ctx`

---

### blueprint

pygments.lexers.blueprint
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for the Blueprint UI markup language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BlueprintLexer

For Blueprint UI markup.

---

### boa

pygments.lexers.boa
~~~~~~~~~~~~~~~~~~~

Lexers for the Boa language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BoaLexer

Lexer for the Boa language.

---

### bqn

pygments.lexers.bqn
~~~~~~~~~~~~~~~~~~~

Lexer for BQN.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BQNLexer

A simple BQN lexer.

---

### business

pygments.lexers.business
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for "business-oriented" languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CobolLexer

Lexer for OpenCOBOL code.

##### CobolFreeformatLexer

Lexer for Free format OpenCOBOL code.

##### ABAPLexer

Lexer for ABAP, SAP's integrated language.

##### OpenEdgeLexer

Lexer for OpenEdge ABL (formerly Progress) source code.

**M√©thodes :**

- `analyse_text()`

##### GoodDataCLLexer

Lexer for GoodData-CL script files.

##### MaqlLexer

Lexer for GoodData MAQL scripts.

#### Fonctions

##### analyse_text

Try to identify OpenEdge ABL based on a few common constructs.

**Param√®tres :**

- `text`

---

### c_cpp

pygments.lexers.c_cpp
~~~~~~~~~~~~~~~~~~~~~

Lexers for C/C++ languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CFamilyLexer

For C family source code.  This is used as a base class to avoid repetitious
definitions.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### CLexer

For C source code with preprocessor directives.

Additional options accepted:

`stdlibhighlighting`
    Highlight common types found in the C/C++ standard library (e.g. `size_t`).
    (default: ``True``).

`c99highlighting`
    Highlight common types found in the C99 standard library (e.g. `int8_t`).
    Actually, this includes all fixed-width integer types.
    (default: ``True``).

`c11highlighting`
    Highlight atomic types found in the C11 standard library (e.g. `atomic_bool`).
    (default: ``True``).

`platformhighlighting`
    Highlight common types found in the platform SDK headers (e.g. `clockid_t` on Linux).
    (default: ``True``).

**M√©thodes :**

- `analyse_text()`

##### CppLexer

For C++ source code with preprocessor directives.

Additional options accepted:

`stdlibhighlighting`
    Highlight common types found in the C/C++ standard library (e.g. `size_t`).
    (default: ``True``).

`c99highlighting`
    Highlight common types found in the C99 standard library (e.g. `int8_t`).
    Actually, this includes all fixed-width integer types.
    (default: ``True``).

`c11highlighting`
    Highlight atomic types found in the C11 standard library (e.g. `atomic_bool`).
    (default: ``True``).

`platformhighlighting`
    Highlight common types found in the platform SDK headers (e.g. `clockid_t` on Linux).
    (default: ``True``).

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### c_like

pygments.lexers.c_like
~~~~~~~~~~~~~~~~~~~~~~

Lexers for other C-like languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PikeLexer

For `Pike <http://pike.lysator.liu.se/>`_ source code.

##### NesCLexer

For `nesC <https://github.com/tinyos/nesc>`_ source code with preprocessor
directives.

##### ClayLexer

For Clay source.

##### ECLexer

For eC source code with preprocessor directives.

##### ValaLexer

For Vala source code with preprocessor directives.

##### CudaLexer

For NVIDIA CUDA‚Ñ¢ source.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### SwigLexer

For `SWIG <http://www.swig.org/>`_ source code.

**M√©thodes :**

- `analyse_text()`

##### MqlLexer

For `MQL4 <http://docs.mql4.com/>`_ and
`MQL5 <http://www.mql5.com/en/docs>`_ source code.

##### ArduinoLexer

For `Arduino(tm) <https://arduino.cc/>`_ source.

This is an extension of the CppLexer, as the Arduino¬Æ Language is a superset
of C++

**M√©thodes :**

- `get_tokens_unprocessed()`

##### CharmciLexer

For `Charm++ <https://charm.cs.illinois.edu>`_ interface files (.ci).

##### OmgIdlLexer

Lexer for Object Management Group Interface Definition Language.

##### PromelaLexer

For the Promela language used with SPIN.

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

---

### capnproto

pygments.lexers.capnproto
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for the Cap'n Proto schema language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CapnProtoLexer

For Cap'n Proto source.

---

### carbon

pygments.lexers.carbon
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the Carbon programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CarbonLexer

For Carbon source.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### cddl

pygments.lexers.cddl
~~~~~~~~~~~~~~~~~~~~

Lexer for the Concise data definition language (CDDL), a notational
convention to express CBOR and JSON data structures.

More information:
https://datatracker.ietf.org/doc/rfc8610/

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CddlLexer

Lexer for CDDL definitions.

---

### chapel

pygments.lexers.chapel
~~~~~~~~~~~~~~~~~~~~~~

Lexer for the Chapel language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ChapelLexer

For Chapel source.

---

### clean

pygments.lexers.clean
~~~~~~~~~~~~~~~~~~~~~

Lexer for the Clean language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CleanLexer

Lexer for the general purpose, state-of-the-art, pure and lazy functional
programming language Clean.

.. versionadded: 2.2

---

### codeql

pygments.lexers.codeql
~~~~~~~~~~~~~~~~~~~~~~

Lexer for CodeQL query language.

The grammar is originating from:
https://github.com/github/vscode-codeql/blob/main/syntaxes/README.md

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CodeQLLexer

---

### comal

pygments.lexers.comal
~~~~~~~~~~~~~~~~~~~~~

Lexer for COMAL-80.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Comal80Lexer

For COMAL-80 source code.

---

### compiled

pygments.lexers.compiled
~~~~~~~~~~~~~~~~~~~~~~~~

Just export lexer classes previously contained in this module.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### configs

pygments.lexers.configs
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for configuration file formats.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### IniLexer

Lexer for configuration files in INI style.

**M√©thodes :**

- `analyse_text()`

##### DesktopLexer

Lexer for .desktop files.

**M√©thodes :**

- `analyse_text()`

##### SystemdLexer

Lexer for systemd unit files.

**M√©thodes :**

- `analyse_text()`

##### RegeditLexer

Lexer for Windows Registry files produced by regedit.

**M√©thodes :**

- `analyse_text()`

##### PropertiesLexer

Lexer for configuration files in Java's properties format.

Note: trailing whitespace counts as part of the value as per spec

##### KconfigLexer

For Linux-style Kconfig files.

**M√©thodes :**

- `call_indent()`
- `do_indent()`

##### Cfengine3Lexer

Lexer for CFEngine3 policy files.

##### ApacheConfLexer

Lexer for configuration files following the Apache config file
format.

##### SquidConfLexer

Lexer for squid configuration files.

##### NginxConfLexer

Lexer for Nginx configuration files.

##### LighttpdConfLexer

Lexer for Lighttpd configuration files.

##### DockerLexer

Lexer for Docker configuration files.

##### TerraformLexer

Lexer for terraformi ``.tf`` files.

**M√©thodes :**

- `heredoc_callback()`

##### TermcapLexer

Lexer for termcap database source.

This is very simple and minimal.

##### TerminfoLexer

Lexer for terminfo database source.

This is very simple and minimal.

##### PkgConfigLexer

Lexer for pkg-config
(see also `manual page <http://linux.die.net/man/1/pkg-config>`_).

##### PacmanConfLexer

Lexer for pacman.conf.

Actually, IniLexer works almost fine for this format,
but it yield error token. It is because pacman.conf has
a form without assignment like:

    UseSyslog
    Color
    TotalDownload
    CheckSpace
    VerbosePkgLists

These are flags to switch on.

##### AugeasLexer

Lexer for Augeas.

##### TOMLLexer

Lexer for TOML, a simple language for config files.

##### NestedTextLexer

Lexer for *NextedText*, a human-friendly data format.

.. versionchanged:: 2.16
    Added support for *NextedText* v3.0.

##### SingularityLexer

Lexer for Singularity definition files.

**M√©thodes :**

- `analyse_text()`

##### UnixConfigLexer

Lexer for Unix/Linux config files using colon-separated values, e.g.

* ``/etc/group``
* ``/etc/passwd``
* ``/etc/shadow``

#### Fonctions

##### _rx_indent

**Param√®tres :**

- `level`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### call_indent

**Param√®tres :**

- `level`

##### do_indent

**Param√®tres :**

- `level`

##### heredoc_callback

**Param√®tres :**

- `match`
- `ctx`

##### analyse_text

This is a quite simple script file, but there are a few keywords
which seem unique to this language.

**Param√®tres :**

- `text`

---

### console

pygments.lexers.console
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for misc console output.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VCTreeStatusLexer

For colorizing output of version control status commands, like "hg
status" or "svn status".

##### PyPyLogLexer

Lexer for PyPy log files.

---

### cplint

pygments.lexers.cplint
~~~~~~~~~~~~~~~~~~~~~~

Lexer for the cplint language

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CplintLexer

Lexer for cplint files, including CP-logic, Logic Programs with Annotated
Disjunctions, Distributional Clauses syntax, ProbLog, DTProbLog.

---

### crystal

pygments.lexers.crystal
~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Crystal.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CrystalLexer

For Crystal source code.

**M√©thodes :**

- `heredoc_callback()`
- `gen_crystalstrings_rules()`

#### Fonctions

##### heredoc_callback

**Param√®tres :**

- `match`
- `ctx`

##### gen_crystalstrings_rules

---

### csound

pygments.lexers.csound
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Csound languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CsoundLexer

##### CsoundScoreLexer

For `Csound <https://csound.com>`_ scores.

##### CsoundOrchestraLexer

For `Csound <https://csound.com>`_ orchestras.

**M√©thodes :**

- `opcode_name_callback()`
- `name_callback()`

##### CsoundDocumentLexer

For Csound documents.

#### Fonctions

##### opcode_name_callback

**Param√®tres :**

- `lexer`
- `match`

##### name_callback

**Param√®tres :**

- `lexer`
- `match`

---

### css

pygments.lexers.css
~~~~~~~~~~~~~~~~~~~

Lexers for CSS and related stylesheet formats.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CssLexer

For CSS (Cascading Style Sheets).

##### SassLexer

For Sass stylesheets.

##### ScssLexer

For SCSS stylesheets.

##### LessCssLexer

For LESS styleshets.

#### Fonctions

##### _indentation

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### _starts_block

**Param√®tres :**

- `token`
- `state`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

---

### d

pygments.lexers.d
~~~~~~~~~~~~~~~~~

Lexers for D languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DLexer

For D source.

##### CrocLexer

For Croc source.

##### MiniDLexer

For MiniD source. MiniD is now known as Croc.

---

### dalvik

pygments.lexers.dalvik
~~~~~~~~~~~~~~~~~~~~~~

Pygments lexers for Dalvik VM-related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SmaliLexer

For Smali (Android/Dalvik) assembly
code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### data

pygments.lexers.data
~~~~~~~~~~~~~~~~~~~~

Lexers for data file format.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### YamlLexerContext

Indentation context for the YAML lexer.

**M√©thodes :**

- `__init__()`

##### YamlLexer

Lexer for YAML, a human-friendly data serialization
language.

**M√©thodes :**

- `something()`
- `reset_indent()`
- `save_indent()`
- `set_indent()`
- `set_block_scalar_indent()`
- `parse_block_scalar_empty_line()`
- `parse_block_scalar_indent()`
- `parse_plain_scalar_indent()`
- `get_tokens_unprocessed()`

##### JsonLexer

For JSON data structures.

Javascript-style comments are supported (like ``/* */`` and ``//``),
though comments are not part of the JSON specification.
This allows users to highlight JSON as it is used in the wild.

No validation is performed on the input JSON document.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### JsonBareObjectLexer

For JSON data structures (with missing object curly braces).

.. deprecated:: 2.8.0

   Behaves the same as `JsonLexer` now.

##### JsonLdLexer

For JSON-LD linked data.

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### __init__

##### something

Do not produce empty tokens.

**Param√®tres :**

- `token_class`

##### reset_indent

Reset the indentation levels.

**Param√®tres :**

- `token_class`

##### save_indent

Save a possible indentation level.

**Param√®tres :**

- `token_class`
- `start`

##### set_indent

Set the previously saved indentation level.

**Param√®tres :**

- `token_class`
- `implicit`

##### set_block_scalar_indent

Set an explicit indentation level for a block scalar.

**Param√®tres :**

- `token_class`

##### parse_block_scalar_empty_line

Process an empty line in a block scalar.

**Param√®tres :**

- `indent_token_class`
- `content_token_class`

##### parse_block_scalar_indent

Process indentation spaces in a block scalar.

**Param√®tres :**

- `token_class`

##### parse_plain_scalar_indent

Process indentation spaces in a plain scalar.

**Param√®tres :**

- `token_class`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `context`

##### get_tokens_unprocessed

Parse JSON data.

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

---

### dax

pygments.lexers.dax
~~~~~~~~~~~~~~~~~~~

Lexer for LilyPond.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DaxLexer

Lexer for Power BI DAX
Referenced from: https://github.com/sql-bi/SyntaxHighlighterBrushDax

---

### devicetree

pygments.lexers.devicetree
~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Devicetree language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DevicetreeLexer

Lexer for Devicetree files.

---

### diff

pygments.lexers.diff
~~~~~~~~~~~~~~~~~~~~

Lexers for diff/patch formats.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DiffLexer

Lexer for unified or context-style diffs or patches.

**M√©thodes :**

- `analyse_text()`

##### DarcsPatchLexer

DarcsPatchLexer is a lexer for the various versions of the darcs patch
format.  Examples of this format are derived by commands such as
``darcs annotate --patch`` and ``darcs send``.

##### WDiffLexer

A wdiff lexer.

Note that:

* It only works with normal output (without options like ``-l``).
* If the target files contain "[-", "-]", "{+", or "+}",
  especially they are unbalanced, the lexer will get confused.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### dns

pygments.lexers.dns
~~~~~~~~~~~~~~~~~~~

Pygments lexers for DNS

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DnsZoneLexer

Lexer for DNS zone file

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### dotnet

pygments.lexers.dotnet
~~~~~~~~~~~~~~~~~~~~~~

Lexers for .net languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CSharpLexer

For C# source code.

Additional options accepted:

`unicodelevel`
  Determines which Unicode characters this lexer allows for identifiers.
  The possible values are:

  * ``none`` -- only the ASCII letters and numbers are allowed. This
    is the fastest selection.
  * ``basic`` -- all Unicode characters from the specification except
    category ``Lo`` are allowed.
  * ``full`` -- all Unicode characters as specified in the C# specs
    are allowed.  Note that this means a considerable slowdown since the
    ``Lo`` category has more than 40,000 characters in it!

  The default value is ``basic``.

  .. versionadded:: 0.8

**M√©thodes :**

- `__init__()`

##### NemerleLexer

For Nemerle source code.

Additional options accepted:

`unicodelevel`
  Determines which Unicode characters this lexer allows for identifiers.
  The possible values are:

  * ``none`` -- only the ASCII letters and numbers are allowed. This
    is the fastest selection.
  * ``basic`` -- all Unicode characters from the specification except
    category ``Lo`` are allowed.
  * ``full`` -- all Unicode characters as specified in the C# specs
    are allowed.  Note that this means a considerable slowdown since the
    ``Lo`` category has more than 40,000 characters in it!

  The default value is ``basic``.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### BooLexer

For Boo source code.

##### VbNetLexer

For Visual Basic.NET source code.
Also LibreOffice Basic, OpenOffice Basic, and StarOffice Basic.

**M√©thodes :**

- `analyse_text()`

##### GenericAspxLexer

Lexer for ASP.NET pages.

##### CSharpAspxLexer

Lexer for highlighting C# within ASP.NET pages.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### VbNetAspxLexer

Lexer for highlighting Visual Basic.net within ASP.NET pages.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### FSharpLexer

For the F# language (version 3.0).

**M√©thodes :**

- `analyse_text()`

##### XppLexer

For X++ source code. This is based loosely on the CSharpLexer

#### Fonctions

##### __init__

##### __init__

##### analyse_text

Nemerle is quite similar to Python, but @if is relatively uncommon
elsewhere.

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

F# doesn't have that many unique features -- |> and <| are weak
indicators.

**Param√®tres :**

- `text`

---

### dsls

pygments.lexers.dsls
~~~~~~~~~~~~~~~~~~~~

Lexers for various domain-specific languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ProtoBufLexer

Lexer for Protocol Buffer definition files.

##### ThriftLexer

For Thrift interface definitions.

##### ZeekLexer

For Zeek scripts.

##### PuppetLexer

For Puppet configuration DSL.

##### RslLexer

RSL is the formal specification
language used in RAISE (Rigorous Approach to Industrial Software Engineering)
method.

**M√©thodes :**

- `analyse_text()`

##### MscgenLexer

For Mscgen files.

##### VGLLexer

For SampleManager VGL source code.

##### AlloyLexer

For Alloy source code.

##### PanLexer

Lexer for pan source files.

Based on tcsh lexer.

##### CrmshLexer

Lexer for crmsh configuration files for Pacemaker clusters.

##### FlatlineLexer

Lexer for Flatline expressions.

##### SnowballLexer

Lexer for Snowball source code.

**M√©thodes :**

- `__init__()`
- `_reset_stringescapes()`
- `_string()`
- `_stringescapes()`
- `get_tokens_unprocessed()`

#### Fonctions

##### analyse_text

Check for the most common text in the beginning of a RSL file.

**Param√®tres :**

- `text`

##### __init__

##### _reset_stringescapes

##### _string

**Param√®tres :**

- `do_string_first`

##### _stringescapes

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `context`

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

---

### dylan

pygments.lexers.dylan
~~~~~~~~~~~~~~~~~~~~~

Lexers for the Dylan language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DylanLexer

For the Dylan language.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### DylanLidLexer

For Dylan LID (Library Interchange Definition) files.

##### DylanConsoleLexer

For Dylan interactive console output.

This is based on a copy of the ``RubyConsoleLexer``.

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### ecl

pygments.lexers.ecl
~~~~~~~~~~~~~~~~~~~

Lexers for the ECL language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ECLLexer

Lexer for the declarative big-data ECL language.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

This is very difficult to guess relative to other business languages.
-> in conjunction with BEGIN/END seems relatively rare though.

**Param√®tres :**

- `text`

---

### eiffel

pygments.lexers.eiffel
~~~~~~~~~~~~~~~~~~~~~~

Lexer for the Eiffel language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### EiffelLexer

For Eiffel source code.

---

### elm

pygments.lexers.elm
~~~~~~~~~~~~~~~~~~~

Lexer for the Elm programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ElmLexer

For Elm source code.

---

### elpi

pygments.lexers.elpi
~~~~~~~~~~~~~~~~~~~~

Lexer for the `Elpi <http://github.com/LPCIC/elpi>`_ programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ElpiLexer

Lexer for the Elpi programming language.

---

### email

pygments.lexers.email
~~~~~~~~~~~~~~~~~~~~~

Lexer for the raw E-mail.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### EmailHeaderLexer

Sub-lexer for raw E-mail. This lexer only process header part of e-mail.

.. versionadded:: 2.5

**M√©thodes :**

- `__init__()`
- `get_x_header_tokens()`

##### EmailLexer

Lexer for raw E-mail.

Additional options accepted:

`highlight-X-header`
    Highlight the fields of ``X-`` user-defined email header. (default:
    ``False``).

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

##### get_x_header_tokens

**Param√®tres :**

- `match`

##### __init__

---

### erlang

pygments.lexers.erlang
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Erlang.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ErlangLexer

For the Erlang functional programming language.

##### ErlangShellLexer

Shell sessions in erl (for Erlang code).

**M√©thodes :**

- `get_tokens_unprocessed()`

##### ElixirLexer

For the Elixir language.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `gen_elixir_sigil_rules()`

##### ElixirConsoleLexer

For Elixir interactive console (iex) output like:

.. sourcecode:: iex

    iex> [head | tail] = [1,2,3]
    [1,2,3]
    iex> head
    1
    iex> tail
    [2,3]
    iex> [head | tail]
    [1,2,3]
    iex> length [head | tail]
    3

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### gen_elixir_string_rules

**Param√®tres :**

- `name`
- `symbol`
- `token`

##### gen_elixir_sigstr_rules

**Param√®tres :**

- `term`
- `term_class`
- `token`
- `interpol`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### gen_elixir_sigil_rules

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### esoteric

pygments.lexers.esoteric
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for esoteric languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BrainfuckLexer

Lexer for the esoteric BrainFuck language.

**M√©thodes :**

- `analyse_text()`

##### BefungeLexer

Lexer for the esoteric Befunge language.

##### CAmkESLexer

Basic lexer for the input language for the CAmkES component platform.

##### CapDLLexer

Basic lexer for CapDL.

The source of the primary tool that reads such specifications is available
at https://github.com/seL4/capdl/tree/master/capDL-tool. Note that this
lexer only supports a subset of the grammar. For example, identifiers can
shadow type names, but these instances are currently incorrectly
highlighted as types. Supporting this would need a stateful lexer that is
considered unnecessarily complex for now.

##### RedcodeLexer

A simple Redcode lexer based on ICWS'94.
Contributed by Adam Blinkinsop <blinks@acm.org>.

##### AheuiLexer

Aheui is esoteric language based on Korean alphabets.

#### Fonctions

##### analyse_text

It's safe to assume that a program which mostly consists of + -
and < > is brainfuck.

**Param√®tres :**

- `text`

---

### ezhil

pygments.lexers.ezhil
~~~~~~~~~~~~~~~~~~~~~

Pygments lexers for Ezhil language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### EzhilLexer

Lexer for Ezhil, a Tamil script-based programming language.

**M√©thodes :**

- `analyse_text()`
- `__init__()`

#### Fonctions

##### analyse_text

This language uses Tamil-script. We'll assume that if there's a
decent amount of Tamil-characters, it's this language. This assumption
is obviously horribly off if someone uses string literals in tamil
in another language.

**Param√®tres :**

- `text`

##### __init__

---

### factor

pygments.lexers.factor
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the Factor language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FactorLexer

Lexer for the Factor language.

---

### fantom

pygments.lexers.fantom
~~~~~~~~~~~~~~~~~~~~~~

Lexer for the Fantom language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FantomLexer

For Fantom source code.

**M√©thodes :**

- `s()`

#### Fonctions

##### s

**Param√®tres :**

- `str`

---

### felix

pygments.lexers.felix
~~~~~~~~~~~~~~~~~~~~~

Lexer for the Felix language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FelixLexer

For Felix source code.

---

### fift

pygments.lexers.fift
~~~~~~~~~~~~~~~~~~~~

Lexers for fift.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FiftLexer

For Fift source code.

---

### floscript

pygments.lexers.floscript
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for FloScript

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FloScriptLexer

For FloScript configuration language source code.

**M√©thodes :**

- `innerstring_rules()`

#### Fonctions

##### innerstring_rules

**Param√®tres :**

- `ttype`

---

### forth

pygments.lexers.forth
~~~~~~~~~~~~~~~~~~~~~

Lexer for the Forth language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ForthLexer

Lexer for Forth files.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

Forth uses : COMMAND ; quite a lot in a single line, so we're trying
to find that.

**Param√®tres :**

- `text`

---

### fortran

pygments.lexers.fortran
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Fortran languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FortranLexer

Lexer for FORTRAN 90 code.

##### FortranFixedLexer

Lexer for fixed format Fortran.

**M√©thodes :**

- `_lex_fortran()`

#### Fonctions

##### _lex_fortran

Lex a line just as free form fortran without line break.

**Param√®tres :**

- `match`
- `ctx`

---

### foxpro

pygments.lexers.foxpro
~~~~~~~~~~~~~~~~~~~~~~

Simple lexer for Microsoft Visual FoxPro source code.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FoxProLexer

Lexer for Microsoft Visual FoxPro language.

FoxPro syntax allows to shorten all keywords and function names
to 4 characters.  Shortened forms are not recognized by this lexer.

---

### freefem

pygments.lexers.freefem
~~~~~~~~~~~~~~~~~~~~~~~

Lexer for FreeFem++ language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FreeFemLexer

For FreeFem++ source.

This is an extension of the CppLexer, as the FreeFem Language is a superset
of C++.

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

---

### func

pygments.lexers.func
~~~~~~~~~~~~~~~~~~~~

Lexers for FunC.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FuncLexer

For FunC source code.

---

### functional

pygments.lexers.functional
~~~~~~~~~~~~~~~~~~~~~~~~~~

Just export lexer classes previously contained in this module.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### futhark

pygments.lexers.futhark
~~~~~~~~~~~~~~~~~~~~~~~

Lexer for the Futhark language

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FutharkLexer

A Futhark lexer

---

### gcodelexer

pygments.lexers.gcodelexer
~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for the G Code Language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GcodeLexer

For gcode source code.

---

### gdscript

pygments.lexers.gdscript
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for GDScript.

Modified by Daniel J. Ramirez <djrmuv@gmail.com> based on the original
python.py.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GDScriptLexer

For GDScript source code.

**M√©thodes :**

- `innerstring_rules()`
- `analyse_text()`

#### Fonctions

##### innerstring_rules

**Param√®tres :**

- `ttype`

##### analyse_text

**Param√®tres :**

- `text`

---

### gleam

pygments.lexers.gleam
~~~~~~~~~~~~~~~~~~~~~

Lexer for the Gleam programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GleamLexer

Lexer for the Gleam programming language (version 1.0.0).

---

### go

pygments.lexers.go
~~~~~~~~~~~~~~~~~~

Lexers for the Google Go language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GoLexer

For Go source.

---

### grammar_notation

pygments.lexers.grammar_notation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for grammar notations like BNF.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BnfLexer

This lexer is for grammar notations which are similar to
original BNF.

In order to maximize a number of targets of this lexer,
let's decide some designs:

* We don't distinguish `Terminal Symbol`.

* We do assume that `NonTerminal Symbol` are always enclosed
  with arrow brackets.

* We do assume that `NonTerminal Symbol` may include
  any printable characters except arrow brackets and ASCII 0x20.
  This assumption is for `RBNF <http://www.rfc-base.org/txt/rfc-5511.txt>`_.

* We do assume that target notation doesn't support comment.

* We don't distinguish any operators and punctuation except
  `::=`.

Though these decision making might cause too minimal highlighting
and you might be disappointed, but it is reasonable for us.

##### AbnfLexer

Lexer for IETF 7405 ABNF.

(Updates `5234 <http://www.ietf.org/rfc/rfc5234.txt>`_) grammars.

##### JsgfLexer

For JSpeech Grammar Format grammars.

##### PegLexer

This lexer is for Parsing Expression Grammars (PEG).

Various implementations of PEG have made different decisions
regarding the syntax, so let's try to be accommodating:

* `<-`, `‚Üê`, `:`, and `=` are all accepted as rule operators.

* Both `|` and `/` are choice operators.

* `^`, `‚Üë`, and `~` are cut operators.

* A single `a-z` character immediately before a string, or
  multiple `a-z` characters following a string, are part of the
  string (e.g., `r"..."` or `"..."ilmsuxa`).

---

### graph

pygments.lexers.graph
~~~~~~~~~~~~~~~~~~~~~

Lexers for graph query languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CypherLexer

For Cypher Query Language

For the Cypher version in Neo4j 3.3

---

### graphics

pygments.lexers.graphics
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for computer graphics and plotting related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GLShaderLexer

GLSL (OpenGL Shader) lexer.

##### HLSLShaderLexer

HLSL (Microsoft Direct3D Shader) lexer.

##### PostScriptLexer

Lexer for PostScript files.

##### AsymptoteLexer

For Asymptote source code.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### GnuplotLexer

For Gnuplot plotting scripts.

##### PovrayLexer

For Persistence of Vision Raytracer files.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### _shortened

**Param√®tres :**

- `word`

##### _shortened_many

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

POVRAY is similar to JSON/C, but the combination of camera and
light_source is probably not very likely elsewhere. HLSL or GLSL
are similar (GLSL even has #version), but they miss #declare, and
light_source/camera are not keywords anywhere else -- it's fair
to assume though that any POVRAY scene must have a camera and
lightsource.

**Param√®tres :**

- `text`

---

### graphql

pygments.lexers.graphql
~~~~~~~~~~~~~~~~~~~~~~~

Lexer for GraphQL, an open-source data query and manipulation
language for APIs.

More information:
https://graphql.org/

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GraphQLLexer

Lexer for GraphQL syntax

---

### graphviz

pygments.lexers.graphviz
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for the DOT language (graphviz).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GraphvizLexer

For graphviz DOT graph description language.

---

### gsql

pygments.lexers.gsql
~~~~~~~~~~~~~~~~~~~~

Lexers for TigerGraph GSQL graph query language

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GSQLLexer

For GSQL queries (version 3.x).

---

### hare

pygments.lexers.hare
~~~~~~~~~~~~~~~~~~~~

Lexers for the Hare language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### HareLexer

Lexer for the Hare programming language.

---

### haskell

pygments.lexers.haskell
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Haskell and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### HaskellLexer

A Haskell lexer based on the lexemes defined in the Haskell 98 Report.

##### HspecLexer

A Haskell lexer with support for Hspec constructs.

##### IdrisLexer

A lexer for the dependently typed programming language Idris.

Based on the Haskell and Agda Lexer.

##### AgdaLexer

For the Agda dependently typed functional programming language and
proof assistant.

##### CryptolLexer

FIXME: A Cryptol2 lexer based on the lexemes defined in the Haskell 98 Report.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### LiterateLexer

Base class for lexers of literate file formats based on LaTeX or Bird-style
(prefixing each code line with ">").

Additional options accepted:

`litstyle`
    If given, must be ``"bird"`` or ``"latex"``.  If not given, the style
    is autodetected: if the first non-whitespace character in the source
    is a backslash or percent character, LaTeX is assumed, else Bird.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### LiterateHaskellLexer

For Literate Haskell (Bird-style or LaTeX) source.

Additional options accepted:

`litstyle`
    If given, must be ``"bird"`` or ``"latex"``.  If not given, the style
    is autodetected: if the first non-whitespace character in the source
    is a backslash or percent character, LaTeX is assumed, else Bird.

**M√©thodes :**

- `__init__()`

##### LiterateIdrisLexer

For Literate Idris (Bird-style or LaTeX) source.

Additional options accepted:

`litstyle`
    If given, must be ``"bird"`` or ``"latex"``.  If not given, the style
    is autodetected: if the first non-whitespace character in the source
    is a backslash or percent character, LaTeX is assumed, else Bird.

**M√©thodes :**

- `__init__()`

##### LiterateAgdaLexer

For Literate Agda source.

Additional options accepted:

`litstyle`
    If given, must be ``"bird"`` or ``"latex"``.  If not given, the style
    is autodetected: if the first non-whitespace character in the source
    is a backslash or percent character, LaTeX is assumed, else Bird.

**M√©thodes :**

- `__init__()`

##### LiterateCryptolLexer

For Literate Cryptol (Bird-style or LaTeX) source.

Additional options accepted:

`litstyle`
    If given, must be ``"bird"`` or ``"latex"``.  If not given, the style
    is autodetected: if the first non-whitespace character in the source
    is a backslash or percent character, LaTeX is assumed, else Bird.

**M√©thodes :**

- `__init__()`

##### KokaLexer

Lexer for the Koka language.

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __init__

**Param√®tres :**

- `baselexer`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### __init__

---

### haxe

pygments.lexers.haxe
~~~~~~~~~~~~~~~~~~~~

Lexers for Haxe and related stuff.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### HaxeLexer

For Haxe source code.

**M√©thodes :**

- `preproc_callback()`
- `analyse_text()`

##### HxmlLexer

Lexer for haXe build files.

#### Fonctions

##### preproc_callback

**Param√®tres :**

- `match`
- `ctx`

##### analyse_text

**Param√®tres :**

- `text`

---

### hdl

pygments.lexers.hdl
~~~~~~~~~~~~~~~~~~~

Lexers for hardware descriptor languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VerilogLexer

For verilog source code with preprocessor directives.

**M√©thodes :**

- `analyse_text()`

##### SystemVerilogLexer

Extends verilog lexer to recognise all SystemVerilog keywords from IEEE
1800-2009 standard.

##### VhdlLexer

For VHDL source code.

#### Fonctions

##### analyse_text

Verilog code will use one of reg/wire/assign for sure, and that
is not common elsewhere.

**Param√®tres :**

- `text`

---

### hexdump

pygments.lexers.hexdump
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for hexadecimal dumps.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### HexdumpLexer

For typical hex dump output formats by the UNIX and GNU/Linux tools ``hexdump``,
``hd``, ``hexcat``, ``od`` and ``xxd``, and the DOS tool ``DEBUG``. For example:

.. sourcecode:: hexdump

    00000000  7f 45 4c 46 02 01 01 00  00 00 00 00 00 00 00 00  |.ELF............|
    00000010  02 00 3e 00 01 00 00 00  c5 48 40 00 00 00 00 00  |..>......H@.....|

The specific supported formats are the outputs of:

* ``hexdump FILE``
* ``hexdump -C FILE`` -- the `canonical` format used in the example.
* ``hd FILE`` -- same as ``hexdump -C FILE``.
* ``hexcat FILE``
* ``od -t x1z FILE``
* ``xxd FILE``
* ``DEBUG.EXE FILE.COM`` and entering ``d`` to the prompt.

---

### html

pygments.lexers.html
~~~~~~~~~~~~~~~~~~~~

Lexers for HTML, XML and related markup.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### HtmlLexer

For HTML 4 and XHTML 1 markup. Nested JavaScript and CSS is highlighted
by the appropriate lexer.

**M√©thodes :**

- `analyse_text()`

##### DtdLexer

A lexer for DTDs (Document Type Definitions).

**M√©thodes :**

- `analyse_text()`

##### XmlLexer

Generic lexer for XML (eXtensible Markup Language).

**M√©thodes :**

- `analyse_text()`

##### XsltLexer

A lexer for XSLT.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `analyse_text()`

##### HamlLexer

For Haml markup.

##### ScamlLexer

For Scaml markup.  Scaml is Haml for Scala.

##### PugLexer

For Pug markup.
Pug is a variant of Scaml, see:
http://scalate.fusesource.org/documentation/scaml-reference.html

##### UrlEncodedLexer

Lexer for urlencoded data

##### VueLexer

For Vue Single-File Component.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### idl

pygments.lexers.idl
~~~~~~~~~~~~~~~~~~~

Lexers for IDL.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### IDLLexer

Pygments Lexer for IDL (Interactive Data Language).

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

endelse seems to be unique to IDL, endswitch is rare at least.

**Param√®tres :**

- `text`

---

### igor

pygments.lexers.igor
~~~~~~~~~~~~~~~~~~~~

Lexers for Igor Pro.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### IgorLexer

Pygments Lexer for Igor Pro procedure files (.ipf).

---

### inferno

pygments.lexers.inferno
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Inferno os and all the related stuff.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LimboLexer

Lexer for Limbo programming language

TODO:
    - maybe implement better var declaration highlighting
    - some simple syntax error highlighting

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### installers

pygments.lexers.installers
~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for installer/packager DSLs and formats.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NSISLexer

For NSIS scripts.

##### RPMSpecLexer

For RPM ``.spec`` files.

##### DebianSourcesLexer

Lexer that highlights debian.sources files.

##### SourcesListLexer

Lexer that highlights debian sources.list files.

**M√©thodes :**

- `analyse_text()`

##### DebianControlLexer

Lexer for Debian ``control`` files and ``apt-cache show <pkg>`` outputs.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### int_fiction

pygments.lexers.int_fiction
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for interactive fiction languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Inform6Lexer

For Inform 6 source code.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `analyse_text()`

##### Inform7Lexer

For Inform 7 source code.

**M√©thodes :**

- `__init__()`

##### Inform6TemplateLexer

For Inform 6 template code.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### Tads3Lexer

For TADS 3 source code.

**M√©thodes :**

- `_make_string_state()`
- `_make_tag_state()`
- `_make_attribute_value_state()`
- `get_tokens_unprocessed()`
- `analyse_text()`

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

We try to find a keyword which seem relatively common, unfortunately
there is a decent overlap with Smalltalk keywords otherwise here..

**Param√®tres :**

- `text`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

##### _make_string_state

**Param√®tres :**

- `triple`
- `double`
- `verbatim`
- `_escape`

##### _make_tag_state

**Param√®tres :**

- `triple`
- `double`
- `_escape`

##### _make_attribute_value_state

**Param√®tres :**

- `terminator`
- `host_triple`
- `host_double`
- `_escape`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

This is a rather generic descriptive language without strong
identifiers. It looks like a 'GameMainDef' has to be present,
and/or a 'versionInfo' with an 'IFID' field.

**Param√®tres :**

- `text`

---

### iolang

pygments.lexers.iolang
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the Io language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### IoLexer

For Io (a small, prototype-based programming language) source.

---

### j

pygments.lexers.j
~~~~~~~~~~~~~~~~~

Lexer for the J programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JLexer

For J source code.

---

### javascript

pygments.lexers.javascript
~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for JavaScript and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JavascriptLexer

For JavaScript source code.

##### TypeScriptLexer

For TypeScript source code.

##### KalLexer

For Kal source code.

##### LiveScriptLexer

For LiveScript source code.

##### DartLexer

For Dart source code.

##### LassoLexer

For Lasso source code, covering both Lasso 9
syntax and LassoScript for Lasso 8.6 and earlier. For Lasso embedded in
HTML, use the `LassoHtmlLexer`.

Additional options accepted:

`builtinshighlighting`
    If given and ``True``, highlight builtin types, traits, methods, and
    members (default: ``True``).
`requiredelimiters`
    If given and ``True``, only highlight code between delimiters as Lasso
    (default: ``False``).

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`
- `analyse_text()`

##### ObjectiveJLexer

For Objective-J source code with preprocessor directives.

**M√©thodes :**

- `analyse_text()`

##### CoffeeScriptLexer

For CoffeeScript source code.

##### MaskLexer

For Mask markup.

##### EarlGreyLexer

For Earl-Grey source code.

.. versionadded: 2.1

##### JuttleLexer

For Juttle source code.

##### NodeConsoleLexer

For parsing within an interactive Node.js REPL, such as:

.. sourcecode:: nodejsrepl

    > let a = 3
    undefined
    > a
    3
    > let b = '4'
    undefined
    > b
    '4'
    > b == a
    false

.. versionadded: 2.10

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### jmespath

pygments.lexers.jmespath
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for the JMESPath language

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JMESPathLexer

For JMESPath queries.

---

### jslt

pygments.lexers.jslt
~~~~~~~~~~~~~~~~~~~~

Lexers for the JSLT language

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JSLTLexer

For JSLT source.

---

### json5

pygments.lexers.json5
~~~~~~~~~~~~~~~~~~~~~

Lexer for Json5 file format.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Json5Lexer

Lexer for JSON5 data structures.

#### Fonctions

##### string_rules

**Param√®tres :**

- `quote_mark`

##### quoted_field_name

**Param√®tres :**

- `quote_mark`

---

### jsonnet

pygments.lexers.jsonnet
~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Jsonnet data templating language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JsonnetLexer

Lexer for Jsonnet source code.

#### Fonctions

##### string_rules

**Param√®tres :**

- `quote_mark`

##### quoted_field_name

**Param√®tres :**

- `quote_mark`

---

### jsx

pygments.lexers.jsx
~~~~~~~~~~~~~~~~~~~

Lexers for JSX (React) and TSX (TypeScript flavor).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JsxLexer

For JavaScript Syntax Extension (JSX).
    

##### TsxLexer

For TypeScript with embedded JSX
    

---

### julia

pygments.lexers.julia
~~~~~~~~~~~~~~~~~~~~~

Lexers for the Julia language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JuliaLexer

For Julia source code.

**M√©thodes :**

- `analyse_text()`

##### JuliaConsoleLexer

For Julia console sessions. Modeled after MatlabSessionLexer.

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### jvm

pygments.lexers.jvm
~~~~~~~~~~~~~~~~~~~

Pygments lexers for JVM languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### JavaLexer

For Java source code.

##### AspectJLexer

For AspectJ source code.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### ScalaLexer

For Scala source code.

##### GosuLexer

For Gosu source code.

##### GosuTemplateLexer

For Gosu templates.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### GroovyLexer

For Groovy source code.

**M√©thodes :**

- `analyse_text()`

##### IokeLexer

For Ioke (a strongly typed, dynamic,
prototype based programming language) source.

##### ClojureLexer

Lexer for Clojure source code.

##### ClojureScriptLexer

Lexer for ClojureScript source code.

##### TeaLangLexer

For Tea source code. Only used within a
TeaTemplateLexer.

.. versionadded:: 1.5

##### CeylonLexer

For Ceylon source code.

##### KotlinLexer

For Kotlin source code.

##### XtendLexer

For Xtend source code.

##### PigLexer

For Pig Latin source code.

##### GoloLexer

For Golo source code.

##### JasminLexer

For Jasmin assembly code.

**M√©thodes :**

- `analyse_text()`

##### SarlLexer

For SARL source code.

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### kuin

pygments.lexers.kuin
~~~~~~~~~~~~~~~~~~~~

Lexers for the Kuin language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### KuinLexer

For Kuin source code.

---

### kusto

pygments.lexers.kusto
~~~~~~~~~~~~~~~~~~~~~

Lexers for Kusto Query Language (KQL).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### KustoLexer

For Kusto Query Language source code.
    

---

### ldap

pygments.lexers.ldap
~~~~~~~~~~~~~~~~~~~~

Pygments lexers for LDAP.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LdifLexer

Lexer for LDIF

##### LdaprcLexer

Lexer for OpenLDAP configuration files.

---

### lean

pygments.lexers.lean
~~~~~~~~~~~~~~~~~~~~

Lexers for the Lean theorem prover.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Lean3Lexer

For the Lean 3 theorem prover.

**M√©thodes :**

- `analyse_text()`

##### Lean4Lexer

For the Lean 4 theorem prover.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### lilypond

pygments.lexers.lilypond
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for LilyPond.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LilyPondLexer

Lexer for input to LilyPond, a text-based music typesetter.

.. important::

   This lexer is meant to be used in conjunction with the ``lilypond`` style.

**M√©thodes :**

- `get_tokens_unprocessed()`

#### Fonctions

##### builtin_words

**Param√®tres :**

- `names`
- `backslash`
- `suffix`

##### get_tokens_unprocessed

Highlight Scheme variables as LilyPond builtins when applicable.

**Param√®tres :**

- `text`

---

### lisp

pygments.lexers.lisp
~~~~~~~~~~~~~~~~~~~~

Lexers for Lispy languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SchemeLexer

A Scheme lexer.

This parser is checked with pastes from the LISP pastebin
at http://paste.lisp.org/ to cover as much syntax as possible.

It supports the full Scheme syntax as defined in R5RS.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `decimal_cb()`

##### CommonLispLexer

A Common Lisp lexer.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`
- `analyse_text()`

##### HyLexer

Lexer for Hy source code.

**M√©thodes :**

- `_multi_escape()`
- `analyse_text()`

##### RacketLexer

Lexer for Racket source code (formerly
known as PLT Scheme).

##### NewLispLexer

For newLISP source code (version 10.3.0).

##### EmacsLispLexer

An ELisp lexer, parsing a stream and outputting the tokens
needed to highlight elisp code.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### ShenLexer

Lexer for Shen source code.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `_relevant()`
- `_process_declarations()`
- `_process_symbols()`
- `_process_declaration()`
- `_process_signature()`

##### CPSALexer

A CPSA lexer based on the CPSA language as of version 2.2.12

##### XtlangLexer

An xtlang lexer for the Extempore programming environment.

This is a mixture of Scheme and xtlang, really. Keyword lists are
taken from the Extempore Emacs mode
(https://github.com/extemporelang/extempore-emacs-mode)

##### FennelLexer

A lexer for the Fennel programming language.

Fennel compiles to Lua, so all the Lua builtins are recognized as well
as the special forms that are particular to the Fennel compiler.

##### JanetLexer

A lexer for the Janet programming language.
    

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### decimal_cb

**Param√®tres :**

- `match`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

Competes with Visual Prolog on *.cl

**Param√®tres :**

- `text`

##### _multi_escape

**Param√®tres :**

- `entries`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### _relevant

**Param√®tres :**

- `token`

##### _process_declarations

**Param√®tres :**

- `tokens`

##### _process_symbols

**Param√®tres :**

- `tokens`

##### _process_declaration

**Param√®tres :**

- `declaration`
- `tokens`

##### _process_signature

**Param√®tres :**

- `tokens`

---

### macaulay2

pygments.lexers.macaulay2
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Macaulay2.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Macaulay2Lexer

Lexer for Macaulay2, a software system for research in algebraic geometry.

---

### make

pygments.lexers.make
~~~~~~~~~~~~~~~~~~~~

Lexers for Makefiles and similar.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MakefileLexer

Lexer for BSD and GNU make extensions (lenient enough to handle both in
the same file even).

*Rewritten in Pygments 0.10.*

**M√©thodes :**

- `get_tokens_unprocessed()`
- `analyse_text()`

##### BaseMakefileLexer

Lexer for simple Makefiles (no preprocessing).

##### CMakeLexer

Lexer for CMake files.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### maple

pygments.lexers.maple
~~~~~~~~~~~~~~~~~~~~~

Lexers for Maple.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MapleLexer

Lexer for Maple.

**M√©thodes :**

- `delayed_callback()`
- `analyse_text()`

#### Fonctions

##### delayed_callback

**Param√®tres :**

- `match`
- `ctx`

##### analyse_text

**Param√®tres :**

- `text`

---

### markup

pygments.lexers.markup
~~~~~~~~~~~~~~~~~~~~~~

Lexers for non-HTML markup languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BBCodeLexer

A lexer that highlights BBCode(-like) syntax.

##### MoinWikiLexer

For MoinMoin (and Trac) Wiki markup.

##### RstLexer

For reStructuredText markup.

Additional options accepted:

`handlecodeblocks`
    Highlight the contents of ``.. sourcecode:: language``,
    ``.. code:: language`` and ``.. code-block:: language``
    directives with a lexer for the given language (default:
    ``True``).

    .. versionadded:: 0.8

**M√©thodes :**

- `_handle_sourcecode()`
- `__init__()`
- `analyse_text()`

##### TexLexer

Lexer for the TeX and LaTeX typesetting languages.

**M√©thodes :**

- `analyse_text()`

##### GroffLexer

Lexer for the (g)roff typesetting language, supporting groff
extensions. Mainly useful for highlighting manpage sources.

**M√©thodes :**

- `analyse_text()`

##### MozPreprocHashLexer

Lexer for Mozilla Preprocessor files (with '#' as the marker).

Other data is left untouched.

##### MozPreprocPercentLexer

Lexer for Mozilla Preprocessor files (with '%' as the marker).

Other data is left untouched.

##### MozPreprocXulLexer

Subclass of the `MozPreprocHashLexer` that highlights unlexed data with the
`XmlLexer`.

**M√©thodes :**

- `__init__()`

##### MozPreprocJavascriptLexer

Subclass of the `MozPreprocHashLexer` that highlights unlexed data with the
`JavascriptLexer`.

**M√©thodes :**

- `__init__()`

##### MozPreprocCssLexer

Subclass of the `MozPreprocHashLexer` that highlights unlexed data with the
`CssLexer`.

**M√©thodes :**

- `__init__()`

##### MarkdownLexer

For Markdown markup.

**M√©thodes :**

- `_handle_codeblock()`
- `__init__()`

##### OrgLexer

For Org Mode markup.

**M√©thodes :**

- `_inline()`

##### TiddlyWiki5Lexer

For TiddlyWiki5 markup.

**M√©thodes :**

- `_handle_codeblock()`
- `_handle_cssblock()`
- `__init__()`

##### WikitextLexer

For MediaWiki Wikitext.

Parsing Wikitext is tricky, and results vary between different MediaWiki
installations, so we only highlight common syntaxes (built-in or from
popular extensions), and also assume templates produce no unbalanced
syntaxes.

**M√©thodes :**

- `nowiki_tag_rules()`
- `plaintext_tag_rules()`
- `delegate_tag_rules()`
- `text_rules()`
- `handle_syntaxhighlight()`
- `handle_score()`

#### Fonctions

##### _handle_sourcecode

**Param√®tres :**

- `match`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### _handle_codeblock

**Param√®tres :**

- `match`

##### __init__

##### _inline

**Param√®tres :**

- `start`
- `end`

##### _handle_codeblock

match args: 1:backticks, 2:lang_name, 3:newline, 4:code, 5:backticks

**Param√®tres :**

- `match`

##### _handle_cssblock

match args: 1:style tag 2:newline, 3:code, 4:closing style tag

**Param√®tres :**

- `match`

##### __init__

##### nowiki_tag_rules

**Param√®tres :**

- `tag_name`

##### plaintext_tag_rules

**Param√®tres :**

- `tag_name`

##### delegate_tag_rules

**Param√®tres :**

- `tag_name`
- `lexer`

##### text_rules

**Param√®tres :**

- `token`

##### handle_syntaxhighlight

**Param√®tres :**

- `match`
- `ctx`

##### handle_score

**Param√®tres :**

- `match`
- `ctx`

---

### math

pygments.lexers.math
~~~~~~~~~~~~~~~~~~~~

Just export lexers that were contained in this module.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### matlab

pygments.lexers.matlab
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Matlab and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MatlabLexer

For Matlab source code.

**M√©thodes :**

- `analyse_text()`

##### MatlabSessionLexer

For Matlab sessions.  Modeled after PythonConsoleLexer.
Contributed by Ken Schutte <kschutte@csail.mit.edu>.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### OctaveLexer

For GNU Octave source code.

**M√©thodes :**

- `analyse_text()`

##### ScilabLexer

For Scilab source code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

Octave is quite hard to spot, and it looks like Matlab as well.

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### maxima

pygments.lexers.maxima
~~~~~~~~~~~~~~~~~~~~~~

Lexer for the computer algebra system Maxima.

Derived from pygments/lexers/algebra.py.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MaximaLexer

A Maxima lexer.
Derived from pygments.lexers.MuPADLexer.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### meson

pygments.lexers.meson
~~~~~~~~~~~~~~~~~~~~~

Pygments lexer for the Meson build system

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MesonLexer

Meson language lexer.

The grammar definition use to transcribe the syntax was retrieved from
https://mesonbuild.com/Syntax.html#grammar for version 0.58.
Some of those definitions are improperly transcribed, so the Meson++
implementation was also checked: https://github.com/dcbaker/meson-plus-plus.

---

### mime

pygments.lexers.mime
~~~~~~~~~~~~~~~~~~~~

Lexer for Multipurpose Internet Mail Extensions (MIME) data.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MIMELexer

Lexer for Multipurpose Internet Mail Extensions (MIME) data. This lexer is
designed to process nested multipart data.

It assumes that the given data contains both header and body (and is
split at an empty line). If no valid header is found, then the entire data
will be treated as body.

Additional options accepted:

`MIME-max-level`
    Max recursion level for nested MIME structure. Any negative number
    would treated as unlimited. (default: -1)

`Content-Type`
    Treat the data as a specific content type. Useful when header is
    missing, or this lexer would try to parse from header. (default:
    `text/plain`)

`Multipart-Boundary`
    Set the default multipart boundary delimiter. This option is only used
    when `Content-Type` is `multipart` and header is missing. This lexer
    would try to parse from header by default. (default: None)

`Content-Transfer-Encoding`
    Treat the data as a specific encoding. Or this lexer would try to parse
    from header by default. (default: None)

**M√©thodes :**

- `__init__()`
- `get_header_tokens()`
- `get_body_tokens()`
- `get_bodypart_tokens()`
- `store_content_type()`
- `get_content_type_subtokens()`
- `store_content_transfer_encoding()`

#### Fonctions

##### __init__

##### get_header_tokens

**Param√®tres :**

- `match`

##### get_body_tokens

**Param√®tres :**

- `match`

##### get_bodypart_tokens

**Param√®tres :**

- `text`

##### store_content_type

**Param√®tres :**

- `match`

##### get_content_type_subtokens

**Param√®tres :**

- `match`

##### store_content_transfer_encoding

**Param√®tres :**

- `match`

---

### minecraft

pygments.lexers.minecraft
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Minecraft related languages.

SNBT. A data communication format used in Minecraft.
wiki: https://minecraft.wiki/w/NBT_format

MCFunction. The Function file for Minecraft Data packs and Add-ons.
official: https://learn.microsoft.com/en-us/minecraft/creator/documents/functionsintroduction
wiki: https://minecraft.wiki/w/Function

MCSchema. A kind of data Schema for Minecraft Add-on Development.
official: https://learn.microsoft.com/en-us/minecraft/creator/reference/content/schemasreference/
community example: https://www.mcbe-dev.net/addons/data-driven/manifest.html

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SNBTLexer

Lexer for stringified NBT, a data format used in Minecraft
    

##### MCFunctionLexer

Lexer for the mcfunction scripting language used in Minecraft
Modelled somewhat after the `GitHub mcfunction grammar <https://github.com/Arcensoth/language-mcfunction>`_.

##### MCSchemaLexer

Lexer for Minecraft Add-ons data Schemas, an interface structure standard used in Minecraft
    

---

### mips

pygments.lexers.mips
~~~~~~~~~~~~~~~~~~~~

Lexers for MIPS assembly.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MIPSLexer

A MIPS Assembly Lexer.

Based on the Emacs major mode by hlissner:
https://github.com/hlissner/emacs-mips-mode

---

### ml

pygments.lexers.ml
~~~~~~~~~~~~~~~~~~

Lexers for ML family languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SMLLexer

For the Standard ML language.

**M√©thodes :**

- `stringy()`
- `long_id_callback()`
- `end_id_callback()`
- `id_callback()`

##### OcamlLexer

For the OCaml language.

##### OpaLexer

Lexer for the Opa language.

##### ReasonLexer

For the ReasonML language.

##### FStarLexer

For the F* language.

#### Fonctions

##### stringy

**Param√®tres :**

- `whatkind`

##### long_id_callback

**Param√®tres :**

- `match`

##### end_id_callback

**Param√®tres :**

- `match`

##### id_callback

**Param√®tres :**

- `match`

---

### .!27290!ada

---

### .!27315!ampl

---

### modeling

pygments.lexers.modeling
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for modeling languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ModelicaLexer

For Modelica source code.

##### BugsLexer

Pygments Lexer for OpenBugs and WinBugs
models.

**M√©thodes :**

- `analyse_text()`

##### JagsLexer

Pygments Lexer for JAGS.

**M√©thodes :**

- `analyse_text()`

##### StanLexer

Pygments Lexer for Stan models.

The Stan modeling language is specified in the *Stan Modeling Language
User's Guide and Reference Manual, v2.17.0*,
`pdf <https://github.com/stan-dev/stan/releases/download/v2.17.0/stan-reference-2.17.0.pdf>`__.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### .!27324!apl

---

### .!27343!asc

---

### modula2

pygments.lexers.modula2
~~~~~~~~~~~~~~~~~~~~~~~

Multi-Dialect Lexer for Modula-2.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Modula2Lexer

For Modula-2 source code.

The Modula-2 lexer supports several dialects.  By default, it operates in
fallback mode, recognising the *combined* literals, punctuation symbols
and operators of all supported dialects, and the *combined* reserved words
and builtins of PIM Modula-2, ISO Modula-2 and Modula-2 R10, while not
differentiating between library defined identifiers.

To select a specific dialect, a dialect option may be passed
or a dialect tag may be embedded into a source file.

Dialect Options:

`m2pim`
    Select PIM Modula-2 dialect.
`m2iso`
    Select ISO Modula-2 dialect.
`m2r10`
    Select Modula-2 R10 dialect.
`objm2`
    Select Objective Modula-2 dialect.

The PIM and ISO dialect options may be qualified with a language extension.

Language Extensions:

`+aglet`
    Select Aglet Modula-2 extensions, available with m2iso.
`+gm2`
    Select GNU Modula-2 extensions, available with m2pim.
`+p1`
    Select p1 Modula-2 extensions, available with m2iso.
`+xds`
    Select XDS Modula-2 extensions, available with m2iso.


Passing a Dialect Option via Unix Commandline Interface

Dialect options may be passed to the lexer using the `dialect` key.
Only one such option should be passed. If multiple dialect options are
passed, the first valid option is used, any subsequent options are ignored.

Examples:

`$ pygmentize -O full,dialect=m2iso -f html -o /path/to/output /path/to/input`
    Use ISO dialect to render input to HTML output
`$ pygmentize -O full,dialect=m2iso+p1 -f rtf -o /path/to/output /path/to/input`
    Use ISO dialect with p1 extensions to render input to RTF output


Embedding a Dialect Option within a source file

A dialect option may be embedded in a source file in form of a dialect
tag, a specially formatted comment that specifies a dialect option.

Dialect Tag EBNF::

   dialectTag :
       OpeningCommentDelim Prefix dialectOption ClosingCommentDelim ;

   dialectOption :
       'm2pim' | 'm2iso' | 'm2r10' | 'objm2' |
       'm2iso+aglet' | 'm2pim+gm2' | 'm2iso+p1' | 'm2iso+xds' ;

   Prefix : '!' ;

   OpeningCommentDelim : '(*' ;

   ClosingCommentDelim : '*)' ;

No whitespace is permitted between the tokens of a dialect tag.

In the event that a source file contains multiple dialect tags, the first
tag that contains a valid dialect option will be used and any subsequent
dialect tags will be ignored.  Ideally, a dialect tag should be placed
at the beginning of a source file.

An embedded dialect tag overrides a dialect option set via command line.

Examples:

``(*!m2r10*) DEFINITION MODULE Foobar; ...``
    Use Modula2 R10 dialect to render this source file.
``(*!m2pim+gm2*) DEFINITION MODULE Bazbam; ...``
    Use PIM dialect with GNU extensions to render this source file.


Algol Publication Mode:

In Algol publication mode, source text is rendered for publication of
algorithms in scientific papers and academic texts, following the format
of the Revised Algol-60 Language Report.  It is activated by passing
one of two corresponding styles as an option:

`algol`
    render reserved words lowercase underline boldface
    and builtins lowercase boldface italic
`algol_nu`
    render reserved words lowercase boldface (no underlining)
    and builtins lowercase boldface italic

The lexer automatically performs the required lowercase conversion when
this mode is activated.

Example:

``$ pygmentize -O full,style=algol -f latex -o /path/to/output /path/to/input``
    Render input file in Algol publication mode to LaTeX output.


Rendering Mode of First Class ADT Identifiers:

The rendering of standard library first class ADT identifiers is controlled
by option flag "treat_stdlib_adts_as_builtins".

When this option is turned on, standard library ADT identifiers are rendered
as builtins.  When it is turned off, they are rendered as ordinary library
identifiers.

`treat_stdlib_adts_as_builtins` (default: On)

The option is useful for dialects that support ADTs as first class objects
and provide ADTs in the standard library that would otherwise be built-in.

At present, only Modula-2 R10 supports library ADTs as first class objects
and therefore, no ADT identifiers are defined for any other dialects.

Example:

``$ pygmentize -O full,dialect=m2r10,treat_stdlib_adts_as_builtins=Off ...``
    Render standard library ADTs as ordinary library types.

.. versionchanged:: 2.1
   Added multi-dialect support.

**M√©thodes :**

- `__init__()`
- `set_dialect()`
- `get_dialect_from_dialect_tag()`
- `get_tokens_unprocessed()`
- `analyse_text()`

#### Fonctions

##### __init__

##### set_dialect

**Param√®tres :**

- `dialect_id`

##### get_dialect_from_dialect_tag

**Param√®tres :**

- `dialect_tag`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

It's Pascal-like, but does not use FUNCTION -- uses PROCEDURE
instead.

**Param√®tres :**

- `text`

---

### .!27348!asm

---

### .!27353!asn1

---

### mojo

pygments.lexers.mojo
~~~~~~~~~~~~~~~~~~~~

Lexers for Mojo and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MojoLexer

For Mojo source code (version 24.2.1).

**M√©thodes :**

- `innerstring_rules()`
- `fstring_rules()`
- `analyse_text()`

#### Fonctions

##### innerstring_rules

**Param√®tres :**

- `ttype`

##### fstring_rules

**Param√®tres :**

- `ttype`

##### analyse_text

**Param√®tres :**

- `text`

---

### .!27362!bare

---

### .!27374!bdd

---

### monte

pygments.lexers.monte
~~~~~~~~~~~~~~~~~~~~~

Lexer for the Monte programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MonteLexer

Lexer for the Monte programming language.

---

### .!27391!boa

---

### .!27397!bqn

---

### mosel

pygments.lexers.mosel
~~~~~~~~~~~~~~~~~~~~~

Lexers for the mosel language.
http://www.fico.com/en/products/fico-xpress-optimization

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MoselLexer

For the Mosel optimization language.

---

### .!27424!cddl

---

### .!27474!css

---

### ncl

pygments.lexers.ncl
~~~~~~~~~~~~~~~~~~~

Lexers for NCAR Command Language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NCLLexer

Lexer for NCL code.

---

### .!27479!d

---

### nimrod

pygments.lexers.nimrod
~~~~~~~~~~~~~~~~~~~~~~

Lexer for the Nim language (formerly known as Nimrod).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NimrodLexer

For Nim source code.

**M√©thodes :**

- `underscorize()`

#### Fonctions

##### underscorize

**Param√®tres :**

- `words`

---

### .!27487!data

---

### nit

pygments.lexers.nit
~~~~~~~~~~~~~~~~~~~

Lexer for the Nit language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NitLexer

For nit source.

---

### .!27492!dax

---

### .!27502!diff

---

### nix

pygments.lexers.nix
~~~~~~~~~~~~~~~~~~~

Lexers for the NixOS Nix language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NixLexer

For the Nix language.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### .!27507!dns

---

### .!27515!dsls

---

### numbair

pygments.lexers.numbair
~~~~~~~~~~~~~~~~~~~~~~~

Lexer for other Numba Intermediate Representation.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NumbaIRLexer

Lexer for Numba IR

---

### .!27526!ecl

---

### .!27533!elm

---

### oberon

pygments.lexers.oberon
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Oberon family languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ComponentPascalLexer

For Component Pascal source code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

The only other lexer using .cp is the C++ one, so we check if for
a few common Pascal keywords here. Those are unfortunately quite
common across various business languages as well.

**Param√®tres :**

- `text`

---

### .!27538!elpi

---

### .!27575!fift

---

### objective

pygments.lexers.objective
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Objective-C family languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ObjectiveCLexer

For Objective-C source code with preprocessor directives.

##### ObjectiveCppLexer

For Objective-C++ source code with preprocessor directives.

##### LogosLexer

For Logos + Objective-C source code with preprocessor directives.

**M√©thodes :**

- `analyse_text()`

##### SwiftLexer

For Swift source.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### GeneratedObjectiveCVariant

Implements Objective-C syntax on top of an existing C family lexer.

**M√©thodes :**

- `analyse_text()`
- `get_tokens_unprocessed()`

#### Fonctions

##### objective

Generate a subclass of baselexer that accepts the Objective-C syntax
extensions.

**Param√®tres :**

- `baselexer`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`
- `stack`

---

### .!27603!func

---

### .!27634!go

---

### ooc

pygments.lexers.ooc
~~~~~~~~~~~~~~~~~~~

Lexers for the Ooc language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### OocLexer

For Ooc source code

---

### openscad

pygments.lexers.openscad
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for the OpenSCAD languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### OpenScadLexer

For openSCAD code.
    

---

### .!27660!gsql

---

### .!27664!hare

---

### other

pygments.lexers.other
~~~~~~~~~~~~~~~~~~~~~

Just export lexer classes previously contained in this module.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### .!27676!haxe

---

### .!27678!hdl

---

### parasail

pygments.lexers.parasail
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for ParaSail.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ParaSailLexer

For ParaSail source code.

---

### .!27689!html

---

### .!27694!idl

---

### parsers

pygments.lexers.parsers
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for parser generators.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RagelLexer

A pure `Ragel <www.colm.net/open-source/ragel>`_ lexer.  Use this
for fragments of Ragel.  For ``.rl`` files, use
:class:`RagelEmbeddedLexer` instead (or one of the
language-specific subclasses).

##### RagelEmbeddedLexer

A lexer for Ragel embedded in a host language file.

This will only highlight Ragel statements. If you want host language
highlighting then call the language-specific Ragel lexer.

**M√©thodes :**

- `analyse_text()`

##### RagelRubyLexer

A lexer for Ragel in a Ruby host file.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### RagelCLexer

A lexer for Ragel in a C host file.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### RagelDLexer

A lexer for Ragel in a D host file.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### RagelCppLexer

A lexer for Ragel in a C++ host file.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### RagelObjectiveCLexer

A lexer for Ragel in an Objective C host file.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### RagelJavaLexer

A lexer for Ragel in a Java host file.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrLexer

Generic ANTLR Lexer.
Should not be called directly, instead
use DelegatingLexer for your target language.

**M√©thodes :**

- `analyse_text()`

##### AntlrCppLexer

ANTLR with C++ Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrObjectiveCLexer

ANTLR with Objective-C Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrCSharpLexer

ANTLR with C# Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrPythonLexer

ANTLR with Python Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrJavaLexer

ANTLR with Java Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrRubyLexer

ANTLR with Ruby Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrPerlLexer

ANTLR with Perl Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### AntlrActionScriptLexer

ANTLR with ActionScript Target

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### TreetopBaseLexer

A base lexer for `Treetop <http://treetop.rubyforge.org/>`_ grammars.
Not for direct use; use :class:`TreetopLexer` instead.

.. versionadded:: 1.6

##### TreetopLexer

A lexer for Treetop grammars.

**M√©thodes :**

- `__init__()`

##### EbnfLexer

Lexer for `ISO/IEC 14977 EBNF
<https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form>`_
grammars.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

---

### .!27699!igor

---

### .!27724!j

---

### pascal

pygments.lexers.pascal
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Pascal family languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PortugolLexer

For Portugol, a Pascal dialect with keywords in Portuguese.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### DelphiLexer

For Delphi (Borland Object Pascal),
Turbo Pascal and Free Pascal source code.

Additional options accepted:

`turbopascal`
    Highlight Turbo Pascal specific keywords (default: ``True``).
`delphi`
    Highlight Borland Delphi specific keywords (default: ``True``).
`freepascal`
    Highlight Free Pascal specific keywords (default: ``True``).
`units`
    A list of units that should be considered builtin, supported are
    ``System``, ``SysUtils``, ``Classes`` and ``Math``.
    Default is to consider all of them builtin.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

#### Fonctions

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### pawn

pygments.lexers.pawn
~~~~~~~~~~~~~~~~~~~~

Lexers for the Pawn languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SourcePawnLexer

For SourcePawn source code with preprocessor directives.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### PawnLexer

For Pawn source code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

This is basically C. There is a keyword which doesn't exist in C
though and is nearly unique to this language.

**Param√®tres :**

- `text`

---

### .!27739!jslt

---

### .!27754!jsx

---

### pddl

pygments.lexers.pddl
~~~~~~~~~~~~~~~~~~~~

Lexer for the Planning Domain Definition Language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PddlLexer

A PDDL lexer.

It should support up to PDDL 3.1.

---

### .!27762!jvm

---

### .!27768!kuin

---

### perl

pygments.lexers.perl
~~~~~~~~~~~~~~~~~~~~

Lexers for Perl, Raku and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PerlLexer

For Perl source code.

**M√©thodes :**

- `analyse_text()`

##### Perl6Lexer

For Raku (a.k.a. Perl 6) source code.

**M√©thodes :**

- `_build_word_match()`
- `brackets_callback()`
- `opening_brace_callback()`
- `closing_brace_callback()`
- `embedded_perl6_callback()`
- `analyse_text()`
- `__init__()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### _build_word_match

**Param√®tres :**

- `words`
- `boundary_regex_fragment`
- `prefix`
- `suffix`

##### brackets_callback

**Param√®tres :**

- `token_class`

##### opening_brace_callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### closing_brace_callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### embedded_perl6_callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### callback

**Param√®tres :**

- `lexer`
- `match`
- `context`

##### strip_pod

**Param√®tres :**

- `lines`

---

### .!27777!ldap

---

### .!27781!lean

---

### phix

pygments.lexers.phix
~~~~~~~~~~~~~~~~~~~~

Lexers for Phix.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PhixLexer

Pygments Lexer for Phix files (.exw).
See http://phix.x10.mx

---

### .!27790!lisp

---

### .!27800!make

---

### php

pygments.lexers.php
~~~~~~~~~~~~~~~~~~~

Lexers for PHP and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ZephirLexer

For Zephir language source code.

Zephir is a compiled high level language aimed
to the creation of C-extensions for PHP.

##### PsyshConsoleLexer

For PsySH console output, such as:

.. sourcecode:: psysh

    >>> $greeting = function($name): string {
    ...     return "Hello, {$name}";
    ... };
    => Closure($name): string {#2371 ‚Ä¶3}
    >>> $greeting('World')
    => "Hello, World"

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### PhpLexer

For PHP source code.
For PHP embedded in HTML, use the `HtmlPhpLexer`.

Additional options accepted:

`startinline`
    If given and ``True`` the lexer starts highlighting with
    php code (i.e.: no starting ``<?php`` required).  The default
    is ``False``.
`funcnamehighlighting`
    If given and ``True``, highlight builtin function names
    (default: ``True``).
`disabledmodules`
    If given, must be a list of module names whose function names
    should not be highlighted. By default all modules are highlighted
    except the special ``'unknown'`` module that includes functions
    that are known to php but are undocumented.

    To get a list of allowed modules have a look into the
    `_php_builtins` module:

    .. sourcecode:: pycon

        >>> from pygments.lexers._php_builtins import MODULES
        >>> MODULES.keys()
        ['PHP Options/Info', 'Zip', 'dba', ...]

    In fact the names of those modules match the module names from
    the php documentation.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`
- `analyse_text()`

#### Fonctions

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### .!27812!math

---

### .!27831!mime

---

### pointless

pygments.lexers.pointless
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Pointless.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PointlessLexer

For Pointless source code.

---

### pony

pygments.lexers.pony
~~~~~~~~~~~~~~~~~~~~

Lexers for Pony and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PonyLexer

For Pony source code.

---

### .!27840!mips

---

### .!27846!ml

---

### praat

pygments.lexers.praat
~~~~~~~~~~~~~~~~~~~~~

Lexer for Praat

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PraatLexer

For Praat scripts.

---

### procfile

pygments.lexers.procfile
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Procfile file format.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ProcfileLexer

Lexer for Procfile file format.

The format is used to run processes on Heroku or is used by Foreman or
Honcho tools.

---

### .!27859!mojo

---

### .!27872!ncl

---

### prolog

pygments.lexers.prolog
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Prolog and Prolog-like languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PrologLexer

Lexer for Prolog files.

**M√©thodes :**

- `analyse_text()`

##### LogtalkLexer

For Logtalk source code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

Competes with IDL and Visual Prolog on *.pro

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### .!27881!nit

---

### .!27887!nix

---

### promql

pygments.lexers.promql
~~~~~~~~~~~~~~~~~~~~~~

Lexer for Prometheus Query Language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PromQLLexer

For PromQL queries.

For details about the grammar see:
https://github.com/prometheus/prometheus/tree/master/promql/parser

.. versionadded: 2.7

---

### .!27911!ooc

---

### .!27944!pawn

---

### prql

pygments.lexers.prql
~~~~~~~~~~~~~~~~~~~~

Lexer for the PRQL query language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PrqlLexer

For PRQL source code.

grammar: https://github.com/PRQL/prql/tree/main/grammars

**M√©thodes :**

- `innerstring_rules()`
- `fstring_rules()`

#### Fonctions

##### innerstring_rules

**Param√®tres :**

- `ttype`

##### fstring_rules

**Param√®tres :**

- `ttype`

---

### .!27949!pddl

---

### .!27953!perl

---

### ptx

pygments.lexers.ptx
~~~~~~~~~~~~~~~~~~~

Lexer for other PTX language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PtxLexer

For NVIDIA `PTX <https://docs.nvidia.com/cuda/parallel-thread-execution/>`_
source.

---

### .!27957!phix

---

### .!27961!php

---

### python

pygments.lexers.python
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Python and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PythonLexer

For Python source code (version 3.x).

.. versionchanged:: 2.5
   This is now the default ``PythonLexer``.  It is still available as the
   alias ``Python3Lexer``.

**M√©thodes :**

- `innerstring_rules()`
- `fstring_rules()`
- `analyse_text()`

##### Python2Lexer

For Python 2.x source code.

.. versionchanged:: 2.5
   This class has been renamed from ``PythonLexer``.  ``PythonLexer`` now
   refers to the Python 3 variant.  File name patterns like ``*.py`` have
   been moved to Python 3 as well.

**M√©thodes :**

- `innerstring_rules()`
- `analyse_text()`

##### _PythonConsoleLexerBase

##### PythonConsoleLexer

For Python console output or doctests, such as:

.. sourcecode:: pycon

    >>> a = 'foo'
    >>> print(a)
    foo
    >>> 1 / 0
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ZeroDivisionError: integer division or modulo by zero

Additional options:

`python3`
    Use Python 3 lexer for code.  Default is ``True``.

    .. versionadded:: 1.0
    .. versionchanged:: 2.5
       Now defaults to ``True``.

**M√©thodes :**

- `__init__()`

##### PythonTracebackLexer

For Python 3.x tracebacks, with support for chained exceptions.

.. versionchanged:: 2.5
   This is now the default ``PythonTracebackLexer``.  It is still available
   as the alias ``Python3TracebackLexer``.

##### Python2TracebackLexer

For Python tracebacks.

.. versionchanged:: 2.5
   This class has been renamed from ``PythonTracebackLexer``.
   ``PythonTracebackLexer`` now refers to the Python 3 variant.

##### CythonLexer

For Pyrex and Cython source code.

##### DgLexer

Lexer for dg,
a functional and object-oriented programming language
running on the CPython 3 VM.

##### NumPyLexer

A Python lexer recognizing Numerical Python builtins.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `analyse_text()`

##### _ReplaceInnerCode

**M√©thodes :**

- `__init__()`

#### Fonctions

##### innerstring_rules

**Param√®tres :**

- `ttype`

##### fstring_rules

**Param√®tres :**

- `ttype`

##### analyse_text

**Param√®tres :**

- `text`

##### innerstring_rules

**Param√®tres :**

- `ttype`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

---

### .!27971!pony

---

### .!27993!prql

---

### q

pygments.lexers.q
~~~~~~~~~~~~~~~~~

Lexer for the Q programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### KLexer

For K source code.

##### QLexer

For `Q <https://code.kx.com/>`_ source code.

---

### .!28001!ptx

---

### .!28010!q

---

### qlik

pygments.lexers.qlik
~~~~~~~~~~~~~~~~~~~~

Lexer for the qlik scripting language

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### QlikLexer

Lexer for qlik code, including .qvs files

---

### qvt

pygments.lexers.qvt
~~~~~~~~~~~~~~~~~~~

Lexer for QVT Operational language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### QVToLexer

For the QVT Operational Mapping language.

Reference for implementing this: ¬´Meta Object Facility (MOF) 2.0
Query/View/Transformation Specification¬ª, Version 1.1 - January 2011
(https://www.omg.org/spec/QVT/1.1/), see ¬ß8.4, ¬´Concrete Syntax¬ª in
particular.

Notable tokens assignments:

- Name.Class is assigned to the identifier following any of the following
  keywords: metamodel, class, exception, primitive, enum, transformation
  or library

- Name.Function is assigned to the names of mappings and queries

- Name.Builtin.Pseudo is assigned to the pre-defined variables 'this',
  'self' and 'result'.

---

### .!28015!qlik

---

### .!28021!qvt

---

### r

pygments.lexers.r
~~~~~~~~~~~~~~~~~

Lexers for the R/S languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RConsoleLexer

For R console transcripts or R CMD BATCH output files.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### SLexer

For S, S-plus, and R source code.

**M√©thodes :**

- `analyse_text()`

##### RdLexer

Pygments Lexer for R documentation (Rd) files

This is a very minimal implementation, highlighting little more
than the macros. A description of Rd syntax is found in `Writing R
Extensions <http://cran.r-project.org/doc/manuals/R-exts.html>`_
and `Parsing Rd files <http://developer.r-project.org/parseRd.pdf>`_.

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### .!28024!r

---

### rdf

pygments.lexers.rdf
~~~~~~~~~~~~~~~~~~~

Lexers for semantic web and RDF query languages and markup.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SparqlLexer

Lexer for SPARQL query language.

##### TurtleLexer

Lexer for Turtle data language.

**M√©thodes :**

- `analyse_text()`

##### ShExCLexer

Lexer for ShExC shape expressions language syntax.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### rebol

pygments.lexers.rebol
~~~~~~~~~~~~~~~~~~~~~

Lexers for the REBOL and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RebolLexer

A REBOL lexer.

**M√©thodes :**

- `word_callback()`
- `analyse_text()`

##### RedLexer

A Red-language lexer.

**M√©thodes :**

- `word_callback()`

#### Fonctions

##### word_callback

**Param√®tres :**

- `lexer`
- `match`

##### analyse_text

Check if code contains REBOL header and so it probably not R code

**Param√®tres :**

- `text`

##### word_callback

**Param√®tres :**

- `lexer`
- `match`

---

### .!28029!rdf

---

### rego

pygments.lexers.rego
~~~~~~~~~~~~~~~~~~~~

Lexers for the Rego policy languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RegoLexer

For Rego source.

---

### .!28038!rego

---

### .!28047!ride

---

### resource

pygments.lexers.resource
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for resource definition files.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ResourceLexer

Lexer for ICU Resource bundles.
    

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### .!28052!rita

---

### .!28057!rnc

---

### ride

pygments.lexers.ride
~~~~~~~~~~~~~~~~~~~~

Lexer for the Ride programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RideLexer

For Ride source code.

---

### .!28072!ruby

---

### .!28077!rust

---

### rita

pygments.lexers.rita
~~~~~~~~~~~~~~~~~~~~

Lexers for RITA language

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RitaLexer

Lexer for RITA.

---

### .!28082!sas

---

### .!28086!savi

---

### rnc

pygments.lexers.rnc
~~~~~~~~~~~~~~~~~~~

Lexer for Relax-NG Compact syntax

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RNCCompactLexer

For RelaxNG-compact syntax.

---

### .!28101!sgf

---

### .!28130!smv

---

### roboconf

pygments.lexers.roboconf
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Roboconf DSL.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RoboconfGraphLexer

Lexer for Roboconf graph files.

##### RoboconfInstancesLexer

Lexer for Roboconf instances files.

---

### .!28162!sql

---

### .!28186!tact

---

### ruby

pygments.lexers.ruby
~~~~~~~~~~~~~~~~~~~~

Lexers for Ruby and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RubyLexer

For Ruby source code.

**M√©thodes :**

- `heredoc_callback()`
- `gen_rubystrings_rules()`
- `analyse_text()`

##### RubyConsoleLexer

For Ruby interactive console (**irb**) output.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### FancyLexer

Pygments Lexer For Fancy.

Fancy is a self-hosted, pure object-oriented, dynamic,
class-based, concurrent general-purpose programming language
running on Rubinius, the Ruby VM.

#### Fonctions

##### heredoc_callback

**Param√®tres :**

- `match`
- `ctx`

##### gen_rubystrings_rules

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### intp_regex_callback

**Param√®tres :**

- `match`
- `ctx`

##### intp_string_callback

**Param√®tres :**

- `match`
- `ctx`

---

### .!28194!tal

---

### .!28198!tcl

---

### rust

pygments.lexers.rust
~~~~~~~~~~~~~~~~~~~~

Lexers for the Rust language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RustLexer

Lexer for the Rust programming language (version 1.47).

---

### .!28205!teal

---

### robotframework

pygments.lexers.robotframework
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Robot Framework.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RobotFrameworkLexer

For Robot Framework test data.

Supports both space and pipe separated plain text formats.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### VariableTokenizer

**M√©thodes :**

- `tokenize()`
- `_tokenize()`

##### RowTokenizer

**M√©thodes :**

- `__init__()`
- `tokenize()`
- `_start_table()`
- `_tokenize()`

##### RowSplitter

**M√©thodes :**

- `split()`
- `_split_from_spaces()`
- `_split_from_pipes()`

##### Tokenizer

**M√©thodes :**

- `__init__()`
- `tokenize()`
- `_tokenize()`
- `_is_assign()`

##### Comment

##### Setting

**M√©thodes :**

- `__init__()`
- `_tokenize()`

##### ImportSetting

##### TestCaseSetting

**M√©thodes :**

- `_tokenize()`

##### KeywordSetting

##### Variable

**M√©thodes :**

- `_tokenize()`

##### KeywordCall

**M√©thodes :**

- `__init__()`
- `_tokenize()`

##### GherkinTokenizer

**M√©thodes :**

- `tokenize()`

##### TemplatedKeywordCall

##### ForLoop

**M√©thodes :**

- `__init__()`
- `_tokenize()`

##### _Table

**M√©thodes :**

- `__init__()`
- `tokenize()`
- `_continues()`
- `_is_empty()`
- `_tokenize()`
- `end_row()`

##### UnknownTable

**M√©thodes :**

- `_continues()`

##### VariableTable

##### SettingTable

**M√©thodes :**

- `__init__()`
- `_tokenize()`
- `end_row()`

##### TestCaseTable

**M√©thodes :**

- `_tokenizer_class()`
- `_continues()`
- `_tokenize()`
- `_is_setting()`
- `_is_template()`
- `_is_for_loop()`
- `set_test_template()`
- `set_default_template()`
- `_is_template_set()`

##### KeywordTable

**M√©thodes :**

- `_is_template()`

##### VariableSplitter

**M√©thodes :**

- `__init__()`
- `get_replaced_base()`
- `_finalize()`
- `_has_list_or_dict_variable_index()`
- `_split()`
- `_scanning_list_variable_index()`
- `_find_variable()`
- `_find_start_index()`
- `_start_index_is_ok()`
- `_is_escaped()`
- `_variable_state()`
- `_is_list_or_dict_variable()`
- `_internal_variable_start_state()`
- `_waiting_list_variable_index_state()`
- `_list_variable_index_state()`

#### Fonctions

##### normalize

**Param√®tres :**

- `string`
- `remove`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### tokenize

**Param√®tres :**

- `string`
- `token`

##### _tokenize

**Param√®tres :**

- `var`
- `string`
- `orig_token`

##### __init__

##### tokenize

**Param√®tres :**

- `row`

##### _start_table

**Param√®tres :**

- `header`

##### _tokenize

**Param√®tres :**

- `value`
- `index`
- `commented`
- `separator`
- `heading`

##### split

**Param√®tres :**

- `row`

##### _split_from_spaces

**Param√®tres :**

- `row`

##### _split_from_pipes

**Param√®tres :**

- `row`

##### __init__

##### tokenize

**Param√®tres :**

- `value`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### _is_assign

**Param√®tres :**

- `value`

##### __init__

**Param√®tres :**

- `template_setter`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### __init__

**Param√®tres :**

- `support_assign`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### tokenize

**Param√®tres :**

- `value`
- `token`

##### __init__

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### __init__

**Param√®tres :**

- `prev_tokenizer`

##### tokenize

**Param√®tres :**

- `value`
- `index`

##### _continues

**Param√®tres :**

- `value`
- `index`

##### _is_empty

**Param√®tres :**

- `value`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### end_row

##### _continues

**Param√®tres :**

- `value`
- `index`

##### __init__

**Param√®tres :**

- `template_setter`
- `prev_tokenizer`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### end_row

##### _tokenizer_class

##### _continues

**Param√®tres :**

- `value`
- `index`

##### _tokenize

**Param√®tres :**

- `value`
- `index`

##### _is_setting

**Param√®tres :**

- `value`

##### _is_template

**Param√®tres :**

- `value`

##### _is_for_loop

**Param√®tres :**

- `value`

##### set_test_template

**Param√®tres :**

- `template`

##### set_default_template

**Param√®tres :**

- `template`

##### _is_template_set

**Param√®tres :**

- `template`

##### _is_template

**Param√®tres :**

- `value`

##### __init__

**Param√®tres :**

- `string`
- `identifiers`

##### get_replaced_base

**Param√®tres :**

- `variables`

##### _finalize

##### _has_list_or_dict_variable_index

##### _split

**Param√®tres :**

- `string`

##### _scanning_list_variable_index

##### _find_variable

**Param√®tres :**

- `string`

##### _find_start_index

**Param√®tres :**

- `string`
- `start`
- `end`

##### _start_index_is_ok

**Param√®tres :**

- `string`
- `index`

##### _is_escaped

**Param√®tres :**

- `string`
- `index`

##### _variable_state

**Param√®tres :**

- `char`
- `index`

##### _is_list_or_dict_variable

##### _internal_variable_start_state

**Param√®tres :**

- `char`
- `index`

##### _waiting_list_variable_index_state

**Param√®tres :**

- `char`
- `index`

##### _list_variable_index_state

**Param√®tres :**

- `char`
- `index`

---

### .!28226!text

---

### sas

pygments.lexers.sas
~~~~~~~~~~~~~~~~~~~

Lexer for SAS.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SASLexer

For SAS files.

---

### .!28251!tlb

---

### .!28254!tls

---

### savi

pygments.lexers.savi
~~~~~~~~~~~~~~~~~~~~

Lexer for Savi.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SaviLexer

For Savi source code.

.. versionadded: 2.10

---

### .!28260!tnt

---

### .!28277!ul4

---

### scdoc

pygments.lexers.scdoc
~~~~~~~~~~~~~~~~~~~~~

Lexer for scdoc, a simple man page generator.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ScdocLexer

`scdoc` is a simple man page generator for POSIX systems written in C99.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

We checks for bold and underline text with * and _. Also
every scdoc file must start with a strictly defined first line.

**Param√®tres :**

- `text`

---

### .!28287!urbi

---

### .!28291!usd

---

### scripting

pygments.lexers.scripting
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for scripting and embedded languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LuaLexer

For Lua source code.

Additional options accepted:

`func_name_highlighting`
    If given and ``True``, highlight builtin function names
    (default: ``True``).
`disabled_modules`
    If given, must be a list of module names whose function names
    should not be highlighted. By default all modules are highlighted.

    To get a list of allowed modules have a look into the
    `_lua_builtins` module:

    .. sourcecode:: pycon

        >>> from pygments.lexers._lua_builtins import MODULES
        >>> MODULES.keys()
        ['string', 'coroutine', 'modules', 'io', 'basic', ...]

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### LuauLexer

For Luau source code.

Additional options accepted:

`include_luau_builtins`
    If given and ``True``, automatically highlight Luau builtins
    (default: ``True``).
`include_roblox_builtins`
    If given and ``True``, automatically highlight Roblox-specific builtins
    (default: ``False``).
`additional_builtins`
    If given, must be a list of additional builtins to highlight.
`disabled_builtins`
    If given, must be a list of builtins that will not be highlighted.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

##### MoonScriptLexer

For MoonScript source code.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### ChaiscriptLexer

For ChaiScript source code.

##### LSLLexer

For Second Life's Linden Scripting Language source code.

##### AppleScriptLexer

For AppleScript source code,
including `AppleScript Studio
<http://developer.apple.com/documentation/AppleScript/
Reference/StudioReference>`_.
Contributed by Andreas Amann <aamann@mac.com>.

##### RexxLexer

Rexx is a scripting language available for
a wide range of different platforms with its roots found on mainframe
systems. It is popular for I/O- and data based tasks and can act as glue
language to bind different applications together.

**M√©thodes :**

- `_c()`
- `analyse_text()`

##### MOOCodeLexer

For MOOCode (the MOO scripting language).

##### HybrisLexer

For Hybris source code.

**M√©thodes :**

- `analyse_text()`

##### EasytrieveLexer

Easytrieve Plus is a programming language for extracting, filtering and
converting sequential data. Furthermore it can layout data for reports.
It is mainly used on mainframe platforms and can access several of the
mainframe's native file formats. It is somewhat comparable to awk.

**M√©thodes :**

- `analyse_text()`

##### JclLexer

Job Control Language (JCL)
is a scripting language used on mainframe platforms to instruct the system
on how to run a batch job or start a subsystem. It is somewhat
comparable to MS DOS batch and Unix shell scripts.

**M√©thodes :**

- `analyse_text()`

##### MiniScriptLexer

For MiniScript source code.

#### Fonctions

##### all_lua_builtins

##### _luau_make_expression

**Param√®tres :**

- `should_pop`
- `_s`

##### _luau_make_expression_special

**Param√®tres :**

- `should_pop`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### _c

**Param√®tres :**

- `s`

##### analyse_text

Check for initial comment and patterns that distinguish Rexx from other
C-like languages.

**Param√®tres :**

- `text`

##### analyse_text

public method and private method don't seem to be quite common
elsewhere.

**Param√®tres :**

- `text`

##### analyse_text

Perform a structural analysis for basic Easytrieve constructs.

**Param√®tres :**

- `text`

##### analyse_text

Recognize JCL job by header.

**Param√®tres :**

- `text`

##### isCommentLine

**Param√®tres :**

- `line`

##### isEmptyLine

**Param√®tres :**

- `line`

---

### sgf

pygments.lexers.sgf
~~~~~~~~~~~~~~~~~~~

Lexer for Smart Game Format (sgf) file format.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SmartGameFormatLexer

Lexer for Smart Game Format (sgf) file format.

The format is used to store game records of board games for two players
(mainly Go game).

---

### .!28310!vip

---

### .!28319!web

---

### shell

pygments.lexers.shell
~~~~~~~~~~~~~~~~~~~~~

Lexers for various shells.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BashLexer

Lexer for (ba|k|z|)sh shell scripts.

**M√©thodes :**

- `analyse_text()`

##### SlurmBashLexer

Lexer for (ba|k|z|)sh Slurm scripts.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### ShellSessionBaseLexer

Base lexer for shell sessions.

.. versionadded:: 2.1

**M√©thodes :**

- `get_tokens_unprocessed()`

##### BashSessionLexer

Lexer for Bash shell sessions, i.e. command lines, including a
prompt, interspersed with output.

##### BatchLexer

Lexer for the DOS/Windows Batch file format.

**M√©thodes :**

- `_make_begin_state()`
- `_make_follow_state()`
- `_make_arithmetic_state()`
- `_make_call_state()`
- `_make_label_state()`
- `_make_redirect_state()`

##### MSDOSSessionLexer

Lexer for MS DOS shell sessions, i.e. command lines, including a
prompt, interspersed with output.

##### TcshLexer

Lexer for tcsh scripts.

##### TcshSessionLexer

Lexer for Tcsh sessions, i.e. command lines, including a
prompt, interspersed with output.

##### PowerShellLexer

For Windows PowerShell code.

##### PowerShellSessionLexer

Lexer for PowerShell sessions, i.e. command lines, including a
prompt, interspersed with output.

##### FishShellLexer

Lexer for Fish shell scripts.

##### ExeclineLexer

Lexer for Laurent Bercot's execline language.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### _make_begin_state

**Param√®tres :**

- `compound`
- `_core_token`
- `_core_token_compound`
- `_keyword_terminator`
- `_nl`
- `_punct`
- `_string`
- `_space`
- `_start_label`
- `_stoken`
- `_token_terminator`
- `_variable`
- `_ws`

##### _make_follow_state

**Param√®tres :**

- `compound`
- `_label`
- `_label_compound`
- `_nl`
- `_space`
- `_start_label`
- `_token`
- `_token_compound`
- `_ws`

##### _make_arithmetic_state

**Param√®tres :**

- `compound`
- `_nl`
- `_punct`
- `_string`
- `_variable`
- `_ws`
- `_nlws`

##### _make_call_state

**Param√®tres :**

- `compound`
- `_label`
- `_label_compound`

##### _make_label_state

**Param√®tres :**

- `compound`
- `_label`
- `_label_compound`
- `_nl`
- `_punct`
- `_string`
- `_variable`

##### _make_redirect_state

**Param√®tres :**

- `compound`
- `_core_token_compound`
- `_nl`
- `_punct`
- `_stoken`
- `_string`
- `_space`
- `_variable`
- `_nlws`

##### analyse_text

**Param√®tres :**

- `text`

---

### .!28340!wgsl

---

### .!28354!wren

---

### sieve

pygments.lexers.sieve
~~~~~~~~~~~~~~~~~~~~~

Lexer for Sieve file format.

https://tools.ietf.org/html/rfc5228
https://tools.ietf.org/html/rfc5173
https://tools.ietf.org/html/rfc5229
https://tools.ietf.org/html/rfc5230
https://tools.ietf.org/html/rfc5232
https://tools.ietf.org/html/rfc5235
https://tools.ietf.org/html/rfc5429
https://tools.ietf.org/html/rfc8580

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SieveLexer

Lexer for sieve format.

---

### slash

pygments.lexers.slash
~~~~~~~~~~~~~~~~~~~~~

Lexer for the Slash programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SlashLanguageLexer

**M√©thodes :**

- `move_state()`
- `right_angle_bracket()`

##### SlashLexer

Lexer for the Slash programming language.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### move_state

**Param√®tres :**

- `new_state`

##### right_angle_bracket

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### __init__

---

### .!28361!x10

---

### .!28364!xorg

---

### smalltalk

pygments.lexers.smalltalk
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Smalltalk and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SmalltalkLexer

For Smalltalk syntax.
Contributed by Stefan Matthias Aust.
Rewritten by Nils Winter.

##### NewspeakLexer

For Newspeak syntax.

---

### .!28367!yang

---

### .!28373!yara

---

### smithy

pygments.lexers.smithy
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the Smithy IDL.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SmithyLexer

For Smithy IDL

---

### .!28380!zig

---

### smv

pygments.lexers.smv
~~~~~~~~~~~~~~~~~~~

Lexers for the SMV languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NuSMVLexer

Lexer for the NuSMV language.

---

### snobol

pygments.lexers.snobol
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the SNOBOL language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SnobolLexer

Lexer for the SNOBOL4 programming language.

Recognizes the common ASCII equivalents of the original SNOBOL4 operators.
Does not require spaces around binary operators.

---

### solidity

pygments.lexers.solidity
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Solidity.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SolidityLexer

For Solidity source code.

---

### soong

pygments.lexers.soong
~~~~~~~~~~~~~~~~~~~~~

Lexers for Soong (Android.bp Blueprint) files.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SoongLexer

---

### sophia

pygments.lexers.sophia
~~~~~~~~~~~~~~~~~~~~~~

Lexer for Sophia.

Derived from pygments/lexers/reason.py.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SophiaLexer

A Sophia lexer.

---

### special

pygments.lexers.special
~~~~~~~~~~~~~~~~~~~~~~~

Special lexers.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TextLexer

"Null" lexer, doesn't highlight anything.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `analyse_text()`

##### OutputLexer

Simple lexer that highlights everything as ``Token.Generic.Output``.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### RawTokenLexer

Recreate a token stream formatted with the `RawTokenFormatter`.

Additional options accepted:

`compress`
    If set to ``"gz"`` or ``"bz2"``, decompress the token stream with
    the given compression algorithm before lexing (default: ``""``).

**M√©thodes :**

- `__init__()`
- `get_tokens()`
- `get_tokens_unprocessed()`

#### Fonctions

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __init__

##### get_tokens

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### spice

pygments.lexers.spice
~~~~~~~~~~~~~~~~~~~~~

Lexers for the Spice programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SpiceLexer

For Spice source.

---

### sql

pygments.lexers.sql
~~~~~~~~~~~~~~~~~~~

Lexers for various SQL dialects and related interactive sessions.

Postgres specific lexers:

`PostgresLexer`
    A SQL lexer for the PostgreSQL dialect. Differences w.r.t. the SQL
    lexer are:

    - keywords and data types list parsed from the PG docs (run the
      `_postgres_builtins` module to update them);
    - Content of $-strings parsed using a specific lexer, e.g. the content
      of a PL/Python function is parsed using the Python lexer;
    - parse PG specific constructs: E-strings, $-strings, U&-strings,
      different operators and punctuation.

`PlPgsqlLexer`
    A lexer for the PL/pgSQL language. Adds a few specific construct on
    top of the PG SQL lexer (such as <<label>>).

`PostgresConsoleLexer`
    A lexer to highlight an interactive psql session:

    - identifies the prompt and does its best to detect the end of command
      in multiline statement where not all the lines are prefixed by a
      prompt, telling them apart from the output;
    - highlights errors in the output and notification levels;
    - handles psql backslash commands.

`PostgresExplainLexer`
    A lexer to highlight Postgres execution plan.

The ``tests/examplefiles`` contains a few test files with data to be
parsed by these lexers.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PostgresBase

Base class for Postgres-related lexers.

This is implemented as a mixin to avoid the Lexer metaclass kicking in.
this way the different lexer don't have a common Lexer ancestor. If they
had, _tokens could be created on this ancestor and not updated for the
other classes, resulting e.g. in PL/pgSQL parsed as SQL. This shortcoming
seem to suggest that regexp lexers are not really subclassable.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `_get_lexer()`

##### PostgresLexer

Lexer for the PostgreSQL dialect of SQL.

##### PlPgsqlLexer

Handle the extra syntax in Pl/pgSQL language.

##### PsqlRegexLexer

Extend the PostgresLexer adding support specific for psql commands.

This is not a complete psql lexer yet as it lacks prompt support
and output rendering.

##### lookahead

Wrap an iterator and allow pushing back an item.

**M√©thodes :**

- `__init__()`
- `__iter__()`
- `send()`
- `__next__()`

##### PostgresConsoleLexer

Lexer for psql sessions.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### PostgresExplainLexer

Handle PostgreSQL EXPLAIN output

##### SqlLexer

Lexer for Structured Query Language. Currently, this lexer does
not recognize any special syntax except ANSI SQL.

**M√©thodes :**

- `analyse_text()`

##### TransactSqlLexer

Transact-SQL (T-SQL) is Microsoft's and Sybase's proprietary extension to
SQL.

The list of keywords includes ODBC and keywords reserved for future use.

**M√©thodes :**

- `analyse_text()`

##### MySqlLexer

The Oracle MySQL lexer.

This lexer does not attempt to maintain strict compatibility with
MariaDB syntax or keywords. Although MySQL and MariaDB's common code
history suggests there may be significant overlap between the two,
compatibility between the two is not a target for this lexer.

**M√©thodes :**

- `analyse_text()`

##### GoogleSqlLexer

GoogleSQL is Google's standard SQL dialect, formerly known as ZetaSQL.

The list of keywords includes reserved words for future use.

**M√©thodes :**

- `analyse_text()`

##### SqliteConsoleLexer

Lexer for example sessions using sqlite3.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### RqlLexer

Lexer for Relation Query Language.

#### Fonctions

##### language_callback

Parse the content of a $-string using a lexer

The lexer is chosen looking for a nearby LANGUAGE or assumed as
plpgsql if inside a DO statement and no LANGUAGE has been found.

**Param√®tres :**

- `lexer`
- `match`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### _get_lexer

**Param√®tres :**

- `lang`

##### __init__

**Param√®tres :**

- `x`

##### __iter__

##### send

**Param√®tres :**

- `i`

##### __next__

##### get_tokens_unprocessed

**Param√®tres :**

- `data`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### get_tokens_unprocessed

**Param√®tres :**

- `data`

---

### srcinfo

pygments.lexers.srcinfo
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for .SRCINFO files used by Arch Linux Packages.

The description of the format can be found in the wiki:
https://wiki.archlinux.org/title/.SRCINFO

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SrcinfoLexer

Lexer for .SRCINFO files used by Arch Linux Packages.
    

---

### stata

pygments.lexers.stata
~~~~~~~~~~~~~~~~~~~~~

Lexer for Stata

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### StataLexer

For Stata do files.

---

### supercollider

pygments.lexers.supercollider
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for SuperCollider

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SuperColliderLexer

For SuperCollider source code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

We're searching for a common function and a unique keyword here.

**Param√®tres :**

- `text`

---

### tablegen

pygments.lexers.tablegen
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for LLVM's TableGen DSL.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TableGenLexer

Lexer for TableGen

---

### tact

pygments.lexers.tact
~~~~~~~~~~~~~~~~~~~~

Lexers for Tact.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TactLexer

For Tact source code.

---

### tal

pygments.lexers.tal
~~~~~~~~~~~~~~~~~~~

Lexer for Uxntal

.. versionadded:: 2.12

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TalLexer

For Uxntal source code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### tcl

pygments.lexers.tcl
~~~~~~~~~~~~~~~~~~~

Lexers for Tcl and related languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TclLexer

For Tcl source code.

**M√©thodes :**

- `_gen_command_rules()`
- `analyse_text()`

#### Fonctions

##### _gen_command_rules

**Param√®tres :**

- `keyword_cmds_re`
- `builtin_cmds_re`
- `context`

##### analyse_text

**Param√®tres :**

- `text`

---

### teal

pygments.lexers.teal
~~~~~~~~~~~~~~~~~~~~

Lexer for TEAL.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TealLexer

For the Transaction Execution Approval Language (TEAL)

For more information about the grammar, see:
https://github.com/algorand/go-algorand/blob/master/data/transactions/logic/assembler.go

---

### templates

pygments.lexers.templates
~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for various template engines' markup.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ErbLexer

Generic ERB (Ruby Templating) lexer.

Just highlights ruby code between the preprocessor directives, other data
is left untouched by the lexer.

All options are also forwarded to the `RubyLexer`.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`
- `analyse_text()`

##### SmartyLexer

Generic Smarty template lexer.

Just highlights smarty code between the preprocessor directives, other
data is left untouched by the lexer.

**M√©thodes :**

- `analyse_text()`

##### VelocityLexer

Generic Velocity template lexer.

Just highlights velocity directives and variable references, other
data is left untouched by the lexer.

**M√©thodes :**

- `analyse_text()`

##### VelocityHtmlLexer

Subclass of the `VelocityLexer` that highlights unlexed data
with the `HtmlLexer`.

**M√©thodes :**

- `__init__()`

##### VelocityXmlLexer

Subclass of the `VelocityLexer` that highlights unlexed data
with the `XmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### DjangoLexer

Generic `Django <https://www.djangoproject.com/documentation/templates/>`_
and `Jinja <https://jinja.palletsprojects.com>`_ template lexer.

It just highlights django/jinja code between the preprocessor directives,
other data is left untouched by the lexer.

**M√©thodes :**

- `analyse_text()`

##### MyghtyLexer

Generic myghty templates lexer. Code that isn't Myghty
markup is yielded as `Token.Other`.

##### MyghtyHtmlLexer

Subclass of the `MyghtyLexer` that highlights unlexed data
with the `HtmlLexer`.

**M√©thodes :**

- `__init__()`

##### MyghtyXmlLexer

Subclass of the `MyghtyLexer` that highlights unlexed data
with the `XmlLexer`.

**M√©thodes :**

- `__init__()`

##### MyghtyJavascriptLexer

Subclass of the `MyghtyLexer` that highlights unlexed data
with the `JavascriptLexer`.

**M√©thodes :**

- `__init__()`

##### MyghtyCssLexer

Subclass of the `MyghtyLexer` that highlights unlexed data
with the `CssLexer`.

**M√©thodes :**

- `__init__()`

##### MasonLexer

Generic mason templates lexer. Stolen from Myghty lexer. Code that isn't
Mason markup is HTML.

**M√©thodes :**

- `analyse_text()`

##### MakoLexer

Generic mako templates lexer. Code that isn't Mako
markup is yielded as `Token.Other`.

##### MakoHtmlLexer

Subclass of the `MakoLexer` that highlights unlexed data
with the `HtmlLexer`.

**M√©thodes :**

- `__init__()`

##### MakoXmlLexer

Subclass of the `MakoLexer` that highlights unlexed data
with the `XmlLexer`.

**M√©thodes :**

- `__init__()`

##### MakoJavascriptLexer

Subclass of the `MakoLexer` that highlights unlexed data
with the `JavascriptLexer`.

**M√©thodes :**

- `__init__()`

##### MakoCssLexer

Subclass of the `MakoLexer` that highlights unlexed data
with the `CssLexer`.

**M√©thodes :**

- `__init__()`

##### CheetahPythonLexer

Lexer for handling Cheetah's special $ tokens in Python syntax.

**M√©thodes :**

- `get_tokens_unprocessed()`

##### CheetahLexer

Generic cheetah templates lexer. Code that isn't Cheetah
markup is yielded as `Token.Other`.  This also works for
`spitfire templates`_ which use the same syntax.

.. _spitfire templates: http://code.google.com/p/spitfire/

##### CheetahHtmlLexer

Subclass of the `CheetahLexer` that highlights unlexed data
with the `HtmlLexer`.

**M√©thodes :**

- `__init__()`

##### CheetahXmlLexer

Subclass of the `CheetahLexer` that highlights unlexed data
with the `XmlLexer`.

**M√©thodes :**

- `__init__()`

##### CheetahJavascriptLexer

Subclass of the `CheetahLexer` that highlights unlexed data
with the `JavascriptLexer`.

**M√©thodes :**

- `__init__()`

##### GenshiTextLexer

A lexer that highlights genshi text templates.

##### GenshiMarkupLexer

Base lexer for Genshi markup, used by `HtmlGenshiLexer` and
`GenshiLexer`.

##### HtmlGenshiLexer

A lexer that highlights `genshi <https://genshi.edgewall.org/>`_ and
`kid <http://kid-templating.org/>`_ kid HTML templates.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### GenshiLexer

A lexer that highlights `genshi <https://genshi.edgewall.org/>`_ and
`kid <http://kid-templating.org/>`_ kid XML templates.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### JavascriptGenshiLexer

A lexer that highlights javascript code in genshi text templates.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### CssGenshiLexer

A lexer that highlights CSS definitions in genshi text templates.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### RhtmlLexer

Subclass of the ERB lexer that highlights the unlexed data with the
html lexer.

Nested Javascript and CSS is highlighted too.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### XmlErbLexer

Subclass of `ErbLexer` which highlights data outside preprocessor
directives with the `XmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### CssErbLexer

Subclass of `ErbLexer` which highlights unlexed data with the `CssLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### JavascriptErbLexer

Subclass of `ErbLexer` which highlights unlexed data with the
`JavascriptLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### HtmlPhpLexer

Subclass of `PhpLexer` that highlights unhandled data with the `HtmlLexer`.

Nested Javascript and CSS is highlighted too.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### XmlPhpLexer

Subclass of `PhpLexer` that highlights unhandled data with the `XmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### CssPhpLexer

Subclass of `PhpLexer` which highlights unmatched data with the `CssLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### JavascriptPhpLexer

Subclass of `PhpLexer` which highlights unmatched data with the
`JavascriptLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### HtmlSmartyLexer

Subclass of the `SmartyLexer` that highlights unlexed data with the
`HtmlLexer`.

Nested Javascript and CSS is highlighted too.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### XmlSmartyLexer

Subclass of the `SmartyLexer` that highlights unlexed data with the
`XmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### CssSmartyLexer

Subclass of the `SmartyLexer` that highlights unlexed data with the
`CssLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### JavascriptSmartyLexer

Subclass of the `SmartyLexer` that highlights unlexed data with the
`JavascriptLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### HtmlDjangoLexer

Subclass of the `DjangoLexer` that highlights unlexed data with the
`HtmlLexer`.

Nested Javascript and CSS is highlighted too.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### XmlDjangoLexer

Subclass of the `DjangoLexer` that highlights unlexed data with the
`XmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### CssDjangoLexer

Subclass of the `DjangoLexer` that highlights unlexed data with the
`CssLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### JavascriptDjangoLexer

Subclass of the `DjangoLexer` that highlights unlexed data with the
`JavascriptLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### JspRootLexer

Base for the `JspLexer`. Yields `Token.Other` for area outside of
JSP tags.

.. versionadded:: 0.7

##### JspLexer

Lexer for Java Server Pages.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### EvoqueLexer

For files using the Evoque templating system.

**M√©thodes :**

- `analyse_text()`

##### EvoqueHtmlLexer

Subclass of the `EvoqueLexer` that highlights unlexed data with the
`HtmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### EvoqueXmlLexer

Subclass of the `EvoqueLexer` that highlights unlexed data with the
`XmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### ColdfusionLexer

Coldfusion statements

##### ColdfusionMarkupLexer

Coldfusion markup only

##### ColdfusionHtmlLexer

Coldfusion markup in html

**M√©thodes :**

- `__init__()`

##### ColdfusionCFCLexer

Coldfusion markup/script components

**M√©thodes :**

- `__init__()`

##### SspLexer

Lexer for Scalate Server Pages.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### TeaTemplateRootLexer

Base for the `TeaTemplateLexer`. Yields `Token.Other` for area outside of
code blocks.

.. versionadded:: 1.5

##### TeaTemplateLexer

Lexer for Tea Templates.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### LassoHtmlLexer

Subclass of the `LassoLexer` which highlights unhandled data with the
`HtmlLexer`.

Nested JavaScript and CSS is also highlighted.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### LassoXmlLexer

Subclass of the `LassoLexer` which highlights unhandled data with the
`XmlLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### LassoCssLexer

Subclass of the `LassoLexer` which highlights unhandled data with the
`CssLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### LassoJavascriptLexer

Subclass of the `LassoLexer` which highlights unhandled data with the
`JavascriptLexer`.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

##### HandlebarsLexer

Generic handlebars template lexer.

Highlights only the Handlebars template tags (stuff between `{{` and `}}`).
Everything else is left for a delegating lexer.

##### HandlebarsHtmlLexer

Subclass of the `HandlebarsLexer` that highlights unlexed data with the
`HtmlLexer`.

**M√©thodes :**

- `__init__()`

##### YamlJinjaLexer

Subclass of the `DjangoLexer` that highlights unlexed data with the
`YamlLexer`.

Commonly used in Saltstack salt states.

**M√©thodes :**

- `__init__()`

##### LiquidLexer

Lexer for Liquid templates.

##### TwigLexer

Twig template lexer.

It just highlights Twig code between the preprocessor directives,
other data is left untouched by the lexer.

##### TwigHtmlLexer

Subclass of the `TwigLexer` that highlights unlexed data with the
`HtmlLexer`.

**M√©thodes :**

- `__init__()`

##### Angular2Lexer

Generic angular2 template lexer.

Highlights only the Angular template tags (stuff between `{{` and `}}` and
special attributes: '(event)=', '[property]=', '[(twoWayBinding)]=').
Everything else is left for a delegating lexer.

##### Angular2HtmlLexer

Subclass of the `Angular2Lexer` that highlights unlexed data with the
`HtmlLexer`.

**M√©thodes :**

- `__init__()`

##### SqlJinjaLexer

Templated SQL lexer.

**M√©thodes :**

- `__init__()`
- `analyse_text()`

#### Fonctions

##### __init__

##### get_tokens_unprocessed

Since ERB doesn't allow "<%" and other tags inside of ruby
blocks we have to use a split approach here that fails for
that too.

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

Evoque templates use $evoque, which is unique.

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

##### __init__

##### __init__

##### __init__

##### __init__

##### analyse_text

**Param√®tres :**

- `text`

---

### teraterm

pygments.lexers.teraterm
~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Tera Term macro files.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TeraTermLexer

For Tera Term macro source code.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### testing

pygments.lexers.testing
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for testing languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GherkinLexer

For Gherkin syntax.

**M√©thodes :**

- `analyse_text()`

##### TAPLexer

For Test Anything Protocol (TAP) output.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### text

pygments.lexers.text
~~~~~~~~~~~~~~~~~~~~

Lexers for non-source code file types.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### textedit

pygments.lexers.textedit
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for languages related to text processing.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AwkLexer

For Awk scripts.

##### SedLexer

Lexer for Sed script files.

##### VimLexer

Lexer for VimL script files.

**M√©thodes :**

- `__init__()`
- `is_in()`
- `get_tokens_unprocessed()`

#### Fonctions

##### __init__

##### is_in

It's kind of difficult to decide if something might be a keyword
in VimL because it allows you to abbreviate them.  In fact,
'ab[breviate]' is a good example.  :ab, :abbre, or :abbreviate are
valid ways to call it so rather than making really awful regexps
like::

    \bab(?:b(?:r(?:e(?:v(?:i(?:a(?:t(?:e)?)?)?)?)?)?)?)?\b

we match `\b\w+\b` and then call is_in() on those tokens.  See
`scripts/get_vimkw.py` for how the lists are extracted.

**Param√®tres :**

- `w`
- `mapping`

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### textfmts

pygments.lexers.textfmts
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for various text formats.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### IrcLogsLexer

Lexer for IRC logs in *irssi*, *xchat* or *weechat* style.

##### GettextLexer

Lexer for Gettext catalog files.

##### HttpLexer

Lexer for HTTP sessions.

**M√©thodes :**

- `get_tokens_unprocessed()`
- `header_callback()`
- `continuous_header_callback()`
- `content_callback()`
- `analyse_text()`

##### TodotxtLexer

Lexer for Todo.txt todo list format.

##### NotmuchLexer

For Notmuch email text format.

Additional options accepted:

`body_lexer`
    If given, highlight the contents of the message body with the specified
    lexer, else guess it according to the body content (default: ``None``).

**M√©thodes :**

- `_highlight_code()`
- `analyse_text()`
- `__init__()`

##### KernelLogLexer

For Linux Kernel log ("dmesg") output.

#### Fonctions

##### get_tokens_unprocessed

Reset the content-type state.

**Param√®tres :**

- `text`
- `stack`

##### header_callback

**Param√®tres :**

- `match`

##### continuous_header_callback

**Param√®tres :**

- `match`

##### content_callback

**Param√®tres :**

- `match`

##### analyse_text

**Param√®tres :**

- `text`

##### _highlight_code

**Param√®tres :**

- `match`

##### analyse_text

**Param√®tres :**

- `text`

##### __init__

---

### theorem

pygments.lexers.theorem
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for theorem-proving languages.

See also :mod:`pygments.lexers.lean`

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CoqLexer

For the Coq theorem prover.

**M√©thodes :**

- `analyse_text()`

##### IsabelleLexer

For the Isabelle proof assistant.

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

---

### thingsdb

pygments.lexers.thingsdb
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for the ThingsDB language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ThingsDBLexer

Lexer for the ThingsDB programming language.

---

### tlb

pygments.lexers.tlb
~~~~~~~~~~~~~~~~~~~

Lexers for TL-b.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TlbLexer

For TL-b source code.

---

### tls

pygments.lexers.tls
~~~~~~~~~~~~~~~~~~~

Lexers for the TLS presentation language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TlsLexer

The TLS presentation language, described in RFC 8446.

---

### tnt

pygments.lexers.tnt
~~~~~~~~~~~~~~~~~~~

Lexer for Typographic Number Theory.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TNTLexer

Lexer for Typographic Number Theory, as described in the book
G√∂del, Escher, Bach, by Douglas R. Hofstadter

**M√©thodes :**

- `__init__()`
- `whitespace()`
- `variable()`
- `term()`
- `formula()`
- `rule()`
- `lineno()`
- `error_till_line_end()`
- `get_tokens_unprocessed()`

#### Fonctions

##### __init__

##### whitespace

Tokenize whitespace.

**Param√®tres :**

- `start`
- `text`
- `required`

##### variable

Tokenize a variable.

**Param√®tres :**

- `start`
- `text`

##### term

Tokenize a term.

**Param√®tres :**

- `start`
- `text`

##### formula

Tokenize a formula.

**Param√®tres :**

- `start`
- `text`

##### rule

Tokenize a rule.

**Param√®tres :**

- `start`
- `text`

##### lineno

Tokenize a line referral.

**Param√®tres :**

- `start`
- `text`

##### error_till_line_end

Mark everything from ``start`` to the end of the line as Error.

**Param√®tres :**

- `start`
- `text`

##### get_tokens_unprocessed

Returns a list of TNT tokens.

**Param√®tres :**

- `text`

---

### trafficscript

pygments.lexers.trafficscript
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for RiverBed's TrafficScript (RTS) language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RtsLexer

For Riverbed Stingray Traffic Manager

---

### typoscript

pygments.lexers.typoscript
~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for TypoScript

`TypoScriptLexer`
    A TypoScript lexer.

`TypoScriptCssDataLexer`
    Lexer that highlights markers, constants and registers within css.

`TypoScriptHtmlDataLexer`
    Lexer that highlights markers, constants and registers within html tags.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TypoScriptCssDataLexer

Lexer that highlights markers, constants and registers within css blocks.

##### TypoScriptHtmlDataLexer

Lexer that highlights markers, constants and registers within html tags.

##### TypoScriptLexer

Lexer for TypoScript code.

---

### typst

pygments.lexers.typst
~~~~~~~~~~~~~~~~~~~~~

Lexers for Typst language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TypstLexer

For Typst code.

Additional options accepted:

`start`
    Specifies the starting state of the lexer (one of 'markup', 'math',
    'code'). The default is 'markup'.

**M√©thodes :**

- `__init__()`
- `get_tokens_unprocessed()`

#### Fonctions

##### __init__

##### get_tokens_unprocessed

**Param√®tres :**

- `text`

---

### ul4

pygments.lexers.ul4
~~~~~~~~~~~~~~~~~~~

Lexer for the UL4 templating language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### UL4Lexer

Generic lexer for UL4.

##### HTMLUL4Lexer

Lexer for UL4 embedded in HTML.

**M√©thodes :**

- `__init__()`

##### XMLUL4Lexer

Lexer for UL4 embedded in XML.

**M√©thodes :**

- `__init__()`

##### CSSUL4Lexer

Lexer for UL4 embedded in CSS.

**M√©thodes :**

- `__init__()`

##### JavascriptUL4Lexer

Lexer for UL4 embedded in Javascript.

**M√©thodes :**

- `__init__()`

##### PythonUL4Lexer

Lexer for UL4 embedded in Python.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

##### __init__

##### __init__

##### __init__

##### __init__

---

### unicon

pygments.lexers.unicon
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the Icon and Unicon languages, including ucode VM.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### UniconLexer

For Unicon source code.

##### IconLexer

Lexer for Icon.

##### UcodeLexer

Lexer for Icon ucode files.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

endsuspend and endrepeat are unique to this language, and
\self, /self doesn't seem to get used anywhere else either.

**Param√®tres :**

- `text`

---

### urbi

pygments.lexers.urbi
~~~~~~~~~~~~~~~~~~~~

Lexers for UrbiScript language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### UrbiscriptLexer

For UrbiScript source code.

**M√©thodes :**

- `blob_callback()`
- `analyse_text()`

#### Fonctions

##### blob_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### analyse_text

This is fairly similar to C and others, but freezeif and
waituntil are unique keywords.

**Param√®tres :**

- `text`

---

### usd

pygments.lexers.usd
~~~~~~~~~~~~~~~~~~~

The module that parses Pixar's Universal Scene Description file format.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### UsdLexer

A lexer that parses Pixar's Universal Scene Description file format.

#### Fonctions

##### _keywords

**Param√®tres :**

- `words`
- `type_`

---

### varnish

pygments.lexers.varnish
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Varnish configuration

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VCLLexer

For Varnish Configuration Language (VCL).

**M√©thodes :**

- `analyse_text()`

##### VCLSnippetLexer

For Varnish Configuration Language snippets.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

**Param√®tres :**

- `text`

##### analyse_text

**Param√®tres :**

- `text`

---

### verification

pygments.lexers.verification
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexer for Intermediate Verification Languages (IVLs).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BoogieLexer

For Boogie source code.

##### SilverLexer

For Silver source code.

---

### verifpal

pygments.lexers.verifpal
~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for Verifpal languages.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VerifpalLexer

For Verifpal code.

---

### vip

pygments.lexers.vip
~~~~~~~~~~~~~~~~~~~

Lexers for Visual Prolog & Grammar files.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VisualPrologBaseLexer

##### VisualPrologLexer

Lexer for VisualProlog
    

**M√©thodes :**

- `analyse_text()`

##### VisualPrologGrammarLexer

Lexer for VisualProlog grammar
    

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### analyse_text

Competes with IDL and Prolog on *.pro; div. lisps on*.cl and SwigLexer on *.i

**Param√®tres :**

- `text`

##### analyse_text

No competditors (currently)

**Param√®tres :**

- `text`

---

### vyper

pygments.lexers.vyper
~~~~~~~~~~~~~~~~~~~~~

Lexer for the Vyper Smart Contract language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VyperLexer

For the Vyper smart contract language.
    

---

### web

pygments.lexers.web
~~~~~~~~~~~~~~~~~~~

Just export previously exported lexers.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

---

### webassembly

pygments.lexers.webassembly
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Lexers for the WebAssembly text format.

The grammar can be found at https://github.com/WebAssembly/spec/blob/master/interpreter/README.md
and https://webassembly.github.io/spec/core/text/.


:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### WatLexer

Lexer for the WebAssembly text format.
    

---

### webidl

pygments.lexers.webidl
~~~~~~~~~~~~~~~~~~~~~~

Lexers for Web IDL, including some extensions.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### WebIDLLexer

For Web IDL.

---

### webmisc

pygments.lexers.webmisc
~~~~~~~~~~~~~~~~~~~~~~~

Lexers for misc. web stuff.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DuelLexer

Lexer for Duel Views Engine (formerly JBST) markup with JavaScript code blocks.

##### XQueryLexer

An XQuery lexer, parsing a stream and outputting the tokens needed to
highlight xquery code.

**M√©thodes :**

- `punctuation_root_callback()`
- `operator_root_callback()`
- `popstate_tag_callback()`
- `popstate_xmlcomment_callback()`
- `popstate_kindtest_callback()`
- `popstate_callback()`
- `pushstate_element_content_starttag_callback()`
- `pushstate_cdata_section_callback()`
- `pushstate_starttag_callback()`
- `pushstate_operator_order_callback()`
- `pushstate_operator_map_callback()`
- `pushstate_operator_root_validate()`
- `pushstate_operator_root_validate_withmode()`
- `pushstate_operator_processing_instruction_callback()`
- `pushstate_element_content_processing_instruction_callback()`
- `pushstate_element_content_cdata_section_callback()`
- `pushstate_operator_cdata_section_callback()`
- `pushstate_element_content_xmlcomment_callback()`
- `pushstate_operator_xmlcomment_callback()`
- `pushstate_kindtest_callback()`
- `pushstate_operator_kindtestforpi_callback()`
- `pushstate_operator_kindtest_callback()`
- `pushstate_occurrenceindicator_kindtest_callback()`
- `pushstate_operator_starttag_callback()`
- `pushstate_operator_root_callback()`
- `pushstate_operator_root_construct_callback()`
- `pushstate_root_callback()`
- `pushstate_operator_attribute_callback()`

##### QmlLexer

For QML files.

##### CirruLexer

* using ``()`` for expressions, but restricted in a same line
* using ``""`` for strings, with ``\`` for escaping chars
* using ``$`` as folding operator
* using ``,`` as unfolding operator
* using indentations for nested blocks

##### SlimLexer

For Slim markup.

#### Fonctions

##### punctuation_root_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### operator_root_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### popstate_tag_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### popstate_xmlcomment_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### popstate_kindtest_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### popstate_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_element_content_starttag_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_cdata_section_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_starttag_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_order_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_map_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_root_validate

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_root_validate_withmode

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_processing_instruction_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_element_content_processing_instruction_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_element_content_cdata_section_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_cdata_section_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_element_content_xmlcomment_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_xmlcomment_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_kindtest_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_kindtestforpi_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_kindtest_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_occurrenceindicator_kindtest_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_starttag_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_root_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_root_construct_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_root_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

##### pushstate_operator_attribute_callback

**Param√®tres :**

- `lexer`
- `match`
- `ctx`

---

### wgsl

pygments.lexers.wgsl
~~~~~~~~~~~~~~~~~~~~

Lexer for the WebGPU Shading Language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### WgslLexer

Lexer for the WebGPU Shading Language.

---

### whiley

pygments.lexers.whiley
~~~~~~~~~~~~~~~~~~~~~~

Lexers for the Whiley language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### WhileyLexer

Lexer for the Whiley programming language.

---

### wowtoc

pygments.lexers.wowtoc
~~~~~~~~~~~~~~~~~~~~~~

Lexer for World of Warcraft TOC files

TOC files describe game addons.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### WoWTocLexer

Lexer for World of Warcraft TOC files.

**M√©thodes :**

- `analyse_text()`

#### Fonctions

##### _create_tag_line_pattern

**Param√®tres :**

- `inner_pattern`
- `ignore_case`

##### _create_tag_line_token

**Param√®tres :**

- `inner_pattern`
- `inner_token`
- `ignore_case`

##### analyse_text

**Param√®tres :**

- `text`

---

### wren

pygments.lexers.wren
~~~~~~~~~~~~~~~~~~~~

Lexer for Wren.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### WrenLexer

For Wren source code, version 0.4.0.

---

### x10

pygments.lexers.x10
~~~~~~~~~~~~~~~~~~~

Lexers for the X10 programming language.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### X10Lexer

For the X10 language.

---

### xorg

pygments.lexers.xorg
~~~~~~~~~~~~~~~~~~~~

Lexers for Xorg configs.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### XorgLexer

Lexer for xorg.conf files.

---

### yang

pygments.lexers.yang
~~~~~~~~~~~~~~~~~~~~

Lexer for the YANG 1.1 modeling language. See :rfc:`7950`.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### YangLexer

Lexer for YANG, based on RFC7950.

---

### yara

pygments.lexers.yara
~~~~~~~~~~~~~~~~~~~~

Lexers for YARA.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### YaraLexer

For YARA rules

---

### zig

pygments.lexers.zig
~~~~~~~~~~~~~~~~~~~

Lexers for Zig.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ZigLexer

Lexer for the Zig language.

grammar: https://ziglang.org/documentation/master/#Grammar

---

### .!27136!__init__

---

### .!27143!_ada_builtins

---

### .!27148!_asy_builtins

---

### .!27152!_cl_builtins

---

### .!27157!_cocoa_builtins

---

### .!27161!_csound_builtins

---

### .!27166!_css_builtins

---

### .!27170!_googlesql_builtins

---

### .!27175!_julia_builtins

---

### .!27180!_lasso_builtins

---

### .!27183!_lilypond_builtins

---

### .!27189!_lua_builtins

---

### .!27195!_luau_builtins

---

### .!27199!_mapping

---

### .!27204!_mql_builtins

---

### .!27209!actionscript

---

### .!27215!_mysql_builtins

---

### .!27219!_openedge_builtins

---

### .!27226!_php_builtins

---

### .!27231!_postgres_builtins

---

### .!27236!_qlik_builtins

---

### .!27241!_scheme_builtins

---

### .!27244!_scilab_builtins

---

### .!27250!_sourcemod_builtins

---

### .!27257!_sql_builtins

---

### .!27261!_stan_builtins

---

### .!27267!_stata_builtins

---

### .!27272!_tsql_builtins

---

### .!27276!_usd_builtins

---

### .!27281!_vbscript_builtins

---

### .!27287!_vim_builtins

---

### .!27297!agile

---

### .!27301!algebra

---

### .!27306!ambient

---

### .!27310!amdgpu

---

### .!27319!apdlexer

---

### .!27328!archetype

---

### .!27333!arrow

---

### .!27338!arturo

---

### .!27358!automation

---

### .!27369!basic

---

### .!27377!berry

---

### .!27383!bibtex

---

### .!27387!blueprint

---

### .!27400!business

---

### .!27406!c_cpp

---

### .!27411!c_like

---

### .!27415!capnproto

---

### .!27421!carbon

---

### .!27429!chapel

---

### .!27433!clean

---

### .!27438!codeql

---

### .!27442!comal

---

### .!27447!compiled

---

### .!27452!configs

---

### .!27456!console

---

### .!27462!cplint

---

### .!27467!crystal

---

### .!27469!csound

---

### .!27482!dalvik

---

### .!27496!devicetree

---

### .!27511!dotnet

---

### .!27521!dylan

---

### .!27531!eiffel

---

### .!27542!email

---

### .!27547!erlang

---

### .!27552!esoteric

---

### .!27556!ezhil

---

### .!27561!factor

---

### .!27565!fantom

---

### .!27570!felix

---

### .!27581!floscript

---

### .!27585!forth

---

### .!27588!fortran

---

### .!27593!foxpro

---

### .!27599!freefem

---

### .!27609!functional

---

### .!27614!futhark

---

### .!27616!gcodelexer

---

### .!27624!gdscript

---

### .!27628!gleam

---

### .!27640!grammar_notation

---

### .!27643!graph

---

### .!27647!graphics

---

### .!27652!graphql

---

### .!27655!graphviz

---

### .!27668!haskell

---

### .!27682!hexdump

---

### .!27705!inferno

---

### .!27708!installers

---

### .!27713!int_fiction

---

### .!27719!iolang

---

### .!27727!javascript

---

### .!27734!jmespath

---

### .!27746!json5

---

### .!27749!jsonnet

---

### .!27758!julia

---

### .!27772!kusto

---

### .!27787!lilypond

---

### .!27795!macaulay2

---

### .!27803!maple

---

### .!27808!markup

---

### .!27817!matlab

---

### .!27822!maxima

---

### .!27826!meson

---

### .!27836!minecraft

---

### .!27850!modeling

---

### .!27854!modula2

---

### .!27864!monte

---

### .!27867!mosel

---

### .!27876!nimrod

---

### .!27894!numbair

---

### .!27899!oberon

---

### .!27904!objective

---

### .!27916!openscad

---

### .!27921!other

---

### .!27926!parasail

---

### .!27933!parsers

---

### .!27937!pascal

---

### .!27966!pointless

---

### .!27975!praat

---

### .!27980!procfile

---

### .!27984!prolog

---

### .!27990!promql

---

### .!28006!python

---

### .!28033!rebol

---

### .!28043!resource

---

### .!28063!roboconf

---

### .!28067!robotframework

---

### .!28091!scdoc

---

### .!28098!scripting

---

### .!28108!shell

---

### .!28112!sieve

---

### .!28118!slash

---

### .!28122!smalltalk

---

### .!28125!smithy

---

### .!28134!snobol

---

### .!28140!solidity

---

### .!28143!soong

---

### .!28149!sophia

---

### .!28153!special

---

### .!28158!spice

---

### .!28168!srcinfo

---

### .!28173!stata

---

### .!28177!supercollider

---

### .!28180!tablegen

---

### .!28209!templates

---

### .!28215!teraterm

---

### .!28220!testing

---

### .!28231!textedit

---

### .!28236!textfmts

---

### .!28243!theorem

---

### .!28245!thingsdb

---

### .!28264!trafficscript

---

### .!28267!typoscript

---

### .!28272!typst

---

### .!28281!unicon

---

### .!28297!varnish

---

### .!28301!verification

---

### .!28305!verifpal

---

### .!28314!vyper

---

### .!28326!webassembly

---

### .!28331!webidl

---

### .!28335!webmisc

---

### .!28345!whiley

---

### .!28350!wowtoc

---

### _mapping

---

### abap

pygments.styles.abap
~~~~~~~~~~~~~~~~~~~~

ABAP workbench like style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AbapStyle

---

### algol

pygments.styles.algol
~~~~~~~~~~~~~~~~~~~~~

Algol publication style.

This style renders source code for publication of algorithms in
scientific papers and academic texts, where its format is frequently used.

It is based on the style of the revised Algol-60 language report[1].

o  No colours, only black, white and shades of grey are used.
o  Keywords are rendered in lowercase underline boldface.
o  Builtins are rendered in lowercase boldface italic.
o  Docstrings and pragmas are rendered in dark grey boldface.
o  Library identifiers are rendered in dark grey boldface italic.
o  Comments are rendered in grey italic.

To render keywords without underlining, refer to the `Algol_Nu` style.

For lowercase conversion of keywords and builtins in languages where
these are not or might not be lowercase, a supporting lexer is required.
The Algol and Modula-2 lexers automatically convert to lowercase whenever
this style is selected.

[1] `Revised Report on the Algorithmic Language Algol-60 <http://www.masswerk.at/algol60/report.htm>`

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AlgolStyle

---

### algol_nu

pygments.styles.algol_nu
~~~~~~~~~~~~~~~~~~~~~~~~

Algol publication style without underlining of keywords.

This style renders source code for publication of algorithms in
scientific papers and academic texts, where its format is frequently used.

It is based on the style of the revised Algol-60 language report[1].

o  No colours, only black, white and shades of grey are used.
o  Keywords are rendered in lowercase boldface.
o  Builtins are rendered in lowercase boldface italic.
o  Docstrings and pragmas are rendered in dark grey boldface.
o  Library identifiers are rendered in dark grey boldface italic.
o  Comments are rendered in grey italic.

To render keywords with underlining, refer to the `Algol` style.

For lowercase conversion of keywords and builtins in languages where
these are not or might not be lowercase, a supporting lexer is required.
The Algol and Modula-2 lexers automatically convert to lowercase whenever
this style is selected.

[1] `Revised Report on the Algorithmic Language Algol-60 <http://www.masswerk.at/algol60/report.htm>`

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### Algol_NuStyle

---

### arduino

pygments.styles.arduino
~~~~~~~~~~~~~~~~~~~~~~~

Arduino¬Æ Syntax highlighting style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ArduinoStyle

The Arduino¬Æ language style. This style is designed to highlight the
Arduino source code, so expect the best results with it.

---

### autumn

pygments.styles.autumn
~~~~~~~~~~~~~~~~~~~~~~

A colorful style, inspired by the terminal highlighting style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### AutumnStyle

A colorful style, inspired by the terminal highlighting style.

---

### borland

pygments.styles.borland
~~~~~~~~~~~~~~~~~~~~~~~

Style similar to the style used in the Borland IDEs.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BorlandStyle

Style similar to the style used in the borland IDEs.

---

### bw

pygments.styles.bw
~~~~~~~~~~~~~~~~~~

Simple black/white only style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### BlackWhiteStyle

---

### coffee

pygments.styles.coffee
~~~~~~~~~~~~~~~~~~~~~~

A warm and cozy theme based off gruvbox

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### CoffeeStyle

A warm and cozy theme based off gruvbox

---

### colorful

pygments.styles.colorful
~~~~~~~~~~~~~~~~~~~~~~~~

A colorful style, inspired by CodeRay.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ColorfulStyle

A colorful style, inspired by CodeRay.

---

### default

pygments.styles.default
~~~~~~~~~~~~~~~~~~~~~~~

The default highlighting style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DefaultStyle

The default style (inspired by Emacs 22).

---

### dracula

pygments.styles.dracula
~~~~~~~~~~~~~~~~~~~~~~~

Pygments version of `Dracula` from https://github.com/dracula/dracula-theme.

Based on the Dracula Theme for pygments by Chris Bracco.
See https://github.com/dracula/pygments/tree/fee9ed5613d1086bc01b9d0a5a0e9867a009f571

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### DraculaStyle

---

### .!28395!abap

---

### .!28427!bw

---

### emacs

pygments.styles.emacs
~~~~~~~~~~~~~~~~~~~~~

A highlighting style for Pygments, inspired by Emacs.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### EmacsStyle

The default style (inspired by Emacs 22).

---

### friendly

pygments.styles.friendly
~~~~~~~~~~~~~~~~~~~~~~~~

A modern style based on the VIM pyte theme.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FriendlyStyle

A modern style based on the VIM pyte theme.

---

### .!28478!igor

---

### .!28525!nord

---

### fruity

pygments.styles.fruity
~~~~~~~~~~~~~~~~~~~~~~

pygments version of my "fruity" vim theme.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FruityStyle

Pygments version of the "native" vim theme.

---

### .!28556!rrt

---

### .!28561!sas

---

### gh_dark

pygments.styles.gh_dark
~~~~~~~~~~~~~~~~~~~~~~~

Github's Dark-Colorscheme based theme for Pygments
Colors extracted from https://github.com/primer/primitives

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GhDarkStyle

Github's Dark-Colorscheme based theme for Pygments

---

### .!28590!trac

---

### .!28594!vim

---

### gruvbox

pygments.styles.gruvbox
~~~~~~~~~~~~~~~~~~~~~~~

pygments version of the "gruvbox" vim theme.
https://github.com/morhetz/gruvbox

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### GruvboxDarkStyle

Pygments version of the "gruvbox" dark vim theme.

##### GruvboxLightStyle

Pygments version of the "gruvbox" Light vim theme.

---

### .!28599!vs

---

### friendly_grayscale

pygments.styles.friendly_grayscale
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A style based on friendly style.
The color values of the friendly style have been converted to grayscale
using the luminosity value calculated by
http://www.workwithcolor.com/color-converter-01.htm

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### FriendlyGrayscaleStyle

A modern grayscale style based on the friendly style.

.. versionadded:: 2.11

---

### igor

pygments.styles.igor
~~~~~~~~~~~~~~~~~~~~

Igor Pro default style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### IgorStyle

Pygments version of the official colors for Igor Pro procedures.

---

### inkpot

pygments.styles.inkpot
~~~~~~~~~~~~~~~~~~~~~~

A highlighting style for Pygments, inspired by the Inkpot theme for VIM.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### InkPotStyle

---

### lightbulb

pygments.styles.lightbulb
~~~~~~~~~~~~~~~~~~~~~~~~~

A minimal dark theme based on the Lightbulb theme for VSCode.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LightbulbStyle

A minimal dark theme based on the Lightbulb theme for VSCode.

---

### lilypond

pygments.styles.lilypond
~~~~~~~~~~~~~~~~~~~~~~~~

LilyPond-specific style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LilyPondStyle

Style for the LilyPond language.

.. versionadded:: 2.11

---

### lovelace

pygments.styles.lovelace
~~~~~~~~~~~~~~~~~~~~~~~~

Lovelace by Miikka Salminen

Pygments style by Miikka Salminen (https://github.com/miikkas)
A desaturated, somewhat subdued style created for the Lovelace interactive
learning environment.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### LovelaceStyle

The style used in Lovelace interactive learning environment. Tries to avoid
the "angry fruit salad" effect with desaturated and dim colours.

---

### manni

pygments.styles.manni
~~~~~~~~~~~~~~~~~~~~~

A colorful style, inspired by the terminal highlighting style.

This is a port of the style used in the `php port`_ of pygments
by Manni. The style is called 'default' there.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ManniStyle

A colorful style, inspired by the terminal highlighting style.

---

### material

pygments.styles.material
~~~~~~~~~~~~~~~~~~~~~~~~

Mimic the Material theme color scheme.

https://github.com/material-theme/vsc-material-theme

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MaterialStyle

This style mimics the Material Theme color scheme.

---

### monokai

pygments.styles.monokai
~~~~~~~~~~~~~~~~~~~~~~~

Mimic the Monokai color scheme. Based on tango.py.

http://www.monokai.nl/blog/2006/07/15/textmate-color-theme/

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MonokaiStyle

This style mimics the Monokai color scheme.

---

### murphy

pygments.styles.murphy
~~~~~~~~~~~~~~~~~~~~~~

Murphy's style from CodeRay.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### MurphyStyle

Murphy's style from CodeRay.

---

### native

pygments.styles.native
~~~~~~~~~~~~~~~~~~~~~~

pygments version of my "native" vim theme.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NativeStyle

Pygments version of the "native" vim theme.

---

### nord

pygments.styles.nord
~~~~~~~~~~~~~~~~~~~~

pygments version of the "nord" theme by Arctic Ice Studio
https://www.nordtheme.com/

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### NordStyle

Pygments version of the "nord" theme by Arctic Ice Studio.

##### NordDarkerStyle

Pygments version of a darker "nord" theme by Arctic Ice Studio

---

### onedark

pygments.styles.onedark
~~~~~~~~~~~~~~~~~~~~~~~

One Dark Theme for Pygments by Tobias Zoghaib (https://github.com/TobiZog)

Inspired by one-dark-ui for the code editor Atom
(https://atom.io/themes/one-dark-ui).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### OneDarkStyle

Theme inspired by One Dark Pro for Atom.

.. versionadded:: 2.11

---

### paraiso_dark

pygments.styles.paraiso_dark
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Para√≠so (Dark) by Jan T. Sott

Pygments template by Jan T. Sott (https://github.com/idleberg)
Created with Base16 Builder by Chris Kempson
(https://github.com/chriskempson/base16-builder).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ParaisoDarkStyle

---

### paraiso_light

pygments.styles.paraiso_light
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Para√≠so (Light) by Jan T. Sott

Pygments template by Jan T. Sott (https://github.com/idleberg)
Created with Base16 Builder by Chris Kempson
(https://github.com/chriskempson/base16-builder).

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ParaisoLightStyle

---

### pastie

pygments.styles.pastie
~~~~~~~~~~~~~~~~~~~~~~

Style similar to the `pastie`_ default style.

.. _pastie: http://pastie.caboo.se/

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PastieStyle

Style similar to the pastie default style.

---

### perldoc

pygments.styles.perldoc
~~~~~~~~~~~~~~~~~~~~~~~

Style similar to the style used in the `perldoc`_ code blocks.

.. _perldoc: http://perldoc.perl.org/

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### PerldocStyle

Style similar to the style used in the perldoc code blocks.

---

### rainbow_dash

pygments.styles.rainbow_dash
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A bright and colorful syntax highlighting `theme`.

.. _theme: http://sanssecours.github.io/Rainbow-Dash.tmbundle

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RainbowDashStyle

A bright and colorful syntax highlighting theme.

---

### rrt

pygments.styles.rrt
~~~~~~~~~~~~~~~~~~~

pygments "rrt" theme, based on Zap and Emacs defaults.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### RrtStyle

Minimalistic "rrt" theme, based on Zap and Emacs defaults.

---

### sas

pygments.styles.sas
~~~~~~~~~~~~~~~~~~~

Style inspired by SAS' enhanced program editor. Note This is not
meant to be a complete style. It's merely meant to mimic SAS'
program editor syntax highlighting.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SasStyle

Style inspired by SAS' enhanced program editor. Note This is not
meant to be a complete style. It's merely meant to mimic SAS'
program editor syntax highlighting.

---

### solarized

pygments.styles.solarized
~~~~~~~~~~~~~~~~~~~~~~~~~

Solarized by Camil Staps

A Pygments style for the Solarized themes (licensed under MIT).
See: https://github.com/altercation/solarized

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### SolarizedDarkStyle

The solarized style, dark.

##### SolarizedLightStyle

The solarized style, light.

#### Fonctions

##### make_style

**Param√®tres :**

- `colors`

---

### staroffice

pygments.styles.staroffice
~~~~~~~~~~~~~~~~~~~~~~~~~~

Style similar to StarOffice style, also in OpenOffice and LibreOffice.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### StarofficeStyle

Style similar to StarOffice style, also in OpenOffice and LibreOffice.

---

### stata_dark

pygments.styles.stata_dark
~~~~~~~~~~~~~~~~~~~~~~~~~~

Dark style inspired by Stata's do-file editor. Note this is not
meant to be a complete style, just for Stata's file formats.


:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### StataDarkStyle

---

### stata_light

pygments.styles.stata_light
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Light Style inspired by Stata's do-file editor. Note this is not
meant to be a complete style, just for Stata's file formats.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### StataLightStyle

Light mode style inspired by Stata's do-file editor. This is not
meant to be a complete style, just for use with Stata.

---

### tango

pygments.styles.tango
~~~~~~~~~~~~~~~~~~~~~

The Crunchy default Style inspired from the color palette from
the Tango Icon Theme Guidelines.

http://tango.freedesktop.org/Tango_Icon_Theme_Guidelines

Butter:     #fce94f     #edd400     #c4a000
Orange:     #fcaf3e     #f57900     #ce5c00
Chocolate:  #e9b96e     #c17d11     #8f5902
Chameleon:  #8ae234     #73d216     #4e9a06
Sky Blue:   #729fcf     #3465a4     #204a87
Plum:       #ad7fa8     #75507b     #5c35cc
Scarlet Red:#ef2929     #cc0000     #a40000
Aluminium:  #eeeeec     #d3d7cf     #babdb6
            #888a85     #555753     #2e3436

Not all of the above colors are used; other colors added:
    very light grey: #f8f8f8  (for background)

This style can be used as a template as it includes all the known
Token types, unlike most (if not all) of the styles included in the
Pygments distribution.

However, since Crunchy is intended to be used by beginners, we have strived
to create a style that gloss over subtle distinctions between different
categories.

Taking Python for example, comments (Comment.*) and docstrings (String.Doc)
have been chosen to have the same style.  Similarly, keywords (Keyword.*),
and Operator.Word (and, or, in) have been assigned the same style.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TangoStyle

The Crunchy default Style inspired from the color palette from
the Tango Icon Theme Guidelines.

---

### trac

pygments.styles.trac
~~~~~~~~~~~~~~~~~~~~

Port of the default trac highlighter design.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### TracStyle

Port of the default trac highlighter design.

---

### vim

pygments.styles.vim
~~~~~~~~~~~~~~~~~~~

A highlighting style for Pygments, inspired by vim.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VimStyle

Styles somewhat like vim 7.0

---

### vs

pygments.styles.vs
~~~~~~~~~~~~~~~~~~

Simple style with MS Visual Studio colors.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### VisualStudioStyle

---

### xcode

pygments.styles.xcode
~~~~~~~~~~~~~~~~~~~~~

Style similar to the `Xcode` default theme.

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### XcodeStyle

Style similar to the Xcode default colouring theme.

---

### zenburn

pygments.styles.zenburn
~~~~~~~~~~~~~~~~~~~~~~~

Low contrast color scheme Zenburn.

See: https://kippura.org/zenburnpage/
     https://github.com/jnurmine/Zenburn

:copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
:license: BSD, see LICENSE for details.

#### Classes

##### ZenburnStyle

Low contrast Zenburn style.

---

### .!28384!__init__

---

### .!28390!_mapping

---

### .!28403!algol

---

### .!28407!algol_nu

---

### .!28414!arduino

---

### .!28419!autumn

---

### .!28424!borland

---

### .!28433!coffee

---

### .!28436!colorful

---

### .!28441!default

---

### .!28446!dracula

---

### .!28451!emacs

---

### .!28455!friendly

---

### .!28459!friendly_grayscale

---

### .!28464!fruity

---

### .!28468!gh_dark

---

### .!28473!gruvbox

---

### .!28482!inkpot

---

### .!28487!lightbulb

---

### .!28493!lilypond

---

### .!28497!lovelace

---

### .!28502!manni

---

### .!28507!material

---

### .!28513!monokai

---

### .!28518!murphy

---

### .!28522!native

---

### .!28531!onedark

---

### .!28534!paraiso_dark

---

### .!28539!paraiso_light

---

### .!28543!pastie

---

### .!28547!perldoc

---

### .!28552!rainbow_dash

---

### .!28566!solarized

---

### .!28571!staroffice

---

### .!28576!stata_dark

---

### .!28581!stata_light

---

### .!28585!tango

---

### .!28605!xcode

---

### .!28608!zenburn

---

### .!28662!mode

---

### .!28613!files

---

### .!28617!parsing

---

### .!28623!handle_ipynb_magics

---

### .!28628!concurrency

---

### .!28632!rusty

---

### .!28638!cache

---

### .!28643!__init__

---

### .!28648!brackets

---

### .!28652!_width_table

---

### .!28658!lines

---

### .!28667!ranges

---

### .!28672!debug

---

### .!28675!trans

---

### .!28681!nodes

---

### .!28685!linegen

---

### .!28690!__main__

---

### .!28694!report

---

### .!28700!strings

---

### .!28704!const

---

### .!28707!output

---

### .!28712!numerics

---

### .!28716!comments

---

### .!28721!schema

---

### .!28760!cffi

---

### .!28773!csv

---

### .!28777!cuda

---

### .!28797!fs

---

### .!28801!ipc

---

### .!28806!json

---

### .!28811!jvm

---

### .!28734!__init__

---

### .!28819!orc

---

### .!28834!util

---

### .!28741!benchmark

---

### .!28746!acero

---

### .!28750!_compute_docstrings

---

### .!28756!_generated_version

---

### .!28764!compute

---

### .!28768!conftest

---

### .!28781!dataset

---

### .!28787!feather

---

### .!28789!flight

---

### .!28815!substrait

---

### .!28824!pandas_compat

---

### .!28827!types

---

### .!28847!__init__

---

### .!28853!buffer

---

### .!28857!column

---

### .!28860!dataframe

---

### .!28866!from_dataframe

---

### .!28877!core

---

### .!28872!__init__

---

### .!28883!encryption

---

### .!29151!util

---

### .!28894!arrow_16597

---

### .!28899!arrow_39313

---

### .!28904!arrow_7980

---

### .!28908!conftest

---

### .!28913!strategies

---

### .!28917!pandas_examples

---

### .!28920!pandas_threaded_import

---

### .!28925!read_record_batch

---

### .!28929!test_acero

---

### .!28935!test_adhoc_memory_leak

---

### .!28938!test_array

---

### .!28943!test_builder

---

### .!28948!test_cffi

---

### .!28956!test_compute

---

### .!28961!test_convert_builtin

---

### .!28966!test_cpp_internals

---

### .!28973!test_csv

---

### .!28976!test_cuda

---

### .!28981!test_cuda_numba_interop

---

### .!28986!test_cython

---

### .!28992!test_dataset

---

### .!28997!test_dataset_encryption

---

### .!29002!test_deprecations

---

### .!29008!test_device

---

### .!29013!test_dlpack

---

### .!29017!test_exec_plan

---

### .!29022!test_extension_type

---

### .!29026!test_feather

---

### .!29033!test_flight

---

### .!29038!test_flight_async

---

### .!29042!test_fs

---

### .!29048!test_gandiva

---

### .!29053!test_gdb

---

### .!29058!test_io

---

### .!29061!test_ipc

---

### .!29067!test_json

---

### .!29073!test_jvm

---

### .!29077!test_memory

---

### .!29081!test_misc

---

### .!29085!test_orc

---

### .!29090!test_pandas

---

### .!29094!test_scalars

---

### .!29100!test_schema

---

### .!29105!test_sparse_tensor

---

### .!29111!test_strategies

---

### .!29115!test_substrait

---

### .!29120!test_table

---

### .!29125!test_tensor

---

### .!29130!test_types

---

### .!29135!test_udf

---

### .!29139!test_util

---

### .!29144!test_without_numpy

---

### .!29155!wsgi_examples

---

### .!29162!__init__

---

### .!29166!test_conversion

---

### .!29175!test_interchange_spec

---

### .!29178!__init__

---

### .!29186!common

---

### .!29190!conftest

---

### .!29195!encryption

---

### .!29200!test_basic

---

### .!29204!test_compliant_nested_type

---

### .!29207!test_data_types

---

### .!29211!test_dataset

---

### .!29217!test_datetime

---

### .!29223!test_encryption

---

### .!29231!test_metadata

---

### .!29236!test_pandas

---

### .!29240!test_parquet_file

---

### .!29245!test_parquet_writer

---

### .!29250!__init__

---

### .!29254!docscrape

---

### .!29259!version

---

### .!29277!any

---

### .!29266!__init__

---

### .!29271!descriptor

---

### .!29296!descriptor_database

---

### .!29301!descriptor_pool

---

### .!29306!duration

---

### .!29392!json_format

---

### .!29399!message

---

### .!29404!message_factory

---

### .!29408!proto_json

---

### .!29413!proto

---

### .!29418!proto_builder

---

### .!29432!reflection

---

### .!29434!runtime_version

---

### .!29439!service

---

### .!29444!service_reflection

---

### .!29447!symbol_database

---

### .!29458!text_encoding

---

### .!29462!text_format

---

### .!29468!timestamp

---

### .!29473!unknown_fields

---

### .!29478!api_pb2

---

### .!29490!any_pb2

---

### .!29494!descriptor_pb2

---

### .!29500!duration_pb2

---

### .!29505!empty_pb2

---

### .!29507!field_mask_pb2

---

### .!29511!source_context_pb2

---

### .!29517!struct_pb2

---

### .!29521!timestamp_pb2

---

### .!29526!type_pb2

---

### .!29532!wrappers_pb2

---

### .!29290!plugin_pb2

---

### .!29312!__init__

---

### .!29317!_parameterized

---

### .!29321!api_implementation

---

### .!29325!builder

---

### .!29330!containers

---

### .!29336!decoder

---

### .!29341!encoder

---

### .!29346!enum_type_wrapper

---

### .!29349!extension_dict

---

### .!29354!field_mask

---

### .!29359!message_listener

---

### .!29366!python_edition_defaults

---

### .!29370!python_message

---

### .!29374!testing_refleaks

---

### .!29380!type_checkers

---

### .!29384!well_known_types

---

### .!29388!wire_format

---

### .!29428!cpp_message

---

### .!29540!__init__

---

### .!29546!_agent

---

### .!29553!_agent_id

---

### .!29558!_agent_instantiation

---

### .!29562!_agent_metadata

---

### .!29568!_agent_proxy

---

### .!29574!_agent_runtime

---

### .!29578!_agent_type

---

### .!29583!_base_agent

---

### .!29588!_cache_store

---

### .!29595!_cancellation_token

---

### .!29598!_closure_agent

---

### .!29603!_component_config

---

### .!29606!_constants

---

### .!29610!_default_subscription

---

### .!29616!_default_topic

---

### .!29619!_function_utils

---

### .!29626!_image

---

### .!29630!_intervention

---

### .!29636!_message_context

---

### .!29642!_message_handler_context

---

### .!29645!_queue

---

### .!29652!_routed_agent

---

### .!29655!_runtime_impl_helpers

---

### .!29658!_serialization

---

### .!29662!_single_threaded_agent_runtime

---

### .!29668!_subscription

---

### .!29671!_subscription_context

---

### .!29675!_topic

---

### .!29680!_type_helpers

---

### .!29684!_type_prefix_subscription

---

### .!29689!_type_subscription

---

### .!29694!_types

---

### .!29699!exceptions

---

### .!29705!logging

---

### .!29709!__init__

---

### .!29713!_constants

---

### .!29719!_genai

---

### .!29724!_propagation

---

### .!29730!_tracing

---

### .!29734!_tracing_config

---

### .!29737!__init__

---

### .!29745!_base

---

### .!29750!_func_with_reqs

---

### .!29754!__init__

---

### .!29760!_base_memory

---

### .!29764!_list_memory

---

### .!29772!__init__

---

### .!29775!_buffered_chat_completion_context

---

### .!29780!_chat_completion_context

---

### .!29787!_head_and_tail_chat_completion_context

---

### .!29792!_token_limited_chat_completion_context

---

### .!29797!_unbounded_chat_completion_context

---

### .!29801!__init__

---

### .!29807!_model_client

---

### .!29812!_types

---

### .!29818!__init__

---

### .!29823!_caller_loop

---

### .!29828!_tool_agent

---

### .!29832!__init__

---

### .!29837!_base

---

### .!29843!_function_tool

---

### .!29850!_static_workbench

---

### .!29854!_workbench

---

### .!29860!__init__

---

### .!29863!_json_to_pydantic

---

### .!29867!_load_json

---

### _callers

Call loop machinery

#### Fonctions

##### run_old_style_hookwrapper

backward compatibility wrapper to run a old style hookwrapper as a wrapper

**Param√®tres :**

- `hook_impl`
- `hook_name`
- `args`

##### _raise_wrapfail

**Param√®tres :**

- `wrap_controller`
- `msg`

##### _warn_teardown_exception

**Param√®tres :**

- `hook_name`
- `hook_impl`
- `e`

##### _multicall

Execute a call into multiple python functions/methods and return the
result(s).

``caller_kwargs`` comes from HookCaller.__call__().

**Param√®tres :**

- `hook_name`
- `hook_impls`
- `caller_kwargs`
- `firstresult`

---

### _hooks

Internal hook annotation, representation and calling machinery.

#### Classes

##### HookspecOpts

Options for a hook specification.

##### HookimplOpts

Options for a hook implementation.

##### HookspecMarker

Decorator for marking functions as hook specifications.

Instantiate it with a project_name to get a decorator.
Calling :meth:`PluginManager.add_hookspecs` later will discover all marked
functions if the :class:`PluginManager` uses the same project name.

**M√©thodes :**

- `__init__()`
- `__call__()`
- `__call__()`
- `__call__()`

##### HookimplMarker

Decorator for marking functions as hook implementations.

Instantiate it with a ``project_name`` to get a decorator.
Calling :meth:`PluginManager.register` later will discover all marked
functions if the :class:`PluginManager` uses the same project name.

**M√©thodes :**

- `__init__()`
- `__call__()`
- `__call__()`
- `__call__()`

##### HookRelay

Hook holder object for performing 1:N hook calls where N is the number
of registered plugins.

**M√©thodes :**

- `__init__()`

##### HookCaller

A caller of all registered implementations of a hook specification.

**M√©thodes :**

- `__init__()`
- `has_spec()`
- `set_specification()`
- `is_historic()`
- `_remove_plugin()`
- `get_hookimpls()`
- `_add_hookimpl()`
- `__repr__()`
- `_verify_all_args_are_provided()`
- `__call__()`
- `call_historic()`
- `call_extra()`
- `_maybe_apply_history()`

##### _SubsetHookCaller

A proxy to another HookCaller which manages calls to all registered
plugins except the ones from remove_plugins.

**M√©thodes :**

- `__init__()`
- `_hookimpls()`
- `spec()`
- `_call_history()`
- `__repr__()`

##### HookImpl

A hook implementation in a :class:`HookCaller`.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### HookSpec

**M√©thodes :**

- `__init__()`

#### Fonctions

##### normalize_hookimpl_opts

**Param√®tres :**

- `opts`

##### varnames

Return tuple of positional and keywrord argument names for a function,
method, class or callable.

In case of a class, its ``__init__`` method is considered.
For methods the ``self`` parameter is not included.

**Param√®tres :**

- `func`

##### __init__

**Param√®tres :**

- `project_name`

##### __call__

**Param√®tres :**

- `function`
- `firstresult`
- `historic`
- `warn_on_impl`
- `warn_on_impl_args`

##### __call__

**Param√®tres :**

- `function`
- `firstresult`
- `historic`
- `warn_on_impl`
- `warn_on_impl_args`

##### __call__

If passed a function, directly sets attributes on the function
which will make it discoverable to :meth:`PluginManager.add_hookspecs`.

If passed no function, returns a decorator which can be applied to a
function later using the attributes supplied.

:param firstresult:
    If ``True``, the 1:N hook call (N being the number of registered
    hook implementation functions) will stop at I<=N when the I'th
    function returns a non-``None`` result. See :ref:`firstresult`.

:param historic:
    If ``True``, every call to the hook will be memorized and replayed
    on plugins registered after the call was made. See :ref:`historic`.

:param warn_on_impl:
    If given, every implementation of this hook will trigger the given
    warning. See :ref:`warn_on_impl`.

:param warn_on_impl_args:
    If given, every implementation of this hook which requests one of
    the arguments in the dict will trigger the corresponding warning.
    See :ref:`warn_on_impl`.

    .. versionadded:: 1.5

**Param√®tres :**

- `function`
- `firstresult`
- `historic`
- `warn_on_impl`
- `warn_on_impl_args`

##### __init__

**Param√®tres :**

- `project_name`

##### __call__

**Param√®tres :**

- `function`
- `hookwrapper`
- `optionalhook`
- `tryfirst`
- `trylast`
- `specname`
- `wrapper`

##### __call__

**Param√®tres :**

- `function`
- `hookwrapper`
- `optionalhook`
- `tryfirst`
- `trylast`
- `specname`
- `wrapper`

##### __call__

If passed a function, directly sets attributes on the function
which will make it discoverable to :meth:`PluginManager.register`.

If passed no function, returns a decorator which can be applied to a
function later using the attributes supplied.

:param optionalhook:
    If ``True``, a missing matching hook specification will not result
    in an error (by default it is an error if no matching spec is
    found). See :ref:`optionalhook`.

:param tryfirst:
    If ``True``, this hook implementation will run as early as possible
    in the chain of N hook implementations for a specification. See
    :ref:`callorder`.

:param trylast:
    If ``True``, this hook implementation will run as late as possible
    in the chain of N hook implementations for a specification. See
    :ref:`callorder`.

:param wrapper:
    If ``True`` ("new-style hook wrapper"), the hook implementation
    needs to execute exactly one ``yield``. The code before the
    ``yield`` is run early before any non-hook-wrapper function is run.
    The code after the ``yield`` is run after all non-hook-wrapper
    functions have run. The ``yield`` receives the result value of the
    inner calls, or raises the exception of inner calls (including
    earlier hook wrapper calls). The return value of the function
    becomes the return value of the hook, and a raised exception becomes
    the exception of the hook. See :ref:`hookwrapper`.

:param hookwrapper:
    If ``True`` ("old-style hook wrapper"), the hook implementation
    needs to execute exactly one ``yield``. The code before the
    ``yield`` is run early before any non-hook-wrapper function is run.
    The code after the ``yield`` is run after all non-hook-wrapper
    function have run  The ``yield`` receives a :class:`Result` object
    representing the exception or result outcome of the inner calls
    (including earlier hook wrapper calls). This option is mutually
    exclusive with ``wrapper``. See :ref:`old_style_hookwrapper`.

:param specname:
    If provided, the given name will be used instead of the function
    name when matching this hook implementation to a hook specification
    during registration. See :ref:`specname`.

.. versionadded:: 1.2.0
    The ``wrapper`` parameter.

**Param√®tres :**

- `function`
- `hookwrapper`
- `optionalhook`
- `tryfirst`
- `trylast`
- `specname`
- `wrapper`

##### __init__

:meta private:

##### __init__

:meta private:

**Param√®tres :**

- `name`
- `hook_execute`
- `specmodule_or_class`
- `spec_opts`

##### has_spec

##### set_specification

**Param√®tres :**

- `specmodule_or_class`
- `spec_opts`

##### is_historic

Whether this caller is :ref:`historic <historic>`.

##### _remove_plugin

**Param√®tres :**

- `plugin`

##### get_hookimpls

Get all registered hook implementations for this hook.

##### _add_hookimpl

Add an implementation to the callback chain.

**Param√®tres :**

- `hookimpl`

##### __repr__

##### _verify_all_args_are_provided

**Param√®tres :**

- `kwargs`

##### __call__

Call the hook.

Only accepts keyword arguments, which should match the hook
specification.

Returns the result(s) of calling all registered plugins, see
:ref:`calling`.

##### call_historic

Call the hook with given ``kwargs`` for all registered plugins and
for all plugins which will be registered afterwards, see
:ref:`historic`.

:param result_callback:
    If provided, will be called for each non-``None`` result obtained
    from a hook implementation.

**Param√®tres :**

- `result_callback`
- `kwargs`

##### call_extra

Call the hook with some additional temporarily participating
methods using the specified ``kwargs`` as call parameters, see
:ref:`call_extra`.

**Param√®tres :**

- `methods`
- `kwargs`

##### _maybe_apply_history

Apply call history to a new hookimpl if it is marked as historic.

**Param√®tres :**

- `method`

##### __init__

**Param√®tres :**

- `orig`
- `remove_plugins`

##### _hookimpls

##### spec

##### _call_history

##### __repr__

##### __init__

:meta private:

**Param√®tres :**

- `plugin`
- `plugin_name`
- `function`
- `hook_impl_opts`

##### __repr__

##### __init__

**Param√®tres :**

- `namespace`
- `name`
- `opts`

##### setattr_hookspec_opts

**Param√®tres :**

- `func`

##### setattr_hookimpl_opts

**Param√®tres :**

- `func`

##### __getattr__

**Param√®tres :**

- `name`

---

### _manager

#### Classes

##### PluginValidationError

Plugin failed validation.

:param plugin: The plugin which failed validation.
:param message: Error message.

**M√©thodes :**

- `__init__()`

##### DistFacade

Emulate a pkg_resources Distribution

**M√©thodes :**

- `__init__()`
- `project_name()`
- `__getattr__()`
- `__dir__()`

##### PluginManager

Core class which manages registration of plugin objects and 1:N hook
calling.

You can register new hooks by calling :meth:`add_hookspecs(module_or_class)
<PluginManager.add_hookspecs>`.

You can register plugin objects (which contain hook implementations) by
calling :meth:`register(plugin) <PluginManager.register>`.

For debugging purposes you can call :meth:`PluginManager.enable_tracing`
which will subsequently send debug information to the trace helper.

:param project_name:
    The short project name. Prefer snake case. Make sure it's unique!

**M√©thodes :**

- `__init__()`
- `_hookexec()`
- `register()`
- `parse_hookimpl_opts()`
- `unregister()`
- `set_blocked()`
- `is_blocked()`
- `unblock()`
- `add_hookspecs()`
- `parse_hookspec_opts()`
- `get_plugins()`
- `is_registered()`
- `get_canonical_name()`
- `get_plugin()`
- `has_plugin()`
- `get_name()`
- `_verify_hook()`
- `check_pending()`
- `load_setuptools_entrypoints()`
- `list_plugin_distinfo()`
- `list_name_plugin()`
- `get_hookcallers()`
- `add_hookcall_monitoring()`
- `enable_tracing()`
- `subset_hook_caller()`

#### Fonctions

##### _warn_for_function

**Param√®tres :**

- `warning`
- `function`

##### _formatdef

**Param√®tres :**

- `func`

##### __init__

**Param√®tres :**

- `plugin`
- `message`

##### __init__

**Param√®tres :**

- `dist`

##### project_name

##### __getattr__

**Param√®tres :**

- `attr`
- `default`

##### __dir__

##### __init__

**Param√®tres :**

- `project_name`

##### _hookexec

**Param√®tres :**

- `hook_name`
- `methods`
- `kwargs`
- `firstresult`

##### register

Register a plugin and return its name.

:param name:
    The name under which to register the plugin. If not specified, a
    name is generated using :func:`get_canonical_name`.

:returns:
    The plugin name. If the name is blocked from registering, returns
    ``None``.

If the plugin is already registered, raises a :exc:`ValueError`.

**Param√®tres :**

- `plugin`
- `name`

##### parse_hookimpl_opts

Try to obtain a hook implementation from an item with the given name
in the given plugin which is being searched for hook impls.

:returns:
    The parsed hookimpl options, or None to skip the given item.

This method can be overridden by ``PluginManager`` subclasses to
customize how hook implementation are picked up. By default, returns the
options for items decorated with :class:`HookimplMarker`.

**Param√®tres :**

- `plugin`
- `name`

##### unregister

Unregister a plugin and all of its hook implementations.

The plugin can be specified either by the plugin object or the plugin
name. If both are specified, they must agree.

Returns the unregistered plugin, or ``None`` if not found.

**Param√®tres :**

- `plugin`
- `name`

##### set_blocked

Block registrations of the given name, unregister if already registered.

**Param√®tres :**

- `name`

##### is_blocked

Return whether the given plugin name is blocked.

**Param√®tres :**

- `name`

##### unblock

Unblocks a name.

Returns whether the name was actually blocked.

**Param√®tres :**

- `name`

##### add_hookspecs

Add new hook specifications defined in the given ``module_or_class``.

Functions are recognized as hook specifications if they have been
decorated with a matching :class:`HookspecMarker`.

**Param√®tres :**

- `module_or_class`

##### parse_hookspec_opts

Try to obtain a hook specification from an item with the given name
in the given module or class which is being searched for hook specs.

:returns:
    The parsed hookspec options for defining a hook, or None to skip the
    given item.

This method can be overridden by ``PluginManager`` subclasses to
customize how hook specifications are picked up. By default, returns the
options for items decorated with :class:`HookspecMarker`.

**Param√®tres :**

- `module_or_class`
- `name`

##### get_plugins

Return a set of all registered plugin objects.

##### is_registered

Return whether the plugin is already registered.

**Param√®tres :**

- `plugin`

##### get_canonical_name

Return a canonical name for a plugin object.

Note that a plugin may be registered under a different name
specified by the caller of :meth:`register(plugin, name) <register>`.
To obtain the name of a registered plugin use :meth:`get_name(plugin)
<get_name>` instead.

**Param√®tres :**

- `plugin`

##### get_plugin

Return the plugin registered under the given name, if any.

**Param√®tres :**

- `name`

##### has_plugin

Return whether a plugin with the given name is registered.

**Param√®tres :**

- `name`

##### get_name

Return the name the plugin is registered under, or ``None`` if
is isn't.

**Param√®tres :**

- `plugin`

##### _verify_hook

**Param√®tres :**

- `hook`
- `hookimpl`

##### check_pending

Verify that all hooks which have not been verified against a
hook specification are optional, otherwise raise
:exc:`PluginValidationError`.

##### load_setuptools_entrypoints

Load modules from querying the specified setuptools ``group``.

:param group:
    Entry point group to load plugins.
:param name:
    If given, loads only plugins with the given ``name``.

:return:
    The number of plugins loaded by this call.

**Param√®tres :**

- `group`
- `name`

##### list_plugin_distinfo

Return a list of (plugin, distinfo) pairs for all
setuptools-registered plugins.

##### list_name_plugin

Return a list of (name, plugin) pairs for all registered plugins.

##### get_hookcallers

Get all hook callers for the specified plugin.

:returns:
    The hook callers, or ``None`` if ``plugin`` is not registered in
    this plugin manager.

**Param√®tres :**

- `plugin`

##### add_hookcall_monitoring

Add before/after tracing functions for all hooks.

Returns an undo function which, when called, removes the added tracers.

``before(hook_name, hook_impls, kwargs)`` will be called ahead
of all hook calls and receive a hookcaller instance, a list
of HookImpl instances and the keyword arguments for the hook call.

``after(outcome, hook_name, hook_impls, kwargs)`` receives the
same arguments as ``before`` but also a :class:`~pluggy.Result` object
which represents the result of the overall hook call.

**Param√®tres :**

- `before`
- `after`

##### enable_tracing

Enable tracing of hook calls.

Returns an undo function which, when called, removes the added tracing.

##### subset_hook_caller

Return a proxy :class:`~pluggy.HookCaller` instance for the named
method which manages calls to all registered plugins except the ones
from remove_plugins.

**Param√®tres :**

- `name`
- `remove_plugins`

##### traced_hookexec

**Param√®tres :**

- `hook_name`
- `hook_impls`
- `caller_kwargs`
- `firstresult`

##### undo

##### before

**Param√®tres :**

- `hook_name`
- `methods`
- `kwargs`

##### after

**Param√®tres :**

- `outcome`
- `hook_name`
- `methods`
- `kwargs`

---

### _result

Hook wrapper "result" utilities.

#### Classes

##### HookCallError

Hook was called incorrectly.

##### Result

An object used to inspect and set the result in a :ref:`hook wrapper
<hookwrappers>`.

**M√©thodes :**

- `__init__()`
- `excinfo()`
- `exception()`
- `from_call()`
- `force_result()`
- `force_exception()`
- `get_result()`

#### Fonctions

##### __init__

:meta private:

**Param√®tres :**

- `result`
- `exception`

##### excinfo

:meta private:

##### exception

:meta private:

##### from_call

:meta private:

**Param√®tres :**

- `cls`
- `func`

##### force_result

Force the result(s) to ``result``.

If the hook was marked as a ``firstresult`` a single value should
be set, otherwise set a (modified) list of results. Any exceptions
found during invocation will be deleted.

This overrides any previous result or exception.

**Param√®tres :**

- `result`

##### force_exception

Force the result to fail with ``exception``.

This overrides any previous result or exception.

.. versionadded:: 1.1.0

**Param√®tres :**

- `exception`

##### get_result

Get the result(s) for this hook call.

If the hook was marked as a ``firstresult`` only a single value
will be returned, otherwise a list of results.

---

### _tracing

Tracing utils

#### Classes

##### TagTracer

**M√©thodes :**

- `__init__()`
- `get()`
- `_format_message()`
- `_processmessage()`
- `setwriter()`
- `setprocessor()`

##### TagTracerSub

**M√©thodes :**

- `__init__()`
- `__call__()`
- `get()`

#### Fonctions

##### __init__

##### get

**Param√®tres :**

- `name`

##### _format_message

**Param√®tres :**

- `tags`
- `args`

##### _processmessage

**Param√®tres :**

- `tags`
- `args`

##### setwriter

**Param√®tres :**

- `writer`

##### setprocessor

**Param√®tres :**

- `tags`
- `processor`

##### __init__

**Param√®tres :**

- `root`
- `tags`

##### __call__

##### get

**Param√®tres :**

- `name`

---

### _version

---

### _warnings

#### Classes

##### PluggyWarning

Base class for all warnings emitted by pluggy.

##### PluggyTeardownRaisedWarning

A plugin raised an exception during an :ref:`old-style hookwrapper
<old_style_hookwrappers>` teardown.

Such exceptions are not handled by pluggy, and may cause subsequent
teardowns to be executed at unexpected times, or be skipped entirely.

This is an issue in the plugin implementation.

If the exception is unintended, fix the underlying cause.

If the exception is intended, switch to :ref:`new-style hook wrappers
<hookwrappers>`, or use :func:`result.force_exception()
<pluggy.Result.force_exception>` to set the exception instead of raising.

---

### .!29873!__init__

---

### .!29876!_callers

---

### .!29883!_hooks

---

### .!29887!_manager

---

### .!29892!_result

---

### .!29897!_tracing

---

### .!29903!_version

---

### .!29906!_warnings

---

### .!29918!MpoImagePlugin

---

### .!29923!ImageMode

---

### .!29929!PngImagePlugin

---

### .!29933!AvifImagePlugin

---

### .!29939!XbmImagePlugin

---

### .!29942!PcxImagePlugin

---

### .!29947!SunImagePlugin

---

### .!29953!ImageFile

---

### .!29957!SpiderImagePlugin

---

### .!29962!TarIO

---

### .!29966!MpegImagePlugin

---

### .!29970!BdfFontFile

---

### .!29975!GribStubImagePlugin

---

### .!29980!ImageStat

---

### .!29985!PixarImagePlugin

---

### .!29992!GimpPaletteFile

---

### .!29997!ImageColor

---

### .!30001!QoiImagePlugin

---

### .!30008!ContainerIO

---

### .!30012!_typing

---

### .!30016!MspImagePlugin

---

### .!30021!MicImagePlugin

---

### .!30025!_version

---

### .!30029!ImtImagePlugin

---

### .!30034!GifImagePlugin

---

### .!30038!PalmImagePlugin

---

### .!30043!ImageQt

---

### .!30048!ImageMath

---

### .!30052!PaletteFile

---

### .!30056!FontFile

---

### .!30062!PdfParser

---

### .!30065!ExifTags

---

### .!30069!ImageCms

---

### .!30074!FpxImagePlugin

---

### .!30079!ImageChops

---

### .!30084!_deprecate

---

### .!30088!ImageFilter

---

### .!30093!BufrStubImagePlugin

---

### .!30098!PSDraw

---

### .!30101!PcdImagePlugin

---

### .!30106!ImageDraw2

---

### .!30110!ImagePath

---

### .!30115!DcxImagePlugin

---

### .!30121!__init__

---

### .!30127!JpegPresets

---

### .!30134!Hdf5StubImagePlugin

---

### .!30139!features

---

### .!30145!ImageDraw

---

### .!30150!GimpGradientFile

---

### .!30155!ImageWin

---

### .!30159!IcoImagePlugin

---

### .!30164!_tkinter_finder

---

### .!30168!EpsImagePlugin

---

### .!30173!TgaImagePlugin

---

### .!30178!ImageMorph

---

### .!30183!Jpeg2KImagePlugin

---

### .!30186!WalImageFile

---

### .!30191!PcfFontFile

---

### .!30197!BlpImagePlugin

---

### .!30201!ImageTk

---

### .!30205!GbrImagePlugin

---

### .!30209!ImageOps

---

### .!30216!ImageShow

---

### .!30221!PdfImagePlugin

---

### .!30226!ImageEnhance

---

### .!30232!WmfImagePlugin

---

### .!30236!ImageGrab

---

### .!30241!WebPImagePlugin

---

### .!30247!FliImagePlugin

---

### .!30250!TiffTags

---

### .!30256!CurImagePlugin

---

### .!30260!GdImageFile

---

### .!30263!_util

---

### .!30270!TiffImagePlugin

---

### .!30275!IptcImagePlugin

---

### .!30279!ImagePalette

---

### .!30284!BmpImagePlugin

---

### .!30290!ImageTransform

---

### .!30297!IcnsImagePlugin

---

### .!30304!McIdasImagePlugin

---

### .!30311!FitsImagePlugin

---

### .!30317!XpmImagePlugin

---

### .!30321!DdsImagePlugin

---

### .!30326!_binary

---

### .!30332!ImageSequence

---

### .!30336!Image

---

### .!30341!__main__

---

### .!30347!XVThumbImagePlugin

---

### .!30351!SgiImagePlugin

---

### .!30355!ImageFont

---

### .!30360!report

---

### .!30366!ImImagePlugin

---

### .!30371!PsdImagePlugin

---

### .!30376!JpegImagePlugin

---

### .!30379!PpmImagePlugin

---

### .!30383!FtexImagePlugin

---

### .!30433!tags

---

### .!30391!__init__

---

### .!30394!requirements

---

### .!30399!_elffile

---

### .!30404!specifiers

---

### .!30409!_manylinux

---

### .!30414!_musllinux

---

### .!30420!_parser

---

### .!30425!_structures

---

### .!30429!_tokenizer

---

### .!30439!markers

---

### .!30444!metadata

---

### .!30447!utils

---

### .!30452!version

---

### .!30457!__init__

---

### .!30461!_spdx

---

### .!30474!__init__

---

### .!30481!_adapters

---

### .!30485!_collections

---

### .!30492!_compat

---

### .!30496!_functools

---

### .!30501!_itertools

---

### .!30505!_meta

---

### .!30509!_text

---

### .!30516!_typing

---

### .!30520!diagnose

---

### .!30535!py39

---

### .!30532!py311

---

### .!30542!_array_api_info

---

### .!30547!conftest

---

### .!30550!version

---

### .!30557!_globals

---

### .!30561!_configtool

---

### .!30567!__init__

---

### .!30572!__config__

---

### .!30575!dtypes

---

### .!30579!exceptions

---

### .!30584!_distributor_init

---

### .!30589!ctypeslib

---

### .!30593!matlib

---

### .!30599!_expired_attrs_2_0

---

### .!30604!_pytesttester

---

### .!30648!log

---

### .!30679!core

---

### .!30610!unixccompiler

---

### .!30614!numpy_distribution

---

### .!30617!conv_template

---

### .!30624!cpuinfo

---

### .!30629!ccompiler

---

### .!30634!msvc9compiler

---

### .!30640!npy_pkg_config

---

### .!30643!misc_util

---

### .!30654!line_endings

---

### .!30657!lib2def

---

### .!30665!pathccompiler

---

### .!30669!system_info

---

### .!30674!__init__

---

### .!30682!exec_command

---

### .!30689!from_template

---

### .!30693!fujitsuccompiler

---

### .!30696!mingw32ccompiler

---

### .!30701!extension

---

### .!30705!msvccompiler

---

### .!30710!armccompiler

---

### .!30716!intelccompiler

---

### .!30721!_shell_utils

---

### .!30726!ccompiler_opt

---

### .!30732!test_system_info

---

### .!30736!test_ccompiler_opt_conf

---

### .!30743!test_mingw32ccompiler

---

### .!30746!test_from_template

---

### .!30756!test_log

---

### .!30760!test_fcompiler_intel

---

### .!30765!utilities

---

### .!30770!test_misc_util

---

### .!30776!test_fcompiler

---

### .!30780!test_build_ext

---

### .!30785!test_shell_utils

---

### .!30790!test_exec_command

---

### .!30793!test_npy_pkg_config

---

### .!30796!test_fcompiler_nagfor

---

### .!30801!test_ccompiler_opt

---

### .!30806!test_fcompiler_gnu

---

### .!30811!gnu

---

### .!30826!none

---

### .!30832!nag

---

### .!30835!pg

---

### .!30817!compaq

---

### .!30821!intel

---

### .!30842!ibm

---

### .!30846!sun

---

### .!30849!nv

---

### .!30853!lahey

---

### .!30858!__init__

---

### .!30862!g95

---

### .!30867!arm

---

### .!30873!mips

---

### .!30875!hpux

---

### .!30882!environment

---

### .!30885!pathf95

---

### .!30889!fujitsu

---

### .!30894!absoft

---

### .!30898!vast

---

### .!30902!build

---

### .!30907!config_compiler

---

### .!30910!build_ext

---

### .!30915!config

---

### .!30920!install_headers

---

### .!30924!build_py

---

### .!30930!build_src

---

### .!30936!__init__

---

### .!30943!sdist

---

### .!30948!build_scripts

---

### .!30955!bdist_rpm

---

### .!30959!install_clib

---

### .!30963!build_clib

---

### .!30968!autodist

---

### .!30972!egg_info

---

### .!30977!install

---

### .!30981!develop

---

### .!30985!install_data

---

### .!30990!_pep440

---

### .!30996!__init__

---

### .!30999!_convertions

---

### .!31005!_inspect

---

### .!31010!__init__

---

### .!31017!py3k

---

### .!31022!__init__

---

### .!31033!__init__

---

### .!31035!umath

---

### .!31043!fromnumeric

---

### .!31048!_dtype

---

### .!31054!_internal

---

### .!31060!multiarray

---

### .!31066!records

---

### .!31072!__init__

---

### .!31075!overrides

---

### .!31079!getlimits

---

### .!31085!_dtype_ctypes

---

### .!31088!defchararray

---

### .!31092!shape_base

---

### .!31098!numeric

---

### .!31101!function_base

---

### .!31107!einsumfunc

---

### .!31113!numerictypes

---

### .!31117!arrayprint

---

### .!31121!_utils

---

### .!31126!_multiarray_umath

---

### .!31132!__init__

---

### .!31136!_linalg

---

### .!31139!linalg

---

### .!31144!test_linalg

---

### .!31148!test_deprecations

---

### .!31159!test_regression

---

### .!31179!core

---

### .!31165!extras

---

### .!31167!testutils

---

### .!31175!__init__

---

### .!31184!timer_comparison

---

### .!31188!mrecords

---

### .!31193!test_old_ma

---

### .!31197!test_core

---

### .!31203!test_deprecations

---

### .!31215!test_subclassing

---

### .!31220!test_extras

---

### .!31225!test_arrayobject

---

### .!31230!test_mrecords

---

### .!31233!test_regression

---

### .!31239!umath

---

### .!31246!fromnumeric

---

### .!31250!_add_newdocs

---

### .!31256!_dtype

---

### .!31260!_methods

---

### .!31265!_internal

---

### .!31271!_string_helpers

---

### .!31275!multiarray

---

### .!31281!_asarray

---

### .!31284!records

---

### .!31290!_add_newdocs_scalars

---

### .!31294!__init__

---

### .!31299!_machar

---

### .!31306!overrides

---

### .!31310!memmap

---

### .!31315!getlimits

---

### .!31321!_dtype_ctypes

---

### .!31328!defchararray

---

### .!31333!shape_base

---

### .!31338!numeric

---

### .!31342!function_base

---

### .!31348!einsumfunc

---

### .!31351!_ufunc_config

---

### .!31355!_exceptions

---

### .!31361!numerictypes

---

### .!31364!cversions

---

### .!31371!_type_aliases

---

### .!31374!strings

---

### .!31378!printoptions

---

### .!31382!arrayprint

---

### .!31390!test_numerictypes

---

### .!31395!test_scalar_methods

---

### .!31399!test_scalarmath

---

### .!31403!test_item_selection

---

### .!31408!test_array_coercion

---

### .!31413!test_limited_api

---

### .!31416!test_casting_floatingpoint_errors

---

### .!31421!test_machar

---

### .!31426!_natype

---

### .!31429!test_unicode

---

### .!31434!test_cpu_dispatcher

---

### .!31439!test_arrayprint

---

### .!31442!test_multithreading

---

### .!31447!test_scalarbuffer

---

### .!31454!test_indexerrors

---

### .!31458!test_print

---

### .!31463!test_half

---

### .!31468!test_arraymethod

---

### .!31473!test_mem_overlap

---

### .!31478!test_shape_base

---

### .!31484!test_hashtable

---

### .!31489!test_array_interface

---

### .!31494!test_deprecations

---

### .!31499!test_errstate

---

### .!31505!test_nep50_promotions

---

### .!31509!test_records

---

### .!31516!test_mem_policy

---

### .!31520!test_simd

---

### .!31523!test_scalarinherit

---

### .!31528!test_indexing

---

### .!31532!test_umath

---

### .!31536!test_numeric

---

### .!31541!test_function_base

---

### .!31547!test_datetime

---

### .!31550!test__exceptions

---

### .!31554!test_extint128

---

### .!31559!test_cython

---

### .!31564!test_umath_complex

---

### .!31568!_locales

---

### .!31573!test_custom_dtypes

---

### .!31577!test_defchararray

---

### .!31582!test_conversion_utils

---

### .!31587!test_arrayobject

---

### .!31590!test_scalarprint

---

### .!31598!test_casting_unittests

---

### .!31602!test_abc

---

### .!31607!test_ufunc

---

### .!31613!test_dtype

---

### .!31618!test_umath_accuracy

---

### .!31623!test_simd_module

---

### .!31628!test_getlimits

---

### .!31634!test_stringdtype

---

### .!31638!test_strings

---

### .!31644!test_dlpack

---

### .!31650!test_einsum

---

### .!31655!test_api

---

### .!31660!test_longdouble

---

### .!31665!test_overrides

---

### .!31671!test_scalar_ctors

---

### .!31675!test_multiarray

---

### .!31681!test_memmap

---

### .!31685!test_nditer

---

### .!31690!test_cpu_features

---

### .!31693!test_protocols

---

### .!31697!test_array_api_info

---

### .!31702!test_argparse

---

### .!31705!test_regression

---

### .!31713!setup

---

### .!31717!setup

---

### .!31723!_char_codes

---

### .!31729!_extended_precision

---

### .!31735!_nbit

---

### .!31738!_ufunc

---

### .!31743!__init__

---

### .!31748!_dtype_like

---

### .!31751!_nbit_base

---

### .!31755!_array_like

---

### .!31759!_scalars

---

### .!31764!_shape

---

### .!31769!_add_docstring

---

### .!31774!_nested_sequence

---

### .!31779!test_warnings

---

### .!31782!test_matlib

---

### .!31787!test_ctypeslib

---

### .!31790!test_lazyloading

---

### .!31794!test__all__

---

### .!31798!test_numpy_version

---

### .!31808!test_reloading

---

### .!31812!test_scripts

---

### .!31818!test_public_api

---

### .!31823!test_configtool

---

### .!31825!test_numpy_config

---

### .!31834!hook-numpy

---

### .!31836!test_pyinstaller

---

### .!31843!__init__

---

### .!31846!pyinstaller-smoke

---

### .!31850!__init__

---

### .!31855!__init__

---

### .!31857!mypy_plugin

---

### .!31865!test_isfile

---

### .!31869!test_typing

---

### .!31873!test_runtime

---

### .!31904!ma

---

### .!32007!mod

---

### .!31883!fromnumeric

---

### .!31887!arithmetic

---

### .!31890!recfunctions

---

### .!31897!ndarray_conversion

---

### .!31899!literal

---

### .!31908!comparisons

---

### .!31911!multiarray

---

### .!31915!array_constructors

---

### .!31920!dtype

---

### .!31922!ndarray_misc

---

### .!31926!ndarray_shape_manipulation

---

### .!31931!ufuncs

---

### .!31935!ufunc_config

---

### .!31939!nditer

---

### .!31943!simple_py3

---

### .!31946!random

---

### .!31950!index_tricks

---

### .!31956!warnings_and_errors

---

### .!31959!arrayterator

---

### .!31963!numeric

---

### .!31968!lib_utils

---

### .!31973!shape

---

### .!31976!modules

---

### .!31978!einsumfunc

---

### .!31981!lib_version

---

### .!31985!scalars

---

### .!31990!array_like

---

### .!31996!simple

---

### .!32000!flatiter

---

### .!32002!numerictypes

---

### .!32012!lib_user_array

---

### .!32014!arrayprint

---

### .!32021!ufunclike

---

### .!32023!bitwise_ops

---

### .!32028!cfuncs

---

### .!32033!_isocbind

---

### .!32035!_src_pyf

---

### .!32040!common_rules

---

### .!32045!crackfortran

---

### .!32050!__main__

---

### .!32053!cb_rules

---

### .!32057!__init__

---

### .!32062!rules

---

### .!32066!f2py2e

---

### .!32068!func2subr

---

### .!32072!__version__

---

### .!32076!symbolic

---

### .!32079!diagnose

---

### .!32085!capi_maps

---

### .!32089!f90mod_rules

---

### .!32092!use_rules

---

### .!32097!auxfuncs

---

### .!32101!_backend

---

### .!32104!__init__

---

### .!32109!_distutils

---

### .!32112!_meson

---

### .!32163!util

---

### .!32118!test_character

---

### .!32122!test_mixed

---

### .!32125!test_return_logical

---

### .!32130!test_assumed_shape

---

### .!32132!test_common

---

### .!32137!test_pyf_src

---

### .!32141!test_kind

---

### .!32146!test_isoc

---

### .!32151!test_array_from_pyobj

---

### .!32154!test_return_real

---

### .!32157!test_symbolic

---

### .!32166!test_size

---

### .!32170!test_callback

---

### .!32176!test_string

---

### .!32178!test_docs

---

### .!32185!__init__

---

### .!32188!test_quoted_character

---

### .!32191!test_parameter

---

### .!32196!test_abstract_interface

---

### .!32198!test_routines

---

### .!32200!test_f2cmap

---

### .!32204!test_semicolon_split

---

### .!32210!test_block_docstring

---

### .!32212!test_return_integer

---

### .!32219!test_return_character

---

### .!32222!test_data

---

### .!32226!test_value_attrspec

---

### .!32232!test_return_complex

---

### .!32235!test_modules

---

### .!32243!test_crackfortran

---

### .!32244!test_f2py2e

---

### .!32249!test_regression

---

### .!32256!__init__

---

### .!32262!overrides

---

### .!32266!print_coercion_tables

---

### .!32271!test_utils

---

### .!32284!extbuild

---

### .!32287!utils

---

### .!32294!_iotools

---

### .!32296!recfunctions

---

### .!32299!mixins

---

### .!32303!_polynomial_impl

---

### .!32309!_user_array_impl

---

### .!32312!_array_utils_impl

---

### .!32318!_arraysetops_impl

---

### .!32321!scimath

---

### .!32325!_stride_tricks_impl

---

### .!32329!_version

---

### .!32333!array_utils

---

### .!32339!_type_check_impl

---

### .!32342!user_array

---

### .!32348!_scimath_impl

---

### .!32352!__init__

---

### .!32358!introspect

---

### .!32362!format

---

### .!32365!_arrayterator_impl

---

### .!32369!npyio

---

### .!32373!_npyio_impl

---

### .!32376!_shape_base_impl

---

### .!32382!_datasource

---

### .!32386!stride_tricks

---

### .!32391!_histograms_impl

---

### .!32395!_arraypad_impl

---

### .!32399!_ufunclike_impl

---

### .!32403!_index_tricks_impl

---

### .!32406!_twodim_base_impl

---

### .!32411!_function_base_impl

---

### .!32416!_nanfunctions_impl

---

### .!32419!_utils_impl

---

### .!32423!test_type_check

---

### .!32427!test_utils

---

### .!32432!test_twodim_base

---

### .!32436!test_polynomial

---

### .!32438!test__iotools

---

### .!32443!test_shape_base

---

### .!32447!test_ufunclike

---

### .!32450!test_index_tricks

---

### .!32458!test_arrayterator

---

### .!32463!test__version

---

### .!32465!test_io

---

### .!32468!test_array_utils

---

### .!32474!test_mixins

---

### .!32476!test_arraysetops

---

### .!32481!test_function_base

---

### .!32486!test_arraypad

---

### .!32488!test_loadtxt

---

### .!32495!test_packbits

---

### .!32498!test__datasource

---

### .!32502!test_stride_tricks

---

### .!32507!test_recfunctions

---

### .!32509!test_nanfunctions

---

### .!32515!test_format

---

### .!32519!test_histograms

---

### .!32522!test_regression

---

### .!32529!_helper

---

### .!32532!_pocketfft

---

### .!32535!__init__

---

### .!32540!helper

---

### .!32543!test_pocketfft

---

### .!32548!test_helper

---

### .!32557!ufuncs

---

### .!32563!_pickle

---

### .!32567!__init__

---

### .!32573!test_generator_mt19937

---

### .!32576!test_randomstate

---

### .!32581!test_direct

---

### .!32586!test_extending

---

### .!32594!test_smoke

---

### .!32598!test_randomstate_regression

---

### .!32601!test_random

---

### .!32607!test_seed_sequence

---

### .!32609!test_generator_mt19937_regressions

---

### .!32612!test_regression

---

### .!32620!parse

---

### .!32623!extending

---

### .!32629!extending

---

### .!32631!extending_distributions

---

### .!32634!__init__

---

### .!32639!defmatrix

---

### .!32642!test_matrix_linalg

---

### .!32645!test_defmatrix

---

### .!32658!test_interaction

---

### .!32662!test_numeric

---

### .!32666!test_masked_matrix

---

### .!32670!test_multiarray

---

### .!32674!test_regression

---

### .!32677!laguerre

---

### .!32683!_polybase

---

### .!32687!polyutils

---

### .!32692!__init__

---

### .!32695!polynomial

---

### .!32698!hermite_e

---

### .!32704!chebyshev

---

### .!32707!legendre

---

### .!32712!hermite

---

### .!32717!test_chebyshev

---

### .!32721!test_hermite_e

---

### .!32726!test_polynomial

---

### .!32734!test_laguerre

---

### .!32739!test_hermite

---

### .!32743!test_legendre

---

### .!32747!test_printing

---

### .!32751!test_classes

---

### .!32754!test_symbol

---

### .!32758!test_polyutils

---

### .!32815!expr

---

### .!32885!this

---

### .!32763!__init__

---

### .!32768!_constants

---

### .!32772!_duration

---

### .!32774!_enum

---

### .!32777!_expression_parsing

---

### .!32783!_namespace

---

### .!32787!_translate

---

### .!32792!_typing_compat

---

### .!32797!_utils

---

### .!32801!dataframe

---

### .!32805!dependencies

---

### .!32810!dtypes

---

### .!32812!exceptions

---

### .!32820!expr_cat

---

### .!32822!expr_dt

---

### .!32826!expr_list

---

### .!32832!expr_name

---

### .!32835!expr_str

---

### .!32841!expr_struct

---

### .!32844!functions

---

### .!32850!group_by

---

### .!32856!schema

---

### .!32859!selectors

---

### .!32863!series

---

### .!32867!series_cat

---

### .!32871!series_dt

---

### .!32876!series_list

---

### .!32878!series_str

---

### .!32881!series_struct

---

### .!32889!translate

---

### .!32892!typing

---

### .!32898!utils

---

### .!32910!expr

---

### .!32908!dataframe

---

### .!32913!group_by

---

### .!32918!namespace

---

### .!32922!selectors

---

### .!32926!series

---

### .!32932!series_cat

---

### .!32936!series_dt

---

### .!32941!series_list

---

### .!32945!series_str

---

### .!32949!series_struct

---

### .!32955!typing

---

### .!32957!utils

---

### .!32972!expr

---

### .!32961!__init__

---

### .!32965!any_namespace

---

### .!32968!dataframe

---

### .!32976!group_by

---

### .!32979!namespace

---

### .!32984!selectors

---

### .!32988!series

---

### .!32990!typing

---

### .!32995!when_then

---

### .!33001!window

---

### .!33018!expr

---

### .!33013!dataframe

---

### .!33023!expr_dt

---

### .!33026!expr_str

---

### .!33033!group_by

---

### .!33035!namespace

---

### .!33039!selectors

---

### .!33044!utils

---

### .!33058!expr

---

### .!33053!dataframe

---

### .!33061!expr_dt

---

### .!33066!expr_list

---

### .!33070!expr_str

---

### .!33075!expr_struct

---

### .!33079!group_by

---

### .!33083!namespace

---

### .!33089!selectors

---

### .!33092!series

---

### .!33095!typing

---

### .!33099!utils

---

### .!33116!expr

---

### .!33110!dataframe

---

### .!33118!expr_dt

---

### .!33127!expr_list

---

### .!33129!expr_str

---

### .!33132!expr_struct

---

### .!33135!group_by

---

### .!33140!namespace

---

### .!33144!selectors

---

### .!33148!series

---

### .!33151!utils

---

### .!33160!dataframe

---

### .!33164!series

---

### .!33176!expr

---

### .!33172!dataframe

---

### .!33180!group_by

---

### .!33185!namespace

---

### .!33189!selectors

---

### .!33192!series

---

### .!33196!series_cat

---

### .!33201!series_dt

---

### .!33204!series_list

---

### .!33209!series_str

---

### .!33213!series_struct

---

### .!33216!typing

---

### .!33220!utils

---

### .!33235!expr

---

### .!33230!dataframe

---

### .!33238!group_by

---

### .!33243!namespace

---

### .!33248!series

---

### .!33251!typing

---

### .!33254!utils

---

### .!33266!expr

---

### .!33262!dataframe

---

### .!33270!expr_dt

---

### .!33273!expr_list

---

### .!33277!expr_str

---

### .!33282!expr_struct

---

### .!33286!group_by

---

### .!33290!namespace

---

### .!33295!selectors

---

### .!33299!utils

---

### .!33307!dataframe

---

### .!33311!expr

---

### .!33314!group_by

---

### .!33318!typing

---

### .!33321!when_then

---

### .!33325!__init__

---

### .!33331!__init__

---

### .!33336!_dtypes

---

### .!33342!_namespace

---

### .!33345!dependencies

---

### .!33351!dtypes

---

### .!33354!selectors

---

### .!33358!typing

---

### .!33382!_url

---

### .!33362!__init__

---

### .!33365!_decode

---

### .!33368!_encode

---

### .!33372!_format

---

### .!33377!_parse

---

### .!33388!__init__

---

### .!33392!_native

---

### _parse

#### Classes

##### _ParsedLine

#### Fonctions

##### parse_lines

**Param√®tres :**

- `path`
- `line_iter`

##### _parseline

**Param√®tres :**

- `path`
- `line`
- `lineno`

##### iscommentline

**Param√®tres :**

- `line`

---

### _version

---

### exceptions

#### Classes

##### ParseError

**M√©thodes :**

- `__init__()`
- `__str__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `path`
- `lineno`
- `msg`

##### __str__

---

### .!33398!__init__

---

### .!33401!_parse

---

### .!33407!_version

---

### .!33410!exceptions

---

### .!33415!__init__

---

### .!33419!messages

---

### .!33421!__init__

---

### .!33426!_assistant_agent

---

### .!33430!_base_chat_agent

---

### .!33433!_code_executor_agent

---

### .!33440!_message_filter_agent

---

### .!33441!_society_of_mind_agent

---

### .!33445!_user_proxy_agent

---

### .!33452!__init__

---

### .!33455!_chat_agent

---

### .!33460!_handoff

---

### .!33463!_task

---

### .!33467!_team

---

### .!33471!_termination

---

### .!33475!__init__

---

### .!33478!_terminations

---

### .!33484!__init__

---

### .!33487!_states

---

### .!33492!__init__

---

### .!33500!_base_group_chat

---

### .!33506!_base_group_chat_manager

---

### .!33510!_chat_agent_container

---

### .!33515!_events

---

### .!33519!_round_robin_group_chat

---

### .!33523!_selector_group_chat

---

### .!33526!_sequential_routed_agent

---

### .!33530!_swarm_group_chat

---

### .!33535!__init__

---

### .!33540!_digraph_group_chat

---

### .!33543!_graph_builder

---

### .!33548!__init__

---

### .!33554!_magentic_one_group_chat

---

### .!33557!_magentic_one_orchestrator

---

### .!33560!_prompts

---

### .!33565!__init__

---

### .!33571!_agent

---

### .!33575!_task_runner_tool

---

### .!33580!_team

---

### .!33584!__init__

---

### .!33588!_console

---

### .!33593!__init__

---

### .!33597!_utils

---

### .!33616!core

---

### .!33601!__init__

---

### .!33606!codec

---

### .!33612!compat

---

### .!33620!idnadata

---

### .!33625!intranges

---

### .!33628!package_data

---

### .!33632!uts46data

---

### patch

Invasive patches for coverage.py

#### Fonctions

##### apply_patches

Apply invasive patches requested by `[run] patch=`.

**Param√®tres :**

- `cov`
- `config`

##### make_exit_patch

**Param√®tres :**

- `old_exit`

##### coverage_os_exit_patch

**Param√®tres :**

- `status`

##### make_execv_patch

**Param√®tres :**

- `fname`
- `old_execv`

##### coverage_execv_patch

---

### misc

Miscellaneous stuff for coverage.py.

#### Classes

##### SysModuleSaver

Saves the contents of sys.modules, and removes new modules later.

**M√©thodes :**

- `__init__()`
- `restore()`

##### Hasher

Hashes Python data for fingerprinting.

**M√©thodes :**

- `__init__()`
- `update()`
- `hexdigest()`

##### DefaultValue

A sentinel object to use for unusual default-value needs.

Construct with a string that will be used as the repr, for display in help
and Sphinx output.

**M√©thodes :**

- `__init__()`
- `__repr__()`

#### Fonctions

##### isolate_module

Copy a module so that we are isolated from aggressive mocking.

If a test suite mocks os.path.exists (for example), and then we need to use
it during the test, everything will get tangled up if we use their mock.
Making a copy of the module when we import it will isolate coverage.py from
those complications.

**Param√®tres :**

- `mod`

##### sys_modules_saved

A context manager to remove any modules imported during a block.

##### import_third_party

Import a third-party module we need, but might not be installed.

This also cleans out the module after the import, so that coverage won't
appear to have imported it.  This lets the third party use coverage for
their own tests.

Arguments:
    modname (str): the name of the module to import.

Returns:
    The imported module, and a boolean indicating if the module could be imported.

If the boolean is False, the module returned is not the one you want: don't use it.

**Param√®tres :**

- `modname`

##### nice_pair

Make a nice string representation of a pair of numbers.

If the numbers are equal, just return the number, otherwise return the pair
with a dash between them, indicating the range.

**Param√®tres :**

- `pair`

##### bool_or_none

Return bool(b), but preserve None.

**Param√®tres :**

- `b`

##### join_regex

Combine a series of regex strings into one that matches any of them.

**Param√®tres :**

- `regexes`

##### file_be_gone

Remove a file, and don't get annoyed if it doesn't exist.

**Param√®tres :**

- `path`

##### ensure_dir

Make sure the directory exists.

If `directory` is None or empty, do nothing.

**Param√®tres :**

- `directory`

##### ensure_dir_for_file

Make sure the directory for the path exists.

**Param√®tres :**

- `path`

##### _needs_to_implement

Helper to raise NotImplementedError in interface stubs.

**Param√®tres :**

- `that`
- `func_name`

##### substitute_variables

Substitute ``${VAR}`` variables in `text` with their values.

Variables in the text can take a number of shell-inspired forms::

    $VAR
    ${VAR}
    ${VAR?}             strict: an error if VAR isn't defined.
    ${VAR-missing}      defaulted: "missing" if VAR isn't defined.
    $$                  just a dollar sign.

`variables` is a dictionary of variable values.

Returns the resulting text with values substituted.

**Param√®tres :**

- `text`
- `variables`

##### format_local_datetime

Return a string with local timezone representing the date.
    

**Param√®tres :**

- `dt`

##### import_local_file

Import a local file as a module.

Opens a file in the current directory named `modname`.py, imports it
as `modname`, and returns the module object.  `modfile` is the file to
import if it isn't in the current directory.

**Param√®tres :**

- `modname`
- `modfile`

##### _human_key

Turn a string into a list of string and number chunks.

"z23a" -> (["z", 23, "a"], "z23a")

The original string is appended as a last value to ensure the
key is unique enough so that "x1y" and "x001y" can be distinguished.

**Param√®tres :**

- `s`

##### human_sorted

Sort the given iterable of strings the way that humans expect.

Numeric components in the strings are sorted as numbers.

Returns the sorted list.

**Param√®tres :**

- `strings`

##### human_sorted_items

Sort (string, ...) items the way humans expect.

The elements of `items` can be any tuple/list. They'll be sorted by the
first element (a string), with ties broken by the remaining elements.

Returns the sorted list of items.

**Param√®tres :**

- `items`
- `reverse`

##### plural

Pluralize a word.

If n is 1, return thing.  Otherwise return things, or thing+s.

**Param√®tres :**

- `n`
- `thing`
- `things`

##### stdout_link

Format text+url as a clickable link for stdout.

If attached to a terminal, use escape sequences. Otherwise, just return
the text.

**Param√®tres :**

- `text`
- `url`

##### __init__

##### restore

Remove any modules imported since this object started.

##### __init__

##### update

Add `v` to the hash, recursively if needed.

**Param√®tres :**

- `v`

##### hexdigest

Retrieve the hex digest of the hash.

##### __init__

**Param√®tres :**

- `display_as`

##### __repr__

##### dollar_replace

Called for each $replacement.

**Param√®tres :**

- `match`

##### tryint

If `s` is a number, return an int, else `s` unchanged.

**Param√®tres :**

- `s`

---

### files

File wrangling.

#### Classes

##### TreeMatcher

A matcher for files in a tree.

Construct with a list of paths, either files or directories. Paths match
with the `match` method if they are one of the files, or if they are
somewhere in a subtree rooted at one of the directories.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `info()`
- `match()`

##### ModuleMatcher

A matcher for modules in a tree.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `info()`
- `match()`

##### GlobMatcher

A matcher for files by file name pattern.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `info()`
- `match()`

##### PathAliases

A collection of aliases for paths.

When combining data files from remote machines, often the paths to source
code are different, for example, due to OS differences, or because of
serialized checkouts on continuous integration machines.

A `PathAliases` object tracks a list of pattern/result pairs, and can
map a path through those aliases to produce a unified path.

**M√©thodes :**

- `__init__()`
- `pprint()`
- `add()`
- `map()`

#### Fonctions

##### set_relative_directory

Set the directory that `relative_filename` will be relative to.

##### relative_directory

Return the directory that `relative_filename` is relative to.

##### relative_filename

Return the relative form of `filename`.

The file name will be relative to the current directory when the
`set_relative_directory` was called.

**Param√®tres :**

- `filename`

##### canonical_filename

Return a canonical file name for `filename`.

An absolute path with no redundant components and normalized case.

**Param√®tres :**

- `filename`

##### flat_rootname

A base for a flat file name to correspond to this file.

Useful for writing files about the code where you want all the files in
the same directory, but need to differentiate same-named files from
different directories.

For example, the file a/b/c.py will return 'z_86bbcbe134d28fd2_c_py'

**Param√®tres :**

- `filename`

##### abs_file

Return the absolute normalized form of `path`.

**Param√®tres :**

- `path`

##### zip_location

Split a filename into a zipfile / inner name pair.

Only return a pair if the zipfile exists.  No check is made if the inner
name is in the zipfile.

**Param√®tres :**

- `filename`

##### source_exists

Determine if a source file path exists.

**Param√®tres :**

- `path`

##### python_reported_file

Return the string as Python would describe this file name.

**Param√®tres :**

- `filename`

##### isabs_anywhere

Is `filename` an absolute path on any OS?

**Param√®tres :**

- `filename`

##### prep_patterns

Prepare the file patterns for use in a `GlobMatcher`.

If a pattern starts with a wildcard, it is used as a pattern
as-is.  If it does not start with a wildcard, then it is made
absolute with the current directory.

If `patterns` is None, an empty list is returned.

**Param√®tres :**

- `patterns`

##### create_pth_file

Create .pth file for measuring subprocesses.

##### sep

Find the path separator used in this string, or os.sep if none.

**Param√®tres :**

- `s`

##### _glob_to_regex

Convert a file-path glob pattern into a regex.

**Param√®tres :**

- `pattern`

##### globs_to_regex

Convert glob patterns to a compiled regex that matches any of them.

Slashes are always converted to match either slash or backslash, for
Windows support, even when running elsewhere.

If the pattern has no slash or backslash, then it is interpreted as
matching a file name anywhere it appears in the tree.  Otherwise, the glob
pattern must match the whole file path.

If `partial` is true, then the pattern will match if the target string
starts with the pattern. Otherwise, it must match the entire string.

Returns: a compiled regex object.  Use the .match method to compare target
strings.

**Param√®tres :**

- `patterns`
- `case_insensitive`
- `partial`

##### find_python_files

Yield all of the importable Python files in `dirname`, recursively.

To be importable, the files have to be in a directory with a __init__.py,
except for `dirname` itself, which isn't required to have one.  The
assumption is that `dirname` was specified directly, so the user knows
best, but sub-directories are checked for a __init__.py to be sure we only
find the importable files.

If `include_namespace_packages` is True, then the check for __init__.py
files is skipped.

Files with strange characters are skipped, since they couldn't have been
imported, and are probably editor side-files.

**Param√®tres :**

- `dirname`
- `include_namespace_packages`

##### actual_path

Get the actual path of `path`, including the correct case.

**Param√®tres :**

- `path`

##### actual_path

The actual path for non-Windows platforms.

**Param√®tres :**

- `path`

##### __init__

**Param√®tres :**

- `paths`
- `name`

##### __repr__

##### info

A list of strings for displaying when dumping state.

##### match

Does `fpath` indicate a file in one of our trees?

**Param√®tres :**

- `fpath`

##### __init__

**Param√®tres :**

- `module_names`
- `name`

##### __repr__

##### info

A list of strings for displaying when dumping state.

##### match

Does `module_name` indicate a module in one of our packages?

**Param√®tres :**

- `module_name`

##### __init__

**Param√®tres :**

- `pats`
- `name`

##### __repr__

##### info

A list of strings for displaying when dumping state.

##### match

Does `fpath` match one of our file name patterns?

**Param√®tres :**

- `fpath`

##### __init__

**Param√®tres :**

- `debugfn`
- `relative`

##### pprint

Dump the important parts of the PathAliases, for debugging.

##### add

Add the `pattern`/`result` pair to the list of aliases.

`pattern` is an `glob`-style pattern.  `result` is a simple
string.  When mapping paths, if a path starts with a match against
`pattern`, then that match is replaced with `result`.  This models
isomorphic source trees being rooted at different places on two
different machines.

`pattern` can't end with a wildcard component, since that would
match an entire tree, and not just its root.

**Param√®tres :**

- `pattern`
- `result`

##### map

Map `path` through the aliases.

`path` is checked against all of the patterns.  The first pattern to
match is used to replace the root of the path with the result root.
Only one pattern is ever used.  If no patterns match, `path` is
returned unchanged.

The separator style in the result is made to match that of the result
in the alias.

`exists` is a function to determine if the resulting path actually
exists.

Returns the mapped path.  If a mapping has happened, this is a
canonical path.  If no mapping has happened, it is the original value
of `path` unchanged.

**Param√®tres :**

- `path`
- `exists`

---

### phystokens

Better tokenizing for coverage.py.

#### Fonctions

##### _phys_tokens

Return all physical tokens, even line continuations.

tokenize.generate_tokens() doesn't return a token for the backslash that
continues lines.  This wrapper provides those tokens so that we can
re-create a faithful representation of the original source.

Returns the same values as generate_tokens()

**Param√®tres :**

- `toks`

##### find_soft_key_lines

Helper for finding lines with soft keywords, like match/case lines.

**Param√®tres :**

- `source`

##### source_token_lines

Generate a series of lines, one for each line in `source`.

Each line is a list of pairs, each pair is a token::

    [('key', 'def'), ('ws', ' '), ('nam', 'hello'), ('op', '('), ... ]

Each pair has a token class, and the token text.

If you concatenate all the token texts, and then join them with newlines,
you should have your original `source` back, with two differences:
trailing white space is not preserved, and a final line with no newline
is indistinguishable from a final line with a newline.

**Param√®tres :**

- `source`

##### generate_tokens

A helper around `tokenize.generate_tokens`.

Originally this was used to cache the results, but it didn't seem to make
reporting go faster, and caused issues with using too much memory.

**Param√®tres :**

- `text`

##### source_encoding

Determine the encoding for `source`, according to PEP 263.

`source` is a byte string: the text of the program.

Returns a string, the name of the encoding.

**Param√®tres :**

- `source`

---

### lcovreport

LCOV reporting for coverage.py.

#### Classes

##### LcovReporter

A reporter for writing LCOV coverage reports.

**M√©thodes :**

- `__init__()`
- `report()`
- `lcov_file()`

#### Fonctions

##### line_hash

Produce a hash of a source line for use in the LCOV file.

**Param√®tres :**

- `line`

##### lcov_lines

Emit line coverage records for an analyzed file.

**Param√®tres :**

- `analysis`
- `lines`
- `source_lines`
- `outfile`

##### lcov_functions

Emit function coverage records for an analyzed file.

**Param√®tres :**

- `fr`
- `file_analysis`
- `outfile`

##### lcov_arcs

Emit branch coverage records for an analyzed file.

**Param√®tres :**

- `fr`
- `analysis`
- `lines`
- `outfile`

##### __init__

**Param√®tres :**

- `coverage`

##### report

Renders the full lcov report.

`morfs` is a list of modules or filenames

outfile is the file object to write the file into.

**Param√®tres :**

- `morfs`
- `outfile`

##### lcov_file

Produces the lcov data for a single file.

This currently supports both line and branch coverage,
however function coverage is not supported.

**Param√®tres :**

- `rel_fname`
- `fr`
- `analysis`
- `outfile`

---

### config

Config file for coverage.py

#### Classes

##### HandyConfigParser

Our specialization of ConfigParser.

**M√©thodes :**

- `__init__()`
- `read()`
- `real_section()`
- `has_option()`
- `has_section()`
- `options()`
- `get_section()`
- `get()`
- `getfile()`
- `getlist()`
- `getregexlist()`

##### CoverageConfig

Coverage.py configuration.

The attributes of this class are the various settings that control the
operation of coverage.py.

**M√©thodes :**

- `__init__()`
- `from_args()`
- `from_file()`
- `copy()`
- `_set_attr_from_config_option()`
- `get_plugin_options()`
- `set_option()`
- `get_option()`
- `post_process()`
- `debug_info()`

#### Fonctions

##### process_file_value

Make adjustments to a file path to make it usable.

**Param√®tres :**

- `path`

##### process_regexlist

Check the values in a regex list and keep the non-blank ones.

**Param√®tres :**

- `name`
- `option`
- `values`

##### config_files_to_try

What config files should we try to read?

Returns a list of tuples:
    (filename, is_our_file, was_file_specified)

**Param√®tres :**

- `config_file`

##### read_coverage_config

Read the coverage.py configuration.

Arguments:
    config_file: a boolean or string, see the `Coverage` class for the
        tricky details.
    warn: a function to issue warnings.
    all others: keyword arguments from the `Coverage` class, used for
        setting values in the configuration.

Returns:
    config:
        config is a CoverageConfig object read from the appropriate
        configuration file.

**Param√®tres :**

- `config_file`
- `warn`

##### __init__

Create the HandyConfigParser.

`our_file` is True if this config file is specifically for coverage,
False if we are examining another config file (tox.ini, setup.cfg)
for possible settings.

**Param√®tres :**

- `our_file`

##### read

Read a file name as UTF-8 configuration data.

**Param√®tres :**

- `filenames`
- `encoding_unused`

##### real_section

Get the actual name of a section.

**Param√®tres :**

- `section`

##### has_option

**Param√®tres :**

- `section`
- `option`

##### has_section

**Param√®tres :**

- `section`

##### options

**Param√®tres :**

- `section`

##### get_section

Get the contents of a section, as a dictionary.

**Param√®tres :**

- `section`

##### get

Get a value, replacing environment variables also.

The arguments are the same as `ConfigParser.get`, but in the found
value, ``$WORD`` or ``${WORD}`` are replaced by the value of the
environment variable ``WORD``.

Returns the finished value.

**Param√®tres :**

- `section`
- `option`

##### getfile

Fix up a file path setting.

**Param√®tres :**

- `section`
- `option`

##### getlist

Read a list of strings.

The value of `section` and `option` is treated as a comma- and newline-
separated list of strings.  Each value is stripped of white space.

Returns the list of strings.

**Param√®tres :**

- `section`
- `option`

##### getregexlist

Read a list of full-line regexes.

The value of `section` and `option` is treated as a newline-separated
list of regexes.  Each value is stripped of white space.

Returns the list of strings.

**Param√®tres :**

- `section`
- `option`

##### __init__

Initialize the configuration attributes to their defaults.

##### from_args

Read config values from `kwargs`.

##### from_file

Read configuration from a .rc file.

`filename` is a file name to read.

`our_file` is True if this config file is specifically for coverage,
False if we are examining another config file (tox.ini, setup.cfg)
for possible settings.

Returns True or False, whether the file could be read, and it had some
coverage.py settings in it.

**Param√®tres :**

- `filename`
- `warn`
- `our_file`

##### copy

Return a copy of the configuration.

##### _set_attr_from_config_option

Set an attribute on self if it exists in the ConfigParser.

Returns True if the attribute was set.

**Param√®tres :**

- `cp`
- `attr`
- `where`
- `type_`

##### get_plugin_options

Get a dictionary of options for the plugin named `plugin`.

**Param√®tres :**

- `plugin`

##### set_option

Set an option in the configuration.

`option_name` is a colon-separated string indicating the section and
option name.  For example, the ``branch`` option in the ``[run]``
section of the config file would be indicated with `"run:branch"`.

`value` is the new value for the option.

**Param√®tres :**

- `option_name`
- `value`

##### get_option

Get an option from the configuration.

`option_name` is a colon-separated string indicating the section and
option name.  For example, the ``branch`` option in the ``[run]``
section of the config file would be indicated with `"run:branch"`.

Returns the value of the option.

**Param√®tres :**

- `option_name`

##### post_process

Make final adjustments to settings to make them usable.

##### debug_info

Make a list of (name, value) pairs for writing debug info.

---

### version

The version and URL for coverage.py

#### Fonctions

##### _make_version

Create a readable version string from version_info tuple components.

**Param√®tres :**

- `major`
- `minor`
- `micro`
- `releaselevel`
- `serial`
- `dev`

##### _make_url

Make the URL people should start at for this version of coverage.py.

**Param√®tres :**

- `major`
- `minor`
- `micro`
- `releaselevel`
- `serial`
- `dev`

---

### .!33642!misc

---

### .!33667!env

---

### env

Determine facts about the environment.

#### Classes

##### PYBEHAVIOR

Flags indicating this Python's behavior.

#### Fonctions

##### debug_info

Return a list of (name, value) pairs for printing debug information.

---

### .!33707!html

---

### .!33726!core

---

### sysmon

Callback functions and support for sys.monitoring data collection.

#### Classes

##### CodeInfo

The information we want about each code object.

##### SysMonitor

Python implementation of the raw data tracer for PEP669 implementations.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `start()`
- `stop()`
- `post_fork()`
- `activity()`
- `reset_activity()`
- `get_stats()`
- `sysmon_py_start()`
- `sysmon_py_return()`
- `sysmon_line_lines()`
- `sysmon_line_arcs()`
- `sysmon_branch_either()`

##### LoggingWrapper

Wrap a namespace to log all its functions.

**M√©thodes :**

- `__init__()`
- `__getattr__()`

#### Fonctions

##### bytes_to_lines

Make a dict mapping byte code offsets to line numbers.

**Param√®tres :**

- `code`

##### log

Write a message to our detailed debugging log(s).

**Param√®tres :**

- `msg`

##### arg_repr

Make a customized repr for logged values.

**Param√®tres :**

- `arg`

##### panopticon

Decorate a function to log its calls.

##### log

Write a message to our detailed debugging log(s), but not really.

**Param√®tres :**

- `msg`

##### panopticon

Decorate a function to log its calls, but not really.

##### __init__

**Param√®tres :**

- `tool_id`

##### __repr__

##### start

Start this Tracer.

##### stop

Stop this Tracer.

##### post_fork

The process has forked, clean up as needed.

##### activity

Has there been any activity?

##### reset_activity

Reset the activity() flag.

##### get_stats

Return a dictionary of statistics, or None.

##### sysmon_py_start

Handle sys.monitoring.events.PY_START events.

**Param√®tres :**

- `code`
- `instruction_offset`

##### sysmon_py_return

Handle sys.monitoring.events.PY_RETURN events for branch coverage.

**Param√®tres :**

- `code`
- `instruction_offset`
- `retval`

##### sysmon_line_lines

Handle sys.monitoring.events.LINE events for line coverage.

**Param√®tres :**

- `code`
- `line_number`

##### sysmon_line_arcs

Handle sys.monitoring.events.LINE events for branch coverage.

**Param√®tres :**

- `code`
- `line_number`

##### sysmon_branch_either

Handle BRANCH_RIGHT and BRANCH_LEFT events.

**Param√®tres :**

- `code`
- `instruction_offset`
- `destination_offset`

##### __init__

**Param√®tres :**

- `wrapped`
- `namespace`

##### __getattr__

**Param√®tres :**

- `name`

##### _decorator

**Param√®tres :**

- `method`

##### _decorator

**Param√®tres :**

- `meth`

##### _wrapped

##### _wrapped

---

### .!33817!data

---

### templite

A simple Python template renderer, for a nano-subset of Django syntax.

For a detailed discussion of this code, see this chapter from 500 Lines:
http://aosabook.org/en/500L/a-template-engine.html

#### Classes

##### TempliteSyntaxError

Raised when a template has a syntax error.

##### TempliteValueError

Raised when an expression won't evaluate in a template.

##### CodeBuilder

Build source code conveniently.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `add_line()`
- `add_section()`
- `indent()`
- `dedent()`
- `get_globals()`

##### Templite

A simple template renderer, for a nano-subset of Django syntax.

Supported constructs are extended variable access::

    {{var.modifier.modifier|filter|filter}}

loops::

    {% for var in list %}...{% endfor %}

and ifs::

    {% if var %}...{% endif %}

Comments are within curly-hash markers::

    {# This will be ignored #}

Lines between `{% joined %}` and `{% endjoined %}` will have lines stripped
and joined.  Be careful, this could join words together!

Any of these constructs can have a hyphen at the end (`-}}`, `-%}`, `-#}`),
which will collapse the white space following the tag.

Construct a Templite with the template text, then use `render` against a
dictionary context to create a finished string::

    templite = Templite('''
        <h1>Hello {{name|upper}}!</h1>
        {% for topic in topics %}
            <p>You are interested in {{topic}}.</p>
        {% endif %}
        ''',
        {"upper": str.upper},
    )
    text = templite.render({
        "name": "Ned",
        "topics": ["Python", "Geometry", "Juggling"],
    })

**M√©thodes :**

- `__init__()`
- `_expr_code()`
- `_syntax_error()`
- `_variable()`
- `render()`
- `_do_dots()`

#### Fonctions

##### __init__

**Param√®tres :**

- `indent`

##### __str__

##### add_line

Add a line of source to the code.

Indentation and newline will be added for you, don't provide them.

**Param√®tres :**

- `line`

##### add_section

Add a section, a sub-CodeBuilder.

##### indent

Increase the current indent for following lines.

##### dedent

Decrease the current indent for following lines.

##### get_globals

Execute the code, and return a dict of globals it defines.

##### __init__

Construct a Templite with the given `text`.

`contexts` are dictionaries of values to use for future renderings.
These are good for filters and global values.

**Param√®tres :**

- `text`

##### _expr_code

Generate a Python expression for `expr`.

**Param√®tres :**

- `expr`

##### _syntax_error

Raise a syntax error using `msg`, and showing `thing`.

**Param√®tres :**

- `msg`
- `thing`

##### _variable

Track that `name` is used as a variable.

Adds the name to `vars_set`, a set of variable names.

Raises an syntax error if `name` is not a valid name.

**Param√®tres :**

- `name`
- `vars_set`

##### render

Render this template by applying it to `context`.

`context` is a dictionary of values to use in this rendering.

**Param√®tres :**

- `context`

##### _do_dots

Evaluate dotted expressions at run-time.

**Param√®tres :**

- `value`

##### flush_output

Force `buffered` to the code builder.

---

### results

Results of coverage measurement.

#### Classes

##### Analysis

The results of analyzing a FileReporter.

**M√©thodes :**

- `__post_init__()`
- `narrow()`
- `missing_formatted()`
- `arcs_missing()`
- `_branch_lines()`
- `_total_branches()`
- `missing_branch_arcs()`
- `executed_branch_arcs()`
- `branch_stats()`

##### Numbers

The numerical results of measuring coverage.

This holds the basic statistics from `Analysis`, and is used to roll
up statistics across files.

**M√©thodes :**

- `n_executed()`
- `n_executed_branches()`
- `pc_covered()`
- `pc_covered_str()`
- `ratio_covered()`
- `__add__()`
- `__radd__()`

#### Fonctions

##### analysis_from_file_reporter

Create an Analysis from a FileReporter.

**Param√®tres :**

- `data`
- `precision`
- `file_reporter`
- `filename`

##### display_covered

Return a displayable total percentage, as a string.

Note that "0" is only returned when the value is truly zero, and "100"
is only returned when the value is truly 100.  Rounding can never
result in either "0" or "100".

**Param√®tres :**

- `pc`
- `precision`

##### _line_ranges

Produce a list of ranges for `format_lines`.

**Param√®tres :**

- `statements`
- `lines`

##### format_lines

Nicely format a list of line numbers.

Format a list of line numbers for printing by coalescing groups of lines as
long as the lines represent consecutive statements.  This will coalesce
even if there are gaps between statements.

For example, if `statements` is [1,2,3,4,5,10,11,12,13,14] and
`lines` is [1,2,5,10,11,13,14] then the result will be "1-2, 5-11, 13-14".

Both `lines` and `statements` can be any iterable. All of the elements of
`lines` must be in `statements`, and all of the values must be positive
integers.

If `arcs` is provided, they are (start,[end,end,end]) pairs that will be
included in the output as long as start isn't in `lines`.

**Param√®tres :**

- `statements`
- `lines`
- `arcs`

##### should_fail_under

Determine if a total should fail due to fail-under.

`total` is a float, the coverage measurement total. `fail_under` is the
fail_under setting to compare with. `precision` is the number of digits
to consider after the decimal point.

Returns True if the total should fail.

**Param√®tres :**

- `total`
- `fail_under`
- `precision`

##### __post_init__

##### narrow

Create a narrowed Analysis.

The current analysis is copied to make a new one that only considers
the lines in `lines`.

**Param√®tres :**

- `lines`

##### missing_formatted

The missing line numbers, formatted nicely.

Returns a string like "1-2, 5-11, 13-14".

If `branches` is true, includes the missing branch arcs also.

**Param√®tres :**

- `branches`

##### arcs_missing

Returns a sorted list of the un-executed arcs in the code.

##### _branch_lines

Returns a list of line numbers that have more than one exit.

##### _total_branches

How many total branches are there?

##### missing_branch_arcs

Return arcs that weren't executed from branch lines.

Returns {l1:[l2a,l2b,...], ...}

##### executed_branch_arcs

Return arcs that were executed from branch lines.

Only include ones that we considered possible.

Returns {l1:[l2a,l2b,...], ...}

##### branch_stats

Get stats about branches.

Returns a dict mapping line numbers to a tuple:
(total_exits, taken_exits).

##### n_executed

Returns the number of executed statements.

##### n_executed_branches

Returns the number of executed branches.

##### pc_covered

Returns a single percentage value for coverage.

##### pc_covered_str

Returns the percent covered, as a string, without a percent sign.

Note that "0" is only returned when the value is truly zero, and "100"
is only returned when the value is truly 100.  Rounding can never
result in either "0" or "100".

##### ratio_covered

Return a numerator and denominator for the coverage ratio.

##### __add__

**Param√®tres :**

- `other`

##### __radd__

**Param√®tres :**

- `other`

---

### plugin_support

Support for plugins.

#### Classes

##### Plugins

The currently loaded collection of coverage.py plugins.

**M√©thodes :**

- `__init__()`
- `load_from_config()`
- `load_from_callables()`
- `add_file_tracer()`
- `add_configurer()`
- `add_dynamic_context()`
- `add_noop()`
- `_add_plugin()`
- `__bool__()`
- `__iter__()`
- `get()`

##### LabelledDebug

A Debug writer, but with labels for prepending to the messages.

**M√©thodes :**

- `__init__()`
- `add_label()`
- `message_prefix()`
- `write()`

##### DebugPluginWrapper

Wrap a plugin, and use debug to report on what it's doing.

**M√©thodes :**

- `__init__()`
- `file_tracer()`
- `file_reporter()`
- `dynamic_context()`
- `find_executable_files()`
- `configure()`
- `sys_info()`

##### DebugFileTracerWrapper

A debugging `FileTracer`.

**M√©thodes :**

- `__init__()`
- `_show_frame()`
- `source_filename()`
- `has_dynamic_source_filename()`
- `dynamic_source_filename()`
- `line_number_range()`

##### DebugFileReporterWrapper

A debugging `FileReporter`.

**M√©thodes :**

- `__init__()`
- `relative_filename()`
- `lines()`
- `excluded_lines()`
- `translate_lines()`
- `translate_arcs()`
- `no_branch_lines()`
- `exit_counts()`
- `arcs()`
- `source()`
- `source_token_lines()`

#### Fonctions

##### __init__

**Param√®tres :**

- `debug`

##### load_from_config

Load plugin modules, and read their settings from configuration.

**Param√®tres :**

- `modules`
- `config`

##### load_from_callables

Load plugins from callables provided.

**Param√®tres :**

- `plugin_inits`

##### add_file_tracer

Add a file tracer plugin.

`plugin` is an instance of a third-party plugin class.  It must
implement the :meth:`CoveragePlugin.file_tracer` method.

**Param√®tres :**

- `plugin`

##### add_configurer

Add a configuring plugin.

`plugin` is an instance of a third-party plugin class. It must
implement the :meth:`CoveragePlugin.configure` method.

**Param√®tres :**

- `plugin`

##### add_dynamic_context

Add a dynamic context plugin.

`plugin` is an instance of a third-party plugin class.  It must
implement the :meth:`CoveragePlugin.dynamic_context` method.

**Param√®tres :**

- `plugin`

##### add_noop

Add a plugin that does nothing.

This is only useful for testing the plugin support.

**Param√®tres :**

- `plugin`

##### _add_plugin

Add a plugin object.

`plugin` is a :class:`CoveragePlugin` instance to add.  `specialized`
is a list to append the plugin to.

**Param√®tres :**

- `plugin`
- `specialized`

##### __bool__

##### __iter__

##### get

Return a plugin by name.

**Param√®tres :**

- `plugin_name`

##### __init__

**Param√®tres :**

- `label`
- `debug`
- `prev_labels`

##### add_label

Add a label to the writer, and return a new `LabelledDebug`.

**Param√®tres :**

- `label`

##### message_prefix

The prefix to use on messages, combining the labels.

##### write

Write `message`, but with the labels prepended.

**Param√®tres :**

- `message`

##### __init__

**Param√®tres :**

- `plugin`
- `debug`

##### file_tracer

**Param√®tres :**

- `filename`

##### file_reporter

**Param√®tres :**

- `filename`

##### dynamic_context

**Param√®tres :**

- `frame`

##### find_executable_files

**Param√®tres :**

- `src_dir`

##### configure

**Param√®tres :**

- `config`

##### sys_info

##### __init__

**Param√®tres :**

- `tracer`
- `debug`

##### _show_frame

A short string identifying a frame, for debug messages.

**Param√®tres :**

- `frame`

##### source_filename

##### has_dynamic_source_filename

##### dynamic_source_filename

**Param√®tres :**

- `filename`
- `frame`

##### line_number_range

**Param√®tres :**

- `frame`

##### __init__

**Param√®tres :**

- `filename`
- `reporter`
- `debug`

##### relative_filename

##### lines

##### excluded_lines

##### translate_lines

**Param√®tres :**

- `lines`

##### translate_arcs

**Param√®tres :**

- `arcs`

##### no_branch_lines

##### exit_counts

##### arcs

##### source

##### source_token_lines

---

### numbits

Functions to manipulate packed binary representations of number sets.

To save space, coverage stores sets of line numbers in SQLite using a packed
binary representation called a numbits.  A numbits is a set of positive
integers.

A numbits is stored as a blob in the database.  The exact meaning of the bytes
in the blobs should be considered an implementation detail that might change in
the future.  Use these functions to work with those binary blobs of data.

#### Fonctions

##### nums_to_numbits

Convert `nums` into a numbits.

Arguments:
    nums: a reusable iterable of integers, the line numbers to store.

Returns:
    A binary blob.

**Param√®tres :**

- `nums`

##### numbits_to_nums

Convert a numbits into a list of numbers.

Arguments:
    numbits: a binary blob, the packed number set.

Returns:
    A list of ints.

When registered as a SQLite function by :func:`register_sqlite_functions`,
this returns a string, a JSON-encoded list of ints.

**Param√®tres :**

- `numbits`

##### numbits_union

Compute the union of two numbits.

Returns:
    A new numbits, the union of `numbits1` and `numbits2`.

**Param√®tres :**

- `numbits1`
- `numbits2`

##### numbits_intersection

Compute the intersection of two numbits.

Returns:
    A new numbits, the intersection `numbits1` and `numbits2`.

**Param√®tres :**

- `numbits1`
- `numbits2`

##### numbits_any_intersection

Is there any number that appears in both numbits?

Determine whether two number sets have a non-empty intersection. This is
faster than computing the intersection.

Returns:
    A bool, True if there is any number in both `numbits1` and `numbits2`.

**Param√®tres :**

- `numbits1`
- `numbits2`

##### num_in_numbits

Does the integer `num` appear in `numbits`?

Returns:
    A bool, True if `num` is a member of `numbits`.

**Param√®tres :**

- `num`
- `numbits`

##### register_sqlite_functions

Define numbits functions in a SQLite connection.

This defines these functions for use in SQLite statements:

* :func:`numbits_union`
* :func:`numbits_intersection`
* :func:`numbits_any_intersection`
* :func:`num_in_numbits`
* :func:`numbits_to_nums`

`connection` is a :class:`sqlite3.Connection <python:sqlite3.Connection>`
object.  After creating the connection, pass it to this function to
register the numbits functions.  Then you can use numbits functions in your
queries::

    import sqlite3
    from coverage.numbits import register_sqlite_functions

    conn = sqlite3.connect("example.db")
    register_sqlite_functions(conn)
    c = conn.cursor()
    # Kind of a nonsense query:
    # Find all the files and contexts that executed line 47 in any file:
    c.execute(
        "select file_id, context_id from line_bits where num_in_numbits(?, numbits)",
        (47,)
    )

**Param√®tres :**

- `connection`

---

### regions

Find functions and classes in Python code.

#### Classes

##### Context

The nested named context of a function or class.

##### RegionFinder

An ast visitor that will find and track regions of code.

Functions and classes are tracked by name. Results are in the .regions
attribute.

**M√©thodes :**

- `__init__()`
- `parse_source()`
- `fq_node_name()`
- `handle_node()`
- `handle_node_body()`
- `handle_FunctionDef()`
- `handle_ClassDef()`

#### Fonctions

##### code_regions

Find function and class regions in source code.

Analyzes the code in `source`, and returns a list of :class:`CodeRegion`
objects describing functions and classes as regions of the code::

    [
        CodeRegion(kind="function", name="func1", start=8, lines={10, 11, 12}),
        CodeRegion(kind="function", name="MyClass.method", start=30, lines={34, 35, 36}),
        CodeRegion(kind="class", name="MyClass", start=25, lines={34, 35, 36}),
    ]

The line numbers will include comments and blank lines.  Later processing
will need to ignore those lines as needed.

Nested functions and classes are excluded from their enclosing region.  No
line should be reported as being part of more than one function, or more
than one class.  Lines in methods are reported as being in a function and
in a class.

**Param√®tres :**

- `source`

##### __init__

##### parse_source

Parse `source` and walk the ast to populate the .regions attribute.

**Param√®tres :**

- `source`

##### fq_node_name

Get the current fully qualified name we're processing.

##### handle_node

Recursively handle any node.

**Param√®tres :**

- `node`

##### handle_node_body

Recursively handle the nodes in this node's body, if any.

**Param√®tres :**

- `node`

##### handle_FunctionDef

Called for `def` or `async def`.

**Param√®tres :**

- `node`

##### handle_ClassDef

Called for `class`.

**Param√®tres :**

- `node`

---

### control

Central control stuff for coverage.py.

#### Classes

##### Coverage

Programmatic access to coverage.py.

To use::

    from coverage import Coverage

    cov = Coverage()
    cov.start()
    #.. call your code ..
    cov.stop()
    cov.html_report(directory="covhtml")

A context manager is available to do the same thing::

    cov = Coverage()
    with cov.collect():
        #.. call your code ..
    cov.html_report(directory="covhtml")

Note: in keeping with Python custom, names starting with underscore are
not part of the public API. They might stop working at any point.  Please
limit yourself to documented methods to avoid problems.

Methods can raise any of the exceptions described in :ref:`api_exceptions`.

**M√©thodes :**

- `current()`
- `__init__()`
- `_init()`
- `_post_init()`
- `_write_startup_debug()`
- `_should_trace()`
- `_check_include_omit_etc()`
- `_warn()`
- `_message()`
- `get_option()`
- `set_option()`
- `load()`
- `_init_for_start()`
- `_init_data()`
- `start()`
- `stop()`
- `collect()`
- `_atexit()`
- `_on_sigterm()`
- `erase()`
- `switch_context()`
- `clear_exclude()`
- `exclude()`
- `_exclude_regex_stale()`
- `_exclude_regex()`
- `get_exclude_list()`
- `save()`
- `_make_aliases()`
- `combine()`
- `get_data()`
- `_post_save_work()`
- `analysis()`
- `analysis2()`
- `_analyze()`
- `branch_stats()`
- `_get_file_reporter()`
- `_get_file_reporters()`
- `_prepare_data_for_reporting()`
- `report()`
- `annotate()`
- `html_report()`
- `xml_report()`
- `json_report()`
- `lcov_report()`
- `sys_info()`

#### Fonctions

##### override_config

Temporarily tweak the configuration of `cov`.

The arguments are applied to `cov.config` with the `from_args` method.
At the end of the with-statement, the old configuration is restored.

**Param√®tres :**

- `cov`

##### process_startup

Call this at Python start-up to perhaps measure coverage.

If the environment variable COVERAGE_PROCESS_START is defined, coverage
measurement is started.  The value of the variable is the config file
to use.

There are two ways to configure your Python installation to invoke this
function when Python starts:

#. Create or append to sitecustomize.py to add these lines::

    import coverage
    coverage.process_startup()

#. Create a .pth file in your Python installation containing::

    import coverage; coverage.process_startup()

Returns the :class:`Coverage` instance that was started, or None if it was
not started by this call.

##### _prevent_sub_process_measurement

Stop any subprocess auto-measurement from writing data.

##### current

Get the latest started `Coverage` instance, if any.

Returns: a `Coverage` instance, or None.

.. versionadded:: 5.0

**Param√®tres :**

- `cls`

##### __init__

Many of these arguments duplicate and override values that can be
provided in a configuration file.  Parameters that are missing here
will use values from the config file.

`data_file` is the base name of the data file to use. The config value
defaults to ".coverage".  None can be provided to prevent writing a data
file.  `data_suffix` is appended (with a dot) to `data_file` to create
the final file name.  If `data_suffix` is simply True, then a suffix is
created with the machine and process identity included.

`cover_pylib` is a boolean determining whether Python code installed
with the Python interpreter is measured.  This includes the Python
standard library and any packages installed with the interpreter.

If `auto_data` is true, then any existing data file will be read when
coverage measurement starts, and data will be saved automatically when
measurement stops.

If `timid` is true, then a slower and simpler trace function will be
used.  This is important for some environments where manipulation of
tracing functions breaks the faster trace function.

If `branch` is true, then branch coverage will be measured in addition
to the usual statement coverage.

`config_file` determines what configuration file to read:

    * If it is ".coveragerc", it is interpreted as if it were True,
      for backward compatibility.

    * If it is a string, it is the name of the file to read.  If the
      file can't be read, it is an error.

    * If it is True, then a few standard files names are tried
      (".coveragerc", "setup.cfg", "tox.ini").  It is not an error for
      these files to not be found.

    * If it is False, then no configuration file is read.

`source` is a list of file paths or package names.  Only code located
in the trees indicated by the file paths or package names will be
measured.

`source_pkgs` is a list of package names. It works the same as
`source`, but can be used to name packages where the name can also be
interpreted as a file path.

`source_dirs` is a list of file paths. It works the same as
`source`, but raises an error if the path doesn't exist, rather
than being treated as a package name.

`include` and `omit` are lists of file name patterns. Files that match
`include` will be measured, files that match `omit` will not.  Each
will also accept a single string argument.

`debug` is a list of strings indicating what debugging information is
desired.

`concurrency` is a string indicating the concurrency library being used
in the measured code.  Without this, coverage.py will get incorrect
results if these libraries are in use.  Valid strings are "greenlet",
"eventlet", "gevent", "multiprocessing", or "thread" (the default).
This can also be a list of these strings.

If `check_preimported` is true, then when coverage is started, the
already-imported files will be checked to see if they should be
measured by coverage.  Importing measured files before coverage is
started can mean that code is missed.

`context` is a string to use as the :ref:`static context
<static_contexts>` label for collected data.

If `messages` is true, some messages will be printed to stdout
indicating what is happening.

If `plugins` are passed, they are an iterable of function objects
accepting a `reg` object to register plugins, as described in
:ref:`api_plugin`.  When they are provided, they will override the
plugins found in the coverage configuration file.

.. versionadded:: 4.0
    The `concurrency` parameter.

.. versionadded:: 4.2
    The `concurrency` parameter can now be a list of strings.

.. versionadded:: 5.0
    The `check_preimported` and `context` parameters.

.. versionadded:: 5.3
    The `source_pkgs` parameter.

.. versionadded:: 6.0
    The `messages` parameter.

.. versionadded:: 7.7
    The `plugins` parameter.

.. versionadded:: 7.8
    The `source_dirs` parameter.

**Param√®tres :**

- `data_file`
- `data_suffix`
- `cover_pylib`
- `auto_data`
- `timid`
- `branch`
- `config_file`
- `source`
- `source_pkgs`
- `source_dirs`
- `omit`
- `include`
- `debug`
- `concurrency`
- `check_preimported`
- `context`
- `messages`
- `plugins`

##### _init

Set all the initial state.

This is called by the public methods to initialize state. This lets us
construct a :class:`Coverage` object, then tweak its state before this
function is called.

##### _post_init

Stuff to do after everything is initialized.

##### _write_startup_debug

Write out debug info at startup if needed.

##### _should_trace

Decide whether to trace execution in `filename`.

Calls `_should_trace_internal`, and returns the FileDisposition.

**Param√®tres :**

- `filename`
- `frame`

##### _check_include_omit_etc

Check a file name against the include/omit/etc, rules, verbosely.

Returns a boolean: True if the file should be traced, False if not.

**Param√®tres :**

- `filename`
- `frame`

##### _warn

Use `msg` as a warning.

For warning suppression, use `slug` as the shorthand.

If `once` is true, only show this warning once (determined by the
slug.)

**Param√®tres :**

- `msg`
- `slug`
- `once`

##### _message

Write a message to the user, if configured to do so.

**Param√®tres :**

- `msg`

##### get_option

Get an option from the configuration.

`option_name` is a colon-separated string indicating the section and
option name.  For example, the ``branch`` option in the ``[run]``
section of the config file would be indicated with `"run:branch"`.

Returns the value of the option.  The type depends on the option
selected.

As a special case, an `option_name` of ``"paths"`` will return an
dictionary with the entire ``[paths]`` section value.

.. versionadded:: 4.0

**Param√®tres :**

- `option_name`

##### set_option

Set an option in the configuration.

`option_name` is a colon-separated string indicating the section and
option name.  For example, the ``branch`` option in the ``[run]``
section of the config file would be indicated with ``"run:branch"``.

`value` is the new value for the option.  This should be an
appropriate Python value.  For example, use True for booleans, not the
string ``"True"``.

As an example, calling:

.. code-block:: python

    cov.set_option("run:branch", True)

has the same effect as this configuration file:

.. code-block:: ini

    [run]
    branch = True

As a special case, an `option_name` of ``"paths"`` will replace the
entire ``[paths]`` section.  The value should be a dictionary.

.. versionadded:: 4.0

**Param√®tres :**

- `option_name`
- `value`

##### load

Load previously-collected coverage data from the data file.

##### _init_for_start

Initialization for start()

##### _init_data

Create a data file if we don't have one yet.

**Param√®tres :**

- `suffix`

##### start

Start measuring code coverage.

Coverage measurement is only collected in functions called after
:meth:`start` is invoked.  Statements in the same scope as
:meth:`start` won't be measured.

Once you invoke :meth:`start`, you must also call :meth:`stop`
eventually, or your process might not shut down cleanly.

The :meth:`collect` method is a context manager to handle both
starting and stopping collection.

##### stop

Stop measuring code coverage.

##### collect

A context manager to start/stop coverage measurement collection.

.. versionadded:: 7.3

##### _atexit

Clean up on process shutdown.

**Param√®tres :**

- `event`

##### _on_sigterm

A handler for signal.SIGTERM.

**Param√®tres :**

- `signum_unused`
- `frame_unused`

##### erase

Erase previously collected coverage data.

This removes the in-memory data collected in this session as well as
discarding the data file.

##### switch_context

Switch to a new dynamic context.

`new_context` is a string to use as the :ref:`dynamic context
<dynamic_contexts>` label for collected data.  If a :ref:`static
context <static_contexts>` is in use, the static and dynamic context
labels will be joined together with a pipe character.

Coverage collection must be started already.

.. versionadded:: 5.0

**Param√®tres :**

- `new_context`

##### clear_exclude

Clear the exclude list.

**Param√®tres :**

- `which`

##### exclude

Exclude source lines from execution consideration.

A number of lists of regular expressions are maintained.  Each list
selects lines that are treated differently during reporting.

`which` determines which list is modified.  The "exclude" list selects
lines that are not considered executable at all.  The "partial" list
indicates lines with branches that are not taken.

`regex` is a regular expression.  The regex is added to the specified
list.  If any of the regexes in the list is found in a line, the line
is marked for special treatment during reporting.

**Param√®tres :**

- `regex`
- `which`

##### _exclude_regex_stale

Drop all the compiled exclusion regexes, a list was modified.

##### _exclude_regex

Return a regex string for the given exclusion list.

**Param√®tres :**

- `which`

##### get_exclude_list

Return a list of excluded regex strings.

`which` indicates which list is desired.  See :meth:`exclude` for the
lists that are available, and their meaning.

**Param√®tres :**

- `which`

##### save

Save the collected coverage data to the data file.

##### _make_aliases

Create a PathAliases from our configuration.

##### combine

Combine together a number of similarly-named coverage data files.

All coverage data files whose name starts with `data_file` (from the
coverage() constructor) will be read, and combined together into the
current measurements.

`data_paths` is a list of files or directories from which data should
be combined. If no list is passed, then the data files from the
directory indicated by the current data file (probably the current
directory) will be combined.

If `strict` is true, then it is an error to attempt to combine when
there are no data files to combine.

If `keep` is true, then original input data files won't be deleted.

.. versionadded:: 4.0
    The `data_paths` parameter.

.. versionadded:: 4.3
    The `strict` parameter.

.. versionadded: 5.5
    The `keep` parameter.

**Param√®tres :**

- `data_paths`
- `strict`
- `keep`

##### get_data

Get the collected data.

Also warn about various problems collecting data.

Returns a :class:`coverage.CoverageData`, the collected coverage data.

.. versionadded:: 4.0

##### _post_save_work

After saving data, look for warnings, post-work, etc.

Warn about things that should have happened but didn't.
Look for un-executed files.

##### analysis

Like `analysis2` but doesn't return excluded line numbers.

**Param√®tres :**

- `morf`

##### analysis2

Analyze a module.

`morf` is a module or a file name.  It will be analyzed to determine
its coverage statistics.  The return value is a 5-tuple:

* The file name for the module.
* A list of line numbers of executable statements.
* A list of line numbers of excluded statements.
* A list of line numbers of statements not run (missing from
  execution).
* A readable formatted string of the missing line numbers.

The analysis uses the source file itself and the current measured
coverage data.

**Param√®tres :**

- `morf`

##### _analyze

Analyze a module or file.  Private for now.

**Param√®tres :**

- `morf`

##### branch_stats

Get branch statistics about a module.

`morf` is a module or a file name.

Returns a dict mapping line numbers to a tuple:
(total_exits, taken_exits).

.. versionadded:: 7.7

**Param√®tres :**

- `morf`

##### _get_file_reporter

Get a FileReporter for a module or file name.

**Param√®tres :**

- `morf`

##### _get_file_reporters

Get FileReporters for a list of modules or file names.

For each module or file name in `morfs`, find a FileReporter.  Return
a list pairing FileReporters with the morfs.

If `morfs` is a single module or file name, this returns a list of one
FileReporter.  If `morfs` is empty or None, then the list of all files
measured is used to find the FileReporters.

**Param√®tres :**

- `morfs`

##### _prepare_data_for_reporting

Re-map data before reporting, to get implicit "combine" behavior.

##### report

Write a textual summary report to `file`.

Each module in `morfs` is listed, with counts of statements, executed
statements, missing statements, and a list of lines missed.

If `show_missing` is true, then details of which lines or branches are
missing will be included in the report.  If `ignore_errors` is true,
then a failure while reporting a single file will not stop the entire
report.

`file` is a file-like object, suitable for writing.

`output_format` determines the format, either "text" (the default),
"markdown", or "total".

`include` is a list of file name patterns.  Files that match will be
included in the report. Files matching `omit` will not be included in
the report.

If `skip_covered` is true, don't report on files with 100% coverage.

If `skip_empty` is true, don't report on empty files (those that have
no statements).

`contexts` is a list of regular expression strings.  Only data from
:ref:`dynamic contexts <dynamic_contexts>` that match one of those
expressions (using :func:`re.search <python:re.search>`) will be
included in the report.

`precision` is the number of digits to display after the decimal
point for percentages.

All of the arguments default to the settings read from the
:ref:`configuration file <config>`.

Returns a float, the total percentage covered.

.. versionadded:: 4.0
    The `skip_covered` parameter.

.. versionadded:: 5.0
    The `contexts` and `skip_empty` parameters.

.. versionadded:: 5.2
    The `precision` parameter.

.. versionadded:: 7.0
    The `format` parameter.

**Param√®tres :**

- `morfs`
- `show_missing`
- `ignore_errors`
- `file`
- `omit`
- `include`
- `skip_covered`
- `contexts`
- `skip_empty`
- `precision`
- `sort`
- `output_format`

##### annotate

Annotate a list of modules.

Each module in `morfs` is annotated.  The source is written to a new
file, named with a ",cover" suffix, with each line prefixed with a
marker to indicate the coverage of the line.  Covered lines have ">",
excluded lines have "-", and missing lines have "!".

See :meth:`report` for other arguments.

**Param√®tres :**

- `morfs`
- `directory`
- `ignore_errors`
- `omit`
- `include`
- `contexts`

##### html_report

Generate an HTML report.

The HTML is written to `directory`.  The file "index.html" is the
overview starting point, with links to more detailed pages for
individual modules.

`extra_css` is a path to a file of other CSS to apply on the page.
It will be copied into the HTML directory.

`title` is a text string (not HTML) to use as the title of the HTML
report.

See :meth:`report` for other arguments.

Returns a float, the total percentage covered.

.. note::

    The HTML report files are generated incrementally based on the
    source files and coverage results. If you modify the report files,
    the changes will not be considered.  You should be careful about
    changing the files in the report folder.

**Param√®tres :**

- `morfs`
- `directory`
- `ignore_errors`
- `omit`
- `include`
- `extra_css`
- `title`
- `skip_covered`
- `show_contexts`
- `contexts`
- `skip_empty`
- `precision`

##### xml_report

Generate an XML report of coverage results.

The report is compatible with Cobertura reports.

Each module in `morfs` is included in the report.  `outfile` is the
path to write the file to, "-" will write to stdout.

See :meth:`report` for other arguments.

Returns a float, the total percentage covered.

**Param√®tres :**

- `morfs`
- `outfile`
- `ignore_errors`
- `omit`
- `include`
- `contexts`
- `skip_empty`

##### json_report

Generate a JSON report of coverage results.

Each module in `morfs` is included in the report.  `outfile` is the
path to write the file to, "-" will write to stdout.

`pretty_print` is a boolean, whether to pretty-print the JSON output or not.

See :meth:`report` for other arguments.

Returns a float, the total percentage covered.

.. versionadded:: 5.0

**Param√®tres :**

- `morfs`
- `outfile`
- `ignore_errors`
- `omit`
- `include`
- `contexts`
- `pretty_print`
- `show_contexts`

##### lcov_report

Generate an LCOV report of coverage results.

Each module in `morfs` is included in the report. `outfile` is the
path to write the file to, "-" will write to stdout.

See :meth:`report` for other arguments.

.. versionadded:: 6.3

**Param√®tres :**

- `morfs`
- `outfile`
- `ignore_errors`
- `omit`
- `include`
- `contexts`

##### sys_info

Return a list of (key, value) pairs showing internal information.

##### plugin_info

Make an entry for the sys_info from a list of plug-ins.

**Param√®tres :**

- `plugins`

---

### sqlitedb

SQLite abstraction for coverage.py

#### Classes

##### SqliteDb

A simple abstraction over a SQLite database.

Use as a context manager, then you can use it like a
:class:`python:sqlite3.Connection` object::

    with SqliteDb(filename, debug_control) as db:
        with db.execute("select a, b from some_table") as cur:
            for a, b in cur:
                etc(a, b)

**M√©thodes :**

- `__init__()`
- `_connect()`
- `close()`
- `__enter__()`
- `__exit__()`
- `_execute()`
- `execute()`
- `execute_void()`
- `execute_for_rowid()`
- `execute_one()`
- `_executemany()`
- `executemany_void()`
- `executescript()`
- `dump()`

#### Fonctions

##### __init__

**Param√®tres :**

- `filename`
- `debug`

##### _connect

Connect to the db and do universal initialization.

##### close

If needed, close the connection.

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `traceback`

##### _execute

Same as :meth:`python:sqlite3.Connection.execute`.

**Param√®tres :**

- `sql`
- `parameters`

##### execute

Context managed :meth:`python:sqlite3.Connection.execute`.

Use with a ``with`` statement to auto-close the returned cursor.

**Param√®tres :**

- `sql`
- `parameters`

##### execute_void

Same as :meth:`python:sqlite3.Connection.execute` when you don't need the cursor.

If `fail_ok` is True, then SQLite errors are ignored.

**Param√®tres :**

- `sql`
- `parameters`
- `fail_ok`

##### execute_for_rowid

Like execute, but returns the lastrowid.

**Param√®tres :**

- `sql`
- `parameters`

##### execute_one

Execute a statement and return the one row that results.

This is like execute(sql, parameters).fetchone(), except it is
correct in reading the entire result set.  This will raise an
exception if more than one row results.

Returns a row, or None if there were no rows.

**Param√®tres :**

- `sql`
- `parameters`

##### _executemany

Same as :meth:`python:sqlite3.Connection.executemany`.

**Param√®tres :**

- `sql`
- `data`

##### executemany_void

Same as :meth:`python:sqlite3.Connection.executemany` when you don't need the cursor.

**Param√®tres :**

- `sql`
- `data`

##### executescript

Same as :meth:`python:sqlite3.Connection.executescript`.

**Param√®tres :**

- `script`

##### dump

Return a multi-line string, the SQL dump of the database.

---

### html

HTML reporting for coverage.py.

#### Classes

##### LineData

The data for each source line of HTML output.

##### FileData

The data for each source file of HTML output.

##### IndexItem

Information for each index entry, to render an index page.

##### IndexPage

Data for each index page.

##### HtmlDataGeneration

Generate structured data to be turned into HTML reports.

**M√©thodes :**

- `__init__()`
- `data_for_file()`

##### FileToReport

A file we're considering reporting.

**M√©thodes :**

- `__init__()`

##### HtmlReporter

HTML reporting.

**M√©thodes :**

- `__init__()`
- `new_index_page()`
- `report()`
- `make_directory()`
- `copy_static_file()`
- `make_local_static_report_files()`
- `should_report()`
- `write_html_page()`
- `write_file_index_page()`
- `write_region_index_pages()`
- `write_index_page()`

##### FileInfo

Summary of the information from last rendering, to avoid duplicate work.

##### IncrementalChecker

Logic and data to support incremental reporting.

When generating an HTML report, often only a few of the source files have
changed since the last time we made the HTML report.  This means previously
created HTML pages can be reused without generating them again, speeding
the command.

This class manages a JSON data file that captures enough information to
know whether an HTML page for a .py file needs to be regenerated or not.
The data file also needs to store all the information needed to create the
entry for the file on the index page so that if the HTML page is reused,
the index page can still be created to refer to it.

The data looks like::

    {
        "note": "This file is an internal implementation detail ...",
        // A fixed number indicating the data format.  STATUS_FORMAT
        "format": 5,
        // The version of coverage.py
        "version": "7.4.4",
        // A hash of a number of global things, including the configuration
        // settings and the pyfile.html template itself.
        "globals": "540ee119c15d52a68a53fe6f0897346d",
        "files": {
            // An entry for each source file keyed by the flat_rootname().
            "z_7b071bdc2a35fa80___init___py": {
                // Hash of the source, the text of the .py file.
                "hash": "e45581a5b48f879f301c0f30bf77a50c",
                // Information for the index.html file.
                "index": {
                    "url": "z_7b071bdc2a35fa80___init___py.html",
                    "file": "cogapp/__init__.py",
                    "description": "",
                    // The Numbers for this file.
                    "nums": { "precision": 2, "n_files": 1, "n_statements": 43, ... }
                }
            },
            ...
        }
    }

**M√©thodes :**

- `__init__()`
- `_reset()`
- `read()`
- `write()`
- `check_global_data()`
- `can_skip_file()`
- `index_info()`
- `set_index_info()`

#### Fonctions

##### data_filename

Return the path to an "htmlfiles" data file of ours.
    

**Param√®tres :**

- `fname`

##### read_data

Return the contents of a data file of ours.

**Param√®tres :**

- `fname`

##### write_html

Write `html` to `fname`, properly encoded.

**Param√®tres :**

- `fname`
- `html`

##### encode_int

Create a short HTML-safe string from an integer, using HTML_SAFE.

**Param√®tres :**

- `n`

##### copy_with_cache_bust

Copy `src` to `dest_dir`, adding a hash to the name.

Returns the updated destination file name with hash.

**Param√®tres :**

- `src`
- `dest_dir`

##### escape

HTML-escape the text in `t`.

This is only suitable for HTML text, not attributes.

**Param√®tres :**

- `t`

##### pair

Format a pair of numbers so JavaScript can read them in an attribute.

**Param√®tres :**

- `ratio`

##### __init__

**Param√®tres :**

- `cov`

##### data_for_file

Produce the data needed for one file's report.

**Param√®tres :**

- `fr`
- `analysis`

##### __init__

**Param√®tres :**

- `fr`
- `analysis`

##### __init__

**Param√®tres :**

- `cov`

##### new_index_page

Create an IndexPage for a kind of region.

**Param√®tres :**

- `noun`
- `plural_noun`

##### report

Generate an HTML report for `morfs`.

`morfs` is a list of modules or file names.

**Param√®tres :**

- `morfs`

##### make_directory

Make sure our htmlcov directory exists.

##### copy_static_file

Copy a static file into the output directory with cache busting.

**Param√®tres :**

- `src`
- `slug`

##### make_local_static_report_files

Make local instances of static files for HTML report.

##### should_report

Determine if we'll report this file or region.

**Param√®tres :**

- `analysis`
- `index_page`

##### write_html_page

Generate an HTML page for one source file.

If the page on disk is already correct based on our incremental status
checking, then the page doesn't have to be generated, and this function
only does page summary bookkeeping.

**Param√®tres :**

- `ftr`

##### write_file_index_page

Write the file index page for this report.

**Param√®tres :**

- `first_html`
- `final_html`

##### write_region_index_pages

Write the other index pages for this report.

**Param√®tres :**

- `files_to_report`

##### write_index_page

Write an index page specified by `index_page`.

Returns the filename created.

**Param√®tres :**

- `index_page`

##### __init__

**Param√®tres :**

- `directory`

##### _reset

Initialize to empty. Causes all files to be reported.

##### read

Read the information we stored last time.

##### write

Write the current status.

##### check_global_data

Check the global data that can affect incremental reporting.

Pass in whatever global information could affect the content of the
HTML pages.  If the global data has changed since last time, this will
clear the data so that all files are regenerated.

##### can_skip_file

Can we skip reporting this file?

`data` is a CoverageData object, `fr` is a `FileReporter`, and
`rootname` is the name being used for the file.

Returns True if the HTML page is fine as-is, False if we need to recreate
the HTML page.

**Param√®tres :**

- `data`
- `fr`
- `rootname`

##### index_info

Get the information for index.html for `fname`.

**Param√®tres :**

- `fname`

##### set_index_info

Set the information for index.html for `fname`.

**Param√®tres :**

- `fname`
- `info`

---

### cmdline

Command-line support for coverage.py.

#### Classes

##### Opts

A namespace class for individual options we'll build parsers from.

##### CoverageOptionParser

Base OptionParser for coverage.py.

Problems don't exit the program.
Defaults are initialized for all options.

**M√©thodes :**

- `__init__()`
- `parse_args_ok()`
- `error()`

##### GlobalOptionParser

Command-line parser for coverage.py global option arguments.

**M√©thodes :**

- `__init__()`

##### CmdOptionParser

Parse one of the new-style commands for coverage.py.

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `get_prog_name()`

##### CoverageScript

The command-line interface to coverage.py.

**M√©thodes :**

- `__init__()`
- `command_line()`
- `do_help()`
- `do_signal_save()`
- `do_run()`
- `do_debug()`

##### OptionParserError

Used to stop the optparse error handler ending the process.

#### Fonctions

##### show_help

Display an error message, or the named topic.

**Param√®tres :**

- `error`
- `topic`
- `parser`

##### unshell_list

Turn a command-line argument into a list.

**Param√®tres :**

- `s`

##### unglob_args

Interpret shell wildcards for platforms that need it.

**Param√®tres :**

- `args`

##### main

The main entry point to coverage.py.

This is installed as the script entry point.

**Param√®tres :**

- `argv`

##### __init__

##### parse_args_ok

Call optparse.parse_args, but return a triple:

(ok, options, args)

**Param√®tres :**

- `args`

##### error

Override optparse.error so sys.exit doesn't get called.

**Param√®tres :**

- `msg`

##### __init__

##### __init__

Create an OptionParser for a coverage.py command.

`action` is the slug to put into `options.action`.
`options` is a list of Option's for the command.
`description` is the description of the command, for the help text.
`usage` is the usage string to display in help.

**Param√®tres :**

- `action`
- `options`
- `description`
- `usage`

##### __eq__

**Param√®tres :**

- `other`

##### get_prog_name

Override of an undocumented function in optparse.OptionParser.

##### __init__

##### command_line

The bulk of the command line interface to coverage.py.

`argv` is the argument list to process.

Returns 0 if all is well, 1 if something went wrong.

**Param√®tres :**

- `argv`

##### do_help

Deal with help requests.

Return True if it handled the request, False if not.

**Param√®tres :**

- `options`
- `args`
- `parser`

##### do_signal_save

Signal handler to save coverage report 

**Param√®tres :**

- `_signum`
- `_frame`

##### do_run

Implementation of 'coverage run'.

**Param√®tres :**

- `options`
- `args`

##### do_debug

Implementation of 'coverage debug'.

**Param√®tres :**

- `args`

##### main

A wrapper around main that profiles.

**Param√®tres :**

- `argv`

---

### collector

Raw data collector for coverage.py.

#### Classes

##### Collector

Collects trace data.

Creates a Tracer object for each thread, since they track stack
information.  Each Tracer points to the same shared data, contributing
traced data points.

When the Collector is started, it creates a Tracer for the current thread,
and installs a function to create Tracers for each new thread started.
When the Collector is stopped, all active Tracers are stopped.

Threads started while the Collector is stopped will never have Tracers
associated with them.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `use_data()`
- `tracer_name()`
- `_clear_data()`
- `reset()`
- `lock_data()`
- `unlock_data()`
- `_start_tracer()`
- `_installation_trace()`
- `start()`
- `stop()`
- `pause()`
- `resume()`
- `post_fork()`
- `_activity()`
- `switch_context()`
- `disable_plugin()`
- `cached_mapped_file()`
- `mapped_file_dict()`
- `plugin_was_disabled()`
- `flush_data()`

#### Fonctions

##### __init__

Create a collector.

`should_trace` is a function, taking a file name and a frame, and
returning a `coverage.FileDisposition object`.

`check_include` is a function taking a file name and a frame. It returns
a boolean: True if the file should be traced, False if not.

`should_start_context` is a function taking a frame, and returning a
string. If the frame should be the start of a new context, the string
is the new context. If the frame should not be the start of a new
context, return None.

`file_mapper` is a function taking a filename, and returning a Unicode
filename.  The result is the name that will be recorded in the data
file.

If `branch` is true, then branches will be measured.  This involves
collecting data on which statements followed each other (arcs).  Use
`get_arc_data` to get the arc data.

`warn` is a warning function, taking a single string message argument
and an optional slug argument which will be a string or None, to be
used if a warning needs to be issued.

`concurrency` is a list of strings indicating the concurrency libraries
in use.  Valid values are "greenlet", "eventlet", "gevent", or "thread"
(the default).  "thread" can be combined with one of the other three.
Other values are ignored.

**Param√®tres :**

- `core`
- `should_trace`
- `check_include`
- `should_start_context`
- `file_mapper`
- `branch`
- `warn`
- `concurrency`

##### __repr__

##### use_data

Use `covdata` for recording data.

**Param√®tres :**

- `covdata`
- `context`

##### tracer_name

Return the class name of the tracer we're using.

##### _clear_data

Clear out existing data, but stay ready for more collection.

##### reset

Clear collected data, and prepare to collect more.

##### lock_data

Lock self.data_lock, for use by the C tracer.

##### unlock_data

Unlock self.data_lock, for use by the C tracer.

##### _start_tracer

Start a new Tracer object, and store it in self.tracers.

##### _installation_trace

Called on new threads, installs the real tracer.

**Param√®tres :**

- `frame`
- `event`
- `arg`

##### start

Start collecting trace information.

##### stop

Stop collecting trace information.

##### pause

Pause tracing, but be prepared to `resume`.

##### resume

Resume tracing after a `pause`.

##### post_fork

After a fork, tracers might need to adjust.

##### _activity

Has any activity been traced?

Returns a boolean, True if any trace function was invoked.

##### switch_context

Switch to a new dynamic context.

**Param√®tres :**

- `new_context`

##### disable_plugin

Disable the plugin mentioned in `disposition`.

**Param√®tres :**

- `disposition`

##### cached_mapped_file

A locally cached version of file names mapped through file_mapper.

**Param√®tres :**

- `filename`

##### mapped_file_dict

Return a dict like d, but with keys modified by file_mapper.

**Param√®tres :**

- `d`

##### plugin_was_disabled

Record that `plugin` was disabled during the run.

**Param√®tres :**

- `plugin`

##### flush_data

Save the collected data to our associated `CoverageData`.

Data may have also been saved along the way. This forces the
last of the data to be saved.

Returns True if there was data to save, False if not.

---

### core

Management of core choices.

#### Classes

##### Core

Information about the central technology enabling execution measurement.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `warn`
- `config`
- `dynamic_contexts`
- `metacov`

---

### pytracer

Raw data collector for coverage.py.

#### Classes

##### PyTracer

Python implementation of the raw data tracer.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `log()`
- `_trace()`
- `start()`
- `stop()`
- `activity()`
- `reset_activity()`
- `get_stats()`

#### Fonctions

##### __init__

##### __repr__

##### log

For hard-core logging of what this tracer is doing.

**Param√®tres :**

- `marker`

##### _trace

The trace function passed to sys.settrace.

**Param√®tres :**

- `frame`
- `event`
- `arg`
- `lineno`

##### start

Start this Tracer.

Return a Python function suitable for use with sys.settrace().

##### stop

Stop this Tracer.

##### activity

Has there been any activity?

##### reset_activity

Reset the activity() flag.

##### get_stats

Return a dictionary of statistics, or None.

---

### types

Types for use throughout coverage.py.

#### Classes

##### TTraceFn

A Python trace function.

**M√©thodes :**

- `__call__()`

##### TFileDisposition

A simple value type for recording what to do with a file.

##### Tracer

Anything that can report on Python execution.

**M√©thodes :**

- `__init__()`
- `start()`
- `stop()`
- `activity()`
- `reset_activity()`
- `get_stats()`

##### TConfigurable

Something that can proxy to the coverage configuration settings.

**M√©thodes :**

- `get_option()`
- `set_option()`

##### TPluginConfig

Something that can provide options to a plugin.

**M√©thodes :**

- `get_plugin_options()`

##### TPlugin

What all plugins have in common.

##### TWarnFn

A callable warn() function.

**M√©thodes :**

- `__call__()`

##### TDebugCtl

A DebugControl object, or something like it.

**M√©thodes :**

- `should()`
- `write()`

##### TWritable

Anything that can be written to.

**M√©thodes :**

- `write()`

#### Fonctions

##### __call__

**Param√®tres :**

- `frame`
- `event`
- `arg`
- `lineno`

##### __init__

##### start

Start this tracer, return a trace function if based on sys.settrace.

##### stop

Stop this tracer.

##### activity

Has there been any activity?

##### reset_activity

Reset the activity() flag.

##### get_stats

Return a dictionary of statistics, or None.

##### get_option

Get an option from the configuration.

`option_name` is a colon-separated string indicating the section and
option name.  For example, the ``branch`` option in the ``[run]``
section of the config file would be indicated with `"run:branch"`.

Returns the value of the option.

**Param√®tres :**

- `option_name`

##### set_option

Set an option in the configuration.

`option_name` is a colon-separated string indicating the section and
option name.  For example, the ``branch`` option in the ``[run]``
section of the config file would be indicated with `"run:branch"`.

`value` is the new value for the option.

**Param√®tres :**

- `option_name`
- `value`

##### get_plugin_options

Get the options for a plugin.

**Param√®tres :**

- `plugin`

##### __call__

**Param√®tres :**

- `msg`
- `slug`
- `once`

##### should

Decide whether to output debug information in category `option`.

**Param√®tres :**

- `option`

##### write

Write a line of debug output.

**Param√®tres :**

- `msg`

##### write

Write a message.

**Param√®tres :**

- `msg`

---

### annotate

Source file annotation for coverage.py.

#### Classes

##### AnnotateReporter

Generate annotated source files showing line coverage.

This reporter creates annotated copies of the measured source files. Each
.py file is copied as a .py,cover file, with a left-hand margin annotating
each line::

    > def h(x):
    -     if 0:   #pragma: no cover
    -         pass
    >     if x == 1:
    !         a = 1
    >     else:
    >         a = 2

    > h(2)

Executed lines use ">", lines not executed use "!", lines excluded from
consideration use "-".

**M√©thodes :**

- `__init__()`
- `report()`
- `annotate_file()`

#### Fonctions

##### __init__

**Param√®tres :**

- `coverage`

##### report

Run the report.

See `coverage.report()` for arguments.

**Param√®tres :**

- `morfs`
- `directory`

##### annotate_file

Annotate a single file.

`fr` is the FileReporter for the file to annotate.

**Param√®tres :**

- `fr`
- `analysis`

---

### sqldata

SQLite coverage data.

#### Classes

##### CoverageData

Manages collected coverage data, including file storage.

This class is the public supported API to the data that coverage.py
collects during program execution.  It includes information about what code
was executed. It does not include information from the analysis phase, to
determine what lines could have been executed, or what lines were not
executed.

.. note::

    The data file is currently a SQLite database file, with a
    :ref:`documented schema <dbschema>`. The schema is subject to change
    though, so be careful about querying it directly. Use this API if you
    can to isolate yourself from changes.

There are a number of kinds of data that can be collected:

* **lines**: the line numbers of source lines that were executed.
  These are always available.

* **arcs**: pairs of source and destination line numbers for transitions
  between source lines.  These are only available if branch coverage was
  used.

* **file tracer names**: the module names of the file tracer plugins that
  handled each file in the data.

Lines, arcs, and file tracer names are stored for each source file. File
names in this API are case-sensitive, even on platforms with
case-insensitive file systems.

A data file either stores lines, or arcs, but not both.

A data file is associated with the data when the :class:`CoverageData`
is created, using the parameters `basename`, `suffix`, and `no_disk`. The
base name can be queried with :meth:`base_filename`, and the actual file
name being used is available from :meth:`data_filename`.

To read an existing coverage.py data file, use :meth:`read`.  You can then
access the line, arc, or file tracer data with :meth:`lines`, :meth:`arcs`,
or :meth:`file_tracer`.

The :meth:`has_arcs` method indicates whether arc data is available.  You
can get a set of the files in the data with :meth:`measured_files`.  As
with most Python containers, you can determine if there is any data at all
by using this object as a boolean value.

The contexts for each line in a file can be read with
:meth:`contexts_by_lineno`.

To limit querying to certain contexts, use :meth:`set_query_context` or
:meth:`set_query_contexts`. These will narrow the focus of subsequent
:meth:`lines`, :meth:`arcs`, and :meth:`contexts_by_lineno` calls. The set
of all measured context names can be retrieved with
:meth:`measured_contexts`.

Most data files will be created by coverage.py itself, but you can use
methods here to create data files if you like.  The :meth:`add_lines`,
:meth:`add_arcs`, and :meth:`add_file_tracers` methods add data, in ways
that are convenient for coverage.py.

To record data for contexts, use :meth:`set_context` to set a context to
be used for subsequent :meth:`add_lines` and :meth:`add_arcs` calls.

To add a source file without any measured data, use :meth:`touch_file`,
or :meth:`touch_files` for a list of such files.

Write the data to its file with :meth:`write`.

You can clear the data in memory with :meth:`erase`.  Data for specific
files can be removed from the database with :meth:`purge_files`.

Two data collections can be combined by using :meth:`update` on one
:class:`CoverageData`, passing it the other.

Data in a :class:`CoverageData` can be serialized and deserialized with
:meth:`dumps` and :meth:`loads`.

The methods used during the coverage.py collection phase
(:meth:`add_lines`, :meth:`add_arcs`, :meth:`set_context`, and
:meth:`add_file_tracers`) are thread-safe.  Other methods may not be.

**M√©thodes :**

- `__init__()`
- `_choose_filename()`
- `_reset()`
- `_open_db()`
- `_read_db()`
- `_init_db()`
- `_connect()`
- `__bool__()`
- `dumps()`
- `loads()`
- `_file_id()`
- `_context_id()`
- `set_context()`
- `_set_context_id()`
- `base_filename()`
- `data_filename()`
- `add_lines()`
- `add_arcs()`
- `_choose_lines_or_arcs()`
- `add_file_tracers()`
- `touch_file()`
- `touch_files()`
- `purge_files()`
- `update()`
- `erase()`
- `read()`
- `write()`
- `_start_using()`
- `has_arcs()`
- `measured_files()`
- `measured_contexts()`
- `file_tracer()`
- `set_query_context()`
- `set_query_contexts()`
- `lines()`
- `arcs()`
- `contexts_by_lineno()`
- `sys_info()`

#### Fonctions

##### _locked

A decorator for methods that should hold self._lock.

**Param√®tres :**

- `method`

##### filename_suffix

Compute a filename suffix for a data file.

If `suffix` is a string or None, simply return it. If `suffix` is True,
then build a suffix incorporating the hostname, process id, and a random
number.

Returns a string or None.

**Param√®tres :**

- `suffix`

##### _wrapped

##### __init__

Create a :class:`CoverageData` object to hold coverage-measured data.

Arguments:
    basename (str): the base name of the data file, defaulting to
        ".coverage". This can be a path to a file in another directory.
    suffix (str or bool): has the same meaning as the `data_suffix`
        argument to :class:`coverage.Coverage`.
    no_disk (bool): if True, keep all data in memory, and don't
        write any disk file.
    warn: a warning callback function, accepting a warning message
        argument.
    debug: a `DebugControl` object (optional)

**Param√®tres :**

- `basename`
- `suffix`
- `no_disk`
- `warn`
- `debug`

##### _choose_filename

Set self._filename based on inited attributes.

##### _reset

Reset our attributes.

##### _open_db

Open an existing db file, and read its metadata.

##### _read_db

Read the metadata from a database so that we are ready to use it.

##### _init_db

Write the initial contents of the database.

**Param√®tres :**

- `db`

##### _connect

Get the SqliteDb object to use.

##### __bool__

##### dumps

Serialize the current data to a byte string.

The format of the serialized data is not documented. It is only
suitable for use with :meth:`loads` in the same version of
coverage.py.

Note that this serialization is not what gets stored in coverage data
files.  This method is meant to produce bytes that can be transmitted
elsewhere and then deserialized with :meth:`loads`.

Returns:
    A byte string of serialized data.

.. versionadded:: 5.0

##### loads

Deserialize data from :meth:`dumps`.

Use with a newly-created empty :class:`CoverageData` object.  It's
undefined what happens if the object already has data in it.

Note that this is not for reading data from a coverage data file.  It
is only for use on data you produced with :meth:`dumps`.

Arguments:
    data: A byte string of serialized data produced by :meth:`dumps`.

.. versionadded:: 5.0

**Param√®tres :**

- `data`

##### _file_id

Get the file id for `filename`.

If filename is not in the database yet, add it if `add` is True.
If `add` is not True, return None.

**Param√®tres :**

- `filename`
- `add`

##### _context_id

Get the id for a context.

**Param√®tres :**

- `context`

##### set_context

Set the current context for future :meth:`add_lines` etc.

`context` is a str, the name of the context to use for the next data
additions.  The context persists until the next :meth:`set_context`.

.. versionadded:: 5.0

**Param√®tres :**

- `context`

##### _set_context_id

Use the _current_context to set _current_context_id.

##### base_filename

The base filename for storing data.

.. versionadded:: 5.0

##### data_filename

Where is the data stored?

.. versionadded:: 5.0

##### add_lines

Add measured line data.

`line_data` is a dictionary mapping file names to iterables of ints::

    { filename: { line1, line2, ... }, ...}

**Param√®tres :**

- `line_data`

##### add_arcs

Add measured arc data.

`arc_data` is a dictionary mapping file names to iterables of pairs of
ints::

    { filename: { (l1,l2), (l1,l2), ... }, ...}

**Param√®tres :**

- `arc_data`

##### _choose_lines_or_arcs

Force the data file to choose between lines and arcs.

**Param√®tres :**

- `lines`
- `arcs`

##### add_file_tracers

Add per-file plugin information.

`file_tracers` is { filename: plugin_name, ... }

**Param√®tres :**

- `file_tracers`

##### touch_file

Ensure that `filename` appears in the data, empty if needed.

`plugin_name` is the name of the plugin responsible for this file.
It is used to associate the right filereporter, etc.

**Param√®tres :**

- `filename`
- `plugin_name`

##### touch_files

Ensure that `filenames` appear in the data, empty if needed.

`plugin_name` is the name of the plugin responsible for these files.
It is used to associate the right filereporter, etc.

**Param√®tres :**

- `filenames`
- `plugin_name`

##### purge_files

Purge any existing coverage data for the given `filenames`.

.. versionadded:: 7.2

**Param√®tres :**

- `filenames`

##### update

Update this data with data from another :class:`CoverageData`.

If `map_path` is provided, it's a function that re-map paths to match
the local machine's.  Note: `map_path` is None only when called
directly from the test suite.

**Param√®tres :**

- `other_data`
- `map_path`

##### erase

Erase the data in this object.

If `parallel` is true, then also deletes data files created from the
basename by parallel-mode.

**Param√®tres :**

- `parallel`

##### read

Start using an existing data file.

##### write

Ensure the data is written to the data file.

##### _start_using

Call this before using the database at all.

##### has_arcs

Does the database have arcs (True) or lines (False).

##### measured_files

A set of all files that have been measured.

Note that a file may be mentioned as measured even though no lines or
arcs for that file are present in the data.

##### measured_contexts

A set of all contexts that have been measured.

.. versionadded:: 5.0

##### file_tracer

Get the plugin name of the file tracer for a file.

Returns the name of the plugin that handles this file.  If the file was
measured, but didn't use a plugin, then "" is returned.  If the file
was not measured, then None is returned.

**Param√®tres :**

- `filename`

##### set_query_context

Set a context for subsequent querying.

The next :meth:`lines`, :meth:`arcs`, or :meth:`contexts_by_lineno`
calls will be limited to only one context.  `context` is a string which
must match a context exactly.  If it does not, no exception is raised,
but queries will return no data.

.. versionadded:: 5.0

**Param√®tres :**

- `context`

##### set_query_contexts

Set a number of contexts for subsequent querying.

The next :meth:`lines`, :meth:`arcs`, or :meth:`contexts_by_lineno`
calls will be limited to the specified contexts.  `contexts` is a list
of Python regular expressions.  Contexts will be matched using
:func:`re.search <python:re.search>`.  Data will be included in query
results if they are part of any of the contexts matched.

.. versionadded:: 5.0

**Param√®tres :**

- `contexts`

##### lines

Get the list of lines executed for a source file.

If the file was not measured, returns None.  A file might be measured,
and have no lines executed, in which case an empty list is returned.

If the file was executed, returns a list of integers, the line numbers
executed in the file. The list is in no particular order.

**Param√®tres :**

- `filename`

##### arcs

Get the list of arcs executed for a file.

If the file was not measured, returns None.  A file might be measured,
and have no arcs executed, in which case an empty list is returned.

If the file was executed, returns a list of 2-tuples of integers. Each
pair is a starting line number and an ending line number for a
transition from one line to another. The list is in no particular
order.

Negative numbers have special meaning.  If the starting line number is
-N, it represents an entry to the code object that starts at line N.
If the ending ling number is -N, it's an exit from the code object that
starts at line N.

**Param√®tres :**

- `filename`

##### contexts_by_lineno

Get the contexts for each line in a file.

Returns:
    A dict mapping line numbers to a list of context names.

.. versionadded:: 5.0

**Param√®tres :**

- `filename`

##### sys_info

Our information for `Coverage.sys_info`.

Returns a list of (key, value) pairs.

**Param√®tres :**

- `cls`

---

### disposition

Simple value objects for tracking what to do with files.

#### Classes

##### FileDisposition

A simple value type for recording what to do with a file.

**M√©thodes :**

- `__repr__()`

#### Fonctions

##### disposition_init

Construct and initialize a new FileDisposition object.

**Param√®tres :**

- `cls`
- `original_filename`

##### disposition_debug_msg

Make a nice debug message of what the FileDisposition is doing.

**Param√®tres :**

- `disp`

##### __repr__

---

### parser

Code parsing for coverage.py.

#### Classes

##### PythonParser

Parse code to find executable lines, excluded lines, etc.

This information is all based on static analysis: no code execution is
involved.

**M√©thodes :**

- `__init__()`
- `lines_matching()`
- `_raw_parse()`
- `first_line()`
- `first_lines()`
- `translate_lines()`
- `translate_arcs()`
- `parse_source()`
- `arcs()`
- `_analyze_ast()`
- `fix_with_jumps()`
- `exit_counts()`
- `_finish_action_msg()`
- `missing_arc_description()`
- `arc_description()`

##### ByteParser

Parse bytecode to understand the structure of code.

**M√©thodes :**

- `__init__()`
- `child_parsers()`
- `_line_numbers()`
- `_find_statements()`

##### ArcStart

The information needed to start an arc.

`lineno` is the line number the arc starts from.

`cause` is an English text fragment used as the `missing_cause_msg` for
AstArcAnalyzer.missing_arc_fragments.  It will be used to describe why an
arc wasn't executed, so should fit well into a sentence of the form,
"Line 17 didn't run because {cause}."  The fragment can include "{lineno}"
to have `lineno` interpolated into it.

As an example, this code::

    if something(x):        # line 1
        func(x)             # line 2
    more_stuff()            # line 3

would have two ArcStarts:

- ArcStart(1, "the condition on line 1 was always true")
- ArcStart(1, "the condition on line 1 was never true")

The first would be used to create an arc from 1 to 3, creating a message like
"line 1 didn't jump to line 3 because the condition on line 1 was always true."

The second would be used for the arc from 1 to 2, creating a message like
"line 1 didn't jump to line 2 because the condition on line 1 was never true."

##### TAddArcFn

The type for AstArcAnalyzer.add_arc().

**M√©thodes :**

- `__call__()`

##### Block

Blocks need to handle various exiting statements in their own ways.

All of these methods take a list of exits, and a callable `add_arc`
function that they can use to add arcs if needed.  They return True if the
exits are handled, or False if the search should continue up the block
stack.

**M√©thodes :**

- `process_break_exits()`
- `process_continue_exits()`
- `process_raise_exits()`
- `process_return_exits()`

##### LoopBlock

A block on the block stack representing a `for` or `while` loop.

**M√©thodes :**

- `__init__()`
- `process_break_exits()`
- `process_continue_exits()`

##### FunctionBlock

A block on the block stack representing a function definition.

**M√©thodes :**

- `__init__()`
- `process_raise_exits()`
- `process_return_exits()`

##### TryBlock

A block on the block stack representing a `try` block.

**M√©thodes :**

- `__init__()`
- `process_raise_exits()`

##### NodeList

A synthetic fictitious node, containing a sequence of nodes.

This is used when collapsing optimized if-statements, to represent the
unconditional execution of one of the clauses.

**M√©thodes :**

- `__init__()`

##### AstArcAnalyzer

Analyze source text with an AST to find executable code paths.

The .analyze() method does the work, and populates these attributes:

`arcs`: a set of (from, to) pairs of the the arcs possible in the code.

`missing_arc_fragments`: a dict mapping (from, to) arcs to lists of
message fragments explaining why the arc is missing from execution::

    { (start, end): [(missing_cause_msg, action_msg), ...], }

For an arc starting from line 17, they should be usable to form complete
sentences like: "Line 17 didn't {action_msg} because {missing_cause_msg}".

NOTE: Starting in July 2024, I've been whittling this down to only report
arc that are part of true branches.  It's not clear how far this work will
go.

**M√©thodes :**

- `__init__()`
- `analyze()`
- `with_jump_fixers()`
- `_code_object__Module()`
- `_code_object__FunctionDef()`
- `_code_object__ClassDef()`
- `add_arc()`
- `nearest_blocks()`
- `line_for_node()`
- `_line_decorated()`
- `_line__Assign()`
- `_line__Dict()`
- `_line__List()`
- `_line__Module()`
- `node_exits()`
- `process_body()`
- `find_non_missing_node()`
- `_missing__If()`
- `_missing__NodeList()`
- `_missing__While()`
- `process_break_exits()`
- `process_continue_exits()`
- `process_raise_exits()`
- `process_return_exits()`
- `_handle__Break()`
- `_handle_decorated()`
- `_handle__Continue()`
- `_handle__For()`
- `_handle__If()`
- `_handle__NodeList()`
- `_handle__Raise()`
- `_handle__Return()`
- `_handle__Try()`
- `_handle__While()`
- `_handle__With()`

#### Fonctions

##### is_constant_test_expr

Is this a compile-time constant test expression?

We don't try to mimic all of CPython's optimizations.  We just have to
handle the kinds of constant expressions people might actually use.

**Param√®tres :**

- `node`

##### __init__

Source can be provided as `text`, the text itself, or `filename`, from
which the text will be read.  Excluded lines are those that match
`exclude`, a regex string.

**Param√®tres :**

- `text`
- `filename`
- `exclude`

##### lines_matching

Find the lines matching a regex.

Returns a set of line numbers, the lines that contain a match for
`regex`. The entire line needn't match, just a part of it.
Handles multiline regex patterns.

**Param√®tres :**

- `regex`

##### _raw_parse

Parse the source to find the interesting facts about its lines.

A handful of attributes are updated.

##### first_line

Return the first line number of the statement including `lineno`.

**Param√®tres :**

- `lineno`

##### first_lines

Map the line numbers in `linenos` to the correct first line of the
statement.

Returns a set of the first lines.

**Param√®tres :**

- `linenos`

##### translate_lines

Implement `FileReporter.translate_lines`.

**Param√®tres :**

- `lines`

##### translate_arcs

Implement `FileReporter.translate_arcs`.

**Param√®tres :**

- `arcs`

##### parse_source

Parse source text to find executable lines, excluded lines, etc.

Sets the .excluded and .statements attributes, normalized to the first
line of multi-line statements.

##### arcs

Get information about the arcs available in the code.

Returns a set of line number pairs.  Line numbers have been normalized
to the first line of multi-line statements.

##### _analyze_ast

Run the AstArcAnalyzer and save its results.

`_all_arcs` is the set of arcs in the code.

##### fix_with_jumps

Adjust arcs to fix jumps leaving `with` statements.

Consider this code:

    with open("/tmp/test", "w") as f1:
        a = 2
        b = 3
    print(4)

In 3.10+, we get traces for lines 1, 2, 3, 1, 4.  But we want to present
it to the user as if it had been 1, 2, 3, 4.  The arc 3->1 should be
replaced with 3->4, and 1->4 should be removed.

For this code, the fixers dict is {(3, 1): ((1, 4), (3, 4))}.  The key
is the actual measured arc from the end of the with block back to the
start of the with-statement.  The values are start_next (the with
statement to the next statement after the with), and end_next (the end
of the with-statement to the next statement after the with).

With nested with-statements, we have to trace through a few levels to
correct a longer chain of arcs.

**Param√®tres :**

- `arcs`

##### exit_counts

Get a count of exits from that each line.

Excluded lines are excluded.

##### _finish_action_msg

Apply some defaulting and formatting to an arc's description.

**Param√®tres :**

- `action_msg`
- `end`

##### missing_arc_description

Provide an English sentence describing a missing arc.

**Param√®tres :**

- `start`
- `end`

##### arc_description

Provide an English description of an arc's effect.

**Param√®tres :**

- `start`
- `end`

##### __init__

**Param√®tres :**

- `text`
- `code`
- `filename`

##### child_parsers

Iterate over all the code objects nested within this one.

The iteration includes `self` as its first value.

We skip code objects named `__annotate__` since they are deferred
annotations that usually are never run.  If there are errors in the
annotations, they will be caught by type checkers or other tools that
use annotations.

##### _line_numbers

Yield the line numbers possible in this code object.

Uses co_lnotab described in Python/compile.c to find the
line numbers.  Produces a sequence: l0, l1, ...

##### _find_statements

Find the statements in `self.code`.

Produce a sequence of line numbers that start statements.  Recurses
into all code objects reachable from `self.code`.

##### __call__

Record an arc from `start` to `end`.

`missing_cause_msg` is a description of the reason the arc wasn't
taken if it wasn't taken.  For example, "the condition on line 10 was
never true."

`action_msg` is a description of what the arc does, like "jump to line
10" or "exit from function 'fooey'."

**Param√®tres :**

- `start`
- `end`
- `missing_cause_msg`
- `action_msg`

##### process_break_exits

Process break exits.

**Param√®tres :**

- `exits`
- `add_arc`

##### process_continue_exits

Process continue exits.

**Param√®tres :**

- `exits`
- `add_arc`

##### process_raise_exits

Process raise exits.

**Param√®tres :**

- `exits`
- `add_arc`

##### process_return_exits

Process return exits.

**Param√®tres :**

- `exits`
- `add_arc`

##### __init__

**Param√®tres :**

- `start`

##### process_break_exits

**Param√®tres :**

- `exits`
- `add_arc`

##### process_continue_exits

**Param√®tres :**

- `exits`
- `add_arc`

##### __init__

**Param√®tres :**

- `start`
- `name`

##### process_raise_exits

**Param√®tres :**

- `exits`
- `add_arc`

##### process_return_exits

**Param√®tres :**

- `exits`
- `add_arc`

##### __init__

**Param√®tres :**

- `handler_start`
- `final_start`

##### process_raise_exits

**Param√®tres :**

- `exits`
- `add_arc`

##### __init__

**Param√®tres :**

- `body`

##### __init__

**Param√®tres :**

- `filename`
- `root_node`
- `statements`
- `multiline`

##### analyze

Examine the AST tree from `self.root_node` to determine possible arcs.

##### with_jump_fixers

Get a dict with data for fixing jumps out of with statements.

Returns a dict.  The keys are arcs leaving a with-statement by jumping
back to its start.  The values are pairs: first, the arc from the start
to the next statement, then the arc that exits the with without going
to the start.

##### _code_object__Module

**Param√®tres :**

- `node`

##### _code_object__FunctionDef

**Param√®tres :**

- `node`

##### _code_object__ClassDef

**Param√®tres :**

- `node`

##### add_arc

Add an arc, including message fragments to use if it is missing.

**Param√®tres :**

- `start`
- `end`
- `missing_cause_msg`
- `action_msg`

##### nearest_blocks

Yield the blocks in nearest-to-farthest order.

##### line_for_node

What is the right line number to use for this node?

This dispatches to _line__Node functions where needed.

**Param√®tres :**

- `node`

##### _line_decorated

Compute first line number for things that can be decorated (classes and functions).

**Param√®tres :**

- `node`

##### _line__Assign

**Param√®tres :**

- `node`

##### _line__Dict

**Param√®tres :**

- `node`

##### _line__List

**Param√®tres :**

- `node`

##### _line__Module

**Param√®tres :**

- `node`

##### node_exits

Find the set of arc starts that exit this node.

Return a set of ArcStarts, exits from this node to the next. Because a
node represents an entire sub-tree (including its children), the exits
from a node can be arbitrarily complex::

    if something(1):
        if other(2):
            doit(3)
        else:
            doit(5)

There are three exits from line 1: they start at lines 1, 3 and 5.
There are two exits from line 2: lines 3 and 5.

**Param√®tres :**

- `node`

##### process_body

Process the body of a compound statement.

`body` is the body node to process.

`from_start` is a single `ArcStart` that starts an arc into this body.
`prev_starts` is a set of ArcStarts that can all be the start of arcs
into this body.  Only one of `from_start` and `prev_starts` should be
given.

Records arcs within the body by calling `self.add_arc`.

Returns a set of ArcStarts, the exits from this body.

**Param√®tres :**

- `body`
- `from_start`
- `prev_starts`

##### find_non_missing_node

Search `node` looking for a child that has not been optimized away.

This might return the node you started with, or it will work recursively
to find a child node in self.statements.

Returns a node, or None if none of the node remains.

**Param√®tres :**

- `node`

##### _missing__If

**Param√®tres :**

- `node`

##### _missing__NodeList

**Param√®tres :**

- `node`

##### _missing__While

**Param√®tres :**

- `node`

##### process_break_exits

Add arcs due to jumps from `exits` being breaks.

**Param√®tres :**

- `exits`

##### process_continue_exits

Add arcs due to jumps from `exits` being continues.

**Param√®tres :**

- `exits`

##### process_raise_exits

Add arcs due to jumps from `exits` being raises.

**Param√®tres :**

- `exits`

##### process_return_exits

Add arcs due to jumps from `exits` being returns.

**Param√®tres :**

- `exits`

##### _handle__Break

**Param√®tres :**

- `node`

##### _handle_decorated

Add arcs for things that can be decorated (classes and functions).

**Param√®tres :**

- `node`

##### _handle__Continue

**Param√®tres :**

- `node`

##### _handle__For

**Param√®tres :**

- `node`

##### _handle__If

**Param√®tres :**

- `node`

##### _handle__NodeList

**Param√®tres :**

- `node`

##### _handle__Raise

**Param√®tres :**

- `node`

##### _handle__Return

**Param√®tres :**

- `node`

##### _handle__Try

**Param√®tres :**

- `node`

##### _handle__While

**Param√®tres :**

- `node`

##### _handle__With

**Param√®tres :**

- `node`

##### _handle__Match

**Param√®tres :**

- `node`

---

### context

Determine contexts for coverage.py

#### Fonctions

##### combine_context_switchers

Create a single context switcher from multiple switchers.

`context_switchers` is a list of functions that take a frame as an
argument and return a string to use as the new context label.

Returns a function that composites `context_switchers` functions, or None
if `context_switchers` is an empty list.

When invoked, the combined switcher calls `context_switchers` one-by-one
until a string is returned.  The combined switcher returns None if all
`context_switchers` return None.

**Param√®tres :**

- `context_switchers`

##### should_start_context_test_function

Is this frame calling a test_* function?

**Param√®tres :**

- `frame`

##### qualname_from_frame

Get a qualified name for the code running in `frame`.

**Param√®tres :**

- `frame`

##### should_start_context

The combiner for multiple context switchers.

**Param√®tres :**

- `frame`

---

### xmlreport

XML reporting for coverage.py

#### Classes

##### PackageData

Data we keep about each "package" (in Java terms).

##### XmlReporter

A reporter for writing Cobertura-style XML coverage results.

**M√©thodes :**

- `__init__()`
- `report()`
- `xml_file()`

#### Fonctions

##### rate

Return the fraction of `hit`/`num`, as a string.

**Param√®tres :**

- `hit`
- `num`

##### appendChild

Append a child to a parent, in a way mypy will shut up about.

**Param√®tres :**

- `parent`
- `child`

##### serialize_xml

Serialize a minidom node to XML.

**Param√®tres :**

- `dom`

##### __init__

**Param√®tres :**

- `coverage`

##### report

Generate a Cobertura-compatible XML report for `morfs`.

`morfs` is a list of modules or file names.

`outfile` is a file object to write the XML to.

**Param√®tres :**

- `morfs`
- `outfile`

##### xml_file

Add to the XML report for a single file.

**Param√®tres :**

- `fr`
- `analysis`
- `has_arcs`

---

### debug

Control of and utilities for debugging.

#### Classes

##### DebugControl

Control and output for debugging.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `should()`
- `without_callers()`
- `write()`

##### NoDebugging

A replacement for DebugControl that will never try to do anything.

**M√©thodes :**

- `__init__()`
- `should()`
- `without_callers()`
- `write()`

##### CwdTracker

A class to add cwd info to debug messages.

**M√©thodes :**

- `__init__()`
- `filter()`

##### ProcessTracker

Track process creation for debug logging.

**M√©thodes :**

- `__init__()`
- `filter()`

##### PytestTracker

Track the current pytest test name to add to debug messages.

**M√©thodes :**

- `__init__()`
- `filter()`

##### DebugOutputFile

A file-like object that includes pid and cwd information.

**M√©thodes :**

- `__init__()`
- `get_one()`
- `_set_singleton_data()`
- `_get_singleton_data()`
- `_del_singleton_data()`
- `write()`
- `flush()`

#### Fonctions

##### info_header

Make a nice header string.

**Param√®tres :**

- `label`

##### info_formatter

Produce a sequence of formatted lines from info.

`info` is a sequence of pairs (label, data).  The produced lines are
nicely formatted, ready to print.

**Param√®tres :**

- `info`

##### write_formatted_info

Write a sequence of (label,data) pairs nicely.

`write` is a function write(str) that accepts each line of output.
`header` is a string to start the section.  `info` is a sequence of
(label, data) pairs, where label is a str, and data can be a single
value, or a list/set/tuple.

**Param√®tres :**

- `write`
- `header`
- `info`

##### exc_one_line

Get a one-line summary of an exception, including class name and message.

**Param√®tres :**

- `exc`

##### short_filename

**Param√®tres :**

- `filename`

##### short_filename

**Param√®tres :**

- `filename`

##### short_filename

Shorten a file name. Directories are replaced by prefixes like 'syspath:'

**Param√®tres :**

- `filename`

##### short_stack

Return a string summarizing the call stack.

The string is multi-line, with one line per stack frame. Each line shows
the function name, the file name, and the line number:

    ...
    start_import_stop : /Users/ned/coverage/trunk/tests/coveragetest.py:95
    import_local_file : /Users/ned/coverage/trunk/tests/coveragetest.py:81
    import_local_file : /Users/ned/coverage/trunk/coverage/backward.py:159
    ...

`skip` is the number of closest immediate frames to skip, so that debugging
functions can call this and not be included in the result.

If `full` is true, then include all frames.  Otherwise, initial "boring"
frames (ones in site-packages and earlier) are omitted.

`short_filenames` will shorten filenames using `short_filename`, to reduce
the amount of repetitive noise in stack traces.

**Param√®tres :**

- `skip`
- `full`
- `frame_ids`
- `short_filenames`

##### dump_stack_frames

Print a summary of the stack to `out`.

**Param√®tres :**

- `out`
- `skip`

##### clipped_repr

`repr(text)`, but limited to `numchars`.

**Param√®tres :**

- `text`
- `numchars`

##### short_id

Given a 64-bit id, make a shorter 16-bit one.

**Param√®tres :**

- `id64`

##### add_pid_and_tid

A filter to add pid and tid to debug messages.

**Param√®tres :**

- `text`

##### auto_repr

A function implementing an automatic __repr__ for debugging.

##### simplify

Turn things which are nearly dict/list/etc into dict/list/etc.

**Param√®tres :**

- `v`

##### pp

Debug helper to pretty-print data, including SimpleNamespace objects.

**Param√®tres :**

- `v`

##### filter_text

Run `text` through a series of filters.

`filters` is a list of functions. Each takes a string and returns a
string.  Each is run in turn. After each filter, the text is split into
lines, and each line is passed through the next filter.

Returns: the final string that results after all of the filters have
run.

**Param√®tres :**

- `text`
- `filters`

##### log

Write a log message as forcefully as possible.

**Param√®tres :**

- `msg`
- `stack`

##### decorate_methods

A class decorator to apply a decorator to methods.

**Param√®tres :**

- `decorator`
- `butnot`
- `private`

##### break_in_pudb

A function decorator to stop in the debugger for each call.

**Param√®tres :**

- `func`

##### show_calls

A method decorator to debug-log each call to the function.

**Param√®tres :**

- `show_args`
- `show_stack`
- `show_return`

##### relevant_environment_display

Filter environment variables for a debug display.

Select variables to display (with COV or PY in the name, or HOME, TEMP, or
TMP), and also cloak sensitive values with asterisks.

Arguments:
    env: a dict of environment variable names and values.

Returns:
    A list of pairs (name, value) to show.

**Param√®tres :**

- `env`

##### __init__

Configure the options and output file for debugging.

**Param√®tres :**

- `options`
- `output`
- `file_name`

##### __repr__

##### should

Decide whether to output debug information in category `option`.

**Param√®tres :**

- `option`

##### without_callers

A context manager to prevent call stacks from being logged.

##### write

Write a line of debug output.

`msg` is the line to write. A newline will be appended.

If `exc` is provided, a stack trace of the exception will be written
after the message.

**Param√®tres :**

- `msg`

##### __init__

##### should

Should we write debug messages?  Never.

**Param√®tres :**

- `option`

##### without_callers

A dummy context manager to satisfy the api.

##### write

This will never be called.

**Param√®tres :**

- `msg`

##### __init__

##### filter

Add a cwd message for each new cwd.

**Param√®tres :**

- `text`

##### __init__

##### filter

Add a message about how new processes came to be.

**Param√®tres :**

- `text`

##### __init__

##### filter

Add a message when the pytest test changes.

**Param√®tres :**

- `text`

##### __init__

**Param√®tres :**

- `outfile`
- `filters`

##### get_one

Get a DebugOutputFile.

If `fileobj` is provided, then a new DebugOutputFile is made with it.

If `fileobj` isn't provided, then a file is chosen (`file_name` if
provided, or COVERAGE_DEBUG_FILE, or stderr), and a process-wide
singleton DebugOutputFile is made.

`filters` are the text filters to apply to the stream to annotate with
pids, etc.

If `interim` is true, then a future `get_one` can replace this one.

**Param√®tres :**

- `cls`
- `fileobj`
- `file_name`
- `filters`
- `interim`

##### _set_singleton_data

Set the one DebugOutputFile to rule them all.

**Param√®tres :**

- `cls`
- `the_one`
- `interim`

##### _get_singleton_data

Get the one DebugOutputFile.

**Param√®tres :**

- `cls`

##### _del_singleton_data

Delete the one DebugOutputFile, just for tests to use.

**Param√®tres :**

- `cls`

##### write

Just like file.write, but filter through all our filters.

**Param√®tres :**

- `text`

##### flush

Flush our file.

##### _decorator

**Param√®tres :**

- `cls`

##### _wrapper

##### _decorator

**Param√®tres :**

- `func`

##### _wrapper

---

### python

Python source expertise for coverage.py

#### Classes

##### PythonFileReporter

Report support for a Python file.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `relative_filename()`
- `parser()`
- `lines()`
- `multiline_map()`
- `excluded_lines()`
- `translate_lines()`
- `translate_arcs()`
- `no_branch_lines()`
- `arcs()`
- `exit_counts()`
- `missing_arc_description()`
- `arc_description()`
- `source()`
- `should_be_python()`
- `source_token_lines()`
- `code_regions()`
- `code_region_kinds()`

#### Fonctions

##### read_python_source

Read the Python source text from `filename`.

Returns bytes.

**Param√®tres :**

- `filename`

##### get_python_source

Return the source code, as unicode.

**Param√®tres :**

- `filename`

##### get_zip_bytes

Get data from `filename` if it is a zip file path.

Returns the bytestring data read from the zip file, or None if no zip file
could be found or `filename` isn't in it.  The data returned will be
an empty string if the file is empty.

**Param√®tres :**

- `filename`

##### source_for_file

Return the source filename for `filename`.

Given a file name being traced, return the best guess as to the source
file to attribute it to.

**Param√®tres :**

- `filename`

##### source_for_morf

Get the source filename for the module-or-file `morf`.

**Param√®tres :**

- `morf`

##### __init__

**Param√®tres :**

- `morf`
- `coverage`

##### __repr__

##### relative_filename

##### parser

Lazily create a :class:`PythonParser`.

##### lines

Return the line numbers of statements in the file.

##### multiline_map

A map of line numbers to first-line in a multi-line statement.

##### excluded_lines

Return the line numbers of statements in the file.

##### translate_lines

**Param√®tres :**

- `lines`

##### translate_arcs

**Param√®tres :**

- `arcs`

##### no_branch_lines

##### arcs

##### exit_counts

##### missing_arc_description

**Param√®tres :**

- `start`
- `end`
- `executed_arcs`

##### arc_description

**Param√®tres :**

- `start`
- `end`

##### source

##### should_be_python

Does it seem like this file should contain Python?

This is used to decide if a file reported as part of the execution of
a program was really likely to have contained Python in the first
place.

##### source_token_lines

##### code_regions

##### code_region_kinds

---

### plugin

.. versionadded:: 4.0

Plug-in interfaces for coverage.py.

Coverage.py supports a few different kinds of plug-ins that change its
behavior:

* File tracers implement tracing of non-Python file types.

* Configurers add custom configuration, using Python code to change the
  configuration.

* Dynamic context switchers decide when the dynamic context has changed, for
  example, to record what test function produced the coverage.

To write a coverage.py plug-in, create a module with a subclass of
:class:`~coverage.CoveragePlugin`.  You will override methods in your class to
participate in various aspects of coverage.py's processing.
Different types of plug-ins have to override different methods.

Any plug-in can optionally implement :meth:`~coverage.CoveragePlugin.sys_info`
to provide debugging information about their operation.

Your module must also contain a ``coverage_init`` function that registers an
instance of your plug-in class::

    import coverage

    class MyPlugin(coverage.CoveragePlugin):
        ...

    def coverage_init(reg, options):
        reg.add_file_tracer(MyPlugin())

You use the `reg` parameter passed to your ``coverage_init`` function to
register your plug-in object.  The registration method you call depends on
what kind of plug-in it is.

If your plug-in takes options, the `options` parameter is a dictionary of your
plug-in's options from the coverage.py configuration file.  Use them however
you want to configure your object before registering it.

Coverage.py will store its own information on your plug-in object, using
attributes whose names start with ``_coverage_``.  Don't be startled.

.. warning::
    Plug-ins are imported by coverage.py before it begins measuring code.
    If you write a plugin in your own project, it might import your product
    code before coverage.py can start measuring.  This can result in your
    own code being reported as missing.

    One solution is to put your plugins in your project tree, but not in
    your importable Python package.


.. _file_tracer_plugins:

File Tracers
============

File tracers implement measurement support for non-Python files.  File tracers
implement the :meth:`~coverage.CoveragePlugin.file_tracer` method to claim
files and the :meth:`~coverage.CoveragePlugin.file_reporter` method to report
on those files.

In your ``coverage_init`` function, use the ``add_file_tracer`` method to
register your file tracer.


.. _configurer_plugins:

Configurers
===========

.. versionadded:: 4.5

Configurers modify the configuration of coverage.py during start-up.
Configurers implement the :meth:`~coverage.CoveragePlugin.configure` method to
change the configuration.

In your ``coverage_init`` function, use the ``add_configurer`` method to
register your configurer.


.. _dynamic_context_plugins:

Dynamic Context Switchers
=========================

.. versionadded:: 5.0

Dynamic context switcher plugins implement the
:meth:`~coverage.CoveragePlugin.dynamic_context` method to dynamically compute
the context label for each measured frame.

Computed context labels are useful when you want to group measured data without
modifying the source code.

For example, you could write a plugin that checks `frame.f_code` to inspect
the currently executed method, and set the context label to a fully qualified
method name if it's an instance method of `unittest.TestCase` and the method
name starts with 'test'.  Such a plugin would provide basic coverage grouping
by test and could be used with test runners that have no built-in coveragepy
support.

In your ``coverage_init`` function, use the ``add_dynamic_context`` method to
register your dynamic context switcher.

#### Classes

##### CoveragePlugin

Base class for coverage.py plug-ins.

**M√©thodes :**

- `file_tracer()`
- `file_reporter()`
- `dynamic_context()`
- `find_executable_files()`
- `configure()`
- `sys_info()`

##### CoveragePluginBase

Plugins produce specialized objects, which point back to the original plugin.

##### FileTracer

Support needed for files during the execution phase.

File tracer plug-ins implement subclasses of FileTracer to return from
their :meth:`~CoveragePlugin.file_tracer` method.

You may construct this object from :meth:`CoveragePlugin.file_tracer` any
way you like.  A natural choice would be to pass the file name given to
`file_tracer`.

`FileTracer` objects should only be created in the
:meth:`CoveragePlugin.file_tracer` method.

See :ref:`howitworks` for details of the different coverage.py phases.

**M√©thodes :**

- `source_filename()`
- `has_dynamic_source_filename()`
- `dynamic_source_filename()`
- `line_number_range()`

##### CodeRegion

Data for a region of code found by :meth:`FileReporter.code_regions`.

**M√©thodes :**

- `__lt__()`

##### FileReporter

Support needed for files during the analysis and reporting phases.

File tracer plug-ins implement a subclass of `FileReporter`, and return
instances from their :meth:`CoveragePlugin.file_reporter` method.

There are many methods here, but only :meth:`lines` is required, to provide
the set of executable lines in the file.

See :ref:`howitworks` for details of the different coverage.py phases.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `relative_filename()`
- `source()`
- `lines()`
- `excluded_lines()`
- `translate_lines()`
- `arcs()`
- `no_branch_lines()`
- `translate_arcs()`
- `exit_counts()`
- `missing_arc_description()`
- `arc_description()`
- `source_token_lines()`
- `code_regions()`
- `code_region_kinds()`
- `__eq__()`
- `__lt__()`

#### Fonctions

##### file_tracer

Get a :class:`FileTracer` object for a file.

Plug-in type: file tracer.

Every Python source file is offered to your plug-in to give it a chance
to take responsibility for tracing the file.  If your plug-in can
handle the file, it should return a :class:`FileTracer` object.
Otherwise return None.

There is no way to register your plug-in for particular files.
Instead, this method is invoked for all  files as they are executed,
and the plug-in decides whether it can trace the file or not.
Be prepared for `filename` to refer to all kinds of files that have
nothing to do with your plug-in.

The file name will be a Python file being executed.  There are two
broad categories of behavior for a plug-in, depending on the kind of
files your plug-in supports:

* Static file names: each of your original source files has been
  converted into a distinct Python file.  Your plug-in is invoked with
  the Python file name, and it maps it back to its original source
  file.

* Dynamic file names: all of your source files are executed by the same
  Python file.  In this case, your plug-in implements
  :meth:`FileTracer.dynamic_source_filename` to provide the actual
  source file for each execution frame.

`filename` is a string, the path to the file being considered.  This is
the absolute real path to the file.  If you are comparing to other
paths, be sure to take this into account.

Returns a :class:`FileTracer` object to use to trace `filename`, or
None if this plug-in cannot trace this file.

**Param√®tres :**

- `filename`

##### file_reporter

Get the :class:`FileReporter` class to use for a file.

Plug-in type: file tracer.

This will only be invoked if `filename` returns non-None from
:meth:`file_tracer`.  It's an error to return None from this method.

Returns a :class:`FileReporter` object to use to report on `filename`,
or the string `"python"` to have coverage.py treat the file as Python.

**Param√®tres :**

- `filename`

##### dynamic_context

Get the dynamically computed context label for `frame`.

Plug-in type: dynamic context.

This method is invoked for each frame when outside of a dynamic
context, to see if a new dynamic context should be started.  If it
returns a string, a new context label is set for this and deeper
frames.  The dynamic context ends when this frame returns.

Returns a string to start a new dynamic context, or None if no new
context should be started.

**Param√®tres :**

- `frame`

##### find_executable_files

Yield all of the executable files in `src_dir`, recursively.

Plug-in type: file tracer.

Executability is a plug-in-specific property, but generally means files
which would have been considered for coverage analysis, had they been
included automatically.

Returns or yields a sequence of strings, the paths to files that could
have been executed, including files that had been executed.

**Param√®tres :**

- `src_dir`

##### configure

Modify the configuration of coverage.py.

Plug-in type: configurer.

This method is called during coverage.py start-up, to give your plug-in
a chance to change the configuration.  The `config` parameter is an
object with :meth:`~coverage.Coverage.get_option` and
:meth:`~coverage.Coverage.set_option` methods.  Do not call any other
methods on the `config` object.

**Param√®tres :**

- `config`

##### sys_info

Get a list of information useful for debugging.

Plug-in type: any.

This method will be invoked for ``--debug=sys``.  Your
plug-in can return any information it wants to be displayed.

Returns a list of pairs: `[(name, value), ...]`.

##### source_filename

The source file name for this file.

This may be any file name you like.  A key responsibility of a plug-in
is to own the mapping from Python execution back to whatever source
file name was originally the source of the code.

See :meth:`CoveragePlugin.file_tracer` for details about static and
dynamic file names.

Returns the file name to credit with this execution.

##### has_dynamic_source_filename

Does this FileTracer have dynamic source file names?

FileTracers can provide dynamically determined file names by
implementing :meth:`dynamic_source_filename`.  Invoking that function
is expensive. To determine whether to invoke it, coverage.py uses the
result of this function to know if it needs to bother invoking
:meth:`dynamic_source_filename`.

See :meth:`CoveragePlugin.file_tracer` for details about static and
dynamic file names.

Returns True if :meth:`dynamic_source_filename` should be called to get
dynamic source file names.

##### dynamic_source_filename

Get a dynamically computed source file name.

Some plug-ins need to compute the source file name dynamically for each
frame.

This function will not be invoked if
:meth:`has_dynamic_source_filename` returns False.

Returns the source file name for this frame, or None if this frame
shouldn't be measured.

**Param√®tres :**

- `filename`
- `frame`

##### line_number_range

Get the range of source line numbers for a given a call frame.

The call frame is examined, and the source line number in the original
file is returned.  The return value is a pair of numbers, the starting
line number and the ending line number, both inclusive.  For example,
returning (5, 7) means that lines 5, 6, and 7 should be considered
executed.

This function might decide that the frame doesn't indicate any lines
from the source file were executed.  Return (-1, -1) in this case to
tell coverage.py that no lines should be recorded for this frame.

**Param√®tres :**

- `frame`

##### __lt__

To support sorting to make test-writing easier.

**Param√®tres :**

- `other`

##### __init__

Simple initialization of a `FileReporter`.

The `filename` argument is the path to the file being reported.  This
will be available as the `.filename` attribute on the object.  Other
method implementations on this base class rely on this attribute.

**Param√®tres :**

- `filename`

##### __repr__

##### relative_filename

Get the relative file name for this file.

This file path will be displayed in reports.  The default
implementation will supply the actual project-relative file path.  You
only need to supply this method if you have an unusual syntax for file
paths.

##### source

Get the source for the file.

Returns a Unicode string.

The base implementation simply reads the `self.filename` file and
decodes it as UTF-8.  Override this method if your file isn't readable
as a text file, or if you need other encoding support.

##### lines

Get the executable lines in this file.

Your plug-in must determine which lines in the file were possibly
executable.  This method returns a set of those line numbers.

Returns a set of line numbers.

##### excluded_lines

Get the excluded executable lines in this file.

Your plug-in can use any method it likes to allow the user to exclude
executable lines from consideration.

Returns a set of line numbers.

The base implementation returns the empty set.

##### translate_lines

Translate recorded lines into reported lines.

Some file formats will want to report lines slightly differently than
they are recorded.  For example, Python records the last line of a
multi-line statement, but reports are nicer if they mention the first
line.

Your plug-in can optionally define this method to perform these kinds
of adjustment.

`lines` is a sequence of integers, the recorded line numbers.

Returns a set of integers, the adjusted line numbers.

The base implementation returns the numbers unchanged.

**Param√®tres :**

- `lines`

##### arcs

Get the executable arcs in this file.

To support branch coverage, your plug-in needs to be able to indicate
possible execution paths, as a set of line number pairs.  Each pair is
a `(prev, next)` pair indicating that execution can transition from the
`prev` line number to the `next` line number.

Returns a set of pairs of line numbers.  The default implementation
returns an empty set.

##### no_branch_lines

Get the lines excused from branch coverage in this file.

Your plug-in can use any method it likes to allow the user to exclude
lines from consideration of branch coverage.

Returns a set of line numbers.

The base implementation returns the empty set.

##### translate_arcs

Translate recorded arcs into reported arcs.

Similar to :meth:`translate_lines`, but for arcs.  `arcs` is a set of
line number pairs.

Returns a set of line number pairs.

The default implementation returns `arcs` unchanged.

**Param√®tres :**

- `arcs`

##### exit_counts

Get a count of exits from that each line.

To determine which lines are branches, coverage.py looks for lines that
have more than one exit.  This function creates a dict mapping each
executable line number to a count of how many exits it has.

To be honest, this feels wrong, and should be refactored.  Let me know
if you attempt to implement this method in your plug-in...

##### missing_arc_description

Provide an English sentence describing a missing arc.

The `start` and `end` arguments are the line numbers of the missing
arc. Negative numbers indicate entering or exiting code objects.

The `executed_arcs` argument is a set of line number pairs, the arcs
that were executed in this file.

By default, this simply returns the string "Line {start} didn't jump
to {end}".

**Param√®tres :**

- `start`
- `end`
- `executed_arcs`

##### arc_description

Provide an English description of an arc's effect.

**Param√®tres :**

- `start`
- `end`

##### source_token_lines

Generate a series of tokenized lines, one for each line in `source`.

These tokens are used for syntax-colored reports.

Each line is a list of pairs, each pair is a token::

    [("key", "def"), ("ws", " "), ("nam", "hello"), ("op", "("), ... ]

Each pair has a token class, and the token text.  The token classes
are:

* ``"com"``: a comment
* ``"key"``: a keyword
* ``"nam"``: a name, or identifier
* ``"num"``: a number
* ``"op"``: an operator
* ``"str"``: a string literal
* ``"ws"``: some white space
* ``"txt"``: some other kind of text

If you concatenate all the token texts, and then join them with
newlines, you should have your original source back.

The default implementation simply returns each line tagged as
``"txt"``.

##### code_regions

Identify regions in the source file for finer reporting than by file.

Returns an iterable of :class:`CodeRegion` objects.  The kinds reported
should be in the possibilities returned by :meth:`code_region_kinds`.

##### code_region_kinds

Return the kinds of code regions this plugin can find.

The returned pairs are the singular and plural forms of the kinds::

    [
        ("function", "functions"),
        ("class", "classes"),
    ]

This will usually be hard-coded, but could also differ by the specific
source file involved.

##### __eq__

**Param√®tres :**

- `other`

##### __lt__

**Param√®tres :**

- `other`

---

### exceptions

Exceptions coverage.py can raise.

#### Classes

##### _BaseCoverageException

The base-base of all Coverage exceptions.

##### CoverageException

The base class of all exceptions raised by Coverage.py.

##### ConfigError

A problem with a config file, or a value in one.

##### DataError

An error in using a data file.

##### NoDataError

We didn't have data to work with.

##### NoSource

We couldn't find the source for a module.

##### NoCode

We couldn't find any code at all.

##### NotPython

A source file turned out not to be parsable Python.

##### PluginError

A plugin misbehaved.

##### _ExceptionDuringRun

An exception happened while running customer code.

Construct it with three arguments, the values from `sys.exc_info`.

##### CoverageWarning

A warning from Coverage.py.

---

### inorout

Determining whether files are being measured/reported or not.

#### Classes

##### InOrOut

Machinery for determining what files to measure.

**M√©thodes :**

- `__init__()`
- `should_trace()`
- `check_include_omit_etc()`
- `warn_conflicting_settings()`
- `warn_already_imported_files()`
- `warn_unimported_source()`
- `_warn_about_unmeasured_code()`
- `find_possibly_unexecuted_files()`
- `_find_plugin_files()`
- `_find_executable_files()`
- `sys_info()`

#### Fonctions

##### canonical_path

Return the canonical path of the module or file `morf`.

If the module is a package, then return its directory. If it is a
module, then return its file, unless `directory` is True, in which
case return its enclosing directory.

**Param√®tres :**

- `morf`
- `directory`

##### name_for_module

Get the name of the module for a filename and frame.

For configurability's sake, we allow __main__ modules to be matched by
their importable name.

If loaded via runpy (aka -m), we can usually recover the "original"
full dotted module name, otherwise, we resort to interpreting the
file name to get the module's name.  In the case that the module name
can't be determined, None is returned.

**Param√®tres :**

- `filename`
- `frame`

##### module_is_namespace

Is the module object `mod` a PEP420 namespace module?

**Param√®tres :**

- `mod`

##### module_has_file

Does the module object `mod` have an existing __file__ ?

**Param√®tres :**

- `mod`

##### file_and_path_for_module

Find the file and search path for `modulename`.

Returns:
    filename: The filename of the module, or None.
    path: A list (possibly empty) of directories to find submodules in.

**Param√®tres :**

- `modulename`

##### add_stdlib_paths

Add paths where the stdlib can be found to the set `paths`.

**Param√®tres :**

- `paths`

##### add_third_party_paths

Add locations for third-party packages to the set `paths`.

**Param√®tres :**

- `paths`

##### add_coverage_paths

Add paths where coverage.py code can be found to the set `paths`.

**Param√®tres :**

- `paths`

##### __init__

**Param√®tres :**

- `config`
- `warn`
- `debug`
- `include_namespace_packages`

##### should_trace

Decide whether to trace execution in `filename`, with a reason.

This function is called from the trace function.  As each new file name
is encountered, this function determines whether it is traced or not.

Returns a FileDisposition object.

**Param√®tres :**

- `filename`
- `frame`

##### check_include_omit_etc

Check a file name against the include, omit, etc, rules.

Returns a string or None.  String means, don't trace, and is the reason
why.  None means no reason found to not trace.

**Param√®tres :**

- `filename`
- `frame`

##### warn_conflicting_settings

Warn if there are settings that conflict.

##### warn_already_imported_files

Warn if files have already been imported that we will be measuring.

##### warn_unimported_source

Warn about source packages that were of interest, but never traced.

##### _warn_about_unmeasured_code

Warn about a package or module that we never traced.

`pkg` is a string, the name of the package or module.

**Param√®tres :**

- `pkg`

##### find_possibly_unexecuted_files

Find files in the areas of interest that might be untraced.

Yields pairs: file path, and responsible plug-in name.

##### _find_plugin_files

Get executable files from the plugins.

**Param√®tres :**

- `src_dir`

##### _find_executable_files

Find executable files in `src_dir`.

Search for files in `src_dir` that can be executed because they
are probably importable. Don't include ones that have been omitted
by the configuration.

Yield the file path, and the plugin name that handles the file.

**Param√®tres :**

- `src_dir`

##### sys_info

Our information for Coverage.sys_info.

Returns a list of (key, value) pairs.

##### _debug

**Param√®tres :**

- `msg`

##### nope

Simple helper to make it easy to return NO.

**Param√®tres :**

- `disp`
- `reason`

---

### jsonreport

Json reporting for coverage.py

#### Classes

##### JsonReporter

A reporter for writing JSON coverage results.

**M√©thodes :**

- `__init__()`
- `make_summary()`
- `make_branch_summary()`
- `report()`
- `report_one_file()`
- `make_region_data()`

#### Fonctions

##### _convert_branch_arcs

Convert branch arcs to a list of two-element tuples.

**Param√®tres :**

- `branch_arcs`

##### __init__

**Param√®tres :**

- `coverage`

##### make_summary

Create a dict summarizing `nums`.

**Param√®tres :**

- `nums`

##### make_branch_summary

Create a dict summarizing the branch info in `nums`.

**Param√®tres :**

- `nums`

##### report

Generate a json report for `morfs`.

`morfs` is a list of modules or file names.

`outfile` is a file object to write the json to.

**Param√®tres :**

- `morfs`
- `outfile`

##### report_one_file

Extract the relevant report data for a single file.

**Param√®tres :**

- `coverage_data`
- `analysis`
- `file_reporter`

##### make_region_data

Create the data object for one region of a file.

**Param√®tres :**

- `coverage_data`
- `narrowed_analysis`

---

### report_core

Reporter foundation for coverage.py.

#### Classes

##### Reporter

What we expect of reporters.

**M√©thodes :**

- `report()`

#### Fonctions

##### render_report

Run a one-file report generator, managing the output file.

This function ensures the output file is ready to be written to. Then writes
the report to it. Then closes the file and cleans up.

**Param√®tres :**

- `output_path`
- `reporter`
- `morfs`
- `msgfn`

##### get_analysis_to_report

Get the files to report on.

For each morf in `morfs`, if it should be reported on (based on the omit
and include configuration options), yield a pair, the `FileReporter` and
`Analysis` for the morf.

**Param√®tres :**

- `coverage`
- `morfs`

##### report

Generate a report of `morfs`, written to `outfile`.

**Param√®tres :**

- `morfs`
- `outfile`

---

### bytecode

Bytecode analysis for coverage.py

#### Classes

##### InstructionWalker

Utility to step through trails of instructions.

We have two reasons to need sequences of instructions from a code object:
First, in strict sequence to visit all the instructions in the object.
This is `walk(follow_jumps=False)`.  Second, we want to follow jumps to
understand how execution will flow: `walk(follow_jumps=True)`.

**M√©thodes :**

- `__init__()`
- `walk()`

#### Fonctions

##### code_objects

Iterate over all the code objects in `code`.

**Param√®tres :**

- `code`

##### op_set

Make a set of opcodes from instruction names.

The names might not exist in this version of Python, skip those if not.

##### branch_trails

Calculate branch trails for `code`.

Instructions can have a jump_target, where they might jump to next.  Some
instructions with a jump_target are unconditional jumps (ALWAYS_JUMPS), so
they aren't interesting to us, since they aren't the start of a branch
possibility.

Instructions that might or might not jump somewhere else are branch
possibilities.  For each of those, we track a trail of instructions.  These
are lists of instruction offsets, the next instructions that can execute.
We follow the trail until we get to a new source line.  That gives us the
arc from the original instruction's line to the new source line.

**Param√®tres :**

- `code`

##### __init__

**Param√®tres :**

- `code`

##### walk

Yield instructions starting from `start_at`.  Follow unconditional
jumps if `follow_jumps` is true.

##### walk_one_branch

**Param√®tres :**

- `start_at`

---

### tomlconfig

TOML configuration support for coverage.py

#### Classes

##### TomlDecodeError

An exception class that exists even when toml isn't installed.

##### TomlConfigParser

TOML file reading with the interface of HandyConfigParser.

**M√©thodes :**

- `__init__()`
- `read()`
- `_get_section()`
- `_get()`
- `_get_single()`
- `has_option()`
- `real_section()`
- `has_section()`
- `options()`
- `get_section()`
- `get()`
- `_check_type()`
- `getboolean()`
- `getfile()`
- `_get_list()`
- `getlist()`
- `getregexlist()`
- `getint()`
- `getfloat()`

#### Fonctions

##### __init__

**Param√®tres :**

- `our_file`

##### read

**Param√®tres :**

- `filenames`

##### _get_section

Get a section from the data.

Arguments:
    section (str): A section name, which can be dotted.

Returns:
    name (str): the actual name of the section that was found, if any,
        or None.
    data (str): the dict of data in the section, or None if not found.

**Param√®tres :**

- `section`

##### _get

Like .get, but returns the real section name and the value.

**Param√®tres :**

- `section`
- `option`

##### _get_single

Get a single-valued option.

Performs environment substitution if the value is a string. Other types
will be converted later as needed.

**Param√®tres :**

- `section`
- `option`

##### has_option

**Param√®tres :**

- `section`
- `option`

##### real_section

**Param√®tres :**

- `section`

##### has_section

**Param√®tres :**

- `section`

##### options

**Param√®tres :**

- `section`

##### get_section

**Param√®tres :**

- `section`

##### get

**Param√®tres :**

- `section`
- `option`

##### _check_type

Check that `value` has the type we want, converting if needed.

Returns the resulting value of the desired type.

**Param√®tres :**

- `section`
- `option`
- `value`
- `type_`
- `converter`
- `type_desc`

##### getboolean

**Param√®tres :**

- `section`
- `option`

##### getfile

**Param√®tres :**

- `section`
- `option`

##### _get_list

Get a list of strings, substituting environment variables in the elements.

**Param√®tres :**

- `section`
- `option`

##### getlist

**Param√®tres :**

- `section`
- `option`

##### getregexlist

**Param√®tres :**

- `section`
- `option`

##### getint

**Param√®tres :**

- `section`
- `option`

##### getfloat

**Param√®tres :**

- `section`
- `option`

---

### execfile

Execute files of Python code.

#### Classes

##### DummyLoader

A shim for the pep302 __loader__, emulating pkgutil.ImpLoader.

Currently only implements the .fullname attribute

**M√©thodes :**

- `__init__()`

##### PyRunner

Multi-stage execution of Python code.

This is meant to emulate real Python execution as closely as possible.

**M√©thodes :**

- `__init__()`
- `prepare()`
- `_prepare2()`
- `run()`

#### Fonctions

##### find_module

Find the module named `modulename`.

Returns the file path of the module, the name of the enclosing
package, and the spec.

**Param√®tres :**

- `modulename`

##### run_python_module

Run a Python module, as though with ``python -m name args...``.

`args` is the argument array to present as sys.argv, including the first
element naming the module being executed.

This is a helper for tests, to encapsulate how to use PyRunner.

**Param√®tres :**

- `args`

##### run_python_file

Run a Python file as if it were the main program on the command line.

`args` is the argument array to present as sys.argv, including the first
element naming the file being executed.  `package` is the name of the
enclosing package, if any.

This is a helper for tests, to encapsulate how to use PyRunner.

**Param√®tres :**

- `args`

##### make_code_from_py

Get source from `filename` and make a code object of it.

**Param√®tres :**

- `filename`

##### make_code_from_pyc

Get a code object from a .pyc file.

**Param√®tres :**

- `filename`

##### __init__

**Param√®tres :**

- `fullname`

##### __init__

**Param√®tres :**

- `args`
- `as_module`

##### prepare

Set sys.path properly.

This needs to happen before any importing, and without importing anything.

##### _prepare2

Do more preparation to run Python code.

Includes finding the module to run and adjusting sys.argv[0].
This method is allowed to import code.

##### run

Run the Python code!

---

### multiproc

Monkey-patching to add multiprocessing support for coverage.py

#### Classes

##### ProcessWithCoverage

A replacement for multiprocess.Process that starts coverage.

**M√©thodes :**

- `_bootstrap()`

##### Stowaway

An object to pickle, so when it is unpickled, it can apply the monkey-patch.

**M√©thodes :**

- `__init__()`
- `__getstate__()`
- `__setstate__()`

#### Fonctions

##### patch_multiprocessing

Monkey-patch the multiprocessing module.

This enables coverage measurement of processes started by multiprocessing.
This involves aggressive monkey-patching.

`rcfile` is the path to the rcfile being used.

**Param√®tres :**

- `rcfile`

##### _bootstrap

Wrapper around _bootstrap to start coverage.

##### __init__

**Param√®tres :**

- `rcfile`

##### __getstate__

##### __setstate__

**Param√®tres :**

- `state`

##### get_preparation_data_with_stowaway

Get the original preparation data, and also insert our stowaway.

**Param√®tres :**

- `name`

---

### __main__

Coverage.py's main entry point.

---

### report

Summary reporting

#### Classes

##### SummaryReporter

A reporter for writing the summary report.

**M√©thodes :**

- `__init__()`
- `write()`
- `write_items()`
- `_report_text()`
- `_report_markdown()`
- `report()`
- `tabular_report()`
- `report_one_file()`

#### Fonctions

##### __init__

**Param√®tres :**

- `coverage`

##### write

Write a line to the output, adding a newline.

**Param√®tres :**

- `line`

##### write_items

Write a list of strings, joined together.

**Param√®tres :**

- `items`

##### _report_text

Internal method that prints report data in text format.

`header` is a list with captions.
`lines_values` is list of lists of sortable values.
`total_line` is a list with values of the total line.
`end_lines` is a list of ending lines with information about skipped files.

**Param√®tres :**

- `header`
- `lines_values`
- `total_line`
- `end_lines`

##### _report_markdown

Internal method that prints report data in markdown format.

`header` is a list with captions.
`lines_values` is a sorted list of lists containing coverage information.
`total_line` is a list with values of the total line.
`end_lines` is a list of ending lines with information about skipped files.

**Param√®tres :**

- `header`
- `lines_values`
- `total_line`
- `end_lines`

##### report

Writes a report summarizing coverage statistics per module.

`outfile` is a text-mode file object to write the summary to.

**Param√®tres :**

- `morfs`
- `outfile`

##### tabular_report

Writes tabular report formats.

##### report_one_file

Report on just one file, the callback from report().

**Param√®tres :**

- `fr`
- `analysis`

---

### data

Coverage data for coverage.py.

This file had the 4.x JSON data support, which is now gone.  This file still
has storage-agnostic helpers, and is kept to avoid changing too many imports.
CoverageData is now defined in sqldata.py, and imported here to keep the
imports working.

#### Fonctions

##### line_counts

Return a dict summarizing the line coverage data.

Keys are based on the file names, and values are the number of executed
lines.  If `fullpath` is true, then the keys are the full pathnames of
the files, otherwise they are the basenames of the files.

Returns a dict mapping file names to counts of lines.

**Param√®tres :**

- `data`
- `fullpath`

##### add_data_to_hash

Contribute `filename`'s data to the `hasher`.

`hasher` is a `coverage.misc.Hasher` instance to be updated with
the file's data.  It should only get the results data, not the run
data.

**Param√®tres :**

- `data`
- `filename`
- `hasher`

##### combinable_files

Make a list of data files to be combined.

`data_file` is a path to a data file.  `data_paths` is a list of files or
directories of files.

Returns a list of absolute file paths.

**Param√®tres :**

- `data_file`
- `data_paths`

##### combine_parallel_data

Combine a number of data files together.

`data` is a CoverageData.

Treat `data.filename` as a file prefix, and combine the data from all
of the data files starting with that prefix plus a dot.

If `aliases` is provided, it's a `PathAliases` object that is used to
re-map paths to match the local machine's.

If `data_paths` is provided, it is a list of directories or files to
combine.  Directories are searched for files that start with
`data.filename` plus dot as a prefix, and those files are combined.

If `data_paths` is not provided, then the directory portion of
`data.filename` is used as the directory to search for data files.

Unless `keep` is True every data file found and combined is then deleted
from disk. If a file cannot be read, a warning will be issued, and the
file will not be deleted.

If `strict` is true, and no files are found to combine, an error is
raised.

`message` is a function to use for printing messages to the user.

**Param√®tres :**

- `data`
- `aliases`
- `data_paths`
- `strict`
- `keep`
- `message`

##### debug_data_file

Implementation of 'coverage debug data'.

**Param√®tres :**

- `filename`

##### sorted_lines

Get the sorted lines for a file, for tests.

**Param√®tres :**

- `data`
- `filename`

---

### .!33639!patch

---

### .!33648!files

---

### .!33652!phystokens

---

### .!33656!lcovreport

---

### .!33661!config

---

### .!33664!version

---

### .!33672!sysmon

---

### .!33676!templite

---

### .!33680!results

---

### .!33685!plugin_support

---

### .!33689!numbits

---

### .!33693!regions

---

### .!33698!control

---

### .!33703!sqlitedb

---

### .!33711!cmdline

---

### .!33716!collector

---

### .!33722!__init__

---

### .!33729!pytracer

---

### .!33733!types

---

### .!33737!annotate

---

### .!33741!sqldata

---

### .!33746!disposition

---

### .!33749!parser

---

### .!33754!context

---

### .!33757!xmlreport

---

### .!33761!debug

---

### .!33767!python

---

### .!33771!plugin

---

### .!33776!exceptions

---

### .!33779!inorout

---

### .!33784!jsonreport

---

### .!33789!report_core

---

### .!33791!bytecode

---

### .!33797!tomlconfig

---

### .!33802!execfile

---

### .!33805!multiproc

---

### .!33809!__main__

---

### .!33814!report

---

### _compat

#### Classes

##### _NonClosingTextIOWrapper

**M√©thodes :**

- `__init__()`
- `__del__()`
- `isatty()`

##### _FixupStream

The new io interface needs more from streams than streams
traditionally implement.  As such, this fix-up code is necessary in
some circumstances.

The forcing of readable and writable flags are there because some tools
put badly patched objects on sys (one such offender are certain version
of jupyter notebook).

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `read1()`
- `readable()`
- `writable()`
- `seekable()`

##### _AtomicFile

**M√©thodes :**

- `__init__()`
- `name()`
- `close()`
- `__getattr__()`
- `__enter__()`
- `__exit__()`
- `__repr__()`

#### Fonctions

##### _make_text_stream

**Param√®tres :**

- `stream`
- `encoding`
- `errors`
- `force_readable`
- `force_writable`

##### is_ascii_encoding

Checks if a given encoding is ascii.

**Param√®tres :**

- `encoding`

##### get_best_encoding

Returns the default stream encoding if not found.

**Param√®tres :**

- `stream`

##### _is_binary_reader

**Param√®tres :**

- `stream`
- `default`

##### _is_binary_writer

**Param√®tres :**

- `stream`
- `default`

##### _find_binary_reader

**Param√®tres :**

- `stream`

##### _find_binary_writer

**Param√®tres :**

- `stream`

##### _stream_is_misconfigured

A stream is misconfigured if its encoding is ASCII.

**Param√®tres :**

- `stream`

##### _is_compat_stream_attr

A stream attribute is compatible if it is equal to the
desired value or the desired value is unset and the attribute
has a value.

**Param√®tres :**

- `stream`
- `attr`
- `value`

##### _is_compatible_text_stream

Check if a stream's encoding and errors attributes are
compatible with the desired values.

**Param√®tres :**

- `stream`
- `encoding`
- `errors`

##### _force_correct_text_stream

**Param√®tres :**

- `text_stream`
- `encoding`
- `errors`
- `is_binary`
- `find_binary`
- `force_readable`
- `force_writable`

##### _force_correct_text_reader

**Param√®tres :**

- `text_reader`
- `encoding`
- `errors`
- `force_readable`

##### _force_correct_text_writer

**Param√®tres :**

- `text_writer`
- `encoding`
- `errors`
- `force_writable`

##### get_binary_stdin

##### get_binary_stdout

##### get_binary_stderr

##### get_text_stdin

**Param√®tres :**

- `encoding`
- `errors`

##### get_text_stdout

**Param√®tres :**

- `encoding`
- `errors`

##### get_text_stderr

**Param√®tres :**

- `encoding`
- `errors`

##### _wrap_io_open

Handles not passing ``encoding`` and ``errors`` in binary mode.

**Param√®tres :**

- `file`
- `mode`
- `encoding`
- `errors`

##### open_stream

**Param√®tres :**

- `filename`
- `mode`
- `encoding`
- `errors`
- `atomic`

##### strip_ansi

**Param√®tres :**

- `value`

##### _is_jupyter_kernel_output

**Param√®tres :**

- `stream`

##### should_strip_ansi

**Param√®tres :**

- `stream`
- `color`

##### term_len

**Param√®tres :**

- `x`

##### isatty

**Param√®tres :**

- `stream`

##### _make_cached_stream_func

**Param√®tres :**

- `src_func`
- `wrapper_func`

##### __init__

**Param√®tres :**

- `stream`
- `encoding`
- `errors`
- `force_readable`
- `force_writable`

##### __del__

##### isatty

##### __init__

**Param√®tres :**

- `stream`
- `force_readable`
- `force_writable`

##### __getattr__

**Param√®tres :**

- `name`

##### read1

**Param√®tres :**

- `size`

##### readable

##### writable

##### seekable

##### __init__

**Param√®tres :**

- `f`
- `tmp_filename`
- `real_filename`

##### name

##### close

**Param√®tres :**

- `delete`

##### __getattr__

**Param√®tres :**

- `name`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `tb`

##### __repr__

##### _get_argv_encoding

##### auto_wrap_for_ansi

Support ANSI color and style codes on Windows by wrapping a
stream with colorama.

**Param√®tres :**

- `stream`
- `color`

##### _get_argv_encoding

##### _get_windows_console_stream

**Param√®tres :**

- `f`
- `encoding`
- `errors`

##### func

##### _safe_write

**Param√®tres :**

- `s`

---

### _termui_impl

This module contains implementations for the termui module. To keep the
import time of Click down, some infrequently used functionality is
placed in this module and only imported as needed.

#### Classes

##### ProgressBar

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `__iter__()`
- `__next__()`
- `render_finish()`
- `pct()`
- `time_per_iteration()`
- `eta()`
- `format_eta()`
- `format_pos()`
- `format_pct()`
- `format_bar()`
- `format_progress_line()`
- `render_progress()`
- `make_step()`
- `update()`
- `finish()`
- `generator()`

##### Editor

**M√©thodes :**

- `__init__()`
- `get_editor()`
- `edit_files()`
- `edit()`
- `edit()`
- `edit()`

#### Fonctions

##### pager

Decide what method to use for paging through text.

**Param√®tres :**

- `generator`
- `color`

##### _pipepager

Page through text by feeding it to another program. Invoking a
pager through this might support colors.

Returns `True` if the command was found, `False` otherwise and thus another
pager should be attempted.

**Param√®tres :**

- `generator`
- `cmd_parts`
- `color`

##### _tempfilepager

Page through text by invoking a program on a temporary file.

Returns `True` if the command was found, `False` otherwise and thus another
pager should be attempted.

**Param√®tres :**

- `generator`
- `cmd_parts`
- `color`

##### _nullpager

Simply print unformatted text.  This is the ultimate fallback.

**Param√®tres :**

- `stream`
- `generator`
- `color`

##### open_url

**Param√®tres :**

- `url`
- `wait`
- `locate`

##### _translate_ch_to_exc

**Param√®tres :**

- `ch`

##### __init__

**Param√®tres :**

- `iterable`
- `length`
- `fill_char`
- `empty_char`
- `bar_template`
- `info_sep`
- `hidden`
- `show_eta`
- `show_percent`
- `show_pos`
- `item_show_func`
- `label`
- `file`
- `color`
- `update_min_steps`
- `width`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `tb`

##### __iter__

##### __next__

##### render_finish

##### pct

##### time_per_iteration

##### eta

##### format_eta

##### format_pos

##### format_pct

##### format_bar

##### format_progress_line

##### render_progress

##### make_step

**Param√®tres :**

- `n_steps`

##### update

Update the progress bar by advancing a specified number of
steps, and optionally set the ``current_item`` for this new
position.

:param n_steps: Number of steps to advance.
:param current_item: Optional item to set as ``current_item``
    for the updated position.

.. versionchanged:: 8.0
    Added the ``current_item`` optional parameter.

.. versionchanged:: 8.0
    Only render when the number of steps meets the
    ``update_min_steps`` threshold.

**Param√®tres :**

- `n_steps`
- `current_item`

##### finish

##### generator

Return a generator which yields the items added to the bar
during construction, and updates the progress bar *after* the
yielded block returns.

##### __init__

**Param√®tres :**

- `editor`
- `env`
- `require_save`
- `extension`

##### get_editor

##### edit_files

**Param√®tres :**

- `filenames`

##### edit

**Param√®tres :**

- `text`

##### edit

**Param√®tres :**

- `text`

##### edit

**Param√®tres :**

- `text`

##### _unquote_file

**Param√®tres :**

- `url`

##### raw_terminal

##### getchar

**Param√®tres :**

- `echo`

##### raw_terminal

##### getchar

**Param√®tres :**

- `echo`

---

### .!33842!core

---

### _textwrap

#### Classes

##### TextWrapper

**M√©thodes :**

- `_handle_long_word()`
- `extra_indent()`
- `indent_only()`

#### Fonctions

##### _handle_long_word

**Param√®tres :**

- `reversed_chunks`
- `cur_line`
- `cur_len`
- `width`

##### extra_indent

**Param√®tres :**

- `indent`

##### indent_only

**Param√®tres :**

- `text`

---

### _winconsole

#### Classes

##### _WindowsConsoleRawIOBase

**M√©thodes :**

- `__init__()`
- `isatty()`

##### _WindowsConsoleReader

**M√©thodes :**

- `readable()`
- `readinto()`

##### _WindowsConsoleWriter

**M√©thodes :**

- `writable()`
- `_get_error_message()`
- `write()`

##### ConsoleStream

**M√©thodes :**

- `__init__()`
- `name()`
- `write()`
- `writelines()`
- `__getattr__()`
- `isatty()`
- `__repr__()`

##### Py_buffer

#### Fonctions

##### _get_text_stdin

**Param√®tres :**

- `buffer_stream`

##### _get_text_stdout

**Param√®tres :**

- `buffer_stream`

##### _get_text_stderr

**Param√®tres :**

- `buffer_stream`

##### _is_console

**Param√®tres :**

- `f`

##### _get_windows_console_stream

**Param√®tres :**

- `f`
- `encoding`
- `errors`

##### get_buffer

**Param√®tres :**

- `obj`
- `writable`

##### __init__

**Param√®tres :**

- `handle`

##### isatty

##### readable

##### readinto

**Param√®tres :**

- `b`

##### writable

##### _get_error_message

**Param√®tres :**

- `errno`

##### write

**Param√®tres :**

- `b`

##### __init__

**Param√®tres :**

- `text_stream`
- `byte_stream`

##### name

##### write

**Param√®tres :**

- `x`

##### writelines

**Param√®tres :**

- `lines`

##### __getattr__

**Param√®tres :**

- `name`

##### isatty

##### __repr__

---

### core

#### Classes

##### ParameterSource

This is an :class:`~enum.Enum` that indicates the source of a
parameter's value.

Use :meth:`click.Context.get_parameter_source` to get the
source for a parameter by name.

.. versionchanged:: 8.0
    Use :class:`~enum.Enum` and drop the ``validate`` method.

.. versionchanged:: 8.0
    Added the ``PROMPT`` value.

##### Context

The context is a special internal object that holds state relevant
for the script execution at every single level.  It's normally invisible
to commands unless they opt-in to getting access to it.

The context is useful as it can pass internal objects around and can
control special execution features such as reading data from
environment variables.

A context can be used as context manager in which case it will call
:meth:`close` on teardown.

:param command: the command class for this context.
:param parent: the parent context.
:param info_name: the info name for this invocation.  Generally this
                  is the most descriptive name for the script or
                  command.  For the toplevel script it is usually
                  the name of the script, for commands below it it's
                  the name of the script.
:param obj: an arbitrary object of user data.
:param auto_envvar_prefix: the prefix to use for automatic environment
                           variables.  If this is `None` then reading
                           from environment variables is disabled.  This
                           does not affect manually set environment
                           variables which are always read.
:param default_map: a dictionary (like object) with default values
                    for parameters.
:param terminal_width: the width of the terminal.  The default is
                       inherit from parent context.  If no context
                       defines the terminal width then auto
                       detection will be applied.
:param max_content_width: the maximum width for content rendered by
                          Click (this currently only affects help
                          pages).  This defaults to 80 characters if
                          not overridden.  In other words: even if the
                          terminal is larger than that, Click will not
                          format things wider than 80 characters by
                          default.  In addition to that, formatters might
                          add some safety mapping on the right.
:param resilient_parsing: if this flag is enabled then Click will
                          parse without any interactivity or callback
                          invocation.  Default values will also be
                          ignored.  This is useful for implementing
                          things such as completion support.
:param allow_extra_args: if this is set to `True` then extra arguments
                         at the end will not raise an error and will be
                         kept on the context.  The default is to inherit
                         from the command.
:param allow_interspersed_args: if this is set to `False` then options
                                and arguments cannot be mixed.  The
                                default is to inherit from the command.
:param ignore_unknown_options: instructs click to ignore options it does
                               not know and keeps them for later
                               processing.
:param help_option_names: optionally a list of strings that define how
                          the default help parameter is named.  The
                          default is ``['--help']``.
:param token_normalize_func: an optional function that is used to
                             normalize tokens (options, choices,
                             etc.).  This for instance can be used to
                             implement case insensitive behavior.
:param color: controls if the terminal supports ANSI colors or not.  The
              default is autodetection.  This is only needed if ANSI
              codes are used in texts that Click prints which is by
              default not the case.  This for instance would affect
              help output.
:param show_default: Show the default value for commands. If this
    value is not set, it defaults to the value from the parent
    context. ``Command.show_default`` overrides this default for the
    specific command.

.. versionchanged:: 8.2
    The ``protected_args`` attribute is deprecated and will be removed in
    Click 9.0. ``args`` will contain remaining unparsed tokens.

.. versionchanged:: 8.1
    The ``show_default`` parameter is overridden by
    ``Command.show_default``, instead of the other way around.

.. versionchanged:: 8.0
    The ``show_default`` parameter defaults to the value from the
    parent context.

.. versionchanged:: 7.1
   Added the ``show_default`` parameter.

.. versionchanged:: 4.0
    Added the ``color``, ``ignore_unknown_options``, and
    ``max_content_width`` parameters.

.. versionchanged:: 3.0
    Added the ``allow_extra_args`` and ``allow_interspersed_args``
    parameters.

.. versionchanged:: 2.0
    Added the ``resilient_parsing``, ``help_option_names``, and
    ``token_normalize_func`` parameters.

**M√©thodes :**

- `__init__()`
- `protected_args()`
- `to_info_dict()`
- `__enter__()`
- `__exit__()`
- `scope()`
- `meta()`
- `make_formatter()`
- `with_resource()`
- `call_on_close()`
- `close()`
- `command_path()`
- `find_root()`
- `find_object()`
- `ensure_object()`
- `lookup_default()`
- `lookup_default()`
- `lookup_default()`
- `fail()`
- `abort()`
- `exit()`
- `get_usage()`
- `get_help()`
- `_make_sub_context()`
- `invoke()`
- `invoke()`
- `invoke()`
- `forward()`
- `set_parameter_source()`
- `get_parameter_source()`

##### Command

Commands are the basic building block of command line interfaces in
Click.  A basic command handles command line parsing and might dispatch
more parsing to commands nested below it.

:param name: the name of the command to use unless a group overrides it.
:param context_settings: an optional dictionary with defaults that are
                         passed to the context object.
:param callback: the callback to invoke.  This is optional.
:param params: the parameters to register with this command.  This can
               be either :class:`Option` or :class:`Argument` objects.
:param help: the help string to use for this command.
:param epilog: like the help string but it's printed at the end of the
               help page after everything else.
:param short_help: the short help to use for this command.  This is
                   shown on the command listing of the parent command.
:param add_help_option: by default each command registers a ``--help``
                        option.  This can be disabled by this parameter.
:param no_args_is_help: this controls what happens if no arguments are
                        provided.  This option is disabled by default.
                        If enabled this will add ``--help`` as argument
                        if no arguments are passed
:param hidden: hide this command from help outputs.
:param deprecated: If ``True`` or non-empty string, issues a message
                    indicating that the command is deprecated and highlights
                    its deprecation in --help. The message can be customized
                    by using a string as the value.

.. versionchanged:: 8.2
    This is the base class for all commands, not ``BaseCommand``.
    ``deprecated`` can be set to a string as well to customize the
    deprecation message.

.. versionchanged:: 8.1
    ``help``, ``epilog``, and ``short_help`` are stored unprocessed,
    all formatting is done when outputting help text, not at init,
    and is done even if not using the ``@command`` decorator.

.. versionchanged:: 8.0
    Added a ``repr`` showing the command name.

.. versionchanged:: 7.1
    Added the ``no_args_is_help`` parameter.

.. versionchanged:: 2.0
    Added the ``context_settings`` parameter.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `__repr__()`
- `get_usage()`
- `get_params()`
- `format_usage()`
- `collect_usage_pieces()`
- `get_help_option_names()`
- `get_help_option()`
- `make_parser()`
- `get_help()`
- `get_short_help_str()`
- `format_help()`
- `format_help_text()`
- `format_options()`
- `format_epilog()`
- `make_context()`
- `parse_args()`
- `invoke()`
- `shell_complete()`
- `main()`
- `main()`
- `main()`
- `_main_shell_completion()`
- `__call__()`

##### _FakeSubclassCheck

**M√©thodes :**

- `__subclasscheck__()`
- `__instancecheck__()`

##### _BaseCommand

.. deprecated:: 8.2
    Will be removed in Click 9.0. Use ``Command`` instead.

##### Group

A group is a command that nests other commands (or more groups).

:param name: The name of the group command.
:param commands: Map names to :class:`Command` objects. Can be a list, which
    will use :attr:`Command.name` as the keys.
:param invoke_without_command: Invoke the group's callback even if a
    subcommand is not given.
:param no_args_is_help: If no arguments are given, show the group's help and
    exit. Defaults to the opposite of ``invoke_without_command``.
:param subcommand_metavar: How to represent the subcommand argument in help.
    The default will represent whether ``chain`` is set or not.
:param chain: Allow passing more than one subcommand argument. After parsing
    a command's arguments, if any arguments remain another command will be
    matched, and so on.
:param result_callback: A function to call after the group's and
    subcommand's callbacks. The value returned by the subcommand is passed.
    If ``chain`` is enabled, the value will be a list of values returned by
    all the commands. If ``invoke_without_command`` is enabled, the value
    will be the value returned by the group's callback, or an empty list if
    ``chain`` is enabled.
:param kwargs: Other arguments passed to :class:`Command`.

.. versionchanged:: 8.0
    The ``commands`` argument can be a list of command objects.

.. versionchanged:: 8.2
    Merged with and replaces the ``MultiCommand`` base class.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `add_command()`
- `command()`
- `command()`
- `command()`
- `group()`
- `group()`
- `group()`
- `result_callback()`
- `get_command()`
- `list_commands()`
- `collect_usage_pieces()`
- `format_options()`
- `format_commands()`
- `parse_args()`
- `invoke()`
- `resolve_command()`
- `shell_complete()`

##### _MultiCommand

.. deprecated:: 8.2
    Will be removed in Click 9.0. Use ``Group`` instead.

##### CommandCollection

A :class:`Group` that looks up subcommands on other groups. If a command
is not found on this group, each registered source is checked in order.
Parameters on a source are not added to this group, and a source's callback
is not invoked when invoking its commands. In other words, this "flattens"
commands in many groups into this one group.

:param name: The name of the group command.
:param sources: A list of :class:`Group` objects to look up commands from.
:param kwargs: Other arguments passed to :class:`Group`.

.. versionchanged:: 8.2
    This is a subclass of ``Group``. Commands are looked up first on this
    group, then each of its sources.

**M√©thodes :**

- `__init__()`
- `add_source()`
- `get_command()`
- `list_commands()`

##### Parameter

A parameter to a command comes in two versions: they are either
:class:`Option`\s or :class:`Argument`\s.  Other subclasses are currently
not supported by design as some of the internals for parsing are
intentionally not finalized.

Some settings are supported by both options and arguments.

:param param_decls: the parameter declarations for this option or
                    argument.  This is a list of flags or argument
                    names.
:param type: the type that should be used.  Either a :class:`ParamType`
             or a Python type.  The latter is converted into the former
             automatically if supported.
:param required: controls if this is optional or not.
:param default: the default value if omitted.  This can also be a callable,
                in which case it's invoked when the default is needed
                without any arguments.
:param callback: A function to further process or validate the value
    after type conversion. It is called as ``f(ctx, param, value)``
    and must return the value. It is called for all sources,
    including prompts.
:param nargs: the number of arguments to match.  If not ``1`` the return
              value is a tuple instead of single value.  The default for
              nargs is ``1`` (except if the type is a tuple, then it's
              the arity of the tuple). If ``nargs=-1``, all remaining
              parameters are collected.
:param metavar: how the value is represented in the help page.
:param expose_value: if this is `True` then the value is passed onwards
                     to the command callback and stored on the context,
                     otherwise it's skipped.
:param is_eager: eager values are processed before non eager ones.  This
                 should not be set for arguments or it will inverse the
                 order of processing.
:param envvar: a string or list of strings that are environment variables
               that should be checked.
:param shell_complete: A function that returns custom shell
    completions. Used instead of the param's type completion if
    given. Takes ``ctx, param, incomplete`` and must return a list
    of :class:`~click.shell_completion.CompletionItem` or a list of
    strings.
:param deprecated: If ``True`` or non-empty string, issues a message
                    indicating that the argument is deprecated and highlights
                    its deprecation in --help. The message can be customized
                    by using a string as the value. A deprecated parameter
                    cannot be required, a ValueError will be raised otherwise.

.. versionchanged:: 8.2.0
    Introduction of ``deprecated``.

.. versionchanged:: 8.2
    Adding duplicate parameter names to a :class:`~click.core.Command` will
    result in a ``UserWarning`` being shown.

.. versionchanged:: 8.2
    Adding duplicate parameter names to a :class:`~click.core.Command` will
    result in a ``UserWarning`` being shown.

.. versionchanged:: 8.0
    ``process_value`` validates required parameters and bounded
    ``nargs``, and invokes the parameter callback before returning
    the value. This allows the callback to validate prompts.
    ``full_process_value`` is removed.

.. versionchanged:: 8.0
    ``autocompletion`` is renamed to ``shell_complete`` and has new
    semantics described above. The old name is deprecated and will
    be removed in 8.1, until then it will be wrapped to match the
    new requirements.

.. versionchanged:: 8.0
    For ``multiple=True, nargs>1``, the default must be a list of
    tuples.

.. versionchanged:: 8.0
    Setting a default is no longer required for ``nargs>1``, it will
    default to ``None``. ``multiple=True`` or ``nargs=-1`` will
    default to ``()``.

.. versionchanged:: 7.1
    Empty environment variables are ignored rather than taking the
    empty string value. This makes it possible for scripts to clear
    variables if they can't unset them.

.. versionchanged:: 2.0
    Changed signature for parameter callback to also be passed the
    parameter. The old callback format will still work, but it will
    raise a warning to give you a chance to migrate the code easier.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `__repr__()`
- `_parse_decls()`
- `human_readable_name()`
- `make_metavar()`
- `get_default()`
- `get_default()`
- `get_default()`
- `add_to_parser()`
- `consume_value()`
- `type_cast_value()`
- `value_is_missing()`
- `process_value()`
- `resolve_envvar_value()`
- `value_from_envvar()`
- `handle_parse_result()`
- `get_help_record()`
- `get_usage_pieces()`
- `get_error_hint()`
- `shell_complete()`

##### Option

Options are usually optional values on the command line and
have some extra features that arguments don't have.

All other parameters are passed onwards to the parameter constructor.

:param show_default: Show the default value for this option in its
    help text. Values are not shown by default, unless
    :attr:`Context.show_default` is ``True``. If this value is a
    string, it shows that string in parentheses instead of the
    actual value. This is particularly useful for dynamic options.
    For single option boolean flags, the default remains hidden if
    its value is ``False``.
:param show_envvar: Controls if an environment variable should be
    shown on the help page and error messages.
    Normally, environment variables are not shown.
:param prompt: If set to ``True`` or a non empty string then the
    user will be prompted for input. If set to ``True`` the prompt
    will be the option name capitalized. A deprecated option cannot be
    prompted.
:param confirmation_prompt: Prompt a second time to confirm the
    value if it was prompted for. Can be set to a string instead of
    ``True`` to customize the message.
:param prompt_required: If set to ``False``, the user will be
    prompted for input only when the option was specified as a flag
    without a value.
:param hide_input: If this is ``True`` then the input on the prompt
    will be hidden from the user. This is useful for password input.
:param is_flag: forces this option to act as a flag.  The default is
                auto detection.
:param flag_value: which value should be used for this flag if it's
                   enabled.  This is set to a boolean automatically if
                   the option string contains a slash to mark two options.
:param multiple: if this is set to `True` then the argument is accepted
                 multiple times and recorded.  This is similar to ``nargs``
                 in how it works but supports arbitrary number of
                 arguments.
:param count: this flag makes an option increment an integer.
:param allow_from_autoenv: if this is enabled then the value of this
                           parameter will be pulled from an environment
                           variable in case a prefix is defined on the
                           context.
:param help: the help string.
:param hidden: hide this option from help outputs.
:param attrs: Other command arguments described in :class:`Parameter`.

.. versionchanged:: 8.2
    ``envvar`` used with ``flag_value`` will always use the ``flag_value``,
    previously it would use the value of the environment variable.

.. versionchanged:: 8.1
    Help text indentation is cleaned here instead of only in the
    ``@option`` decorator.

.. versionchanged:: 8.1
    The ``show_default`` parameter overrides
    ``Context.show_default``.

.. versionchanged:: 8.1
    The default of a single option boolean flag is not shown if the
    default value is ``False``.

.. versionchanged:: 8.0.1
    ``type`` is detected from ``flag_value`` if given.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `get_error_hint()`
- `_parse_decls()`
- `add_to_parser()`
- `get_help_record()`
- `get_help_extra()`
- `get_default()`
- `get_default()`
- `get_default()`
- `prompt_for_value()`
- `resolve_envvar_value()`
- `value_from_envvar()`
- `consume_value()`

##### Argument

Arguments are positional parameters to a command.  They generally
provide fewer features than options but can have infinite ``nargs``
and are required by default.

All parameters are passed onwards to the constructor of :class:`Parameter`.

**M√©thodes :**

- `__init__()`
- `human_readable_name()`
- `make_metavar()`
- `_parse_decls()`
- `get_usage_pieces()`
- `get_error_hint()`
- `add_to_parser()`

#### Fonctions

##### _complete_visible_commands

List all the subcommands of a group that start with the
incomplete value and aren't hidden.

:param ctx: Invocation context for the group.
:param incomplete: Value being completed. May be empty.

**Param√®tres :**

- `ctx`
- `incomplete`

##### _check_nested_chain

**Param√®tres :**

- `base_command`
- `cmd_name`
- `cmd`
- `register`

##### batch

**Param√®tres :**

- `iterable`
- `batch_size`

##### augment_usage_errors

Context manager that attaches extra information to exceptions.

**Param√®tres :**

- `ctx`
- `param`

##### iter_params_for_processing

Returns all declared parameters in the order they should be processed.

The declared parameters are re-shuffled depending on the order in which
they were invoked, as well as the eagerness of each parameters.

The invocation order takes precedence over the declaration order. I.e. the
order in which the user provided them to the CLI is respected.

This behavior and its effect on callback evaluation is detailed at:
https://click.palletsprojects.com/en/stable/advanced/#callback-evaluation-order

**Param√®tres :**

- `invocation_order`
- `declaration_order`

##### _check_iter

Check if the value is iterable but not a string. Raises a type
error, or return an iterator over the value.

**Param√®tres :**

- `value`

##### __getattr__

**Param√®tres :**

- `name`

##### sort_key

**Param√®tres :**

- `item`

##### __init__

**Param√®tres :**

- `command`
- `parent`
- `info_name`
- `obj`
- `auto_envvar_prefix`
- `default_map`
- `terminal_width`
- `max_content_width`
- `resilient_parsing`
- `allow_extra_args`
- `allow_interspersed_args`
- `ignore_unknown_options`
- `help_option_names`
- `token_normalize_func`
- `color`
- `show_default`

##### protected_args

##### to_info_dict

Gather information that could be useful for a tool generating
user-facing documentation. This traverses the entire CLI
structure.

.. code-block:: python

    with Context(cli) as ctx:
        info = ctx.to_info_dict()

.. versionadded:: 8.0

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `tb`

##### scope

This helper method can be used with the context object to promote
it to the current thread local (see :func:`get_current_context`).
The default behavior of this is to invoke the cleanup functions which
can be disabled by setting `cleanup` to `False`.  The cleanup
functions are typically used for things such as closing file handles.

If the cleanup is intended the context object can also be directly
used as a context manager.

Example usage::

    with ctx.scope():
        assert get_current_context() is ctx

This is equivalent::

    with ctx:
        assert get_current_context() is ctx

.. versionadded:: 5.0

:param cleanup: controls if the cleanup functions should be run or
                not.  The default is to run these functions.  In
                some situations the context only wants to be
                temporarily pushed in which case this can be disabled.
                Nested pushes automatically defer the cleanup.

**Param√®tres :**

- `cleanup`

##### meta

This is a dictionary which is shared with all the contexts
that are nested.  It exists so that click utilities can store some
state here if they need to.  It is however the responsibility of
that code to manage this dictionary well.

The keys are supposed to be unique dotted strings.  For instance
module paths are a good choice for it.  What is stored in there is
irrelevant for the operation of click.  However what is important is
that code that places data here adheres to the general semantics of
the system.

Example usage::

    LANG_KEY = f'{__name__}.lang'

    def set_language(value):
        ctx = get_current_context()
        ctx.meta[LANG_KEY] = value

    def get_language():
        return get_current_context().meta.get(LANG_KEY, 'en_US')

.. versionadded:: 5.0

##### make_formatter

Creates the :class:`~click.HelpFormatter` for the help and
usage output.

To quickly customize the formatter class used without overriding
this method, set the :attr:`formatter_class` attribute.

.. versionchanged:: 8.0
    Added the :attr:`formatter_class` attribute.

##### with_resource

Register a resource as if it were used in a ``with``
statement. The resource will be cleaned up when the context is
popped.

Uses :meth:`contextlib.ExitStack.enter_context`. It calls the
resource's ``__enter__()`` method and returns the result. When
the context is popped, it closes the stack, which calls the
resource's ``__exit__()`` method.

To register a cleanup function for something that isn't a
context manager, use :meth:`call_on_close`. Or use something
from :mod:`contextlib` to turn it into a context manager first.

.. code-block:: python

    @click.group()
    @click.option("--name")
    @click.pass_context
    def cli(ctx):
        ctx.obj = ctx.with_resource(connect_db(name))

:param context_manager: The context manager to enter.
:return: Whatever ``context_manager.__enter__()`` returns.

.. versionadded:: 8.0

**Param√®tres :**

- `context_manager`

##### call_on_close

Register a function to be called when the context tears down.

This can be used to close resources opened during the script
execution. Resources that support Python's context manager
protocol which would be used in a ``with`` statement should be
registered with :meth:`with_resource` instead.

:param f: The function to execute on teardown.

**Param√®tres :**

- `f`

##### close

Invoke all close callbacks registered with
:meth:`call_on_close`, and exit all context managers entered
with :meth:`with_resource`.

##### command_path

The computed command path.  This is used for the ``usage``
information on the help page.  It's automatically created by
combining the info names of the chain of contexts to the root.

##### find_root

Finds the outermost context.

##### find_object

Finds the closest object of a given type.

**Param√®tres :**

- `object_type`

##### ensure_object

Like :meth:`find_object` but sets the innermost object to a
new instance of `object_type` if it does not exist.

**Param√®tres :**

- `object_type`

##### lookup_default

**Param√®tres :**

- `name`
- `call`

##### lookup_default

**Param√®tres :**

- `name`
- `call`

##### lookup_default

Get the default for a parameter from :attr:`default_map`.

:param name: Name of the parameter.
:param call: If the default is a callable, call it. Disable to
    return the callable instead.

.. versionchanged:: 8.0
    Added the ``call`` parameter.

**Param√®tres :**

- `name`
- `call`

##### fail

Aborts the execution of the program with a specific error
message.

:param message: the error message to fail with.

**Param√®tres :**

- `message`

##### abort

Aborts the script.

##### exit

Exits the application with a given exit code.

.. versionchanged:: 8.2
    Callbacks and context managers registered with :meth:`call_on_close`
    and :meth:`with_resource` are closed before exiting.

**Param√®tres :**

- `code`

##### get_usage

Helper method to get formatted usage string for the current
context and command.

##### get_help

Helper method to get formatted help page for the current
context and command.

##### _make_sub_context

Create a new context of the same type as this context, but
for a new command.

:meta private:

**Param√®tres :**

- `command`

##### invoke

##### invoke

##### invoke

Invokes a command callback in exactly the way it expects.  There
are two ways to invoke this method:

1.  the first argument can be a callback and all other arguments and
    keyword arguments are forwarded directly to the function.
2.  the first argument is a click command object.  In that case all
    arguments are forwarded as well but proper click parameters
    (options and click arguments) must be keyword arguments and Click
    will fill in defaults.

.. versionchanged:: 8.0
    All ``kwargs`` are tracked in :attr:`params` so they will be
    passed if :meth:`forward` is called at multiple levels.

.. versionchanged:: 3.2
    A new context is created, and missing arguments use default values.

##### forward

Similar to :meth:`invoke` but fills in default keyword
arguments from the current context if the other command expects
it.  This cannot invoke callbacks directly, only other commands.

.. versionchanged:: 8.0
    All ``kwargs`` are tracked in :attr:`params` so they will be
    passed if ``forward`` is called at multiple levels.

##### set_parameter_source

Set the source of a parameter. This indicates the location
from which the value of the parameter was obtained.

:param name: The name of the parameter.
:param source: A member of :class:`~click.core.ParameterSource`.

**Param√®tres :**

- `name`
- `source`

##### get_parameter_source

Get the source of a parameter. This indicates the location
from which the value of the parameter was obtained.

This can be useful for determining when a user specified a value
on the command line that is the same as the default value. It
will be :attr:`~click.core.ParameterSource.DEFAULT` only if the
value was actually taken from the default.

:param name: The name of the parameter.
:rtype: ParameterSource

.. versionchanged:: 8.0
    Returns ``None`` if the parameter was not provided from any
    source.

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `name`
- `context_settings`
- `callback`
- `params`
- `help`
- `epilog`
- `short_help`
- `options_metavar`
- `add_help_option`
- `no_args_is_help`
- `hidden`
- `deprecated`

##### to_info_dict

**Param√®tres :**

- `ctx`

##### __repr__

##### get_usage

Formats the usage line into a string and returns it.

Calls :meth:`format_usage` internally.

**Param√®tres :**

- `ctx`

##### get_params

**Param√®tres :**

- `ctx`

##### format_usage

Writes the usage line into the formatter.

This is a low-level method called by :meth:`get_usage`.

**Param√®tres :**

- `ctx`
- `formatter`

##### collect_usage_pieces

Returns all the pieces that go into the usage line and returns
it as a list of strings.

**Param√®tres :**

- `ctx`

##### get_help_option_names

Returns the names for the help option.

**Param√®tres :**

- `ctx`

##### get_help_option

Returns the help option object.

Skipped if :attr:`add_help_option` is ``False``.

.. versionchanged:: 8.1.8
    The help option is now cached to avoid creating it multiple times.

**Param√®tres :**

- `ctx`

##### make_parser

Creates the underlying option parser for this command.

**Param√®tres :**

- `ctx`

##### get_help

Formats the help into a string and returns it.

Calls :meth:`format_help` internally.

**Param√®tres :**

- `ctx`

##### get_short_help_str

Gets short help for the command or makes it by shortening the
long help string.

**Param√®tres :**

- `limit`

##### format_help

Writes the help into the formatter if it exists.

This is a low-level method called by :meth:`get_help`.

This calls the following methods:

-   :meth:`format_usage`
-   :meth:`format_help_text`
-   :meth:`format_options`
-   :meth:`format_epilog`

**Param√®tres :**

- `ctx`
- `formatter`

##### format_help_text

Writes the help text to the formatter if it exists.

**Param√®tres :**

- `ctx`
- `formatter`

##### format_options

Writes all the options into the formatter if they exist.

**Param√®tres :**

- `ctx`
- `formatter`

##### format_epilog

Writes the epilog into the formatter if it exists.

**Param√®tres :**

- `ctx`
- `formatter`

##### make_context

This function when given an info name and arguments will kick
off the parsing and create a new :class:`Context`.  It does not
invoke the actual command callback though.

To quickly customize the context class used without overriding
this method, set the :attr:`context_class` attribute.

:param info_name: the info name for this invocation.  Generally this
                  is the most descriptive name for the script or
                  command.  For the toplevel script it's usually
                  the name of the script, for commands below it's
                  the name of the command.
:param args: the arguments to parse as list of strings.
:param parent: the parent context if available.
:param extra: extra keyword arguments forwarded to the context
              constructor.

.. versionchanged:: 8.0
    Added the :attr:`context_class` attribute.

**Param√®tres :**

- `info_name`
- `args`
- `parent`

##### parse_args

**Param√®tres :**

- `ctx`
- `args`

##### invoke

Given a context, this invokes the attached callback (if it exists)
in the right way.

**Param√®tres :**

- `ctx`

##### shell_complete

Return a list of completions for the incomplete value. Looks
at the names of options and chained multi-commands.

Any command could be part of a chained multi-command, so sibling
commands are valid at any point during command completion.

:param ctx: Invocation context for this command.
:param incomplete: Value being completed. May be empty.

.. versionadded:: 8.0

**Param√®tres :**

- `ctx`
- `incomplete`

##### main

**Param√®tres :**

- `args`
- `prog_name`
- `complete_var`
- `standalone_mode`

##### main

**Param√®tres :**

- `args`
- `prog_name`
- `complete_var`
- `standalone_mode`

##### main

This is the way to invoke a script with all the bells and
whistles as a command line application.  This will always terminate
the application after a call.  If this is not wanted, ``SystemExit``
needs to be caught.

This method is also available by directly calling the instance of
a :class:`Command`.

:param args: the arguments that should be used for parsing.  If not
             provided, ``sys.argv[1:]`` is used.
:param prog_name: the program name that should be used.  By default
                  the program name is constructed by taking the file
                  name from ``sys.argv[0]``.
:param complete_var: the environment variable that controls the
                     bash completion support.  The default is
                     ``"_<prog_name>_COMPLETE"`` with prog_name in
                     uppercase.
:param standalone_mode: the default behavior is to invoke the script
                        in standalone mode.  Click will then
                        handle exceptions and convert them into
                        error messages and the function will never
                        return but shut down the interpreter.  If
                        this is set to `False` they will be
                        propagated to the caller and the return
                        value of this function is the return value
                        of :meth:`invoke`.
:param windows_expand_args: Expand glob patterns, user dir, and
    env vars in command line args on Windows.
:param extra: extra keyword arguments are forwarded to the context
              constructor.  See :class:`Context` for more information.

.. versionchanged:: 8.0.1
    Added the ``windows_expand_args`` parameter to allow
    disabling command line arg expansion on Windows.

.. versionchanged:: 8.0
    When taking arguments from ``sys.argv`` on Windows, glob
    patterns, user dir, and env vars are expanded.

.. versionchanged:: 3.0
   Added the ``standalone_mode`` parameter.

**Param√®tres :**

- `args`
- `prog_name`
- `complete_var`
- `standalone_mode`
- `windows_expand_args`

##### _main_shell_completion

Check if the shell is asking for tab completion, process
that, then exit early. Called from :meth:`main` before the
program is invoked.

:param prog_name: Name of the executable in the shell.
:param complete_var: Name of the environment variable that holds
    the completion instruction. Defaults to
    ``_{PROG_NAME}_COMPLETE``.

.. versionchanged:: 8.2.0
    Dots (``.``) in ``prog_name`` are replaced with underscores (``_``).

**Param√®tres :**

- `ctx_args`
- `prog_name`
- `complete_var`

##### __call__

Alias for :meth:`main`.

##### __subclasscheck__

**Param√®tres :**

- `cls`
- `subclass`

##### __instancecheck__

**Param√®tres :**

- `cls`
- `instance`

##### __init__

**Param√®tres :**

- `name`
- `commands`
- `invoke_without_command`
- `no_args_is_help`
- `subcommand_metavar`
- `chain`
- `result_callback`

##### to_info_dict

**Param√®tres :**

- `ctx`

##### add_command

Registers another :class:`Command` with this group.  If the name
is not provided, the name of the command is used.

**Param√®tres :**

- `cmd`
- `name`

##### command

**Param√®tres :**

- `__func`

##### command

##### command

A shortcut decorator for declaring and attaching a command to
the group. This takes the same arguments as :func:`command` and
immediately registers the created command with this group by
calling :meth:`add_command`.

To customize the command class used, set the
:attr:`command_class` attribute.

.. versionchanged:: 8.1
    This decorator can be applied without parentheses.

.. versionchanged:: 8.0
    Added the :attr:`command_class` attribute.

##### group

**Param√®tres :**

- `__func`

##### group

##### group

A shortcut decorator for declaring and attaching a group to
the group. This takes the same arguments as :func:`group` and
immediately registers the created group with this group by
calling :meth:`add_command`.

To customize the group class used, set the :attr:`group_class`
attribute.

.. versionchanged:: 8.1
    This decorator can be applied without parentheses.

.. versionchanged:: 8.0
    Added the :attr:`group_class` attribute.

##### result_callback

Adds a result callback to the command.  By default if a
result callback is already registered this will chain them but
this can be disabled with the `replace` parameter.  The result
callback is invoked with the return value of the subcommand
(or the list of return values from all subcommands if chaining
is enabled) as well as the parameters as they would be passed
to the main callback.

Example::

    @click.group()
    @click.option('-i', '--input', default=23)
    def cli(input):
        return 42

    @cli.result_callback()
    def process_result(result, input):
        return result + input

:param replace: if set to `True` an already existing result
                callback will be removed.

.. versionchanged:: 8.0
    Renamed from ``resultcallback``.

.. versionadded:: 3.0

**Param√®tres :**

- `replace`

##### get_command

Given a context and a command name, this returns a :class:`Command`
object if it exists or returns ``None``.

**Param√®tres :**

- `ctx`
- `cmd_name`

##### list_commands

Returns a list of subcommand names in the order they should appear.

**Param√®tres :**

- `ctx`

##### collect_usage_pieces

**Param√®tres :**

- `ctx`

##### format_options

**Param√®tres :**

- `ctx`
- `formatter`

##### format_commands

Extra format methods for multi methods that adds all the commands
after the options.

**Param√®tres :**

- `ctx`
- `formatter`

##### parse_args

**Param√®tres :**

- `ctx`
- `args`

##### invoke

**Param√®tres :**

- `ctx`

##### resolve_command

**Param√®tres :**

- `ctx`
- `args`

##### shell_complete

Return a list of completions for the incomplete value. Looks
at the names of options, subcommands, and chained
multi-commands.

:param ctx: Invocation context for this command.
:param incomplete: Value being completed. May be empty.

.. versionadded:: 8.0

**Param√®tres :**

- `ctx`
- `incomplete`

##### __init__

**Param√®tres :**

- `name`
- `sources`

##### add_source

Add a group as a source of commands.

**Param√®tres :**

- `group`

##### get_command

**Param√®tres :**

- `ctx`
- `cmd_name`

##### list_commands

**Param√®tres :**

- `ctx`

##### __init__

**Param√®tres :**

- `param_decls`
- `type`
- `required`
- `default`
- `callback`
- `nargs`
- `multiple`
- `metavar`
- `expose_value`
- `is_eager`
- `envvar`
- `shell_complete`
- `deprecated`

##### to_info_dict

Gather information that could be useful for a tool generating
user-facing documentation.

Use :meth:`click.Context.to_info_dict` to traverse the entire
CLI structure.

.. versionadded:: 8.0

##### __repr__

##### _parse_decls

**Param√®tres :**

- `decls`
- `expose_value`

##### human_readable_name

Returns the human readable name of this parameter.  This is the
same as the name for options, but the metavar for arguments.

##### make_metavar

**Param√®tres :**

- `ctx`

##### get_default

**Param√®tres :**

- `ctx`
- `call`

##### get_default

**Param√®tres :**

- `ctx`
- `call`

##### get_default

Get the default for the parameter. Tries
:meth:`Context.lookup_default` first, then the local default.

:param ctx: Current context.
:param call: If the default is a callable, call it. Disable to
    return the callable instead.

.. versionchanged:: 8.0.2
    Type casting is no longer performed when getting a default.

.. versionchanged:: 8.0.1
    Type casting can fail in resilient parsing mode. Invalid
    defaults will not prevent showing help text.

.. versionchanged:: 8.0
    Looks at ``ctx.default_map`` first.

.. versionchanged:: 8.0
    Added the ``call`` parameter.

**Param√®tres :**

- `ctx`
- `call`

##### add_to_parser

**Param√®tres :**

- `parser`
- `ctx`

##### consume_value

**Param√®tres :**

- `ctx`
- `opts`

##### type_cast_value

Convert and validate a value against the option's
:attr:`type`, :attr:`multiple`, and :attr:`nargs`.

**Param√®tres :**

- `ctx`
- `value`

##### value_is_missing

**Param√®tres :**

- `value`

##### process_value

**Param√®tres :**

- `ctx`
- `value`

##### resolve_envvar_value

**Param√®tres :**

- `ctx`

##### value_from_envvar

**Param√®tres :**

- `ctx`

##### handle_parse_result

**Param√®tres :**

- `ctx`
- `opts`
- `args`

##### get_help_record

**Param√®tres :**

- `ctx`

##### get_usage_pieces

**Param√®tres :**

- `ctx`

##### get_error_hint

Get a stringified version of the param for use in error messages to
indicate which param caused the error.

**Param√®tres :**

- `ctx`

##### shell_complete

Return a list of completions for the incomplete value. If a
``shell_complete`` function was given during init, it is used.
Otherwise, the :attr:`type`
:meth:`~click.types.ParamType.shell_complete` function is used.

:param ctx: Invocation context for this command.
:param incomplete: Value being completed. May be empty.

.. versionadded:: 8.0

**Param√®tres :**

- `ctx`
- `incomplete`

##### __init__

**Param√®tres :**

- `param_decls`
- `show_default`
- `prompt`
- `confirmation_prompt`
- `prompt_required`
- `hide_input`
- `is_flag`
- `flag_value`
- `multiple`
- `count`
- `allow_from_autoenv`
- `type`
- `help`
- `hidden`
- `show_choices`
- `show_envvar`
- `deprecated`

##### to_info_dict

##### get_error_hint

**Param√®tres :**

- `ctx`

##### _parse_decls

**Param√®tres :**

- `decls`
- `expose_value`

##### add_to_parser

**Param√®tres :**

- `parser`
- `ctx`

##### get_help_record

**Param√®tres :**

- `ctx`

##### get_help_extra

**Param√®tres :**

- `ctx`

##### get_default

**Param√®tres :**

- `ctx`
- `call`

##### get_default

**Param√®tres :**

- `ctx`
- `call`

##### get_default

**Param√®tres :**

- `ctx`
- `call`

##### prompt_for_value

This is an alternative flow that can be activated in the full
value processing if a value does not exist.  It will prompt the
user until a valid value exists and then returns the processed
value as result.

**Param√®tres :**

- `ctx`

##### resolve_envvar_value

**Param√®tres :**

- `ctx`

##### value_from_envvar

**Param√®tres :**

- `ctx`

##### consume_value

**Param√®tres :**

- `ctx`
- `opts`

##### __init__

**Param√®tres :**

- `param_decls`
- `required`

##### human_readable_name

##### make_metavar

**Param√®tres :**

- `ctx`

##### _parse_decls

**Param√®tres :**

- `decls`
- `expose_value`

##### get_usage_pieces

**Param√®tres :**

- `ctx`

##### get_error_hint

**Param√®tres :**

- `ctx`

##### add_to_parser

**Param√®tres :**

- `parser`
- `ctx`

##### decorator

**Param√®tres :**

- `f`

##### decorator

**Param√®tres :**

- `f`

##### decorator

**Param√®tres :**

- `f`

##### _process_result

**Param√®tres :**

- `value`

##### check_iter

**Param√®tres :**

- `value`

##### _write_opts

**Param√®tres :**

- `opts`

##### function

##### convert

**Param√®tres :**

- `value`

##### convert

**Param√®tres :**

- `value`

##### convert

**Param√®tres :**

- `value`

---

### decorators

#### Fonctions

##### pass_context

Marks a callback as wanting to receive the current context
object as first argument.

**Param√®tres :**

- `f`

##### pass_obj

Similar to :func:`pass_context`, but only pass the object on the
context onwards (:attr:`Context.obj`).  This is useful if that object
represents the state of a nested system.

**Param√®tres :**

- `f`

##### make_pass_decorator

Given an object type this creates a decorator that will work
similar to :func:`pass_obj` but instead of passing the object of the
current context, it will find the innermost context of type
:func:`object_type`.

This generates a decorator that works roughly like this::

    from functools import update_wrapper

    def decorator(f):
        @pass_context
        def new_func(ctx, *args, **kwargs):
            obj = ctx.find_object(object_type)
            return ctx.invoke(f, obj, *args, **kwargs)
        return update_wrapper(new_func, f)
    return decorator

:param object_type: the type of the object to pass.
:param ensure: if set to `True`, a new object will be created and
               remembered on the context if it's not there yet.

**Param√®tres :**

- `object_type`
- `ensure`

##### pass_meta_key

Create a decorator that passes a key from
:attr:`click.Context.meta` as the first argument to the decorated
function.

:param key: Key in ``Context.meta`` to pass.
:param doc_description: Description of the object being passed,
    inserted into the decorator's docstring. Defaults to "the 'key'
    key from Context.meta".

.. versionadded:: 8.0

**Param√®tres :**

- `key`

##### command

**Param√®tres :**

- `name`

##### command

**Param√®tres :**

- `name`
- `cls`

##### command

**Param√®tres :**

- `name`

##### command

**Param√®tres :**

- `name`
- `cls`

##### command

Creates a new :class:`Command` and uses the decorated function as
callback.  This will also automatically attach all decorated
:func:`option`\s and :func:`argument`\s as parameters to the command.

The name of the command defaults to the name of the function, converted to
lowercase, with underscores ``_`` replaced by dashes ``-``, and the suffixes
``_command``, ``_cmd``, ``_group``, and ``_grp`` are removed. For example,
``init_data_command`` becomes ``init-data``.

All keyword arguments are forwarded to the underlying command class.
For the ``params`` argument, any decorated params are appended to
the end of the list.

Once decorated the function turns into a :class:`Command` instance
that can be invoked as a command line utility or be attached to a
command :class:`Group`.

:param name: The name of the command. Defaults to modifying the function's
    name as described above.
:param cls: The command class to create. Defaults to :class:`Command`.

.. versionchanged:: 8.2
    The suffixes ``_command``, ``_cmd``, ``_group``, and ``_grp`` are
    removed when generating the name.

.. versionchanged:: 8.1
    This decorator can be applied without parentheses.

.. versionchanged:: 8.1
    The ``params`` argument can be used. Decorated params are
    appended to the end of the list.

**Param√®tres :**

- `name`
- `cls`

##### group

**Param√®tres :**

- `name`

##### group

**Param√®tres :**

- `name`
- `cls`

##### group

**Param√®tres :**

- `name`

##### group

**Param√®tres :**

- `name`
- `cls`

##### group

Creates a new :class:`Group` with a function as callback.  This
works otherwise the same as :func:`command` just that the `cls`
parameter is set to :class:`Group`.

.. versionchanged:: 8.1
    This decorator can be applied without parentheses.

**Param√®tres :**

- `name`
- `cls`

##### _param_memo

**Param√®tres :**

- `f`
- `param`

##### argument

Attaches an argument to the command.  All positional arguments are
passed as parameter declarations to :class:`Argument`; all keyword
arguments are forwarded unchanged (except ``cls``).
This is equivalent to creating an :class:`Argument` instance manually
and attaching it to the :attr:`Command.params` list.

For the default argument class, refer to :class:`Argument` and
:class:`Parameter` for descriptions of parameters.

:param cls: the argument class to instantiate.  This defaults to
            :class:`Argument`.
:param param_decls: Passed as positional arguments to the constructor of
    ``cls``.
:param attrs: Passed as keyword arguments to the constructor of ``cls``.

##### option

Attaches an option to the command.  All positional arguments are
passed as parameter declarations to :class:`Option`; all keyword
arguments are forwarded unchanged (except ``cls``).
This is equivalent to creating an :class:`Option` instance manually
and attaching it to the :attr:`Command.params` list.

For the default option class, refer to :class:`Option` and
:class:`Parameter` for descriptions of parameters.

:param cls: the option class to instantiate.  This defaults to
            :class:`Option`.
:param param_decls: Passed as positional arguments to the constructor of
    ``cls``.
:param attrs: Passed as keyword arguments to the constructor of ``cls``.

##### confirmation_option

Add a ``--yes`` option which shows a prompt before continuing if
not passed. If the prompt is declined, the program will exit.

:param param_decls: One or more option names. Defaults to the single
    value ``"--yes"``.
:param kwargs: Extra arguments are passed to :func:`option`.

##### password_option

Add a ``--password`` option which prompts for a password, hiding
input and asking to enter the value again for confirmation.

:param param_decls: One or more option names. Defaults to the single
    value ``"--password"``.
:param kwargs: Extra arguments are passed to :func:`option`.

##### version_option

Add a ``--version`` option which immediately prints the version
number and exits the program.

If ``version`` is not provided, Click will try to detect it using
:func:`importlib.metadata.version` to get the version for the
``package_name``.

If ``package_name`` is not provided, Click will try to detect it by
inspecting the stack frames. This will be used to detect the
version, so it must match the name of the installed package.

:param version: The version number to show. If not provided, Click
    will try to detect it.
:param param_decls: One or more option names. Defaults to the single
    value ``"--version"``.
:param package_name: The package name to detect the version from. If
    not provided, Click will try to detect it.
:param prog_name: The name of the CLI to show in the message. If not
    provided, it will be detected from the command.
:param message: The message to show. The values ``%(prog)s``,
    ``%(package)s``, and ``%(version)s`` are available. Defaults to
    ``"%(prog)s, version %(version)s"``.
:param kwargs: Extra arguments are passed to :func:`option`.
:raise RuntimeError: ``version`` could not be detected.

.. versionchanged:: 8.0
    Add the ``package_name`` parameter, and the ``%(package)s``
    value for messages.

.. versionchanged:: 8.0
    Use :mod:`importlib.metadata` instead of ``pkg_resources``. The
    version is detected based on the package name, not the entry
    point name. The Python package name must match the installed
    package name, or be passed with ``package_name=``.

**Param√®tres :**

- `version`

##### help_option

Pre-configured ``--help`` option which immediately prints the help page
and exits the program.

:param param_decls: One or more option names. Defaults to the single
    value ``"--help"``.
:param kwargs: Extra arguments are passed to :func:`option`.

##### new_func

##### new_func

##### decorator

**Param√®tres :**

- `f`

##### decorator

**Param√®tres :**

- `f`

##### decorator

**Param√®tres :**

- `f`

##### decorator

**Param√®tres :**

- `f`

##### decorator

**Param√®tres :**

- `f`

##### callback

**Param√®tres :**

- `ctx`
- `param`
- `value`

##### callback

**Param√®tres :**

- `ctx`
- `param`
- `value`

##### show_help

Callback that print the help page on ``<stdout>`` and exits.

**Param√®tres :**

- `ctx`
- `param`
- `value`

##### new_func

##### new_func

---

### exceptions

#### Classes

##### ClickException

An exception that Click can handle and show to the user.

**M√©thodes :**

- `__init__()`
- `format_message()`
- `__str__()`
- `show()`

##### UsageError

An internal exception that signals a usage error.  This typically
aborts any further handling.

:param message: the error message to display.
:param ctx: optionally the context that caused this error.  Click will
            fill in the context automatically in some situations.

**M√©thodes :**

- `__init__()`
- `show()`

##### BadParameter

An exception that formats out a standardized error message for a
bad parameter.  This is useful when thrown from a callback or type as
Click will attach contextual information to it (for instance, which
parameter it is).

.. versionadded:: 2.0

:param param: the parameter object that caused this error.  This can
              be left out, and Click will attach this info itself
              if possible.
:param param_hint: a string that shows up as parameter name.  This
                   can be used as alternative to `param` in cases
                   where custom validation should happen.  If it is
                   a string it's used as such, if it's a list then
                   each item is quoted and separated.

**M√©thodes :**

- `__init__()`
- `format_message()`

##### MissingParameter

Raised if click required an option or argument but it was not
provided when invoking the script.

.. versionadded:: 4.0

:param param_type: a string that indicates the type of the parameter.
                   The default is to inherit the parameter type from
                   the given `param`.  Valid values are ``'parameter'``,
                   ``'option'`` or ``'argument'``.

**M√©thodes :**

- `__init__()`
- `format_message()`
- `__str__()`

##### NoSuchOption

Raised if click attempted to handle an option that does not
exist.

.. versionadded:: 4.0

**M√©thodes :**

- `__init__()`
- `format_message()`

##### BadOptionUsage

Raised if an option is generally supplied but the use of the option
was incorrect.  This is for instance raised if the number of arguments
for an option is not correct.

.. versionadded:: 4.0

:param option_name: the name of the option being used incorrectly.

**M√©thodes :**

- `__init__()`

##### BadArgumentUsage

Raised if an argument is generally supplied but the use of the argument
was incorrect.  This is for instance raised if the number of values
for an argument is not correct.

.. versionadded:: 6.0

##### NoArgsIsHelpError

**M√©thodes :**

- `__init__()`
- `show()`

##### FileError

Raised if a file cannot be opened.

**M√©thodes :**

- `__init__()`
- `format_message()`

##### Abort

An internal signalling exception that signals Click to abort.

##### Exit

An exception that indicates that the application should exit with some
status code.

:param code: the status code to exit with.

**M√©thodes :**

- `__init__()`

#### Fonctions

##### _join_param_hints

**Param√®tres :**

- `param_hint`

##### __init__

**Param√®tres :**

- `message`

##### format_message

##### __str__

##### show

**Param√®tres :**

- `file`

##### __init__

**Param√®tres :**

- `message`
- `ctx`

##### show

**Param√®tres :**

- `file`

##### __init__

**Param√®tres :**

- `message`
- `ctx`
- `param`
- `param_hint`

##### format_message

##### __init__

**Param√®tres :**

- `message`
- `ctx`
- `param`
- `param_hint`
- `param_type`

##### format_message

##### __str__

##### __init__

**Param√®tres :**

- `option_name`
- `message`
- `possibilities`
- `ctx`

##### format_message

##### __init__

**Param√®tres :**

- `option_name`
- `message`
- `ctx`

##### __init__

**Param√®tres :**

- `ctx`

##### show

**Param√®tres :**

- `file`

##### __init__

**Param√®tres :**

- `filename`
- `hint`

##### format_message

##### __init__

**Param√®tres :**

- `code`

---

### formatting

#### Classes

##### HelpFormatter

This class helps with formatting text-based help pages.  It's
usually just needed for very special internal cases, but it's also
exposed so that developers can write their own fancy outputs.

At present, it always writes into memory.

:param indent_increment: the additional increment for each level.
:param width: the width for the text.  This defaults to the terminal
              width clamped to a maximum of 78.

**M√©thodes :**

- `__init__()`
- `write()`
- `indent()`
- `dedent()`
- `write_usage()`
- `write_heading()`
- `write_paragraph()`
- `write_text()`
- `write_dl()`
- `section()`
- `indentation()`
- `getvalue()`

#### Fonctions

##### measure_table

**Param√®tres :**

- `rows`

##### iter_rows

**Param√®tres :**

- `rows`
- `col_count`

##### wrap_text

A helper function that intelligently wraps text.  By default, it
assumes that it operates on a single paragraph of text but if the
`preserve_paragraphs` parameter is provided it will intelligently
handle paragraphs (defined by two empty lines).

If paragraphs are handled, a paragraph can be prefixed with an empty
line containing the ``\b`` character (``\x08``) to indicate that
no rewrapping should happen in that block.

:param text: the text that should be rewrapped.
:param width: the maximum width for the text.
:param initial_indent: the initial indent that should be placed on the
                       first line as a string.
:param subsequent_indent: the indent string that should be placed on
                          each consecutive line.
:param preserve_paragraphs: if this flag is set then the wrapping will
                            intelligently handle paragraphs.

**Param√®tres :**

- `text`
- `width`
- `initial_indent`
- `subsequent_indent`
- `preserve_paragraphs`

##### join_options

Given a list of option strings this joins them in the most appropriate
way and returns them in the form ``(formatted_string,
any_prefix_is_slash)`` where the second item in the tuple is a flag that
indicates if any of the option prefixes was a slash.

**Param√®tres :**

- `options`

##### _flush_par

##### __init__

**Param√®tres :**

- `indent_increment`
- `width`
- `max_width`

##### write

Writes a unicode string into the internal buffer.

**Param√®tres :**

- `string`

##### indent

Increases the indentation.

##### dedent

Decreases the indentation.

##### write_usage

Writes a usage line into the buffer.

:param prog: the program name.
:param args: whitespace separated list of arguments.
:param prefix: The prefix for the first line. Defaults to
    ``"Usage: "``.

**Param√®tres :**

- `prog`
- `args`
- `prefix`

##### write_heading

Writes a heading into the buffer.

**Param√®tres :**

- `heading`

##### write_paragraph

Writes a paragraph into the buffer.

##### write_text

Writes re-indented text into the buffer.  This rewraps and
preserves paragraphs.

**Param√®tres :**

- `text`

##### write_dl

Writes a definition list into the buffer.  This is how options
and commands are usually formatted.

:param rows: a list of two item tuples for the terms and values.
:param col_max: the maximum width of the first column.
:param col_spacing: the number of spaces between the first and
                    second column.

**Param√®tres :**

- `rows`
- `col_max`
- `col_spacing`

##### section

Helpful context manager that writes a paragraph, a heading,
and the indents.

:param name: the section name that is written as heading.

**Param√®tres :**

- `name`

##### indentation

A context manager that increases the indentation.

##### getvalue

Returns the buffer contents.

---

### globals

#### Fonctions

##### get_current_context

**Param√®tres :**

- `silent`

##### get_current_context

**Param√®tres :**

- `silent`

##### get_current_context

Returns the current click context.  This can be used as a way to
access the current context object from anywhere.  This is a more implicit
alternative to the :func:`pass_context` decorator.  This function is
primarily useful for helpers such as :func:`echo` which might be
interested in changing its behavior based on the current context.

To push the current context, :meth:`Context.scope` can be used.

.. versionadded:: 5.0

:param silent: if set to `True` the return value is `None` if no context
               is available.  The default behavior is to raise a
               :exc:`RuntimeError`.

**Param√®tres :**

- `silent`

##### push_context

Pushes a new context to the current stack.

**Param√®tres :**

- `ctx`

##### pop_context

Removes the top level from the stack.

##### resolve_color_default

Internal helper to get the default value of the color flag.  If a
value is passed it's returned unchanged, otherwise it's looked up from
the current context.

**Param√®tres :**

- `color`

---

### parser

This module started out as largely a copy paste from the stdlib's
optparse module with the features removed that we do not need from
optparse because we implement them in Click on a higher level (for
instance type handling, help formatting and a lot more).

The plan is to remove more and more from here over time.

The reason this is a different module and not optparse from the stdlib
is that there are differences in 2.x and 3.x about the error messages
generated and optparse in the stdlib uses gettext for no good reason
and might cause us issues.

Click uses parts of optparse written by Gregory P. Ward and maintained
by the Python Software Foundation. This is limited to code in parser.py.

Copyright 2001-2006 Gregory P. Ward. All rights reserved.
Copyright 2002-2006 Python Software Foundation. All rights reserved.

#### Classes

##### _Option

**M√©thodes :**

- `__init__()`
- `takes_value()`
- `process()`

##### _Argument

**M√©thodes :**

- `__init__()`
- `process()`

##### _ParsingState

**M√©thodes :**

- `__init__()`

##### _OptionParser

The option parser is an internal class that is ultimately used to
parse options and arguments.  It's modelled after optparse and brings
a similar but vastly simplified API.  It should generally not be used
directly as the high level Click classes wrap it for you.

It's not nearly as extensible as optparse or argparse as it does not
implement features that are implemented on a higher level (such as
types or defaults).

:param ctx: optionally the :class:`~click.Context` where this parser
            should go with.

.. deprecated:: 8.2
    Will be removed in Click 9.0.

**M√©thodes :**

- `__init__()`
- `add_option()`
- `add_argument()`
- `parse_args()`
- `_process_args_for_args()`
- `_process_args_for_options()`
- `_match_long_opt()`
- `_match_short_opt()`
- `_get_value_from_state()`
- `_process_opts()`

#### Fonctions

##### _unpack_args

Given an iterable of arguments and an iterable of nargs specifications,
it returns a tuple with all the unpacked arguments at the first index
and all remaining arguments as the second.

The nargs specification is the number of arguments that should be consumed
or `-1` to indicate that this position should eat up all the remainders.

Missing items are filled with `None`.

**Param√®tres :**

- `args`
- `nargs_spec`

##### _split_opt

**Param√®tres :**

- `opt`

##### _normalize_opt

**Param√®tres :**

- `opt`
- `ctx`

##### __getattr__

**Param√®tres :**

- `name`

##### _fetch

**Param√®tres :**

- `c`

##### __init__

**Param√®tres :**

- `obj`
- `opts`
- `dest`
- `action`
- `nargs`
- `const`

##### takes_value

##### process

**Param√®tres :**

- `value`
- `state`

##### __init__

**Param√®tres :**

- `obj`
- `dest`
- `nargs`

##### process

**Param√®tres :**

- `value`
- `state`

##### __init__

**Param√®tres :**

- `rargs`

##### __init__

**Param√®tres :**

- `ctx`

##### add_option

Adds a new option named `dest` to the parser.  The destination
is not inferred (unlike with optparse) and needs to be explicitly
provided.  Action can be any of ``store``, ``store_const``,
``append``, ``append_const`` or ``count``.

The `obj` can be used to identify the option in the order list
that is returned from the parser.

**Param√®tres :**

- `obj`
- `opts`
- `dest`
- `action`
- `nargs`
- `const`

##### add_argument

Adds a positional argument named `dest` to the parser.

The `obj` can be used to identify the option in the order list
that is returned from the parser.

**Param√®tres :**

- `obj`
- `dest`
- `nargs`

##### parse_args

Parses positional arguments and returns ``(values, args, order)``
for the parsed options and arguments as well as the leftover
arguments if there are any.  The order is a list of objects as they
appear on the command line.  If arguments appear multiple times they
will be memorized multiple times as well.

**Param√®tres :**

- `args`

##### _process_args_for_args

**Param√®tres :**

- `state`

##### _process_args_for_options

**Param√®tres :**

- `state`

##### _match_long_opt

**Param√®tres :**

- `opt`
- `explicit_value`
- `state`

##### _match_short_opt

**Param√®tres :**

- `arg`
- `state`

##### _get_value_from_state

**Param√®tres :**

- `option_name`
- `option`
- `state`

##### _process_opts

**Param√®tres :**

- `arg`
- `state`

---

### shell_completion

#### Classes

##### CompletionItem

Represents a completion value and metadata about the value. The
default metadata is ``type`` to indicate special shell handling,
and ``help`` if a shell supports showing a help string next to the
value.

Arbitrary parameters can be passed when creating the object, and
accessed using ``item.attr``. If an attribute wasn't passed,
accessing it returns ``None``.

:param value: The completion suggestion.
:param type: Tells the shell script to provide special completion
    support for the type. Click uses ``"dir"`` and ``"file"``.
:param help: String shown next to the value if supported.
:param kwargs: Arbitrary metadata. The built-in implementations
    don't use this, but custom type completions paired with custom
    shell support could use it.

**M√©thodes :**

- `__init__()`
- `__getattr__()`

##### ShellComplete

Base class for providing shell completion support. A subclass for
a given shell will override attributes and methods to implement the
completion instructions (``source`` and ``complete``).

:param cli: Command being called.
:param prog_name: Name of the executable in the shell.
:param complete_var: Name of the environment variable that holds
    the completion instruction.

.. versionadded:: 8.0

**M√©thodes :**

- `__init__()`
- `func_name()`
- `source_vars()`
- `source()`
- `get_completion_args()`
- `get_completions()`
- `format_completion()`
- `complete()`

##### BashComplete

Shell completion for Bash.

**M√©thodes :**

- `_check_version()`
- `source()`
- `get_completion_args()`
- `format_completion()`

##### ZshComplete

Shell completion for Zsh.

**M√©thodes :**

- `get_completion_args()`
- `format_completion()`

##### FishComplete

Shell completion for Fish.

**M√©thodes :**

- `get_completion_args()`
- `format_completion()`

#### Fonctions

##### shell_complete

Perform shell completion for the given CLI program.

:param cli: Command being called.
:param ctx_args: Extra arguments to pass to
    ``cli.make_context``.
:param prog_name: Name of the executable in the shell.
:param complete_var: Name of the environment variable that holds
    the completion instruction.
:param instruction: Value of ``complete_var`` with the completion
    instruction and shell, in the form ``instruction_shell``.
:return: Status code to exit with.

**Param√®tres :**

- `cli`
- `ctx_args`
- `prog_name`
- `complete_var`
- `instruction`

##### add_completion_class

Register a :class:`ShellComplete` subclass under the given name.
The name will be provided by the completion instruction environment
variable during completion.

:param cls: The completion class that will handle completion for the
    shell.
:param name: Name to register the class under. Defaults to the
    class's ``name`` attribute.

**Param√®tres :**

- `cls`
- `name`

##### get_completion_class

Look up a registered :class:`ShellComplete` subclass by the name
provided by the completion instruction environment variable. If the
name isn't registered, returns ``None``.

:param shell: Name the class is registered under.

**Param√®tres :**

- `shell`

##### split_arg_string

Split an argument string as with :func:`shlex.split`, but don't
fail if the string is incomplete. Ignores a missing closing quote or
incomplete escape sequence and uses the partial token as-is.

.. code-block:: python

    split_arg_string("example 'my file")
    ["example", "my file"]

    split_arg_string("example my\")
    ["example", "my"]

:param string: String to split.

.. versionchanged:: 8.2
    Moved to ``shell_completion`` from ``parser``.

**Param√®tres :**

- `string`

##### _is_incomplete_argument

Determine if the given parameter is an argument that can still
accept values.

:param ctx: Invocation context for the command represented by the
    parsed complete args.
:param param: Argument object being checked.

**Param√®tres :**

- `ctx`
- `param`

##### _start_of_option

Check if the value looks like the start of an option.

**Param√®tres :**

- `ctx`
- `value`

##### _is_incomplete_option

Determine if the given parameter is an option that needs a value.

:param args: List of complete args before the incomplete value.
:param param: Option object being checked.

**Param√®tres :**

- `ctx`
- `args`
- `param`

##### _resolve_context

Produce the context hierarchy starting with the command and
traversing the complete arguments. This only follows the commands,
it doesn't trigger input prompts or callbacks.

:param cli: Command being called.
:param prog_name: Name of the executable in the shell.
:param args: List of complete args before the incomplete value.

**Param√®tres :**

- `cli`
- `ctx_args`
- `prog_name`
- `args`

##### _resolve_incomplete

Find the Click object that will handle the completion of the
incomplete value. Return the object and the incomplete value.

:param ctx: Invocation context for the command represented by
    the parsed complete args.
:param args: List of complete args before the incomplete value.
:param incomplete: Value being completed. May be empty.

**Param√®tres :**

- `ctx`
- `args`
- `incomplete`

##### __init__

**Param√®tres :**

- `value`
- `type`
- `help`

##### __getattr__

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `cli`
- `ctx_args`
- `prog_name`
- `complete_var`

##### func_name

The name of the shell function defined by the completion
script.

##### source_vars

Vars for formatting :attr:`source_template`.

By default this provides ``complete_func``, ``complete_var``,
and ``prog_name``.

##### source

Produce the shell script that defines the completion
function. By default this ``%``-style formats
:attr:`source_template` with the dict returned by
:meth:`source_vars`.

##### get_completion_args

Use the env vars defined by the shell script to return a
tuple of ``args, incomplete``. This must be implemented by
subclasses.

##### get_completions

Determine the context and last complete command or parameter
from the complete args. Call that object's ``shell_complete``
method to get the completions for the incomplete value.

:param args: List of complete args before the incomplete value.
:param incomplete: Value being completed. May be empty.

**Param√®tres :**

- `args`
- `incomplete`

##### format_completion

Format a completion item into the form recognized by the
shell script. This must be implemented by subclasses.

:param item: Completion item to format.

**Param√®tres :**

- `item`

##### complete

Produce the completion data to send back to the shell.

By default this calls :meth:`get_completion_args`, gets the
completions, then calls :meth:`format_completion` for each
completion.

##### _check_version

##### source

##### get_completion_args

##### format_completion

**Param√®tres :**

- `item`

##### get_completion_args

##### format_completion

**Param√®tres :**

- `item`

##### get_completion_args

##### format_completion

**Param√®tres :**

- `item`

---

### termui

#### Fonctions

##### hidden_prompt_func

**Param√®tres :**

- `prompt`

##### _build_prompt

**Param√®tres :**

- `text`
- `suffix`
- `show_default`
- `default`
- `show_choices`
- `type`

##### _format_default

**Param√®tres :**

- `default`

##### prompt

Prompts a user for input.  This is a convenience function that can
be used to prompt a user for input later.

If the user aborts the input by sending an interrupt signal, this
function will catch it and raise a :exc:`Abort` exception.

:param text: the text to show for the prompt.
:param default: the default value to use if no input happens.  If this
                is not given it will prompt until it's aborted.
:param hide_input: if this is set to true then the input value will
                   be hidden.
:param confirmation_prompt: Prompt a second time to confirm the
    value. Can be set to a string instead of ``True`` to customize
    the message.
:param type: the type to use to check the value against.
:param value_proc: if this parameter is provided it's a function that
                   is invoked instead of the type conversion to
                   convert a value.
:param prompt_suffix: a suffix that should be added to the prompt.
:param show_default: shows or hides the default value in the prompt.
:param err: if set to true the file defaults to ``stderr`` instead of
            ``stdout``, the same as with echo.
:param show_choices: Show or hide choices if the passed type is a Choice.
                     For example if type is a Choice of either day or week,
                     show_choices is true and text is "Group by" then the
                     prompt will be "Group by (day, week): ".

.. versionadded:: 8.0
    ``confirmation_prompt`` can be a custom string.

.. versionadded:: 7.0
    Added the ``show_choices`` parameter.

.. versionadded:: 6.0
    Added unicode support for cmd.exe on Windows.

.. versionadded:: 4.0
    Added the `err` parameter.

**Param√®tres :**

- `text`
- `default`
- `hide_input`
- `confirmation_prompt`
- `type`
- `value_proc`
- `prompt_suffix`
- `show_default`
- `err`
- `show_choices`

##### confirm

Prompts for confirmation (yes/no question).

If the user aborts the input by sending a interrupt signal this
function will catch it and raise a :exc:`Abort` exception.

:param text: the question to ask.
:param default: The default value to use when no input is given. If
    ``None``, repeat until input is given.
:param abort: if this is set to `True` a negative answer aborts the
              exception by raising :exc:`Abort`.
:param prompt_suffix: a suffix that should be added to the prompt.
:param show_default: shows or hides the default value in the prompt.
:param err: if set to true the file defaults to ``stderr`` instead of
            ``stdout``, the same as with echo.

.. versionchanged:: 8.0
    Repeat until input is given if ``default`` is ``None``.

.. versionadded:: 4.0
    Added the ``err`` parameter.

**Param√®tres :**

- `text`
- `default`
- `abort`
- `prompt_suffix`
- `show_default`
- `err`

##### echo_via_pager

This function takes a text and shows it via an environment specific
pager on stdout.

.. versionchanged:: 3.0
   Added the `color` flag.

:param text_or_generator: the text to page, or alternatively, a
                          generator emitting the text to page.
:param color: controls if the pager supports ANSI colors or not.  The
              default is autodetection.

**Param√®tres :**

- `text_or_generator`
- `color`

##### progressbar

##### progressbar

**Param√®tres :**

- `iterable`
- `length`
- `label`
- `hidden`
- `show_eta`
- `show_percent`
- `show_pos`
- `item_show_func`
- `fill_char`
- `empty_char`
- `bar_template`
- `info_sep`
- `width`
- `file`
- `color`
- `update_min_steps`

##### progressbar

This function creates an iterable context manager that can be used
to iterate over something while showing a progress bar.  It will
either iterate over the `iterable` or `length` items (that are counted
up).  While iteration happens, this function will print a rendered
progress bar to the given `file` (defaults to stdout) and will attempt
to calculate remaining time and more.  By default, this progress bar
will not be rendered if the file is not a terminal.

The context manager creates the progress bar.  When the context
manager is entered the progress bar is already created.  With every
iteration over the progress bar, the iterable passed to the bar is
advanced and the bar is updated.  When the context manager exits,
a newline is printed and the progress bar is finalized on screen.

Note: The progress bar is currently designed for use cases where the
total progress can be expected to take at least several seconds.
Because of this, the ProgressBar class object won't display
progress that is considered too fast, and progress where the time
between steps is less than a second.

No printing must happen or the progress bar will be unintentionally
destroyed.

Example usage::

    with progressbar(items) as bar:
        for item in bar:
            do_something_with(item)

Alternatively, if no iterable is specified, one can manually update the
progress bar through the `update()` method instead of directly
iterating over the progress bar.  The update method accepts the number
of steps to increment the bar with::

    with progressbar(length=chunks.total_bytes) as bar:
        for chunk in chunks:
            process_chunk(chunk)
            bar.update(chunks.bytes)

The ``update()`` method also takes an optional value specifying the
``current_item`` at the new position. This is useful when used
together with ``item_show_func`` to customize the output for each
manual step::

    with click.progressbar(
        length=total_size,
        label='Unzipping archive',
        item_show_func=lambda a: a.filename
    ) as bar:
        for archive in zip_file:
            archive.extract()
            bar.update(archive.size, archive)

:param iterable: an iterable to iterate over.  If not provided the length
                 is required.
:param length: the number of items to iterate over.  By default the
               progressbar will attempt to ask the iterator about its
               length, which might or might not work.  If an iterable is
               also provided this parameter can be used to override the
               length.  If an iterable is not provided the progress bar
               will iterate over a range of that length.
:param label: the label to show next to the progress bar.
:param hidden: hide the progressbar. Defaults to ``False``. When no tty is
    detected, it will only print the progressbar label. Setting this to
    ``False`` also disables that.
:param show_eta: enables or disables the estimated time display.  This is
                 automatically disabled if the length cannot be
                 determined.
:param show_percent: enables or disables the percentage display.  The
                     default is `True` if the iterable has a length or
                     `False` if not.
:param show_pos: enables or disables the absolute position display.  The
                 default is `False`.
:param item_show_func: A function called with the current item which
    can return a string to show next to the progress bar. If the
    function returns ``None`` nothing is shown. The current item can
    be ``None``, such as when entering and exiting the bar.
:param fill_char: the character to use to show the filled part of the
                  progress bar.
:param empty_char: the character to use to show the non-filled part of
                   the progress bar.
:param bar_template: the format string to use as template for the bar.
                     The parameters in it are ``label`` for the label,
                     ``bar`` for the progress bar and ``info`` for the
                     info section.
:param info_sep: the separator between multiple info items (eta etc.)
:param width: the width of the progress bar in characters, 0 means full
              terminal width
:param file: The file to write to. If this is not a terminal then
    only the label is printed.
:param color: controls if the terminal supports ANSI colors or not.  The
              default is autodetection.  This is only needed if ANSI
              codes are included anywhere in the progress bar output
              which is not the case by default.
:param update_min_steps: Render only when this many updates have
    completed. This allows tuning for very fast iterators.

.. versionadded:: 8.2
    The ``hidden`` argument.

.. versionchanged:: 8.0
    Output is shown even if execution time is less than 0.5 seconds.

.. versionchanged:: 8.0
    ``item_show_func`` shows the current item, not the previous one.

.. versionchanged:: 8.0
    Labels are echoed if the output is not a TTY. Reverts a change
    in 7.0 that removed all output.

.. versionadded:: 8.0
   The ``update_min_steps`` parameter.

.. versionadded:: 4.0
    The ``color`` parameter and ``update`` method.

.. versionadded:: 2.0

**Param√®tres :**

- `iterable`
- `length`
- `label`
- `hidden`
- `show_eta`
- `show_percent`
- `show_pos`
- `item_show_func`
- `fill_char`
- `empty_char`
- `bar_template`
- `info_sep`
- `width`
- `file`
- `color`
- `update_min_steps`

##### clear

Clears the terminal screen.  This will have the effect of clearing
the whole visible space of the terminal and moving the cursor to the
top left.  This does not do anything if not connected to a terminal.

.. versionadded:: 2.0

##### _interpret_color

**Param√®tres :**

- `color`
- `offset`

##### style

Styles a text with ANSI styles and returns the new string.  By
default the styling is self contained which means that at the end
of the string a reset code is issued.  This can be prevented by
passing ``reset=False``.

Examples::

    click.echo(click.style('Hello World!', fg='green'))
    click.echo(click.style('ATTENTION!', blink=True))
    click.echo(click.style('Some things', reverse=True, fg='cyan'))
    click.echo(click.style('More colors', fg=(255, 12, 128), bg=117))

Supported color names:

* ``black`` (might be a gray)
* ``red``
* ``green``
* ``yellow`` (might be an orange)
* ``blue``
* ``magenta``
* ``cyan``
* ``white`` (might be light gray)
* ``bright_black``
* ``bright_red``
* ``bright_green``
* ``bright_yellow``
* ``bright_blue``
* ``bright_magenta``
* ``bright_cyan``
* ``bright_white``
* ``reset`` (reset the color code only)

If the terminal supports it, color may also be specified as:

-   An integer in the interval [0, 255]. The terminal must support
    8-bit/256-color mode.
-   An RGB tuple of three integers in [0, 255]. The terminal must
    support 24-bit/true-color mode.

See https://en.wikipedia.org/wiki/ANSI_color and
https://gist.github.com/XVilka/8346728 for more information.

:param text: the string to style with ansi codes.
:param fg: if provided this will become the foreground color.
:param bg: if provided this will become the background color.
:param bold: if provided this will enable or disable bold mode.
:param dim: if provided this will enable or disable dim mode.  This is
            badly supported.
:param underline: if provided this will enable or disable underline.
:param overline: if provided this will enable or disable overline.
:param italic: if provided this will enable or disable italic.
:param blink: if provided this will enable or disable blinking.
:param reverse: if provided this will enable or disable inverse
                rendering (foreground becomes background and the
                other way round).
:param strikethrough: if provided this will enable or disable
    striking through text.
:param reset: by default a reset-all code is added at the end of the
              string which means that styles do not carry over.  This
              can be disabled to compose styles.

.. versionchanged:: 8.0
    A non-string ``message`` is converted to a string.

.. versionchanged:: 8.0
   Added support for 256 and RGB color codes.

.. versionchanged:: 8.0
    Added the ``strikethrough``, ``italic``, and ``overline``
    parameters.

.. versionchanged:: 7.0
    Added support for bright colors.

.. versionadded:: 2.0

**Param√®tres :**

- `text`
- `fg`
- `bg`
- `bold`
- `dim`
- `underline`
- `overline`
- `italic`
- `blink`
- `reverse`
- `strikethrough`
- `reset`

##### unstyle

Removes ANSI styling information from a string.  Usually it's not
necessary to use this function as Click's echo function will
automatically remove styling if necessary.

.. versionadded:: 2.0

:param text: the text to remove style information from.

**Param√®tres :**

- `text`

##### secho

This function combines :func:`echo` and :func:`style` into one
call.  As such the following two calls are the same::

    click.secho('Hello World!', fg='green')
    click.echo(click.style('Hello World!', fg='green'))

All keyword arguments are forwarded to the underlying functions
depending on which one they go with.

Non-string types will be converted to :class:`str`. However,
:class:`bytes` are passed directly to :meth:`echo` without applying
style. If you want to style bytes that represent text, call
:meth:`bytes.decode` first.

.. versionchanged:: 8.0
    A non-string ``message`` is converted to a string. Bytes are
    passed through without style applied.

.. versionadded:: 2.0

**Param√®tres :**

- `message`
- `file`
- `nl`
- `err`
- `color`

##### edit

**Param√®tres :**

- `text`
- `editor`
- `env`
- `require_save`
- `extension`

##### edit

**Param√®tres :**

- `text`
- `editor`
- `env`
- `require_save`
- `extension`

##### edit

**Param√®tres :**

- `text`
- `editor`
- `env`
- `require_save`
- `extension`
- `filename`

##### edit

Edits the given text in the defined editor.  If an editor is given
(should be the full path to the executable but the regular operating
system search path is used for finding the executable) it overrides
the detected editor.  Optionally, some environment variables can be
used.  If the editor is closed without changes, `None` is returned.  In
case a file is edited directly the return value is always `None` and
`require_save` and `extension` are ignored.

If the editor cannot be opened a :exc:`UsageError` is raised.

Note for Windows: to simplify cross-platform usage, the newlines are
automatically converted from POSIX to Windows and vice versa.  As such,
the message here will have ``\n`` as newline markers.

:param text: the text to edit.
:param editor: optionally the editor to use.  Defaults to automatic
               detection.
:param env: environment variables to forward to the editor.
:param require_save: if this is true, then not saving in the editor
                     will make the return value become `None`.
:param extension: the extension to tell the editor about.  This defaults
                  to `.txt` but changing this might change syntax
                  highlighting.
:param filename: if provided it will edit this file instead of the
                 provided text contents.  It will not use a temporary
                 file as an indirection in that case. If the editor supports
                 editing multiple files at once, a sequence of files may be
                 passed as well. Invoke `click.file` once per file instead
                 if multiple files cannot be managed at once or editing the
                 files serially is desired.

.. versionchanged:: 8.2.0
    ``filename`` now accepts any ``Iterable[str]`` in addition to a ``str``
    if the ``editor`` supports editing multiple files at once.

**Param√®tres :**

- `text`
- `editor`
- `env`
- `require_save`
- `extension`
- `filename`

##### launch

This function launches the given URL (or filename) in the default
viewer application for this file type.  If this is an executable, it
might launch the executable in a new session.  The return value is
the exit code of the launched application.  Usually, ``0`` indicates
success.

Examples::

    click.launch('https://click.palletsprojects.com/')
    click.launch('/my/downloaded/file', locate=True)

.. versionadded:: 2.0

:param url: URL or filename of the thing to launch.
:param wait: Wait for the program to exit before returning. This
    only works if the launched program blocks. In particular,
    ``xdg-open`` on Linux does not block.
:param locate: if this is set to `True` then instead of launching the
               application associated with the URL it will attempt to
               launch a file manager with the file located.  This
               might have weird effects if the URL does not point to
               the filesystem.

**Param√®tres :**

- `url`
- `wait`
- `locate`

##### getchar

Fetches a single character from the terminal and returns it.  This
will always return a unicode character and under certain rare
circumstances this might return more than one character.  The
situations which more than one character is returned is when for
whatever reason multiple characters end up in the terminal buffer or
standard input was not actually a terminal.

Note that this will always read from the terminal, even if something
is piped into the standard input.

Note for Windows: in rare cases when typing non-ASCII characters, this
function might wait for a second character and then return both at once.
This is because certain Unicode characters look like special-key markers.

.. versionadded:: 2.0

:param echo: if set to `True`, the character read will also show up on
             the terminal.  The default is to not show it.

**Param√®tres :**

- `echo`

##### raw_terminal

##### pause

This command stops execution and waits for the user to press any
key to continue.  This is similar to the Windows batch "pause"
command.  If the program is not run through a terminal, this command
will instead do nothing.

.. versionadded:: 2.0

.. versionadded:: 4.0
   Added the `err` parameter.

:param info: The message to print before pausing. Defaults to
    ``"Press any key to continue..."``.
:param err: if set to message goes to ``stderr`` instead of
            ``stdout``, the same as with echo.

**Param√®tres :**

- `info`
- `err`

##### prompt_func

**Param√®tres :**

- `text`

---

### testing

#### Classes

##### EchoingStdin

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `_echo()`
- `read()`
- `read1()`
- `readline()`
- `readlines()`
- `__iter__()`
- `__repr__()`

##### BytesIOCopy

Patch ``io.BytesIO`` to let the written stream be copied to another.

.. versionadded:: 8.2

**M√©thodes :**

- `__init__()`
- `flush()`
- `write()`

##### StreamMixer

Mixes `<stdout>` and `<stderr>` streams.

The result is available in the ``output`` attribute.

.. versionadded:: 8.2

**M√©thodes :**

- `__init__()`

##### _NamedTextIOWrapper

**M√©thodes :**

- `__init__()`
- `name()`
- `mode()`
- `__next__()`

##### Result

Holds the captured result of an invoked CLI script.

:param runner: The runner that created the result
:param stdout_bytes: The standard output as bytes.
:param stderr_bytes: The standard error as bytes.
:param output_bytes: A mix of ``stdout_bytes`` and ``stderr_bytes``, as the
    user would see  it in its terminal.
:param return_value: The value returned from the invoked command.
:param exit_code: The exit code as integer.
:param exception: The exception that happened if one did.
:param exc_info: Exception information (exception type, exception instance,
    traceback type).

.. versionchanged:: 8.2
    ``stderr_bytes`` no longer optional, ``output_bytes`` introduced and
    ``mix_stderr`` has been removed.

.. versionadded:: 8.0
    Added ``return_value``.

**M√©thodes :**

- `__init__()`
- `output()`
- `stdout()`
- `stderr()`
- `__repr__()`

##### CliRunner

The CLI runner provides functionality to invoke a Click command line
script for unittesting purposes in a isolated environment.  This only
works in single-threaded systems without any concurrency as it changes the
global interpreter state.

:param charset: the character set for the input and output data.
:param env: a dictionary with environment variables for overriding.
:param echo_stdin: if this is set to `True`, then reading from `<stdin>` writes
                   to `<stdout>`.  This is useful for showing examples in
                   some circumstances.  Note that regular prompts
                   will automatically echo the input.
:param catch_exceptions: Whether to catch any exceptions other than
                         ``SystemExit`` when running :meth:`~CliRunner.invoke`.

.. versionchanged:: 8.2
    Added the ``catch_exceptions`` parameter.

.. versionchanged:: 8.2
    ``mix_stderr`` parameter has been removed.

**M√©thodes :**

- `__init__()`
- `get_default_prog_name()`
- `make_env()`
- `isolation()`
- `invoke()`
- `isolated_filesystem()`

#### Fonctions

##### _pause_echo

**Param√®tres :**

- `stream`

##### make_input_stream

**Param√®tres :**

- `input`
- `charset`

##### __init__

**Param√®tres :**

- `input`
- `output`

##### __getattr__

**Param√®tres :**

- `x`

##### _echo

**Param√®tres :**

- `rv`

##### read

**Param√®tres :**

- `n`

##### read1

**Param√®tres :**

- `n`

##### readline

**Param√®tres :**

- `n`

##### readlines

##### __iter__

##### __repr__

##### __init__

**Param√®tres :**

- `copy_to`

##### flush

##### write

**Param√®tres :**

- `b`

##### __init__

##### __init__

**Param√®tres :**

- `buffer`
- `name`
- `mode`

##### name

##### mode

##### __next__

##### __init__

**Param√®tres :**

- `runner`
- `stdout_bytes`
- `stderr_bytes`
- `output_bytes`
- `return_value`
- `exit_code`
- `exception`
- `exc_info`

##### output

The terminal output as unicode string, as the user would see it.

.. versionchanged:: 8.2
    No longer a proxy for ``self.stdout``. Now has its own independent stream
    that is mixing `<stdout>` and `<stderr>`, in the order they were written.

##### stdout

The standard output as unicode string.

##### stderr

The standard error as unicode string.

.. versionchanged:: 8.2
    No longer raise an exception, always returns the `<stderr>` string.

##### __repr__

##### __init__

**Param√®tres :**

- `charset`
- `env`
- `echo_stdin`
- `catch_exceptions`

##### get_default_prog_name

Given a command object it will return the default program name
for it.  The default is the `name` attribute or ``"root"`` if not
set.

**Param√®tres :**

- `cli`

##### make_env

Returns the environment overrides for invoking a script.

**Param√®tres :**

- `overrides`

##### isolation

A context manager that sets up the isolation for invoking of a
command line tool.  This sets up `<stdin>` with the given input data
and `os.environ` with the overrides from the given dictionary.
This also rebinds some internals in Click to be mocked (like the
prompt functionality).

This is automatically done in the :meth:`invoke` method.

:param input: the input stream to put into `sys.stdin`.
:param env: the environment overrides as dictionary.
:param color: whether the output should contain color codes. The
              application can still override this explicitly.

.. versionadded:: 8.2
    An additional output stream is returned, which is a mix of
    `<stdout>` and `<stderr>` streams.

.. versionchanged:: 8.2
    Always returns the `<stderr>` stream.

.. versionchanged:: 8.0
    `<stderr>` is opened with ``errors="backslashreplace"``
    instead of the default ``"strict"``.

.. versionchanged:: 4.0
    Added the ``color`` parameter.

**Param√®tres :**

- `input`
- `env`
- `color`

##### invoke

Invokes a command in an isolated environment.  The arguments are
forwarded directly to the command line script, the `extra` keyword
arguments are passed to the :meth:`~clickpkg.Command.main` function of
the command.

This returns a :class:`Result` object.

:param cli: the command to invoke
:param args: the arguments to invoke. It may be given as an iterable
             or a string. When given as string it will be interpreted
             as a Unix shell command. More details at
             :func:`shlex.split`.
:param input: the input data for `sys.stdin`.
:param env: the environment overrides.
:param catch_exceptions: Whether to catch any other exceptions than
                         ``SystemExit``. If :data:`None`, the value
                         from :class:`CliRunner` is used.
:param extra: the keyword arguments to pass to :meth:`main`.
:param color: whether the output should contain color codes. The
              application can still override this explicitly.

.. versionadded:: 8.2
    The result object has the ``output_bytes`` attribute with
    the mix of ``stdout_bytes`` and ``stderr_bytes``, as the user would
    see it in its terminal.

.. versionchanged:: 8.2
    The result object always returns the ``stderr_bytes`` stream.

.. versionchanged:: 8.0
    The result object has the ``return_value`` attribute with
    the value returned from the invoked command.

.. versionchanged:: 4.0
    Added the ``color`` parameter.

.. versionchanged:: 3.0
    Added the ``catch_exceptions`` parameter.

.. versionchanged:: 3.0
    The result object has the ``exc_info`` attribute with the
    traceback if available.

**Param√®tres :**

- `cli`
- `args`
- `input`
- `env`
- `catch_exceptions`
- `color`

##### isolated_filesystem

A context manager that creates a temporary directory and
changes the current working directory to it. This isolates tests
that affect the contents of the CWD to prevent them from
interfering with each other.

:param temp_dir: Create the temporary directory under this
    directory. If given, the created directory is not removed
    when exiting.

.. versionchanged:: 8.0
    Added the ``temp_dir`` parameter.

**Param√®tres :**

- `temp_dir`

##### visible_input

**Param√®tres :**

- `prompt`

##### hidden_input

**Param√®tres :**

- `prompt`

##### _getchar

**Param√®tres :**

- `echo`

##### should_strip_ansi

**Param√®tres :**

- `stream`
- `color`

---

### types

#### Classes

##### ParamType

Represents the type of a parameter. Validates and converts values
from the command line or Python into the correct type.

To implement a custom type, subclass and implement at least the
following:

-   The :attr:`name` class attribute must be set.
-   Calling an instance of the type with ``None`` must return
    ``None``. This is already implemented by default.
-   :meth:`convert` must convert string values to the correct type.
-   :meth:`convert` must accept values that are already the correct
    type.
-   It must be able to convert a value if the ``ctx`` and ``param``
    arguments are ``None``. This can occur when converting prompt
    input.

**M√©thodes :**

- `to_info_dict()`
- `__call__()`
- `get_metavar()`
- `get_missing_message()`
- `convert()`
- `split_envvar_value()`
- `fail()`
- `shell_complete()`

##### CompositeParamType

**M√©thodes :**

- `arity()`

##### FuncParamType

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `convert()`

##### UnprocessedParamType

**M√©thodes :**

- `convert()`
- `__repr__()`

##### StringParamType

**M√©thodes :**

- `convert()`
- `__repr__()`

##### Choice

The choice type allows a value to be checked against a fixed set
of supported values.

You may pass any iterable value which will be converted to a tuple
and thus will only be iterated once.

The resulting value will always be one of the originally passed choices.
See :meth:`normalize_choice` for more info on the mapping of strings
to choices. See :ref:`choice-opts` for an example.

:param case_sensitive: Set to false to make choices case
    insensitive. Defaults to true.

.. versionchanged:: 8.2.0
    Non-``str`` ``choices`` are now supported. It can additionally be any
    iterable. Before you were not recommended to pass anything but a list or
    tuple.

.. versionadded:: 8.2.0
    Choice normalization can be overridden via :meth:`normalize_choice`.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `_normalized_mapping()`
- `normalize_choice()`
- `get_metavar()`
- `get_missing_message()`
- `convert()`
- `get_invalid_choice_message()`
- `__repr__()`
- `shell_complete()`

##### DateTime

The DateTime type converts date strings into `datetime` objects.

The format strings which are checked are configurable, but default to some
common (non-timezone aware) ISO 8601 formats.

When specifying *DateTime* formats, you should only pass a list or a tuple.
Other iterables, like generators, may lead to surprising results.

The format strings are processed using ``datetime.strptime``, and this
consequently defines the format strings which are allowed.

Parsing is tried using each format, in order, and the first format which
parses successfully is used.

:param formats: A list or tuple of date format strings, in the order in
                which they should be tried. Defaults to
                ``'%Y-%m-%d'``, ``'%Y-%m-%dT%H:%M:%S'``,
                ``'%Y-%m-%d %H:%M:%S'``.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `get_metavar()`
- `_try_to_convert_date()`
- `convert()`
- `__repr__()`

##### _NumberParamTypeBase

**M√©thodes :**

- `convert()`

##### _NumberRangeBase

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `convert()`
- `_clamp()`
- `_describe_range()`
- `__repr__()`

##### IntParamType

**M√©thodes :**

- `__repr__()`

##### IntRange

Restrict an :data:`click.INT` value to a range of accepted
values. See :ref:`ranges`.

If ``min`` or ``max`` are not passed, any value is accepted in that
direction. If ``min_open`` or ``max_open`` are enabled, the
corresponding boundary is not included in the range.

If ``clamp`` is enabled, a value outside the range is clamped to the
boundary instead of failing.

.. versionchanged:: 8.0
    Added the ``min_open`` and ``max_open`` parameters.

**M√©thodes :**

- `_clamp()`

##### FloatParamType

**M√©thodes :**

- `__repr__()`

##### FloatRange

Restrict a :data:`click.FLOAT` value to a range of accepted
values. See :ref:`ranges`.

If ``min`` or ``max`` are not passed, any value is accepted in that
direction. If ``min_open`` or ``max_open`` are enabled, the
corresponding boundary is not included in the range.

If ``clamp`` is enabled, a value outside the range is clamped to the
boundary instead of failing. This is not supported if either
boundary is marked ``open``.

.. versionchanged:: 8.0
    Added the ``min_open`` and ``max_open`` parameters.

**M√©thodes :**

- `__init__()`
- `_clamp()`

##### BoolParamType

**M√©thodes :**

- `convert()`
- `__repr__()`

##### UUIDParameterType

**M√©thodes :**

- `convert()`
- `__repr__()`

##### File

Declares a parameter to be a file for reading or writing.  The file
is automatically closed once the context tears down (after the command
finished working).

Files can be opened for reading or writing.  The special value ``-``
indicates stdin or stdout depending on the mode.

By default, the file is opened for reading text data, but it can also be
opened in binary mode or for writing.  The encoding parameter can be used
to force a specific encoding.

The `lazy` flag controls if the file should be opened immediately or upon
first IO. The default is to be non-lazy for standard input and output
streams as well as files opened for reading, `lazy` otherwise. When opening a
file lazily for reading, it is still opened temporarily for validation, but
will not be held open until first IO. lazy is mainly useful when opening
for writing to avoid creating the file until it is needed.

Files can also be opened atomically in which case all writes go into a
separate file in the same folder and upon completion the file will
be moved over to the original location.  This is useful if a file
regularly read by other users is modified.

See :ref:`file-args` for more information.

.. versionchanged:: 2.0
    Added the ``atomic`` parameter.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `resolve_lazy_flag()`
- `convert()`
- `shell_complete()`

##### Path

The ``Path`` type is similar to the :class:`File` type, but
returns the filename instead of an open file. Various checks can be
enabled to validate the type of file and permissions.

:param exists: The file or directory needs to exist for the value to
    be valid. If this is not set to ``True``, and the file does not
    exist, then all further checks are silently skipped.
:param file_okay: Allow a file as a value.
:param dir_okay: Allow a directory as a value.
:param readable: if true, a readable check is performed.
:param writable: if true, a writable check is performed.
:param executable: if true, an executable check is performed.
:param resolve_path: Make the value absolute and resolve any
    symlinks. A ``~`` is not expanded, as this is supposed to be
    done by the shell only.
:param allow_dash: Allow a single dash as a value, which indicates
    a standard stream (but does not open it). Use
    :func:`~click.open_file` to handle opening this value.
:param path_type: Convert the incoming path value to this type. If
    ``None``, keep Python's default, which is ``str``. Useful to
    convert to :class:`pathlib.Path`.

.. versionchanged:: 8.1
    Added the ``executable`` parameter.

.. versionchanged:: 8.0
    Allow passing ``path_type=pathlib.Path``.

.. versionchanged:: 6.0
    Added the ``allow_dash`` parameter.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `coerce_path_result()`
- `convert()`
- `shell_complete()`

##### Tuple

The default behavior of Click is to apply a type on a value directly.
This works well in most cases, except for when `nargs` is set to a fixed
count and different types should be used for different items.  In this
case the :class:`Tuple` type can be used.  This type can only be used
if `nargs` is set to a fixed number.

For more information see :ref:`tuple-type`.

This can be selected by using a Python tuple literal as a type.

:param types: a list of types that should be used for the tuple items.

**M√©thodes :**

- `__init__()`
- `to_info_dict()`
- `name()`
- `arity()`
- `convert()`

##### OptionHelpExtra

#### Fonctions

##### _is_file_like

**Param√®tres :**

- `value`

##### convert_type

Find the most appropriate :class:`ParamType` for the given Python
type. If the type isn't provided, it can be inferred from a default
value.

**Param√®tres :**

- `ty`
- `default`

##### to_info_dict

Gather information that could be useful for a tool generating
user-facing documentation.

Use :meth:`click.Context.to_info_dict` to traverse the entire
CLI structure.

.. versionadded:: 8.0

##### __call__

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### get_metavar

Returns the metavar default for this param if it provides one.

**Param√®tres :**

- `param`
- `ctx`

##### get_missing_message

Optionally might return extra information about a missing
parameter.

.. versionadded:: 2.0

**Param√®tres :**

- `param`
- `ctx`

##### convert

Convert the value to the correct type. This is not called if
the value is ``None`` (the missing value).

This must accept string values from the command line, as well as
values that are already the correct type. It may also convert
other compatible types.

The ``param`` and ``ctx`` arguments may be ``None`` in certain
situations, such as when converting prompt input.

If the value cannot be converted, call :meth:`fail` with a
descriptive message.

:param value: The value to convert.
:param param: The parameter that is using this type to convert
    its value. May be ``None``.
:param ctx: The current context that arrived at this value. May
    be ``None``.

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### split_envvar_value

Given a value from an environment variable this splits it up
into small chunks depending on the defined envvar list splitter.

If the splitter is set to `None`, which means that whitespace splits,
then leading and trailing whitespace is ignored.  Otherwise, leading
and trailing splitters usually lead to empty items being included.

**Param√®tres :**

- `rv`

##### fail

Helper method to fail with an invalid value message.

**Param√®tres :**

- `message`
- `param`
- `ctx`

##### shell_complete

Return a list of
:class:`~click.shell_completion.CompletionItem` objects for the
incomplete value. Most types do not provide completions, but
some do, and this allows custom types to provide custom
completions as well.

:param ctx: Invocation context for this command.
:param param: The parameter that is requesting completion.
:param incomplete: Value being completed. May be empty.

.. versionadded:: 8.0

**Param√®tres :**

- `ctx`
- `param`
- `incomplete`

##### arity

##### __init__

**Param√®tres :**

- `func`

##### to_info_dict

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### __repr__

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### __repr__

##### __init__

**Param√®tres :**

- `choices`
- `case_sensitive`

##### to_info_dict

##### _normalized_mapping

Returns mapping where keys are the original choices and the values are
the normalized values that are accepted via the command line.

This is a simple wrapper around :meth:`normalize_choice`, use that
instead which is supported.

**Param√®tres :**

- `ctx`

##### normalize_choice

Normalize a choice value, used to map a passed string to a choice.
Each choice must have a unique normalized value.

By default uses :meth:`Context.token_normalize_func` and if not case
sensitive, convert it to a casefolded value.

.. versionadded:: 8.2.0

**Param√®tres :**

- `choice`
- `ctx`

##### get_metavar

**Param√®tres :**

- `param`
- `ctx`

##### get_missing_message

Message shown when no choice is passed.

.. versionchanged:: 8.2.0 Added ``ctx`` argument.

**Param√®tres :**

- `param`
- `ctx`

##### convert

For a given value from the parser, normalize it and find its
matching normalized value in the list of choices. Then return the
matched "original" choice.

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### get_invalid_choice_message

Get the error message when the given choice is invalid.

:param value: The invalid value.

.. versionadded:: 8.2

**Param√®tres :**

- `value`
- `ctx`

##### __repr__

##### shell_complete

Complete choices that start with the incomplete value.

:param ctx: Invocation context for this command.
:param param: The parameter that is requesting completion.
:param incomplete: Value being completed. May be empty.

.. versionadded:: 8.0

**Param√®tres :**

- `ctx`
- `param`
- `incomplete`

##### __init__

**Param√®tres :**

- `formats`

##### to_info_dict

##### get_metavar

**Param√®tres :**

- `param`
- `ctx`

##### _try_to_convert_date

**Param√®tres :**

- `value`
- `format`

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### __repr__

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### __init__

**Param√®tres :**

- `min`
- `max`
- `min_open`
- `max_open`
- `clamp`

##### to_info_dict

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### _clamp

Find the valid value to clamp to bound in the given
direction.

:param bound: The boundary value.
:param dir: 1 or -1 indicating the direction to move.
:param open: If true, the range does not include the bound.

**Param√®tres :**

- `bound`
- `dir`
- `open`

##### _describe_range

Describe the range for use in help text.

##### __repr__

##### __repr__

##### _clamp

**Param√®tres :**

- `bound`
- `dir`
- `open`

##### __repr__

##### __init__

**Param√®tres :**

- `min`
- `max`
- `min_open`
- `max_open`
- `clamp`

##### _clamp

**Param√®tres :**

- `bound`
- `dir`
- `open`

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### __repr__

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### __repr__

##### __init__

**Param√®tres :**

- `mode`
- `encoding`
- `errors`
- `lazy`
- `atomic`

##### to_info_dict

##### resolve_lazy_flag

**Param√®tres :**

- `value`

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### shell_complete

Return a special completion marker that tells the completion
system to use the shell to provide file path completions.

:param ctx: Invocation context for this command.
:param param: The parameter that is requesting completion.
:param incomplete: Value being completed. May be empty.

.. versionadded:: 8.0

**Param√®tres :**

- `ctx`
- `param`
- `incomplete`

##### __init__

**Param√®tres :**

- `exists`
- `file_okay`
- `dir_okay`
- `writable`
- `readable`
- `resolve_path`
- `allow_dash`
- `path_type`
- `executable`

##### to_info_dict

##### coerce_path_result

**Param√®tres :**

- `value`

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

##### shell_complete

Return a special completion marker that tells the completion
system to use the shell to provide path completions for only
directories or any paths.

:param ctx: Invocation context for this command.
:param param: The parameter that is requesting completion.
:param incomplete: Value being completed. May be empty.

.. versionadded:: 8.0

**Param√®tres :**

- `ctx`
- `param`
- `incomplete`

##### __init__

**Param√®tres :**

- `types`

##### to_info_dict

##### name

##### arity

##### convert

**Param√®tres :**

- `value`
- `param`
- `ctx`

---

### utils

#### Classes

##### LazyFile

A lazy file works like a regular file but it does not fully open
the file but it does perform some basic checks early to see if the
filename parameter does make sense.  This is useful for safely opening
files for writing.

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `__repr__()`
- `open()`
- `close()`
- `close_intelligently()`
- `__enter__()`
- `__exit__()`
- `__iter__()`

##### KeepOpenFile

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `__enter__()`
- `__exit__()`
- `__repr__()`
- `__iter__()`

##### PacifyFlushWrapper

This wrapper is used to catch and suppress BrokenPipeErrors resulting
from ``.flush()`` being called on broken pipe during the shutdown/final-GC
of the Python interpreter. Notably ``.flush()`` is always called on
``sys.stdout`` and ``sys.stderr``. So as to have minimal impact on any
other cleanup code, and the case where the underlying file is not a broken
pipe, all calls and attributes are proxied.

**M√©thodes :**

- `__init__()`
- `flush()`
- `__getattr__()`

#### Fonctions

##### _posixify

**Param√®tres :**

- `name`

##### safecall

Wraps a function so that it swallows exceptions.

**Param√®tres :**

- `func`

##### make_str

Converts a value into a valid string.

**Param√®tres :**

- `value`

##### make_default_short_help

Returns a condensed version of help string.

**Param√®tres :**

- `help`
- `max_length`

##### echo

Print a message and newline to stdout or a file. This should be
used instead of :func:`print` because it provides better support
for different data, files, and environments.

Compared to :func:`print`, this does the following:

-   Ensures that the output encoding is not misconfigured on Linux.
-   Supports Unicode in the Windows console.
-   Supports writing to binary outputs, and supports writing bytes
    to text outputs.
-   Supports colors and styles on Windows.
-   Removes ANSI color and style codes if the output does not look
    like an interactive terminal.
-   Always flushes the output.

:param message: The string or bytes to output. Other objects are
    converted to strings.
:param file: The file to write to. Defaults to ``stdout``.
:param err: Write to ``stderr`` instead of ``stdout``.
:param nl: Print a newline after the message. Enabled by default.
:param color: Force showing or hiding colors and other styles. By
    default Click will remove color if the output does not look like
    an interactive terminal.

.. versionchanged:: 6.0
    Support Unicode output on the Windows console. Click does not
    modify ``sys.stdout``, so ``sys.stdout.write()`` and ``print()``
    will still not support Unicode.

.. versionchanged:: 4.0
    Added the ``color`` parameter.

.. versionadded:: 3.0
    Added the ``err`` parameter.

.. versionchanged:: 2.0
    Support colors on Windows if colorama is installed.

**Param√®tres :**

- `message`
- `file`
- `nl`
- `err`
- `color`

##### get_binary_stream

Returns a system stream for byte processing.

:param name: the name of the stream to open.  Valid names are ``'stdin'``,
             ``'stdout'`` and ``'stderr'``

**Param√®tres :**

- `name`

##### get_text_stream

Returns a system stream for text processing.  This usually returns
a wrapped stream around a binary stream returned from
:func:`get_binary_stream` but it also can take shortcuts for already
correctly configured streams.

:param name: the name of the stream to open.  Valid names are ``'stdin'``,
             ``'stdout'`` and ``'stderr'``
:param encoding: overrides the detected default encoding.
:param errors: overrides the default error mode.

**Param√®tres :**

- `name`
- `encoding`
- `errors`

##### open_file

Open a file, with extra behavior to handle ``'-'`` to indicate
a standard stream, lazy open on write, and atomic write. Similar to
the behavior of the :class:`~click.File` param type.

If ``'-'`` is given to open ``stdout`` or ``stdin``, the stream is
wrapped so that using it in a context manager will not close it.
This makes it possible to use the function without accidentally
closing a standard stream:

.. code-block:: python

    with open_file(filename) as f:
        ...

:param filename: The name or Path of the file to open, or ``'-'`` for
    ``stdin``/``stdout``.
:param mode: The mode in which to open the file.
:param encoding: The encoding to decode or encode a file opened in
    text mode.
:param errors: The error handling mode.
:param lazy: Wait to open the file until it is accessed. For read
    mode, the file is temporarily opened to raise access errors
    early, then closed until it is read again.
:param atomic: Write to a temporary file and replace the given file
    on close.

.. versionadded:: 3.0

**Param√®tres :**

- `filename`
- `mode`
- `encoding`
- `errors`
- `lazy`
- `atomic`

##### format_filename

Format a filename as a string for display. Ensures the filename can be
displayed by replacing any invalid bytes or surrogate escapes in the name
with the replacement character ``ÔøΩ``.

Invalid bytes or surrogate escapes will raise an error when written to a
stream with ``errors="strict"``. This will typically happen with ``stdout``
when the locale is something like ``en_GB.UTF-8``.

Many scenarios *are* safe to write surrogates though, due to PEP 538 and
PEP 540, including:

-   Writing to ``stderr``, which uses ``errors="backslashreplace"``.
-   The system has ``LANG=C.UTF-8``, ``C``, or ``POSIX``. Python opens
    stdout and stderr with ``errors="surrogateescape"``.
-   None of ``LANG/LC_*`` are set. Python assumes ``LANG=C.UTF-8``.
-   Python is started in UTF-8 mode  with  ``PYTHONUTF8=1`` or ``-X utf8``.
    Python opens stdout and stderr with ``errors="surrogateescape"``.

:param filename: formats a filename for UI display.  This will also convert
                 the filename into unicode without failing.
:param shorten: this optionally shortens the filename to strip of the
                path that leads up to it.

**Param√®tres :**

- `filename`
- `shorten`

##### get_app_dir

Returns the config folder for the application.  The default behavior
is to return whatever is most appropriate for the operating system.

To give you an idea, for an app called ``"Foo Bar"``, something like
the following folders could be returned:

Mac OS X:
  ``~/Library/Application Support/Foo Bar``
Mac OS X (POSIX):
  ``~/.foo-bar``
Unix:
  ``~/.config/foo-bar``
Unix (POSIX):
  ``~/.foo-bar``
Windows (roaming):
  ``C:\Users\<user>\AppData\Roaming\Foo Bar``
Windows (not roaming):
  ``C:\Users\<user>\AppData\Local\Foo Bar``

.. versionadded:: 2.0

:param app_name: the application name.  This should be properly capitalized
                 and can contain whitespace.
:param roaming: controls if the folder should be roaming or not on Windows.
                Has no effect otherwise.
:param force_posix: if this is set to `True` then on any POSIX system the
                    folder will be stored in the home folder with a leading
                    dot instead of the XDG config home or darwin's
                    application support folder.

**Param√®tres :**

- `app_name`
- `roaming`
- `force_posix`

##### _detect_program_name

Determine the command used to run the program, for use in help
text. If a file or entry point was executed, the file name is
returned. If ``python -m`` was used to execute a module or package,
``python -m name`` is returned.

This doesn't try to be too precise, the goal is to give a concise
name for help text. Files are only shown as their name without the
path. ``python`` is only shown for modules, and the full path to
``sys.executable`` is not shown.

:param path: The Python file being executed. Python puts this in
    ``sys.argv[0]``, which is used by default.
:param _main: The ``__main__`` module. This should only be passed
    during internal testing.

.. versionadded:: 8.0
    Based on command args detection in the Werkzeug reloader.

:meta private:

**Param√®tres :**

- `path`
- `_main`

##### _expand_args

Simulate Unix shell expansion with Python functions.

See :func:`glob.glob`, :func:`os.path.expanduser`, and
:func:`os.path.expandvars`.

This is intended for use on Windows, where the shell does not do any
expansion. It may not exactly match what a Unix shell would do.

:param args: List of command line arguments to expand.
:param user: Expand user home directory.
:param env: Expand environment variables.
:param glob_recursive: ``**`` matches directories recursively.

.. versionchanged:: 8.1
    Invalid glob patterns are treated as empty expansions rather
    than raising an error.

.. versionadded:: 8.0

:meta private:

**Param√®tres :**

- `args`

##### wrapper

##### __init__

**Param√®tres :**

- `filename`
- `mode`
- `encoding`
- `errors`
- `atomic`

##### __getattr__

**Param√®tres :**

- `name`

##### __repr__

##### open

Opens the file if it's not yet open.  This call might fail with
a :exc:`FileError`.  Not handling this error will produce an error
that Click shows.

##### close

Closes the underlying file, no matter what.

##### close_intelligently

This function only closes the file if it was opened by the lazy
file wrapper.  For instance this will never close stdin.

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `tb`

##### __iter__

##### __init__

**Param√®tres :**

- `file`

##### __getattr__

**Param√®tres :**

- `name`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `tb`

##### __repr__

##### __iter__

##### __init__

**Param√®tres :**

- `wrapped`

##### flush

##### __getattr__

**Param√®tres :**

- `attr`

---

### .!33823!__init__

---

### .!33826!_compat

---

### .!33830!_termui_impl

---

### .!33834!_textwrap

---

### .!33839!_winconsole

---

### .!33846!decorators

---

### .!33851!exceptions

---

### .!33854!formatting

---

### .!33858!globals

---

### .!33861!parser

---

### .!33867!shell_completion

---

### .!33871!termui

---

### .!33874!testing

---

### .!33879!types

---

### .!33883!utils

---

### .!33891!md

---

### .!33911!api

---

### .!33895!version

---

### .!33900!legacy

---

### .!33904!models

---

### .!33908!__init__

---

### .!33915!utils

---

### .!33922!constant

---

### .!33925!__main__

---

### .!33928!cd

---

### .!33933!__init__

---

### .!33936!__main__

---

### __main__

---

### .!33951!core

---

### core

certifi.py
~~~~~~~~~~

This module returns the installation location of cacert.pem or its contents.

#### Fonctions

##### exit_cacert_ctx

##### where

##### contents

##### where

##### contents

---

### .!33942!__init__

---

### .!33946!__main__

---

### .!33968!func

---

### .!33955!__init__

---

### .!33961!_cached

---

### .!33964!_cachedmethod

---

### .!33972!keys

---

### .!33981!base

---

### .!33976!__init__

---

### .!33978!_utilities

---

### .!33987!_cmp

---

### .!33984!__init__

---

### .!33990!_compat

---

### .!33994!_config

---

### .!33997!_funcs

---

### .!34000!_make

---

### .!34006!_next_gen

---

### .!34010!converters

---

### .!34014!_version_info

---

### .!34017!exceptions

---

### .!34019!filters

---

### .!34022!setters

---

### .!34025!validators

---

### .!34027!__init__

---

### .!34031!converters

---

### .!34034!exceptions

---

### .!34036!filters

---

### .!34039!setters

---

### .!34041!validators

---

### __version__

---

### _internal_utils

requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)

#### Fonctions

##### to_native_string

Given a string object, regardless of type, returns a representation of
that string in the native string type, encoding and decoding where
necessary. This assumes ASCII unless told otherwise.

**Param√®tres :**

- `string`
- `encoding`

##### unicode_is_ascii

Determine if unicode string only contains ASCII characters.

:param str u_string: unicode string to check. Must be unicode
    and not Python 2 `str`.
:rtype: bool

**Param√®tres :**

- `u_string`

---

### adapters

requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.

#### Classes

##### BaseAdapter

The Base Transport Adapter

**M√©thodes :**

- `__init__()`
- `send()`
- `close()`

##### HTTPAdapter

The built-in HTTP Adapter for urllib3.

Provides a general-case interface for Requests sessions to contact HTTP and
HTTPS urls by implementing the Transport Adapter interface. This class will
usually be created by the :class:`Session <Session>` class under the
covers.

:param pool_connections: The number of urllib3 connection pools to cache.
:param pool_maxsize: The maximum number of connections to save in the pool.
:param max_retries: The maximum number of retries each connection
    should attempt. Note, this applies only to failed DNS lookups, socket
    connections and connection timeouts, never to requests where data has
    made it to the server. By default, Requests does not retry failed
    connections. If you need granular control over the conditions under
    which we retry a request, import urllib3's ``Retry`` class and pass
    that instead.
:param pool_block: Whether the connection pool should block for connections.

Usage::

  >>> import requests
  >>> s = requests.Session()
  >>> a = requests.adapters.HTTPAdapter(max_retries=3)
  >>> s.mount('http://', a)

**M√©thodes :**

- `__init__()`
- `__getstate__()`
- `__setstate__()`
- `init_poolmanager()`
- `proxy_manager_for()`
- `cert_verify()`
- `build_response()`
- `build_connection_pool_key_attributes()`
- `get_connection_with_tls_context()`
- `get_connection()`
- `close()`
- `request_url()`
- `add_headers()`
- `proxy_headers()`
- `send()`

#### Fonctions

##### _urllib3_request_context

**Param√®tres :**

- `request`
- `verify`
- `client_cert`
- `poolmanager`

##### __init__

##### send

Sends PreparedRequest object. Returns Response object.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param stream: (optional) Whether to stream the request content.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param verify: (optional) Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use
:param cert: (optional) Any user-provided SSL certificate to be trusted.
:param proxies: (optional) The proxies dictionary to apply to the request.

**Param√®tres :**

- `request`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`

##### close

Cleans up adapter specific items.

##### __init__

**Param√®tres :**

- `pool_connections`
- `pool_maxsize`
- `max_retries`
- `pool_block`

##### __getstate__

##### __setstate__

**Param√®tres :**

- `state`

##### init_poolmanager

Initializes a urllib3 PoolManager.

This method should not be called from user code, and is only
exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param connections: The number of urllib3 connection pools to cache.
:param maxsize: The maximum number of connections to save in the pool.
:param block: Block when no free connections are available.
:param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.

**Param√®tres :**

- `connections`
- `maxsize`
- `block`

##### proxy_manager_for

Return urllib3 ProxyManager for the given proxy.

This method should not be called from user code, and is only
exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param proxy: The proxy to return a urllib3 ProxyManager for.
:param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
:returns: ProxyManager
:rtype: urllib3.ProxyManager

**Param√®tres :**

- `proxy`

##### cert_verify

Verify a SSL certificate. This method should not be called from user
code, and is only exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param conn: The urllib3 connection object associated with the cert.
:param url: The requested URL.
:param verify: Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use
:param cert: The SSL certificate to verify.

**Param√®tres :**

- `conn`
- `url`
- `verify`
- `cert`

##### build_response

Builds a :class:`Response <requests.Response>` object from a urllib3
response. This should not be called from user code, and is only exposed
for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

:param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
:param resp: The urllib3 response object.
:rtype: requests.Response

**Param√®tres :**

- `req`
- `resp`

##### build_connection_pool_key_attributes

Build the PoolKey attributes used by urllib3 to return a connection.

This looks at the PreparedRequest, the user-specified verify value,
and the value of the cert parameter to determine what PoolKey values
to use to select a connection from a given urllib3 Connection Pool.

The SSL related pool key arguments are not consistently set. As of
this writing, use the following to determine what keys may be in that
dictionary:

* If ``verify`` is ``True``, ``"ssl_context"`` will be set and will be the
  default Requests SSL Context
* If ``verify`` is ``False``, ``"ssl_context"`` will not be set but
  ``"cert_reqs"`` will be set
* If ``verify`` is a string, (i.e., it is a user-specified trust bundle)
  ``"ca_certs"`` will be set if the string is not a directory recognized
  by :py:func:`os.path.isdir`, otherwise ``"ca_certs_dir"`` will be
  set.
* If ``"cert"`` is specified, ``"cert_file"`` will always be set. If
  ``"cert"`` is a tuple with a second item, ``"key_file"`` will also
  be present

To override these settings, one may subclass this class, call this
method and use the above logic to change parameters as desired. For
example, if one wishes to use a custom :py:class:`ssl.SSLContext` one
must both set ``"ssl_context"`` and based on what else they require,
alter the other keys to ensure the desired behaviour.

:param request:
    The PreparedReqest being sent over the connection.
:type request:
    :class:`~requests.models.PreparedRequest`
:param verify:
    Either a boolean, in which case it controls whether
    we verify the server's TLS certificate, or a string, in which case it
    must be a path to a CA bundle to use.
:param cert:
    (optional) Any user-provided SSL certificate for client
    authentication (a.k.a., mTLS). This may be a string (i.e., just
    the path to a file which holds both certificate and key) or a
    tuple of length 2 with the certificate file path and key file
    path.
:returns:
    A tuple of two dictionaries. The first is the "host parameters"
    portion of the Pool Key including scheme, hostname, and port. The
    second is a dictionary of SSLContext related parameters.

**Param√®tres :**

- `request`
- `verify`
- `cert`

##### get_connection_with_tls_context

Returns a urllib3 connection for the given request and TLS settings.
This should not be called from user code, and is only exposed for use
when subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request:
    The :class:`PreparedRequest <PreparedRequest>` object to be sent
    over the connection.
:param verify:
    Either a boolean, in which case it controls whether we verify the
    server's TLS certificate, or a string, in which case it must be a
    path to a CA bundle to use.
:param proxies:
    (optional) The proxies dictionary to apply to the request.
:param cert:
    (optional) Any user-provided SSL certificate to be used for client
    authentication (a.k.a., mTLS).
:rtype:
    urllib3.ConnectionPool

**Param√®tres :**

- `request`
- `verify`
- `proxies`
- `cert`

##### get_connection

DEPRECATED: Users should move to `get_connection_with_tls_context`
for all subclasses of HTTPAdapter using Requests>=2.32.2.

Returns a urllib3 connection for the given URL. This should not be
called from user code, and is only exposed for use when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param url: The URL to connect to.
:param proxies: (optional) A Requests-style dictionary of proxies used on this request.
:rtype: urllib3.ConnectionPool

**Param√®tres :**

- `url`
- `proxies`

##### close

Disposes of any internal state.

Currently, this closes the PoolManager and any active ProxyManager,
which closes any pooled connections.

##### request_url

Obtain the url to use when making the final request.

If the message is being sent through a HTTP proxy, the full URL has to
be used. Otherwise, we should only use the path portion of the URL.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
:rtype: str

**Param√®tres :**

- `request`
- `proxies`

##### add_headers

Add any headers needed by the connection. As of v2.0 this does
nothing by default, but is left for overriding by users that subclass
the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
:param kwargs: The keyword arguments from the call to send().

**Param√®tres :**

- `request`

##### proxy_headers

Returns a dictionary of the headers to add to any request sent
through a proxy. This works with urllib3 magic to ensure that they are
correctly sent to the proxy, rather than in a tunnelled request if
CONNECT is being used.

This should not be called from user code, and is only exposed for use
when subclassing the
:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

:param proxy: The url of the proxy being used for this request.
:rtype: dict

**Param√®tres :**

- `proxy`

##### send

Sends PreparedRequest object. Returns Response object.

:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
:param stream: (optional) Whether to stream the request content.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple or urllib3 Timeout object
:param verify: (optional) Either a boolean, in which case it controls whether
    we verify the server's TLS certificate, or a string, in which case it
    must be a path to a CA bundle to use
:param cert: (optional) Any user-provided SSL certificate to be trusted.
:param proxies: (optional) The proxies dictionary to apply to the request.
:rtype: requests.Response

**Param√®tres :**

- `request`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`

##### SOCKSProxyManager

---

### api

requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.

#### Fonctions

##### request

Constructs and sends a :class:`Request <Request>`.

:param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
    in the query string for the :class:`Request`.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
:param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
:param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
    ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
    or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string
    defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
    to add for the file.
:param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
:param timeout: (optional) How many seconds to wait for the server to send data
    before giving up, as a float, or a :ref:`(connect timeout, read
    timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
:type allow_redirects: bool
:param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
:param verify: (optional) Either a boolean, in which case it controls whether we verify
        the server's TLS certificate, or a string, in which case it must be a path
        to a CA bundle to use. Defaults to ``True``.
:param stream: (optional) if ``False``, the response content will be immediately downloaded.
:param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
:return: :class:`Response <Response>` object
:rtype: requests.Response

Usage::

  >>> import requests
  >>> req = requests.request('GET', 'https://httpbin.org/get')
  >>> req
  <Response [200]>

**Param√®tres :**

- `method`
- `url`

##### get

Sends a GET request.

:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary, list of tuples or bytes to send
    in the query string for the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `params`

##### options

Sends an OPTIONS request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`

##### head

Sends a HEAD request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes. If
    `allow_redirects` is not provided, it will be set to `False` (as
    opposed to the default :meth:`request` behavior).
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`

##### post

Sends a POST request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`
- `json`

##### put

Sends a PUT request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### patch

Sends a PATCH request.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### delete

Sends a DELETE request.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:return: :class:`Response <Response>` object
:rtype: requests.Response

**Param√®tres :**

- `url`

---

### auth

requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.

#### Classes

##### AuthBase

Base class that all auth implementations derive from

**M√©thodes :**

- `__call__()`

##### HTTPBasicAuth

Attaches HTTP Basic Authentication to the given Request object.

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `__ne__()`
- `__call__()`

##### HTTPProxyAuth

Attaches HTTP Proxy Authentication to a given Request object.

**M√©thodes :**

- `__call__()`

##### HTTPDigestAuth

Attaches HTTP Digest Authentication to the given Request object.

**M√©thodes :**

- `__init__()`
- `init_per_thread_state()`
- `build_digest_header()`
- `handle_redirect()`
- `handle_401()`
- `__call__()`
- `__eq__()`
- `__ne__()`

#### Fonctions

##### _basic_auth_str

Returns a Basic Auth string.

**Param√®tres :**

- `username`
- `password`

##### __call__

**Param√®tres :**

- `r`

##### __init__

**Param√®tres :**

- `username`
- `password`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __call__

**Param√®tres :**

- `r`

##### __call__

**Param√®tres :**

- `r`

##### __init__

**Param√®tres :**

- `username`
- `password`

##### init_per_thread_state

##### build_digest_header

:rtype: str

**Param√®tres :**

- `method`
- `url`

##### handle_redirect

Reset num_401_calls counter on redirects.

**Param√®tres :**

- `r`

##### handle_401

Takes the given response and tries digest-auth, if needed.

:rtype: requests.Response

**Param√®tres :**

- `r`

##### __call__

**Param√®tres :**

- `r`

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### md5_utf8

**Param√®tres :**

- `x`

##### sha_utf8

**Param√®tres :**

- `x`

##### sha256_utf8

**Param√®tres :**

- `x`

##### sha512_utf8

**Param√®tres :**

- `x`

---

### .!34058!api

---

### .!34062!auth

---

### certs

requests.certs
~~~~~~~~~~~~~~

This module returns the preferred default CA certificate bundle. There is
only one ‚Äî the one from the certifi package.

If you are packaging Requests, e.g., for a Linux distribution or a managed
environment, you can change the definition of where() to return a separately
packaged CA bundle.

---

### .!34076!help

---

### compat

requests.compat
~~~~~~~~~~~~~~~

This module previously handled import compatibility issues
between Python 2 and Python 3. It remains for backwards
compatibility until the next major version.

#### Fonctions

##### _resolve_char_detection

Find supported character detection libraries.

---

### cookies

requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `http.cookiejar.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.

#### Classes

##### MockRequest

Wraps a `requests.Request` to mimic a `urllib2.Request`.

The code in `http.cookiejar.CookieJar` expects this interface in order to correctly
manage cookie policies, i.e., determine whether a cookie can be set, given the
domains of the request and the cookie.

The original request object is read-only. The client is responsible for collecting
the new headers via `get_new_headers()` and interpreting them appropriately. You
probably want `get_cookie_header`, defined below.

**M√©thodes :**

- `__init__()`
- `get_type()`
- `get_host()`
- `get_origin_req_host()`
- `get_full_url()`
- `is_unverifiable()`
- `has_header()`
- `get_header()`
- `add_header()`
- `add_unredirected_header()`
- `get_new_headers()`
- `unverifiable()`
- `origin_req_host()`
- `host()`

##### MockResponse

Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

...what? Basically, expose the parsed HTTP headers from the server response
the way `http.cookiejar` expects to see them.

**M√©thodes :**

- `__init__()`
- `info()`
- `getheaders()`

##### CookieConflictError

There are two cookies that meet the criteria specified in the cookie jar.
Use .get and .set and include domain and path args in order to be more specific.

##### RequestsCookieJar

Compatibility class; is a http.cookiejar.CookieJar, but exposes a dict
interface.

This is the CookieJar we create by default for requests and sessions that
don't specify one, since some clients may expect response.cookies and
session.cookies to support dict operations.

Requests does not use the dict interface internally; it's just for
compatibility with external client code. All requests code should work
out of the box with externally provided instances of ``CookieJar``, e.g.
``LWPCookieJar`` and ``FileCookieJar``.

Unlike a regular CookieJar, this class is pickleable.

.. warning:: dictionary operations that are normally O(1) may be O(n).

**M√©thodes :**

- `get()`
- `set()`
- `iterkeys()`
- `keys()`
- `itervalues()`
- `values()`
- `iteritems()`
- `items()`
- `list_domains()`
- `list_paths()`
- `multiple_domains()`
- `get_dict()`
- `__contains__()`
- `__getitem__()`
- `__setitem__()`
- `__delitem__()`
- `set_cookie()`
- `update()`
- `_find()`
- `_find_no_duplicates()`
- `__getstate__()`
- `__setstate__()`
- `copy()`
- `get_policy()`

#### Fonctions

##### extract_cookies_to_jar

Extract the cookies from the response into a CookieJar.

:param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)
:param request: our own requests.Request object
:param response: urllib3.HTTPResponse object

**Param√®tres :**

- `jar`
- `request`
- `response`

##### get_cookie_header

Produce an appropriate Cookie header string to be sent with `request`, or None.

:rtype: str

**Param√®tres :**

- `jar`
- `request`

##### remove_cookie_by_name

Unsets a cookie by name, by default over all domains and paths.

Wraps CookieJar.clear(), is O(n).

**Param√®tres :**

- `cookiejar`
- `name`
- `domain`
- `path`

##### _copy_cookie_jar

**Param√®tres :**

- `jar`

##### create_cookie

Make a cookie from underspecified parameters.

By default, the pair of `name` and `value` will be set for the domain ''
and sent on every request (this is sometimes called a "supercookie").

**Param√®tres :**

- `name`
- `value`

##### morsel_to_cookie

Convert a Morsel object into a Cookie containing the one k/v pair.

**Param√®tres :**

- `morsel`

##### cookiejar_from_dict

Returns a CookieJar from a key/value dictionary.

:param cookie_dict: Dict of key/values to insert into CookieJar.
:param cookiejar: (optional) A cookiejar to add the cookies to.
:param overwrite: (optional) If False, will not replace cookies
    already in the jar with new ones.
:rtype: CookieJar

**Param√®tres :**

- `cookie_dict`
- `cookiejar`
- `overwrite`

##### merge_cookies

Add cookies to cookiejar and returns a merged CookieJar.

:param cookiejar: CookieJar object to add the cookies to.
:param cookies: Dictionary or CookieJar object to be added.
:rtype: CookieJar

**Param√®tres :**

- `cookiejar`
- `cookies`

##### __init__

**Param√®tres :**

- `request`

##### get_type

##### get_host

##### get_origin_req_host

##### get_full_url

##### is_unverifiable

##### has_header

**Param√®tres :**

- `name`

##### get_header

**Param√®tres :**

- `name`
- `default`

##### add_header

cookiejar has no legitimate use for this method; add it back if you find one.

**Param√®tres :**

- `key`
- `val`

##### add_unredirected_header

**Param√®tres :**

- `name`
- `value`

##### get_new_headers

##### unverifiable

##### origin_req_host

##### host

##### __init__

Make a MockResponse for `cookiejar` to read.

:param headers: a httplib.HTTPMessage or analogous carrying the headers

**Param√®tres :**

- `headers`

##### info

##### getheaders

**Param√®tres :**

- `name`

##### get

Dict-like get() that also supports optional domain and path args in
order to resolve naming collisions from using one cookie jar over
multiple domains.

.. warning:: operation is O(n), not O(1).

**Param√®tres :**

- `name`
- `default`
- `domain`
- `path`

##### set

Dict-like set() that also supports optional domain and path args in
order to resolve naming collisions from using one cookie jar over
multiple domains.

**Param√®tres :**

- `name`
- `value`

##### iterkeys

Dict-like iterkeys() that returns an iterator of names of cookies
from the jar.

.. seealso:: itervalues() and iteritems().

##### keys

Dict-like keys() that returns a list of names of cookies from the
jar.

.. seealso:: values() and items().

##### itervalues

Dict-like itervalues() that returns an iterator of values of cookies
from the jar.

.. seealso:: iterkeys() and iteritems().

##### values

Dict-like values() that returns a list of values of cookies from the
jar.

.. seealso:: keys() and items().

##### iteritems

Dict-like iteritems() that returns an iterator of name-value tuples
from the jar.

.. seealso:: iterkeys() and itervalues().

##### items

Dict-like items() that returns a list of name-value tuples from the
jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
vanilla python dict of key value pairs.

.. seealso:: keys() and values().

##### list_domains

Utility method to list all the domains in the jar.

##### list_paths

Utility method to list all the paths in the jar.

##### multiple_domains

Returns True if there are multiple domains in the jar.
Returns False otherwise.

:rtype: bool

##### get_dict

Takes as an argument an optional domain and path and returns a plain
old Python dict of name-value pairs of cookies that meet the
requirements.

:rtype: dict

**Param√®tres :**

- `domain`
- `path`

##### __contains__

**Param√®tres :**

- `name`

##### __getitem__

Dict-like __getitem__() for compatibility with client code. Throws
exception if there are more than one cookie with name. In that case,
use the more explicit get() method instead.

.. warning:: operation is O(n), not O(1).

**Param√®tres :**

- `name`

##### __setitem__

Dict-like __setitem__ for compatibility with client code. Throws
exception if there is already a cookie of that name in the jar. In that
case, use the more explicit set() method instead.

**Param√®tres :**

- `name`
- `value`

##### __delitem__

Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s
``remove_cookie_by_name()``.

**Param√®tres :**

- `name`

##### set_cookie

**Param√®tres :**

- `cookie`

##### update

Updates this jar with cookies from another CookieJar or dict-like

**Param√®tres :**

- `other`

##### _find

Requests uses this method internally to get cookie values.

If there are conflicting cookies, _find arbitrarily chooses one.
See _find_no_duplicates if you want an exception thrown if there are
conflicting cookies.

:param name: a string containing name of cookie
:param domain: (optional) string containing domain of cookie
:param path: (optional) string containing path of cookie
:return: cookie.value

**Param√®tres :**

- `name`
- `domain`
- `path`

##### _find_no_duplicates

Both ``__get_item__`` and ``get`` call this function: it's never
used elsewhere in Requests.

:param name: a string containing name of cookie
:param domain: (optional) string containing domain of cookie
:param path: (optional) string containing path of cookie
:raises KeyError: if cookie is not found
:raises CookieConflictError: if there are multiple cookies
    that match name and optionally domain and path
:return: cookie.value

**Param√®tres :**

- `name`
- `domain`
- `path`

##### __getstate__

Unlike a normal CookieJar, this class is pickleable.

##### __setstate__

Unlike a normal CookieJar, this class is pickleable.

**Param√®tres :**

- `state`

##### copy

Return a copy of this RequestsCookieJar.

##### get_policy

Return the CookiePolicy instance used.

---

### exceptions

requests.exceptions
~~~~~~~~~~~~~~~~~~~

This module contains the set of Requests' exceptions.

#### Classes

##### RequestException

There was an ambiguous exception that occurred while handling your
request.

**M√©thodes :**

- `__init__()`

##### InvalidJSONError

A JSON error occurred.

##### JSONDecodeError

Couldn't decode the text into json

**M√©thodes :**

- `__init__()`
- `__reduce__()`

##### HTTPError

An HTTP error occurred.

##### ConnectionError

A Connection error occurred.

##### ProxyError

A proxy error occurred.

##### SSLError

An SSL error occurred.

##### Timeout

The request timed out.

Catching this error will catch both
:exc:`~requests.exceptions.ConnectTimeout` and
:exc:`~requests.exceptions.ReadTimeout` errors.

##### ConnectTimeout

The request timed out while trying to connect to the remote server.

Requests that produced this error are safe to retry.

##### ReadTimeout

The server did not send any data in the allotted amount of time.

##### URLRequired

A valid URL is required to make a request.

##### TooManyRedirects

Too many redirects.

##### MissingSchema

The URL scheme (e.g. http or https) is missing.

##### InvalidSchema

The URL scheme provided is either invalid or unsupported.

##### InvalidURL

The URL provided was somehow invalid.

##### InvalidHeader

The header value provided was somehow invalid.

##### InvalidProxyURL

The proxy URL provided is invalid.

##### ChunkedEncodingError

The server declared chunked encoding but sent an invalid chunk.

##### ContentDecodingError

Failed to decode response content.

##### StreamConsumedError

The content for this response was already consumed.

##### RetryError

Custom retries logic failed

##### UnrewindableBodyError

Requests encountered an error when trying to rewind a body.

##### RequestsWarning

Base warning for Requests.

##### FileModeWarning

A file was opened in text mode, but Requests determined its binary length.

##### RequestsDependencyWarning

An imported dependency doesn't match the expected version range.

#### Fonctions

##### __init__

Initialize RequestException with `request` and `response` objects.

##### __init__

Construct the JSONDecodeError instance first with all
args. Then use it's args to construct the IOError so that
the json specific args aren't used as IOError specific args
and the error message from JSONDecodeError is preserved.

##### __reduce__

The __reduce__ method called when pickling the object must
be the one from the JSONDecodeError (be it json/simplejson)
as it expects all the arguments for instantiation, not just
one like the IOError, and the MRO would by default call the
__reduce__ method from the IOError due to the inheritance order.

---

### help

Module containing bug report helper(s).

#### Fonctions

##### _implementation

Return a dict with the Python implementation and version.

Provide both the name and the version of the Python implementation
currently running. For example, on CPython 3.10.3 it will return
{'name': 'CPython', 'version': '3.10.3'}.

This function works best on CPython and PyPy: in particular, it probably
doesn't work for Jython or IronPython. Future investigation should be done
to work out the correct shape of the code for those platforms.

##### info

Generate information for a bug report.

##### main

Pretty-print the bug information as JSON.

---

### hooks

requests.hooks
~~~~~~~~~~~~~~

This module provides the capabilities for the Requests hooks system.

Available hooks:

``response``:
    The response generated from a Request.

#### Fonctions

##### default_hooks

##### dispatch_hook

Dispatches a hook dictionary on a given piece of data.

**Param√®tres :**

- `key`
- `hooks`
- `hook_data`

---

### models

requests.models
~~~~~~~~~~~~~~~

This module contains the primary objects that power Requests.

#### Classes

##### RequestEncodingMixin

**M√©thodes :**

- `path_url()`
- `_encode_params()`
- `_encode_files()`

##### RequestHooksMixin

**M√©thodes :**

- `register_hook()`
- `deregister_hook()`

##### Request

A user-created :class:`Request <Request>` object.

Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.

:param method: HTTP method to use.
:param url: URL to send.
:param headers: dictionary of headers to send.
:param files: dictionary of {filename: fileobject} files to multipart upload.
:param data: the body to attach to the request. If a dictionary or
    list of tuples ``[(key, value)]`` is provided, form-encoding will
    take place.
:param json: json for the body to attach to the request (if files or data is not specified).
:param params: URL parameters to append to the URL. If a dictionary or
    list of tuples ``[(key, value)]`` is provided, form-encoding will
    take place.
:param auth: Auth handler or (user, pass) tuple.
:param cookies: dictionary or CookieJar of cookies to attach to this request.
:param hooks: dictionary of callback hooks, for internal usage.

Usage::

  >>> import requests
  >>> req = requests.Request('GET', 'https://httpbin.org/get')
  >>> req.prepare()
  <PreparedRequest [GET]>

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `prepare()`

##### PreparedRequest

The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
containing the exact bytes that will be sent to the server.

Instances are generated from a :class:`Request <Request>` object, and
should not be instantiated manually; doing so may produce undesirable
effects.

Usage::

  >>> import requests
  >>> req = requests.Request('GET', 'https://httpbin.org/get')
  >>> r = req.prepare()
  >>> r
  <PreparedRequest [GET]>

  >>> s = requests.Session()
  >>> s.send(r)
  <Response [200]>

**M√©thodes :**

- `__init__()`
- `prepare()`
- `__repr__()`
- `copy()`
- `prepare_method()`
- `_get_idna_encoded_host()`
- `prepare_url()`
- `prepare_headers()`
- `prepare_body()`
- `prepare_content_length()`
- `prepare_auth()`
- `prepare_cookies()`
- `prepare_hooks()`

##### Response

The :class:`Response <Response>` object, which contains a
server's response to an HTTP request.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `__getstate__()`
- `__setstate__()`
- `__repr__()`
- `__bool__()`
- `__nonzero__()`
- `__iter__()`
- `ok()`
- `is_redirect()`
- `is_permanent_redirect()`
- `next()`
- `apparent_encoding()`
- `iter_content()`
- `iter_lines()`
- `content()`
- `text()`
- `json()`
- `links()`
- `raise_for_status()`
- `close()`

#### Fonctions

##### path_url

Build the path URL to use.

##### _encode_params

Encode parameters in a piece of data.

Will successfully encode parameters when passed as a dict or a list of
2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
if parameters are supplied as a dict.

**Param√®tres :**

- `data`

##### _encode_files

Build the body for a multipart/form-data request.

Will successfully encode files when passed as a dict or a list of
tuples. Order is retained if data is a list of tuples but arbitrary
if parameters are supplied as a dict.
The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
or 4-tuples (filename, fileobj, contentype, custom_headers).

**Param√®tres :**

- `files`
- `data`

##### register_hook

Properly register a hook.

**Param√®tres :**

- `event`
- `hook`

##### deregister_hook

Deregister a previously registered hook.
Returns True if the hook existed, False if not.

**Param√®tres :**

- `event`
- `hook`

##### __init__

**Param√®tres :**

- `method`
- `url`
- `headers`
- `files`
- `data`
- `params`
- `auth`
- `cookies`
- `hooks`
- `json`

##### __repr__

##### prepare

Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.

##### __init__

##### prepare

Prepares the entire request with the given parameters.

**Param√®tres :**

- `method`
- `url`
- `headers`
- `files`
- `data`
- `params`
- `auth`
- `cookies`
- `hooks`
- `json`

##### __repr__

##### copy

##### prepare_method

Prepares the given HTTP method.

**Param√®tres :**

- `method`

##### _get_idna_encoded_host

**Param√®tres :**

- `host`

##### prepare_url

Prepares the given HTTP URL.

**Param√®tres :**

- `url`
- `params`

##### prepare_headers

Prepares the given HTTP headers.

**Param√®tres :**

- `headers`

##### prepare_body

Prepares the given HTTP body data.

**Param√®tres :**

- `data`
- `files`
- `json`

##### prepare_content_length

Prepare Content-Length header based on request method and body

**Param√®tres :**

- `body`

##### prepare_auth

Prepares the given HTTP auth data.

**Param√®tres :**

- `auth`
- `url`

##### prepare_cookies

Prepares the given HTTP cookie data.

This function eventually generates a ``Cookie`` header from the
given cookies using cookielib. Due to cookielib's design, the header
will not be regenerated if it already exists, meaning this function
can only be called once for the life of the
:class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
header is removed beforehand.

**Param√®tres :**

- `cookies`

##### prepare_hooks

Prepares the given hooks.

**Param√®tres :**

- `hooks`

##### __init__

##### __enter__

##### __exit__

##### __getstate__

##### __setstate__

**Param√®tres :**

- `state`

##### __repr__

##### __bool__

Returns True if :attr:`status_code` is less than 400.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code, is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``.

##### __nonzero__

Returns True if :attr:`status_code` is less than 400.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code, is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``.

##### __iter__

Allows you to use a response as an iterator.

##### ok

Returns True if :attr:`status_code` is less than 400, False if not.

This attribute checks if the status code of the response is between
400 and 600 to see if there was a client error or a server error. If
the status code is between 200 and 400, this will return True. This
is **not** a check to see if the response code is ``200 OK``.

##### is_redirect

True if this Response is a well-formed HTTP redirect that could have
been processed automatically (by :meth:`Session.resolve_redirects`).

##### is_permanent_redirect

True if this Response one of the permanent versions of redirect.

##### next

Returns a PreparedRequest for the next request in a redirect chain, if there is one.

##### apparent_encoding

The apparent encoding, provided by the charset_normalizer or chardet libraries.

##### iter_content

Iterates over the response data.  When stream=True is set on the
request, this avoids reading the content at once into memory for
large responses.  The chunk size is the number of bytes it should
read into memory.  This is not necessarily the length of each item
returned as decoding can take place.

chunk_size must be of type int or None. A value of None will
function differently depending on the value of `stream`.
stream=True will read data as it arrives in whatever size the
chunks are received. If stream=False, data is returned as
a single chunk.

If decode_unicode is True, content will be decoded using the best
available encoding based on the response.

**Param√®tres :**

- `chunk_size`
- `decode_unicode`

##### iter_lines

Iterates over the response data, one line at a time.  When
stream=True is set on the request, this avoids reading the
content at once into memory for large responses.

.. note:: This method is not reentrant safe.

**Param√®tres :**

- `chunk_size`
- `decode_unicode`
- `delimiter`

##### content

Content of the response, in bytes.

##### text

Content of the response, in unicode.

If Response.encoding is None, encoding will be guessed using
``charset_normalizer`` or ``chardet``.

The encoding of the response content is determined based solely on HTTP
headers, following RFC 2616 to the letter. If you can take advantage of
non-HTTP knowledge to make a better guess at the encoding, you should
set ``r.encoding`` appropriately before accessing this property.

##### json

Decodes the JSON response body (if any) as a Python object.

This may return a dictionary, list, etc. depending on what is in the response.

:param \*\*kwargs: Optional arguments that ``json.loads`` takes.
:raises requests.exceptions.JSONDecodeError: If the response body does not
    contain valid json.

##### links

Returns the parsed header links of the response, if any.

##### raise_for_status

Raises :class:`HTTPError`, if one occurred.

##### close

Releases the connection back to the pool. Once this method has been
called the underlying ``raw`` object must not be accessed again.

*Note: Should not normally need to be called explicitly.*

##### generate

---

### packages

---

### sessions

requests.sessions
~~~~~~~~~~~~~~~~~

This module provides a Session object to manage and persist settings across
requests (cookies, auth, proxies).

#### Classes

##### SessionRedirectMixin

**M√©thodes :**

- `get_redirect_target()`
- `should_strip_auth()`
- `resolve_redirects()`
- `rebuild_auth()`
- `rebuild_proxies()`
- `rebuild_method()`

##### Session

A Requests session.

Provides cookie persistence, connection-pooling, and configuration.

Basic Usage::

  >>> import requests
  >>> s = requests.Session()
  >>> s.get('https://httpbin.org/get')
  <Response [200]>

Or as a context manager::

  >>> with requests.Session() as s:
  ...     s.get('https://httpbin.org/get')
  <Response [200]>

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `prepare_request()`
- `request()`
- `get()`
- `options()`
- `head()`
- `post()`
- `put()`
- `patch()`
- `delete()`
- `send()`
- `merge_environment_settings()`
- `get_adapter()`
- `close()`
- `mount()`
- `__getstate__()`
- `__setstate__()`

#### Fonctions

##### merge_setting

Determines appropriate setting for a given request, taking into account
the explicit setting on that request, and the setting in the session. If a
setting is a dictionary, they will be merged together using `dict_class`

**Param√®tres :**

- `request_setting`
- `session_setting`
- `dict_class`

##### merge_hooks

Properly merges both requests and session hooks.

This is necessary because when request_hooks == {'response': []}, the
merge breaks Session hooks entirely.

**Param√®tres :**

- `request_hooks`
- `session_hooks`
- `dict_class`

##### session

Returns a :class:`Session` for context-management.

.. deprecated:: 1.0.0

    This method has been deprecated since version 1.0.0 and is only kept for
    backwards compatibility. New code should use :class:`~requests.sessions.Session`
    to create a session. This may be removed at a future date.

:rtype: Session

##### get_redirect_target

Receives a Response. Returns a redirect URI or ``None``

**Param√®tres :**

- `resp`

##### should_strip_auth

Decide whether Authorization header should be removed when redirecting

**Param√®tres :**

- `old_url`
- `new_url`

##### resolve_redirects

Receives a Response. Returns a generator of Responses or Requests.

**Param√®tres :**

- `resp`
- `req`
- `stream`
- `timeout`
- `verify`
- `cert`
- `proxies`
- `yield_requests`

##### rebuild_auth

When being redirected we may want to strip authentication from the
request to avoid leaking credentials. This method intelligently removes
and reapplies authentication where possible to avoid credential loss.

**Param√®tres :**

- `prepared_request`
- `response`

##### rebuild_proxies

This method re-evaluates the proxy configuration by considering the
environment variables. If we are redirected to a URL covered by
NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
proxy keys for this URL (in case they were stripped by a previous
redirect).

This method also replaces the Proxy-Authorization header where
necessary.

:rtype: dict

**Param√®tres :**

- `prepared_request`
- `proxies`

##### rebuild_method

When being redirected we may want to change the method of the request
based on certain specs or browser behavior.

**Param√®tres :**

- `prepared_request`
- `response`

##### __init__

##### __enter__

##### __exit__

##### prepare_request

Constructs a :class:`PreparedRequest <PreparedRequest>` for
transmission and returns it. The :class:`PreparedRequest` has settings
merged from the :class:`Request <Request>` instance and those of the
:class:`Session`.

:param request: :class:`Request` instance to prepare with this
    session's settings.
:rtype: requests.PreparedRequest

**Param√®tres :**

- `request`

##### request

Constructs a :class:`Request <Request>`, prepares it and sends it.
Returns :class:`Response <Response>` object.

:param method: method for the new :class:`Request` object.
:param url: URL for the new :class:`Request` object.
:param params: (optional) Dictionary or bytes to be sent in the query
    string for the :class:`Request`.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) json to send in the body of the
    :class:`Request`.
:param headers: (optional) Dictionary of HTTP Headers to send with the
    :class:`Request`.
:param cookies: (optional) Dict or CookieJar object to send with the
    :class:`Request`.
:param files: (optional) Dictionary of ``'filename': file-like-objects``
    for multipart encoding upload.
:param auth: (optional) Auth tuple or callable to enable
    Basic/Digest/Custom HTTP Auth.
:param timeout: (optional) How long to wait for the server to send
    data before giving up, as a float, or a :ref:`(connect timeout,
    read timeout) <timeouts>` tuple.
:type timeout: float or tuple
:param allow_redirects: (optional) Set to True by default.
:type allow_redirects: bool
:param proxies: (optional) Dictionary mapping protocol or protocol and
    hostname to the URL of the proxy.
:param hooks: (optional) Dictionary mapping hook name to one event or
    list of events, event must be callable.
:param stream: (optional) whether to immediately download the response
    content. Defaults to ``False``.
:param verify: (optional) Either a boolean, in which case it controls whether we verify
    the server's TLS certificate, or a string, in which case it must be a path
    to a CA bundle to use. Defaults to ``True``. When set to
    ``False``, requests will accept any TLS certificate presented by
    the server, and will ignore hostname mismatches and/or expired
    certificates, which will make your application vulnerable to
    man-in-the-middle (MitM) attacks. Setting verify to ``False``
    may be useful during local development or testing.
:param cert: (optional) if String, path to ssl client cert file (.pem).
    If Tuple, ('cert', 'key') pair.
:rtype: requests.Response

**Param√®tres :**

- `method`
- `url`
- `params`
- `data`
- `headers`
- `cookies`
- `files`
- `auth`
- `timeout`
- `allow_redirects`
- `proxies`
- `hooks`
- `stream`
- `verify`
- `cert`
- `json`

##### get

Sends a GET request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### options

Sends a OPTIONS request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### head

Sends a HEAD request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### post

Sends a POST request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param json: (optional) json to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`
- `json`

##### put

Sends a PUT request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### patch

Sends a PATCH request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param data: (optional) Dictionary, list of tuples, bytes, or file-like
    object to send in the body of the :class:`Request`.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`
- `data`

##### delete

Sends a DELETE request. Returns :class:`Response` object.

:param url: URL for the new :class:`Request` object.
:param \*\*kwargs: Optional arguments that ``request`` takes.
:rtype: requests.Response

**Param√®tres :**

- `url`

##### send

Send a given PreparedRequest.

:rtype: requests.Response

**Param√®tres :**

- `request`

##### merge_environment_settings

Check the environment and merge it with some settings.

:rtype: dict

**Param√®tres :**

- `url`
- `proxies`
- `stream`
- `verify`
- `cert`

##### get_adapter

Returns the appropriate connection adapter for the given URL.

:rtype: requests.adapters.BaseAdapter

**Param√®tres :**

- `url`

##### close

Closes all adapters and as such the session

##### mount

Registers a connection adapter to a prefix.

Adapters are sorted in descending order by prefix length.

**Param√®tres :**

- `prefix`
- `adapter`

##### __getstate__

##### __setstate__

**Param√®tres :**

- `state`

---

### status_codes

The ``codes`` object defines a mapping from common names for HTTP statuses
to their numerical codes, accessible either as attributes or as dictionary
items.

Example::

    >>> import requests
    >>> requests.codes['temporary_redirect']
    307
    >>> requests.codes.teapot
    418
    >>> requests.codes['\o/']
    200

Some codes have multiple names, and both upper- and lower-case versions of
the names are allowed. For example, ``codes.ok``, ``codes.OK``, and
``codes.okay`` all correspond to the HTTP status code 200.

#### Fonctions

##### _init

##### doc

**Param√®tres :**

- `code`

---

### structures

requests.structures
~~~~~~~~~~~~~~~~~~~

Data structures that power Requests.

#### Classes

##### CaseInsensitiveDict

A case-insensitive ``dict``-like object.

Implements all methods and operations of
``MutableMapping`` as well as dict's ``copy``. Also
provides ``lower_items``.

All keys are expected to be strings. The structure remembers the
case of the last key to be set, and ``iter(instance)``,
``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``
will contain case-sensitive keys. However, querying and contains
testing is case insensitive::

    cid = CaseInsensitiveDict()
    cid['Accept'] = 'application/json'
    cid['aCCEPT'] == 'application/json'  # True
    list(cid) == ['Accept']  # True

For example, ``headers['content-encoding']`` will return the
value of a ``'Content-Encoding'`` response header, regardless
of how the header name was originally stored.

If the constructor, ``.update``, or equality comparison
operations are given keys that have equal ``.lower()``s, the
behavior is undefined.

**M√©thodes :**

- `__init__()`
- `__setitem__()`
- `__getitem__()`
- `__delitem__()`
- `__iter__()`
- `__len__()`
- `lower_items()`
- `__eq__()`
- `copy()`
- `__repr__()`

##### LookupDict

Dictionary lookup object.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__getitem__()`
- `get()`

#### Fonctions

##### __init__

**Param√®tres :**

- `data`

##### __setitem__

**Param√®tres :**

- `key`
- `value`

##### __getitem__

**Param√®tres :**

- `key`

##### __delitem__

**Param√®tres :**

- `key`

##### __iter__

##### __len__

##### lower_items

Like iteritems(), but with all lowercase keys.

##### __eq__

**Param√®tres :**

- `other`

##### copy

##### __repr__

##### __init__

**Param√®tres :**

- `name`

##### __repr__

##### __getitem__

**Param√®tres :**

- `key`

##### get

**Param√®tres :**

- `key`
- `default`

---

### utils

requests.utils
~~~~~~~~~~~~~~

This module provides utility functions that are used within Requests
that are also useful for external consumption.

#### Fonctions

##### dict_to_sequence

Returns an internal sequence dictionary update.

**Param√®tres :**

- `d`

##### super_len

**Param√®tres :**

- `o`

##### get_netrc_auth

Returns the Requests tuple auth for a given url from netrc.

**Param√®tres :**

- `url`
- `raise_errors`

##### guess_filename

Tries to guess the filename of the given object.

**Param√®tres :**

- `obj`

##### extract_zipped_paths

Replace nonexistent paths that look like they refer to a member of a zip
archive with the location of an extracted copy of the target, or else
just return the provided path unchanged.

**Param√®tres :**

- `path`

##### atomic_open

Write a file to the disk in an atomic fashion

**Param√®tres :**

- `filename`

##### from_key_val_list

Take an object and test to see if it can be represented as a
dictionary. Unless it can not be represented as such, return an
OrderedDict, e.g.,

::

    >>> from_key_val_list([('key', 'val')])
    OrderedDict([('key', 'val')])
    >>> from_key_val_list('string')
    Traceback (most recent call last):
    ...
    ValueError: cannot encode objects that are not 2-tuples
    >>> from_key_val_list({'key': 'val'})
    OrderedDict([('key', 'val')])

:rtype: OrderedDict

**Param√®tres :**

- `value`

##### to_key_val_list

Take an object and test to see if it can be represented as a
dictionary. If it can be, return a list of tuples, e.g.,

::

    >>> to_key_val_list([('key', 'val')])
    [('key', 'val')]
    >>> to_key_val_list({'key': 'val'})
    [('key', 'val')]
    >>> to_key_val_list('string')
    Traceback (most recent call last):
    ...
    ValueError: cannot encode objects that are not 2-tuples

:rtype: list

**Param√®tres :**

- `value`

##### parse_list_header

Parse lists as described by RFC 2068 Section 2.

In particular, parse comma-separated lists where the elements of
the list may include quoted-strings.  A quoted-string could
contain a comma.  A non-quoted string could have quotes in the
middle.  Quotes are removed automatically after parsing.

It basically works like :func:`parse_set_header` just that items
may appear multiple times and case sensitivity is preserved.

The return value is a standard :class:`list`:

>>> parse_list_header('token, "quoted value"')
['token', 'quoted value']

To create a header from the :class:`list` again, use the
:func:`dump_header` function.

:param value: a string with a list header.
:return: :class:`list`
:rtype: list

**Param√®tres :**

- `value`

##### parse_dict_header

Parse lists of key, value pairs as described by RFC 2068 Section 2 and
convert them into a python dict:

>>> d = parse_dict_header('foo="is a fish", bar="as well"')
>>> type(d) is dict
True
>>> sorted(d.items())
[('bar', 'as well'), ('foo', 'is a fish')]

If there is no value for a key it will be `None`:

>>> parse_dict_header('key_without_value')
{'key_without_value': None}

To create a header from the :class:`dict` again, use the
:func:`dump_header` function.

:param value: a string with a dict header.
:return: :class:`dict`
:rtype: dict

**Param√®tres :**

- `value`

##### unquote_header_value

Unquotes a header value.  (Reversal of :func:`quote_header_value`).
This does not use the real unquoting but what browsers are actually
using for quoting.

:param value: the header value to unquote.
:rtype: str

**Param√®tres :**

- `value`
- `is_filename`

##### dict_from_cookiejar

Returns a key/value dictionary from a CookieJar.

:param cj: CookieJar object to extract cookies from.
:rtype: dict

**Param√®tres :**

- `cj`

##### add_dict_to_cookiejar

Returns a CookieJar from a key/value dictionary.

:param cj: CookieJar to insert cookies into.
:param cookie_dict: Dict of key/values to insert into CookieJar.
:rtype: CookieJar

**Param√®tres :**

- `cj`
- `cookie_dict`

##### get_encodings_from_content

Returns encodings from given content string.

:param content: bytestring to extract encodings from.

**Param√®tres :**

- `content`

##### _parse_content_type_header

Returns content type and parameters from given header

:param header: string
:return: tuple containing content type and dictionary of
     parameters

**Param√®tres :**

- `header`

##### get_encoding_from_headers

Returns encodings from given HTTP Header Dict.

:param headers: dictionary to extract encoding from.
:rtype: str

**Param√®tres :**

- `headers`

##### stream_decode_response_unicode

Stream decodes an iterator.

**Param√®tres :**

- `iterator`
- `r`

##### iter_slices

Iterate over slices of a string.

**Param√®tres :**

- `string`
- `slice_length`

##### get_unicode_from_response

Returns the requested content back in unicode.

:param r: Response object to get unicode content from.

Tried:

1. charset from content-type
2. fall back and replace all unicode characters

:rtype: str

**Param√®tres :**

- `r`

##### unquote_unreserved

Un-escape any percent-escape sequences in a URI that are unreserved
characters. This leaves all reserved, illegal and non-ASCII bytes encoded.

:rtype: str

**Param√®tres :**

- `uri`

##### requote_uri

Re-quote the given URI.

This function passes the given URI through an unquote/quote cycle to
ensure that it is fully and consistently quoted.

:rtype: str

**Param√®tres :**

- `uri`

##### address_in_network

This function allows you to check if an IP belongs to a network subnet

Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24
         returns False if ip = 192.168.1.1 and net = 192.168.100.0/24

:rtype: bool

**Param√®tres :**

- `ip`
- `net`

##### dotted_netmask

Converts mask from /xx format to xxx.xxx.xxx.xxx

Example: if mask is 24 function returns 255.255.255.0

:rtype: str

**Param√®tres :**

- `mask`

##### is_ipv4_address

:rtype: bool

**Param√®tres :**

- `string_ip`

##### is_valid_cidr

Very simple check of the cidr format in no_proxy variable.

:rtype: bool

**Param√®tres :**

- `string_network`

##### set_environ

Set the environment variable 'env_name' to 'value'

Save previous value, yield, and then restore the previous value stored in
the environment variable 'env_name'.

If 'value' is None, do nothing

**Param√®tres :**

- `env_name`
- `value`

##### should_bypass_proxies

Returns whether we should bypass proxies or not.

:rtype: bool

**Param√®tres :**

- `url`
- `no_proxy`

##### get_environ_proxies

Return a dict of environment proxies.

:rtype: dict

**Param√®tres :**

- `url`
- `no_proxy`

##### select_proxy

Select a proxy for the url, if applicable.

:param url: The url being for the request
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs

**Param√®tres :**

- `url`
- `proxies`

##### resolve_proxies

This method takes proxy information from a request and configuration
input to resolve a mapping of target proxies. This will consider settings
such as NO_PROXY to strip proxy configurations.

:param request: Request or PreparedRequest
:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
:param trust_env: Boolean declaring whether to trust environment configs

:rtype: dict

**Param√®tres :**

- `request`
- `proxies`
- `trust_env`

##### default_user_agent

Return a string representing the default user agent.

:rtype: str

**Param√®tres :**

- `name`

##### default_headers

:rtype: requests.structures.CaseInsensitiveDict

##### parse_header_links

Return a list of parsed link headers proxies.

i.e. Link: <http:/.../front.jpeg>; rel=front; type="image/jpeg",<http://.../back.jpeg>; rel=back;type="image/jpeg"

:rtype: list

**Param√®tres :**

- `value`

##### guess_json_utf

:rtype: str

**Param√®tres :**

- `data`

##### prepend_scheme_if_needed

Given a URL that may or may not have a scheme, prepend the given scheme.
Does not replace a present scheme with the one provided as an argument.

:rtype: str

**Param√®tres :**

- `url`
- `new_scheme`

##### get_auth_from_url

Given a url with authentication components, extract them into a tuple of
username,password.

:rtype: (str,str)

**Param√®tres :**

- `url`

##### check_header_validity

Verifies that header parts don't contain leading whitespace
reserved characters, or return characters.

:param header: tuple, in the format (name, value).

**Param√®tres :**

- `header`

##### _validate_header_part

**Param√®tres :**

- `header`
- `header_part`
- `header_validator_index`

##### urldefragauth

Given a url remove the fragment and the authentication part.

:rtype: str

**Param√®tres :**

- `url`

##### rewind_body

Move file pointer back to its recorded starting position
so it can be read again on redirect.

**Param√®tres :**

- `prepared_request`

##### proxy_bypass_registry

**Param√®tres :**

- `host`

##### proxy_bypass

Return True, if the host should be bypassed.

Checks proxy settings gathered from the environment, if specified,
or the registry.

**Param√®tres :**

- `host`

##### get_proxy

**Param√®tres :**

- `key`

---

### .!34044!__init__

---

### .!34047!__version__

---

### .!34051!_internal_utils

---

### .!34055!adapters

---

### .!34064!certs

---

### .!34067!compat

---

### .!34069!cookies

---

### .!34073!exceptions

---

### .!34077!hooks

---

### .!34081!models

---

### .!34084!packages

---

### .!34085!sessions

---

### .!34089!status_codes

---

### .!34092!structures

---

### .!34094!utils

---

### .!34099!__init__

---

### .!34102!_attrs

---

### .!34107!_core

---

### .!34110!exceptions

---

### .!34114!jsonschema

---

### .!34117!retrieval

---

### .!34120!typing

---

### .!34126!test_core

---

### .!34129!test_exceptions

---

### .!34132!test_jsonschema

---

### .!34134!test_referencing_suite

---

### .!34137!test_retrieval

---

### .!34140!__init__

---

### .!34144!_common

---

### .!34145!_version

---

### .!34149!easter

---

### .!34152!relativedelta

---

### .!34153!rrule

---

### .!34155!tzwin

---

### .!34158!utils

---

### .!34160!__init__

---

### .!34163!_parser

---

### .!34167!isoparser

---

### .!34169!__init__

---

### .!34172!_common

---

### .!34175!_factories

---

### .!34178!tz

---

### .!34182!win

---

### .!34186!__init__

---

### .!34189!rebuild

---

### .!34201!main

---

### .!34224!tree

---

### .!34192!__init__

---

### .!34195!_compat

---

### .!34199!_punycode

---

### .!34205!parser_block

---

### .!34207!parser_core

---

### .!34211!parser_inline

---

### .!34215!renderer

---

### .!34219!ruler

---

### .!34221!token

---

### .!34228!utils

---

### .!34236!parse

---

### .!34245!entities

---

### .!34250!html_blocks

---

### .!34253!html_re

---

### .!34256!normalize_url

---

### .!34258!utils

---

### .!34261!__init__

---

### .!34263!parse_link_destination

---

### .!34266!parse_link_label

---

### .!34268!parse_link_title

---

### .!34281!zero

---

### .!34272!__init__

---

### .!34274!commonmark

---

### .!34277!default

---

### .!34292!code

---

### .!34301!hr

---

### .!34309!list

---

### .!34285!__init__

---

### .!34288!blockquote

---

### .!34295!fence

---

### .!34299!heading

---

### .!34304!html_block

---

### .!34307!lheading

---

### .!34312!paragraph

---

### .!34315!reference

---

### .!34317!state_block

---

### .!34321!table

---

### .!34323!__init__

---

### .!34326!block

---

### .!34330!inline

---

### .!34333!linkify

---

### .!34337!normalize

---

### .!34338!replacements

---

### .!34342!smartquotes

---

### .!34344!state_core

---

### .!34347!text_join

---

### .!34385!link

---

### .!34401!text

---

### .!34349!__init__

---

### .!34354!autolink

---

### .!34357!backticks

---

### .!34361!balance_pairs

---

### .!34365!emphasis

---

### .!34369!entity

---

### .!34372!escape

---

### .!34375!fragments_join

---

### .!34378!html_inline

---

### .!34380!image

---

### .!34387!linkify

---

### .!34392!newline

---

### .!34395!state_inline

---

### .!34398!strikethrough

---

### .!34431!ext

---

### .!34447!meta

---

### .!34403!__init__

---

### .!34407!_identifier

---

### .!34409!async_utils

---

### .!34413!bccache

---

### .!34417!compiler

---

### .!34420!constants

---

### .!34422!debug

---

### .!34424!defaults

---

### .!34426!environment

---

### .!34429!exceptions

---

### .!34434!filters

---

### .!34438!idtracking

---

### .!34441!lexer

---

### .!34445!loaders

---

### .!34450!nativetypes

---

### .!34454!nodes

---

### .!34458!optimizer

---

### .!34460!parser

---

### .!34464!runtime

---

### .!34468!sandbox

---

### .!34472!tests

---

### .!34474!utils

---

### .!34478!visitor

---

### .!34485!base

---

### .!34490!exc

---

### .!34494!fun

---

### .!34496!pack

---

### .!34500!typ

---

### .!34481!__init__

---

### .!34486!const

---

### .!34498!stream

---

### .!34503!util

---

### .!34510!base

---

### .!34506!__init__

---

### .!34514!git

---

### .!34518!loose

---

### .!34521!mem

---

### .!34524!pack

---

### .!34526!ref

---

### .!34531!lib

---

### .!34529!__init__

---

### .!34534!test_base

---

### .!34536!test_example

---

### .!34539!test_pack

---

### .!34543!test_stream

---

### .!34547!test_util

---

### .!34554!encoding

---

### _catch

#### Classes

##### _Catcher

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `handle_exception()`

#### Fonctions

##### catch

**Param√®tres :**

- `__handlers`

##### __init__

**Param√®tres :**

- `handler_map`

##### __enter__

##### __exit__

**Param√®tres :**

- `etype`
- `exc`
- `tb`

##### handle_exception

**Param√®tres :**

- `exc`

---

### _exceptions

#### Classes

##### BaseExceptionGroup

A combination of multiple unrelated exceptions.

**M√©thodes :**

- `__new__()`
- `__init__()`
- `add_note()`
- `message()`
- `exceptions()`
- `subgroup()`
- `subgroup()`
- `subgroup()`
- `subgroup()`
- `split()`
- `split()`
- `split()`
- `split()`
- `derive()`
- `derive()`
- `derive()`
- `__str__()`
- `__repr__()`

##### ExceptionGroup

**M√©thodes :**

- `__new__()`

#### Fonctions

##### check_direct_subclass

**Param√®tres :**

- `exc`
- `parents`

##### get_condition_filter

**Param√®tres :**

- `condition`

##### _derive_and_copy_attributes

**Param√®tres :**

- `excs`

##### __new__

**Param√®tres :**

- `cls`
- `__message`
- `__exceptions`

##### __init__

**Param√®tres :**

- `__message`
- `__exceptions`

##### add_note

**Param√®tres :**

- `note`

##### message

##### exceptions

##### subgroup

**Param√®tres :**

- `__condition`

##### subgroup

**Param√®tres :**

- `__condition`

##### subgroup

**Param√®tres :**

- `__condition`

##### subgroup

**Param√®tres :**

- `__condition`

##### split

**Param√®tres :**

- `__condition`

##### split

**Param√®tres :**

- `__condition`

##### split

**Param√®tres :**

- `__condition`

##### split

**Param√®tres :**

- `__condition`

##### derive

**Param√®tres :**

- `__excs`

##### derive

**Param√®tres :**

- `__excs`

##### derive

**Param√®tres :**

- `__excs`

##### __str__

##### __repr__

##### __new__

**Param√®tres :**

- `cls`
- `__message`
- `__exceptions`

##### exceptions

##### subgroup

**Param√®tres :**

- `__condition`

##### subgroup

**Param√®tres :**

- `__condition`

##### subgroup

**Param√®tres :**

- `__condition`

##### split

**Param√®tres :**

- `__condition`

##### split

**Param√®tres :**

- `__condition`

##### split

**Param√®tres :**

- `__condition`

---

### _formatting

#### Classes

##### _ExceptionPrintContext

**M√©thodes :**

- `__init__()`
- `indent()`
- `emit()`

##### PatchedTracebackException

**M√©thodes :**

- `__init__()`
- `format()`
- `format_exception_only()`

#### Fonctions

##### _format_final_exc_line

**Param√®tres :**

- `etype`
- `value`

##### _safe_string

**Param√®tres :**

- `value`
- `what`
- `func`

##### exceptiongroup_excepthook

**Param√®tres :**

- `etype`
- `value`
- `tb`

##### format_exception_only

**Param√®tres :**

- `__exc`

##### _

**Param√®tres :**

- `__exc`
- `value`

##### format_exception

**Param√®tres :**

- `__exc`
- `limit`
- `chain`

##### _

**Param√®tres :**

- `__exc`
- `value`
- `tb`
- `limit`
- `chain`

##### print_exception

**Param√®tres :**

- `__exc`
- `limit`
- `file`
- `chain`

##### _

**Param√®tres :**

- `__exc`
- `value`
- `tb`
- `limit`
- `file`
- `chain`

##### print_exc

**Param√®tres :**

- `limit`
- `file`
- `chain`

##### _substitution_cost

**Param√®tres :**

- `ch_a`
- `ch_b`

##### _compute_suggestion_error

**Param√®tres :**

- `exc_value`
- `tb`

##### _levenshtein_distance

**Param√®tres :**

- `a`
- `b`
- `max_cost`

##### __init__

##### indent

##### emit

**Param√®tres :**

- `text_gen`
- `margin_char`

##### __init__

**Param√®tres :**

- `exc_type`
- `exc_value`
- `exc_traceback`

##### format

##### format_exception_only

Format the exception part of the traceback.
The return value is a generator of strings, each ending in a newline.
Normally, the generator emits a single string; however, for
SyntaxError exceptions, it emits several lines that (when
printed) display detailed information about where the syntax
error occurred.
The message indicating which exception occurred is always the last
string in the output.

---

### _suppress

#### Classes

##### suppress

Backport of :class:`contextlib.suppress` from Python 3.12.1.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

#### Fonctions

##### __init__

##### __enter__

##### __exit__

**Param√®tres :**

- `exctype`
- `excinst`
- `exctb`

---

### _version

---

### .!34557!__init__

---

### .!34560!_catch

---

### .!34563!_exceptions

---

### .!34566!_formatting

---

### .!34571!_suppress

---

### .!34572!_version

---

### .!34645!abc

---

### .!34655!ansi

---

### .!34658!bar

---

### .!34660!box

---

### .!34708!json

---

### .!34716!live

---

### .!34768!repr

---

### .!34771!rule

---

### .!34807!text

---

### .!34816!tree

---

### .!34576!__init__

---

### .!34581!__main__

---

### .!34584!_cell_widths

---

### .!34586!_emoji_codes

---

### .!34590!_emoji_replace

---

### .!34593!_export_format

---

### .!34597!_extension

---

### .!34599!_fileno

---

### .!34601!_inspect

---

### .!34604!_log_render

---

### .!34608!_loop

---

### .!34612!_null_file

---

### .!34613!_palettes

---

### .!34615!_pick

---

### .!34619!_ratio

---

### .!34621!_spinners

---

### .!34624!_stack

---

### .!34627!_timer

---

### .!34631!_win32_console

---

### .!34635!_windows

---

### .!34638!_windows_renderer

---

### .!34642!_wrap

---

### .!34650!align

---

### .!34663!cells

---

### .!34667!color

---

### .!34670!color_triplet

---

### .!34672!columns

---

### .!34675!console

---

### .!34677!constrain

---

### .!34681!containers

---

### .!34684!control

---

### .!34688!default_styles

---

### .!34690!diagnose

---

### .!34693!emoji

---

### .!34697!errors

---

### .!34701!file_proxy

---

### .!34703!filesize

---

### .!34706!highlighter

---

### .!34711!jupyter

---

### .!34712!layout

---

### .!34720!live_render

---

### .!34724!logging

---

### .!34729!markdown

---

### .!34732!markup

---

### .!34736!measure

---

### .!34737!padding

---

### .!34741!pager

---

### .!34742!palette

---

### .!34746!panel

---

### .!34749!pretty

---

### .!34753!progress

---

### .!34755!progress_bar

---

### .!34757!prompt

---

### .!34761!protocol

---

### .!34764!region

---

### .!34773!scope

---

### .!34776!screen

---

### .!34780!segment

---

### .!34786!spinner

---

### .!34789!status

---

### .!34792!style

---

### .!34795!styled

---

### .!34798!syntax

---

### .!34802!table

---

### .!34803!terminal_theme

---

### .!34808!theme

---

### .!34811!themes

---

### .!34814!traceback

---

### _argcomplete

Allow bash-completion for argparse with argcomplete if installed.

Needs argcomplete>=0.5.6 for python 3.2/3.3 (older versions fail
to find the magic string, so _ARGCOMPLETE env. var is never set, and
this does not need special code).

Function try_argcomplete(parser) should be called directly before
the call to ArgumentParser.parse_args().

The filescompleter is what you normally would use on the positional
arguments specification, in order to get "dirname/" after "dirn<TAB>"
instead of the default "dirname ":

   optparser.add_argument(Config._file_or_dir, nargs='*').completer=filescompleter

Other, application specific, completers should go in the file
doing the add_argument calls as they need to be specified as .completer
attributes as well. (If argcomplete is not installed, the function the
attribute points to will not be used).

SPEEDUP
=======

The generic argcomplete script for bash-completion
(/etc/bash_completion.d/python-argcomplete.sh)
uses a python program to determine startup script generated by pip.
You can speed up completion somewhat by changing this script to include
  # PYTHON_ARGCOMPLETE_OK
so the python-argcomplete-check-easy-install-script does not
need to be called to find the entry point of the code and see if that is
marked  with PYTHON_ARGCOMPLETE_OK.

INSTALL/DEBUGGING
=================

To include this support in another application that has setup.py generated
scripts:

- Add the line:
    # PYTHON_ARGCOMPLETE_OK
  near the top of the main python entry point.

- Include in the file calling parse_args():
    from _argcomplete import try_argcomplete, filescompleter
  Call try_argcomplete just before parse_args(), and optionally add
  filescompleter to the positional arguments' add_argument().

If things do not work right away:

- Switch on argcomplete debugging with (also helpful when doing custom
  completers):
    export _ARC_DEBUG=1

- Run:
    python-argcomplete-check-easy-install-script $(which appname)
    echo $?
  will echo 0 if the magic line has been found, 1 if not.

- Sometimes it helps to find early on errors using:
    _ARGCOMPLETE=1 _ARC_DEBUG=1 appname
  which should throw a KeyError: 'COMPLINE' (which is properly set by the
  global argcomplete script).

#### Classes

##### FastFilesCompleter

Fast file completer class.

**M√©thodes :**

- `__init__()`
- `__call__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `directories`

##### __call__

**Param√®tres :**

- `prefix`

##### try_argcomplete

**Param√®tres :**

- `parser`

##### try_argcomplete

**Param√®tres :**

- `parser`

---

### .!34877!main

---

### _version

---

### cacheprovider

Implementation of the cache provider.

#### Classes

##### Cache

Instance of the `cache` fixture.

**M√©thodes :**

- `__init__()`
- `for_config()`
- `clear_cache()`
- `cache_dir_from_config()`
- `warn()`
- `_mkdir()`
- `mkdir()`
- `_getvaluepath()`
- `get()`
- `set()`
- `_ensure_cache_dir_and_supporting_files()`

##### LFPluginCollWrapper

**M√©thodes :**

- `__init__()`
- `pytest_make_collect_report()`

##### LFPluginCollSkipfiles

**M√©thodes :**

- `__init__()`
- `pytest_make_collect_report()`

##### LFPlugin

Plugin which implements the --lf (run last-failing) option.

**M√©thodes :**

- `__init__()`
- `get_last_failed_paths()`
- `pytest_report_collectionfinish()`
- `pytest_runtest_logreport()`
- `pytest_collectreport()`
- `pytest_collection_modifyitems()`
- `pytest_sessionfinish()`

##### NFPlugin

Plugin which implements the --nf (run new-first) option.

**M√©thodes :**

- `__init__()`
- `pytest_collection_modifyitems()`
- `_get_increasing_order()`
- `pytest_sessionfinish()`

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_cmdline_main

**Param√®tres :**

- `config`

##### pytest_configure

**Param√®tres :**

- `config`

##### cache

Return a cache object that can persist state between testing sessions.

cache.get(key, default)
cache.set(key, value)

Keys must be ``/`` separated strings, where the first part is usually the
name of your plugin or application to avoid clashes with other cache users.

Values can be any object handled by the json stdlib module.

**Param√®tres :**

- `request`

##### pytest_report_header

Display cachedir with --cache-show and if non-default.

**Param√®tres :**

- `config`

##### cacheshow

**Param√®tres :**

- `config`
- `session`

##### __init__

**Param√®tres :**

- `cachedir`
- `config`

##### for_config

Create the Cache instance for a Config.

:meta private:

**Param√®tres :**

- `cls`
- `config`

##### clear_cache

Clear the sub-directories used to hold cached directories and values.

:meta private:

**Param√®tres :**

- `cls`
- `cachedir`
- `_ispytest`

##### cache_dir_from_config

Get the path to the cache directory for a Config.

:meta private:

**Param√®tres :**

- `config`

##### warn

Issue a cache warning.

:meta private:

**Param√®tres :**

- `fmt`

##### _mkdir

**Param√®tres :**

- `path`

##### mkdir

Return a directory path object with the given name.

If the directory does not yet exist, it will be created. You can use
it to manage files to e.g. store/retrieve database dumps across test
sessions.

.. versionadded:: 7.0

:param name:
    Must be a string not containing a ``/`` separator.
    Make sure the name contains your plugin or application
    identifiers to prevent clashes with other cache users.

**Param√®tres :**

- `name`

##### _getvaluepath

**Param√®tres :**

- `key`

##### get

Return the cached value for the given key.

If no value was yet cached or the value cannot be read, the specified
default is returned.

:param key:
    Must be a ``/`` separated value. Usually the first
    name is the name of your plugin or your application.
:param default:
    The value to return in case of a cache-miss or invalid cache value.

**Param√®tres :**

- `key`
- `default`

##### set

Save value for the given key.

:param key:
    Must be a ``/`` separated value. Usually the first
    name is the name of your plugin or your application.
:param value:
    Must be of any combination of basic python types,
    including nested types like lists of dictionaries.

**Param√®tres :**

- `key`
- `value`

##### _ensure_cache_dir_and_supporting_files

Create the cache dir and its supporting files.

##### __init__

**Param√®tres :**

- `lfplugin`

##### pytest_make_collect_report

**Param√®tres :**

- `collector`

##### __init__

**Param√®tres :**

- `lfplugin`

##### pytest_make_collect_report

**Param√®tres :**

- `collector`

##### __init__

**Param√®tres :**

- `config`

##### get_last_failed_paths

Return a set with all Paths of the previously failed nodeids and
their parents.

##### pytest_report_collectionfinish

##### pytest_runtest_logreport

**Param√®tres :**

- `report`

##### pytest_collectreport

**Param√®tres :**

- `report`

##### pytest_collection_modifyitems

**Param√®tres :**

- `config`
- `items`

##### pytest_sessionfinish

**Param√®tres :**

- `session`

##### __init__

**Param√®tres :**

- `config`

##### pytest_collection_modifyitems

**Param√®tres :**

- `items`

##### _get_increasing_order

**Param√®tres :**

- `items`

##### pytest_sessionfinish

##### sort_key

**Param√®tres :**

- `node`

---

### capture

Per-test stdout/stderr capturing mechanism.

#### Classes

##### EncodedFile

**M√©thodes :**

- `name()`
- `mode()`

##### CaptureIO

**M√©thodes :**

- `__init__()`
- `getvalue()`

##### TeeCaptureIO

**M√©thodes :**

- `__init__()`
- `write()`

##### DontReadFromInput

**M√©thodes :**

- `encoding()`
- `read()`
- `__next__()`
- `readlines()`
- `__iter__()`
- `fileno()`
- `flush()`
- `isatty()`
- `close()`
- `readable()`
- `seek()`
- `seekable()`
- `tell()`
- `truncate()`
- `write()`
- `writelines()`
- `writable()`
- `__enter__()`
- `__exit__()`
- `buffer()`

##### CaptureBase

**M√©thodes :**

- `__init__()`
- `start()`
- `done()`
- `suspend()`
- `resume()`
- `writeorg()`
- `snap()`

##### NoCapture

**M√©thodes :**

- `__init__()`
- `start()`
- `done()`
- `suspend()`
- `resume()`
- `snap()`
- `writeorg()`

##### SysCaptureBase

**M√©thodes :**

- `__init__()`
- `repr()`
- `__repr__()`
- `_assert_state()`
- `start()`
- `done()`
- `suspend()`
- `resume()`

##### SysCaptureBinary

**M√©thodes :**

- `snap()`
- `writeorg()`

##### SysCapture

**M√©thodes :**

- `snap()`
- `writeorg()`

##### FDCaptureBase

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `_assert_state()`
- `start()`
- `done()`
- `suspend()`
- `resume()`

##### FDCaptureBinary

Capture IO to/from a given OS-level file descriptor.

snap() produces `bytes`.

**M√©thodes :**

- `snap()`
- `writeorg()`

##### FDCapture

Capture IO to/from a given OS-level file descriptor.

snap() produces text.

**M√©thodes :**

- `snap()`
- `writeorg()`

##### MultiCapture

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `start_capturing()`
- `pop_outerr_to_orig()`
- `suspend_capturing()`
- `resume_capturing()`
- `stop_capturing()`
- `is_started()`
- `readouterr()`

##### CaptureManager

The capture plugin.

Manages that the appropriate capture method is enabled/disabled during
collection and each test phase (setup, call, teardown). After each of
those points, the captured output is obtained and attached to the
collection/runtest report.

There are two levels of capture:

* global: enabled by default and can be suppressed by the ``-s``
  option. This is always enabled/disabled during collection and each test
  phase.

* fixture: when a test function or one of its fixture depend on the
  ``capsys`` or ``capfd`` fixtures. In this case special handling is
  needed to ensure the fixtures take precedence over the global capture.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `is_capturing()`
- `is_globally_capturing()`
- `start_global_capturing()`
- `stop_global_capturing()`
- `resume_global_capture()`
- `suspend_global_capture()`
- `suspend()`
- `resume()`
- `read_global_capture()`
- `set_fixture()`
- `unset_fixture()`
- `activate_fixture()`
- `deactivate_fixture()`
- `suspend_fixture()`
- `resume_fixture()`
- `global_and_fixture_disabled()`
- `item_capture()`
- `pytest_make_collect_report()`
- `pytest_runtest_setup()`
- `pytest_runtest_call()`
- `pytest_runtest_teardown()`
- `pytest_keyboard_interrupt()`
- `pytest_internalerror()`

##### CaptureFixture

Object returned by the :fixture:`capsys`, :fixture:`capsysbinary`,
:fixture:`capfd` and :fixture:`capfdbinary` fixtures.

**M√©thodes :**

- `__init__()`
- `_start()`
- `close()`
- `readouterr()`
- `_suspend()`
- `_resume()`
- `_is_started()`
- `disabled()`

##### CaptureResult

The result of :method:`caplog.readouterr() <pytest.CaptureFixture.readouterr>`.

##### CaptureResult

The result of :method:`caplog.readouterr() <pytest.CaptureFixture.readouterr>`.

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### _colorama_workaround

Ensure colorama is imported so that it attaches to the correct stdio
handles on Windows.

colorama uses the terminal on import time. So if something does the
first import of colorama while I/O capture is active, colorama will
fail in various ways.

##### _readline_workaround

Ensure readline is imported early so it attaches to the correct stdio handles.

This isn't a problem with the default GNU readline implementation, but in
some configurations, Python uses libedit instead (on macOS, and for prebuilt
binaries such as used by uv).

In theory this is only needed if readline.backend == "libedit", but the
workaround consists of importing readline here, so we already worked around
the issue by the time we could check if we need to.

##### _windowsconsoleio_workaround

Workaround for Windows Unicode console handling.

Python 3.6 implemented Unicode console handling for Windows. This works
by reading/writing to the raw console handle using
``{Read,Write}ConsoleW``.

The problem is that we are going to ``dup2`` over the stdio file
descriptors when doing ``FDCapture`` and this will ``CloseHandle`` the
handles used by Python to write to the console. Though there is still some
weirdness and the console handle seems to only be closed randomly and not
on the first call to ``CloseHandle``, or maybe it gets reopened with the
same handle value when we suspend capturing.

The workaround in this case will reopen stdio with a different fd which
also means a different handle by replicating the logic in
"Py_lifecycle.c:initstdio/create_stdio".

:param stream:
    In practice ``sys.stdout`` or ``sys.stderr``, but given
    here as parameter for unittesting purposes.

See https://github.com/pytest-dev/py/issues/103.

**Param√®tres :**

- `stream`

##### pytest_load_initial_conftests

**Param√®tres :**

- `early_config`

##### _get_multicapture

**Param√®tres :**

- `method`

##### capsys

Enable text capturing of writes to ``sys.stdout`` and ``sys.stderr``.

The captured output is made available via ``capsys.readouterr()`` method
calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``text`` objects.

Returns an instance of :class:`CaptureFixture[str] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

    def test_output(capsys):
        print("hello")
        captured = capsys.readouterr()
        assert captured.out == "hello\n"

**Param√®tres :**

- `request`

##### capteesys

Enable simultaneous text capturing and pass-through of writes
to ``sys.stdout`` and ``sys.stderr`` as defined by ``--capture=``.


The captured output is made available via ``capteesys.readouterr()`` method
calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``text`` objects.

The output is also passed-through, allowing it to be "live-printed",
reported, or both as defined by ``--capture=``.

Returns an instance of :class:`CaptureFixture[str] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

    def test_output(capteesys):
        print("hello")
        captured = capteesys.readouterr()
        assert captured.out == "hello\n"

**Param√®tres :**

- `request`

##### capsysbinary

Enable bytes capturing of writes to ``sys.stdout`` and ``sys.stderr``.

The captured output is made available via ``capsysbinary.readouterr()``
method calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``bytes`` objects.

Returns an instance of :class:`CaptureFixture[bytes] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

    def test_output(capsysbinary):
        print("hello")
        captured = capsysbinary.readouterr()
        assert captured.out == b"hello\n"

**Param√®tres :**

- `request`

##### capfd

Enable text capturing of writes to file descriptors ``1`` and ``2``.

The captured output is made available via ``capfd.readouterr()`` method
calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``text`` objects.

Returns an instance of :class:`CaptureFixture[str] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

    def test_system_echo(capfd):
        os.system('echo "hello"')
        captured = capfd.readouterr()
        assert captured.out == "hello\n"

**Param√®tres :**

- `request`

##### capfdbinary

Enable bytes capturing of writes to file descriptors ``1`` and ``2``.

The captured output is made available via ``capfd.readouterr()`` method
calls, which return a ``(out, err)`` namedtuple.
``out`` and ``err`` will be ``byte`` objects.

Returns an instance of :class:`CaptureFixture[bytes] <pytest.CaptureFixture>`.

Example:

.. code-block:: python

    def test_system_echo(capfdbinary):
        os.system('echo "hello"')
        captured = capfdbinary.readouterr()
        assert captured.out == b"hello\n"

**Param√®tres :**

- `request`

##### _reopen_stdio

**Param√®tres :**

- `f`
- `mode`

##### name

##### mode

##### __init__

##### getvalue

##### __init__

**Param√®tres :**

- `other`

##### write

**Param√®tres :**

- `s`

##### encoding

##### read

**Param√®tres :**

- `size`

##### __next__

##### readlines

**Param√®tres :**

- `hint`

##### __iter__

##### fileno

##### flush

##### isatty

##### close

##### readable

##### seek

**Param√®tres :**

- `offset`
- `whence`

##### seekable

##### tell

##### truncate

**Param√®tres :**

- `size`

##### write

**Param√®tres :**

- `data`

##### writelines

**Param√®tres :**

- `lines`

##### writable

##### __enter__

##### __exit__

**Param√®tres :**

- `type`
- `value`
- `traceback`

##### buffer

##### __init__

**Param√®tres :**

- `fd`

##### start

##### done

##### suspend

##### resume

##### writeorg

**Param√®tres :**

- `data`

##### snap

##### __init__

**Param√®tres :**

- `fd`

##### start

##### done

##### suspend

##### resume

##### snap

##### writeorg

**Param√®tres :**

- `data`

##### __init__

**Param√®tres :**

- `fd`
- `tmpfile`

##### repr

**Param√®tres :**

- `class_name`

##### __repr__

##### _assert_state

**Param√®tres :**

- `op`
- `states`

##### start

##### done

##### suspend

##### resume

##### snap

##### writeorg

**Param√®tres :**

- `data`

##### snap

##### writeorg

**Param√®tres :**

- `data`

##### __init__

**Param√®tres :**

- `targetfd`

##### __repr__

##### _assert_state

**Param√®tres :**

- `op`
- `states`

##### start

Start capturing on targetfd using memorized tmpfile.

##### done

Stop capturing, restore streams, return original capture file,
seeked to position zero.

##### suspend

##### resume

##### snap

##### writeorg

Write to original file descriptor.

**Param√®tres :**

- `data`

##### snap

##### writeorg

Write to original file descriptor.

**Param√®tres :**

- `data`

##### __init__

**Param√®tres :**

- `in_`
- `out`
- `err`

##### __repr__

##### start_capturing

##### pop_outerr_to_orig

Pop current snapshot out/err capture and flush to orig streams.

##### suspend_capturing

**Param√®tres :**

- `in_`

##### resume_capturing

##### stop_capturing

Stop capturing and reset capturing streams.

##### is_started

Whether actively capturing -- not suspended or stopped.

##### readouterr

##### __init__

**Param√®tres :**

- `method`

##### __repr__

##### is_capturing

##### is_globally_capturing

##### start_global_capturing

##### stop_global_capturing

##### resume_global_capture

##### suspend_global_capture

**Param√®tres :**

- `in_`

##### suspend

**Param√®tres :**

- `in_`

##### resume

##### read_global_capture

##### set_fixture

**Param√®tres :**

- `capture_fixture`

##### unset_fixture

##### activate_fixture

If the current item is using ``capsys`` or ``capfd``, activate
them so they take precedence over the global capture.

##### deactivate_fixture

Deactivate the ``capsys`` or ``capfd`` fixture of this item, if any.

##### suspend_fixture

##### resume_fixture

##### global_and_fixture_disabled

Context manager to temporarily disable global and current fixture capturing.

##### item_capture

**Param√®tres :**

- `when`
- `item`

##### pytest_make_collect_report

**Param√®tres :**

- `collector`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

**Param√®tres :**

- `item`

##### pytest_keyboard_interrupt

##### pytest_internalerror

##### __init__

**Param√®tres :**

- `captureclass`
- `request`

##### _start

##### close

##### readouterr

Read and return the captured output so far, resetting the internal
buffer.

:returns:
    The captured content as a namedtuple with ``out`` and ``err``
    string attributes.

##### _suspend

Suspend this fixture's own capturing temporarily.

##### _resume

Resume this fixture's own capturing temporarily.

##### _is_started

Whether actively capturing -- not disabled or closed.

##### disabled

Temporarily disable capturing while inside the ``with`` block.

---

### compat

Python version compatibility code.

#### Classes

##### NotSetType

##### CallableBool

A bool-like object that can also be called, returning its true/false value.

Used for backwards compatibility in cases where something was supposed to be a method
but was implemented as a simple attribute by mistake (see `TerminalReporter.isatty`).

Do not use in new code.

**M√©thodes :**

- `__init__()`
- `__bool__()`
- `__call__()`

#### Fonctions

##### legacy_path

Internal wrapper to prepare lazy proxies for legacy_path instances

**Param√®tres :**

- `path`

##### iscoroutinefunction

Return True if func is a coroutine function (a function defined with async
def syntax, and doesn't contain yield), or a function decorated with
@asyncio.coroutine.

Note: copied and modified from Python 3.5's builtin coroutines.py to avoid
importing asyncio directly, which in turns also initializes the "logging"
module as a side-effect (see issue #8).

**Param√®tres :**

- `func`

##### is_async_function

Return True if the given function seems to be an async function or
an async generator.

**Param√®tres :**

- `func`

##### getlocation

**Param√®tres :**

- `function`
- `curdir`

##### num_mock_patch_args

Return number of arguments used up by mock arguments (if any).

**Param√®tres :**

- `function`

##### getfuncargnames

Return the names of a function's mandatory arguments.

Should return the names of all function arguments that:
* Aren't bound to an instance or type as in instance or class methods.
* Don't have default values.
* Aren't bound with functools.partial.
* Aren't replaced with mocks.

The cls arguments indicate that the function should be treated as a bound
method even though it's not unless the function is a static method.

The name parameter should be the original name in which the function was collected.

**Param√®tres :**

- `function`

##### get_default_arg_names

**Param√®tres :**

- `function`

##### ascii_escaped

If val is pure ASCII, return it as an str, otherwise, escape
bytes objects into a sequence of escaped bytes:

b'\xc3\xb4\xc5\xd6' -> r'\xc3\xb4\xc5\xd6'

and escapes strings into a sequence of escaped unicode ids, e.g.:

r'4\nV\U00043efa\x0eMXWB\x1e\u3028\u15fd\xcd\U0007d944'

Note:
   The obvious "v.decode('unicode-escape')" will return
   valid UTF-8 unicode if it finds them in bytes, but we
   want to return escaped bytes for any byte, even if they match
   a UTF-8 string.

**Param√®tres :**

- `val`

##### get_real_func

Get the real function object of the (possibly) wrapped object by
:func:`functools.wraps`, or :func:`functools.partial`.

**Param√®tres :**

- `obj`

##### getimfunc

**Param√®tres :**

- `func`

##### safe_getattr

Like getattr but return default upon any Exception or any OutcomeException.

Attribute access can potentially fail for 'evil' Python objects.
See issue #214.
It catches OutcomeException because of #2490 (issue #580), new outcomes
are derived from BaseException instead of Exception (for more details
check #2707).

**Param√®tres :**

- `object`
- `name`
- `default`

##### safe_isclass

Ignore any exception via isinstance on Python 3.

**Param√®tres :**

- `obj`

##### get_user_id

Return the current process's real user id or None if it could not be
determined.

:return: The user id or None if it could not be determined.

##### assert_never

**Param√®tres :**

- `value`

##### __init__

**Param√®tres :**

- `value`

##### __bool__

##### __call__

---

### debugging

Interactive debugging with PDB, the Python Debugger.

#### Classes

##### pytestPDB

Pseudo PDB that defers to the real pdb.

**M√©thodes :**

- `_is_capturing()`
- `_import_pdb_cls()`
- `_get_pdb_wrapper_class()`
- `_init_pdb()`
- `set_trace()`

##### PdbInvoke

**M√©thodes :**

- `pytest_exception_interact()`
- `pytest_internalerror()`

##### PdbTrace

**M√©thodes :**

- `pytest_pyfunc_call()`

##### PytestPdbWrapper

**M√©thodes :**

- `do_debug()`
- `do_continue()`
- `do_quit()`
- `setup()`
- `get_stack()`

#### Fonctions

##### _validate_usepdb_cls

Validate syntax of --pdbcls option.

**Param√®tres :**

- `value`

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### wrap_pytest_function_for_tracing

Change the Python function object of the given Function item by a
wrapper which actually enters pdb before calling the python function
itself, effectively leaving the user in the pdb prompt in the first
statement of the function.

**Param√®tres :**

- `pyfuncitem`

##### maybe_wrap_pytest_function_for_tracing

Wrap the given pytestfunct item for tracing support if --trace was given in
the command line.

**Param√®tres :**

- `pyfuncitem`

##### _enter_pdb

**Param√®tres :**

- `node`
- `excinfo`
- `rep`

##### _postmortem_exc_or_tb

**Param√®tres :**

- `excinfo`

##### post_mortem

**Param√®tres :**

- `tb_or_exc`

##### fin

##### _is_capturing

**Param√®tres :**

- `cls`
- `capman`

##### _import_pdb_cls

**Param√®tres :**

- `cls`
- `capman`

##### _get_pdb_wrapper_class

**Param√®tres :**

- `cls`
- `pdb_cls`
- `capman`

##### _init_pdb

Initialize PDB debugging, dropping any IO capturing.

**Param√®tres :**

- `cls`
- `method`

##### set_trace

Invoke debugging via ``Pdb.set_trace``, dropping any IO capturing.

**Param√®tres :**

- `cls`

##### pytest_exception_interact

**Param√®tres :**

- `node`
- `call`
- `report`

##### pytest_internalerror

**Param√®tres :**

- `excinfo`

##### pytest_pyfunc_call

**Param√®tres :**

- `pyfuncitem`

##### wrapper

##### do_debug

**Param√®tres :**

- `arg`

##### do_continue

**Param√®tres :**

- `arg`

##### do_quit

**Param√®tres :**

- `arg`

##### setup

Suspend on setup().

Needed after do_continue resumed, and entering another
breakpoint again.

**Param√®tres :**

- `f`
- `tb`

##### get_stack

**Param√®tres :**

- `f`
- `t`

---

### deprecated

Deprecation messages and bits of code used elsewhere in the codebase that
is planned to be removed in the next pytest release.

Keeping it in a central location makes it easy to track what is deprecated and should
be removed when the time comes.

All constants defined in this module should be either instances of
:class:`PytestWarning`, or :class:`UnformattedWarning`
in case of warnings which need to format their messages.

#### Fonctions

##### check_ispytest

**Param√®tres :**

- `ispytest`

---

### doctest

Discover and run doctests in modules and test files.

#### Classes

##### ReprFailDoctest

**M√©thodes :**

- `__init__()`
- `toterminal()`

##### MultipleDoctestFailures

**M√©thodes :**

- `__init__()`

##### DoctestItem

**M√©thodes :**

- `__init__()`
- `from_parent()`
- `_initrequest()`
- `setup()`
- `runtest()`
- `_disable_output_capturing_for_darwin()`
- `repr_failure()`
- `reportinfo()`

##### DoctestTextfile

**M√©thodes :**

- `collect()`

##### DoctestModule

**M√©thodes :**

- `collect()`

##### PytestDoctestRunner

Runner to collect failures.

Note that the out variable in this case is a list instead of a
stdout-like object.

**M√©thodes :**

- `__init__()`
- `report_failure()`
- `report_unexpected_exception()`

##### LiteralsOutputChecker

**M√©thodes :**

- `check_output()`
- `_remove_unwanted_precision()`

##### MockAwareDocTestFinder

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_unconfigure

##### pytest_collect_file

**Param√®tres :**

- `file_path`
- `parent`

##### _is_setup_py

**Param√®tres :**

- `path`

##### _is_doctest

**Param√®tres :**

- `config`
- `path`
- `parent`

##### _is_main_py

**Param√®tres :**

- `path`

##### _init_runner_class

##### _get_runner

**Param√®tres :**

- `checker`
- `verbose`
- `optionflags`
- `continue_on_failure`

##### _get_flag_lookup

##### get_optionflags

**Param√®tres :**

- `config`

##### _get_continue_on_failure

**Param√®tres :**

- `config`

##### _check_all_skipped

Raise pytest.skip() if all examples in the given DocTest have the SKIP
option set.

**Param√®tres :**

- `test`

##### _is_mocked

Return if an object is possibly a mock object by checking the
existence of a highly improbable attribute.

**Param√®tres :**

- `obj`

##### _patch_unwrap_mock_aware

Context manager which replaces ``inspect.unwrap`` with a version
that's aware of mock objects and doesn't recurse into them.

##### _init_checker_class

##### _get_checker

Return a doctest.OutputChecker subclass that supports some
additional options:

* ALLOW_UNICODE and ALLOW_BYTES options to ignore u'' and b''
  prefixes (respectively) in string literals. Useful when the same
  doctest should run in Python 2 and Python 3.

* NUMBER to ignore floating-point differences smaller than the
  precision of the literal number in the doctest.

An inner class is used to avoid importing "doctest" at the module
level.

##### _get_allow_unicode_flag

Register and return the ALLOW_UNICODE flag.

##### _get_allow_bytes_flag

Register and return the ALLOW_BYTES flag.

##### _get_number_flag

Register and return the NUMBER flag.

##### _get_report_choice

Return the actual `doctest` module flag value.

We want to do it as late as possible to avoid importing `doctest` and all
its dependencies when parsing options, as it adds overhead and breaks tests.

**Param√®tres :**

- `key`

##### doctest_namespace

Fixture that returns a :py:class:`dict` that will be injected into the
namespace of doctests.

Usually this fixture is used in conjunction with another ``autouse`` fixture:

.. code-block:: python

    @pytest.fixture(autouse=True)
    def add_np(doctest_namespace):
        doctest_namespace["np"] = numpy

For more details: :ref:`doctest_namespace`.

##### __init__

**Param√®tres :**

- `reprlocation_lines`

##### toterminal

**Param√®tres :**

- `tw`

##### __init__

**Param√®tres :**

- `failures`

##### __init__

**Param√®tres :**

- `name`
- `parent`
- `runner`
- `dtest`

##### from_parent

The public named constructor.

**Param√®tres :**

- `cls`
- `parent`

##### _initrequest

##### setup

##### runtest

##### _disable_output_capturing_for_darwin

Disable output capturing. Otherwise, stdout is lost to doctest (#985).

##### repr_failure

**Param√®tres :**

- `excinfo`

##### reportinfo

##### collect

##### _mock_aware_unwrap

**Param√®tres :**

- `func`

##### collect

##### __init__

**Param√®tres :**

- `checker`
- `verbose`
- `optionflags`
- `continue_on_failure`

##### report_failure

**Param√®tres :**

- `out`
- `test`
- `example`
- `got`

##### report_unexpected_exception

**Param√®tres :**

- `out`
- `test`
- `example`
- `exc_info`

##### check_output

**Param√®tres :**

- `want`
- `got`
- `optionflags`

##### _remove_unwanted_precision

**Param√®tres :**

- `want`
- `got`

##### remove_prefixes

**Param√®tres :**

- `regex`
- `txt`

##### _find_lineno

On older Pythons, doctest code does not take into account
`@property`. https://github.com/python/cpython/issues/61648

Moreover, wrapped Doctests need to be unwrapped so the correct
line number is returned. #8796

**Param√®tres :**

- `obj`
- `source_lines`

##### _find

Override _find to work around issue in stdlib.

https://github.com/pytest-dev/pytest/issues/3456
https://github.com/python/cpython/issues/69718

**Param√®tres :**

- `tests`
- `obj`
- `name`
- `module`
- `source_lines`
- `globs`
- `seen`

##### _from_module

`cached_property` objects are never considered a part
of the 'current module'. As such they are skipped by doctest.
Here we override `_from_module` to check the underlying
function instead. https://github.com/python/cpython/issues/107995

**Param√®tres :**

- `module`
- `object`

---

### faulthandler

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### pytest_unconfigure

**Param√®tres :**

- `config`

##### get_stderr_fileno

##### get_timeout_config_value

**Param√®tres :**

- `config`

##### pytest_runtest_protocol

**Param√®tres :**

- `item`

##### pytest_enter_pdb

Cancel any traceback dumping due to timeout before entering pdb.

##### pytest_exception_interact

Cancel any traceback dumping due to an interactive exception being
raised.

---

### fixtures

#### Classes

##### PseudoFixtureDef

##### ParamArgKey

A key for a high-scoped parameter used by an item.

For use as a hashable key in `reorder_items`. The combination of fields
is meant to uniquely identify a particular "instance" of a param,
potentially shared by multiple items in a scope.

##### FuncFixtureInfo

Fixture-related information for a fixture-requesting item (e.g. test
function).

This is used to examine the fixtures which an item requests statically
(known during collection). This includes autouse fixtures, fixtures
requested by the `usefixtures` marker, fixtures requested in the function
parameters, and the transitive closure of these.

An item may also request fixtures dynamically (using `request.getfixturevalue`);
these are not reflected here.

**M√©thodes :**

- `prune_dependency_tree()`

##### FixtureRequest

The type of the ``request`` fixture.

A request object gives access to the requesting test context and has a
``param`` attribute in case the fixture is parametrized.

**M√©thodes :**

- `__init__()`
- `_fixturemanager()`
- `_scope()`
- `scope()`
- `_check_scope()`
- `fixturenames()`
- `node()`
- `config()`
- `function()`
- `cls()`
- `instance()`
- `module()`
- `path()`
- `keywords()`
- `session()`
- `addfinalizer()`
- `applymarker()`
- `raiseerror()`
- `getfixturevalue()`
- `_iter_chain()`
- `_get_active_fixturedef()`
- `_check_fixturedef_without_param()`
- `_get_fixturestack()`

##### TopRequest

The type of the ``request`` fixture in a test function.

**M√©thodes :**

- `__init__()`
- `_scope()`
- `_check_scope()`
- `node()`
- `__repr__()`
- `_fillfixtures()`
- `addfinalizer()`

##### SubRequest

The type of the ``request`` fixture in a fixture function requested
(transitively) by a test function.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `_scope()`
- `node()`
- `_check_scope()`
- `_format_fixturedef_line()`
- `addfinalizer()`

##### FixtureLookupError

Could not return a requested fixture (missing or invalid).

**M√©thodes :**

- `__init__()`
- `formatrepr()`

##### FixtureLookupErrorRepr

**M√©thodes :**

- `__init__()`
- `toterminal()`

##### FixtureDef

A container for a fixture definition.

Note: At this time, only explicitly documented fields and methods are
considered public stable API.

**M√©thodes :**

- `__init__()`
- `scope()`
- `addfinalizer()`
- `finish()`
- `execute()`
- `cache_key()`
- `__repr__()`

##### FixtureFunctionMarker

**M√©thodes :**

- `__post_init__()`
- `__call__()`

##### FixtureFunctionDefinition

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `__get__()`
- `__call__()`
- `_get_wrapped_function()`

##### FixtureManager

pytest fixture definitions and information is stored and managed
from this class.

During collection fm.parsefactories() is called multiple times to parse
fixture function definitions into FixtureDef objects and internal
data structures.

During collection of test functions, metafunc-mechanics instantiate
a FuncFixtureInfo object which is cached per node/func-name.
This FuncFixtureInfo object is later retrieved by Function nodes
which themselves offer a fixturenames attribute.

The FuncFixtureInfo object holds information about fixtures and FixtureDefs
relevant for a particular function. An initial list of fixtures is
assembled like this:

- ini-defined usefixtures
- autouse-marked fixtures along the collection chain up from the function
- usefixtures markers at module/class/function level
- test function funcargs

Subsequently the funcfixtureinfo.fixturenames attribute is computed
as the closure of the fixtures needed to setup the initial fixtures,
i.e. fixtures needed by fixture functions themselves are appended
to the fixturenames list.

Upon the test-setup phases all fixturenames are instantiated, retrieved
by a lookup of their FuncFixtureInfo.

**M√©thodes :**

- `__init__()`
- `getfixtureinfo()`
- `pytest_plugin_registered()`
- `_getautousenames()`
- `_getusefixturesnames()`
- `getfixtureclosure()`
- `pytest_generate_tests()`
- `pytest_collection_modifyitems()`
- `_register_fixture()`
- `parsefactories()`
- `parsefactories()`
- `parsefactories()`
- `getfixturedefs()`
- `_matchfactories()`

#### Fonctions

##### pytest_sessionstart

**Param√®tres :**

- `session`

##### get_scope_package

**Param√®tres :**

- `node`
- `fixturedef`

##### get_scope_node

Get the closest parent node (including self) which matches the given
scope.

If there is no parent node for the scope (e.g. asking for class scope on a
Module, or on a Function when not defined in a class), returns None.

**Param√®tres :**

- `node`
- `scope`

##### getfixturemarker

Return fixturemarker or None if it doesn't exist

**Param√®tres :**

- `obj`

##### get_param_argkeys

Return all ParamArgKeys for item matching the specified high scope.

**Param√®tres :**

- `item`
- `scope`

##### reorder_items

**Param√®tres :**

- `items`

##### reorder_items_atscope

**Param√®tres :**

- `items`
- `argkeys_by_item`
- `items_by_argkey`
- `scope`

##### call_fixture_func

**Param√®tres :**

- `fixturefunc`
- `request`
- `kwargs`

##### _teardown_yield_fixture

Execute the teardown of a fixture function by advancing the iterator
after the yield and ensure the iteration ends (if not it means there is
more than one yield in the function).

**Param√®tres :**

- `fixturefunc`
- `it`

##### _eval_scope_callable

**Param√®tres :**

- `scope_callable`
- `fixture_name`
- `config`

##### resolve_fixture_function

Get the actual callable that can be called to obtain the fixture
value.

**Param√®tres :**

- `fixturedef`
- `request`

##### pytest_fixture_setup

Execution of fixture setup.

**Param√®tres :**

- `fixturedef`
- `request`

##### fixture

**Param√®tres :**

- `fixture_function`

##### fixture

**Param√®tres :**

- `fixture_function`

##### fixture

Decorator to mark a fixture factory function.

This decorator can be used, with or without parameters, to define a
fixture function.

The name of the fixture function can later be referenced to cause its
invocation ahead of running tests: test modules or classes can use the
``pytest.mark.usefixtures(fixturename)`` marker.

Test functions can directly use fixture names as input arguments in which
case the fixture instance returned from the fixture function will be
injected.

Fixtures can provide their values to test functions using ``return`` or
``yield`` statements. When using ``yield`` the code block after the
``yield`` statement is executed as teardown code regardless of the test
outcome, and must yield exactly once.

:param scope:
    The scope for which this fixture is shared; one of ``"function"``
    (default), ``"class"``, ``"module"``, ``"package"`` or ``"session"``.

    This parameter may also be a callable which receives ``(fixture_name, config)``
    as parameters, and must return a ``str`` with one of the values mentioned above.

    See :ref:`dynamic scope` in the docs for more information.

:param params:
    An optional list of parameters which will cause multiple invocations
    of the fixture function and all of the tests using it. The current
    parameter is available in ``request.param``.

:param autouse:
    If True, the fixture func is activated for all tests that can see it.
    If False (the default), an explicit reference is needed to activate
    the fixture.

:param ids:
    Sequence of ids each corresponding to the params so that they are
    part of the test id. If no ids are provided they will be generated
    automatically from the params.

:param name:
    The name of the fixture. This defaults to the name of the decorated
    function. If a fixture is used in the same module in which it is
    defined, the function name of the fixture will be shadowed by the
    function arg that requests the fixture; one way to resolve this is to
    name the decorated function ``fixture_<fixturename>`` and then use
    ``@pytest.fixture(name='<fixturename>')``.

**Param√®tres :**

- `fixture_function`

##### yield_fixture

(Return a) decorator to mark a yield-fixture factory function.

.. deprecated:: 3.0
    Use :py:func:`pytest.fixture` directly instead.

**Param√®tres :**

- `fixture_function`

##### pytestconfig

Session-scoped fixture that returns the session's :class:`pytest.Config`
object.

Example::

    def test_foo(pytestconfig):
        if pytestconfig.get_verbosity() > 0:
            ...

**Param√®tres :**

- `request`

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_cmdline_main

**Param√®tres :**

- `config`

##### _get_direct_parametrize_args

Return all direct parametrization arguments of a node, so we don't
mistake them for fixtures.

Check https://github.com/pytest-dev/pytest/issues/5036.

These things are done later as well when dealing with parametrization
so this could be improved.

**Param√®tres :**

- `node`

##### deduplicate_names

De-duplicate the sequence of names while keeping the original order.

##### show_fixtures_per_test

**Param√®tres :**

- `config`

##### _pretty_fixture_path

**Param√®tres :**

- `invocation_dir`
- `func`

##### _show_fixtures_per_test

**Param√®tres :**

- `config`
- `session`

##### showfixtures

**Param√®tres :**

- `config`

##### _showfixtures_main

**Param√®tres :**

- `config`
- `session`

##### write_docstring

**Param√®tres :**

- `tw`
- `doc`
- `indent`

##### prune_dependency_tree

Recompute names_closure from initialnames and name2fixturedefs.

Can only reduce names_closure, which means that the new closure will
always be a subset of the old one. The order is preserved.

This method is needed because direct parametrization may shadow some
of the fixtures that were included in the originally built dependency
tree. In this way the dependency tree can get pruned, and the closure
of argnames may get reduced.

##### __init__

**Param√®tres :**

- `pyfuncitem`
- `fixturename`
- `arg2fixturedefs`
- `fixture_defs`

##### _fixturemanager

##### _scope

##### scope

Scope string, one of "function", "class", "module", "package", "session".

##### _check_scope

**Param√®tres :**

- `requested_fixturedef`
- `requested_scope`

##### fixturenames

Names of all active fixtures in this request.

##### node

Underlying collection node (depends on current request scope).

##### config

The pytest config object associated with this request.

##### function

Test function object if the request has a per-function scope.

##### cls

Class (can be None) where the test function was collected.

##### instance

Instance (can be None) on which test function was collected.

##### module

Python module object where the test function was collected.

##### path

Path where the test function was collected.

##### keywords

Keywords/markers dictionary for the underlying node.

##### session

Pytest session object.

##### addfinalizer

Add finalizer/teardown function to be called without arguments after
the last test within the requesting test context finished execution.

**Param√®tres :**

- `finalizer`

##### applymarker

Apply a marker to a single test function invocation.

This method is useful if you don't want to have a keyword/marker
on all function invocations.

:param marker:
    An object created by a call to ``pytest.mark.NAME(...)``.

**Param√®tres :**

- `marker`

##### raiseerror

Raise a FixtureLookupError exception.

:param msg:
    An optional custom error message.

**Param√®tres :**

- `msg`

##### getfixturevalue

Dynamically run a named fixture function.

Declaring fixtures via function argument is recommended where possible.
But if you can only decide whether to use another fixture at test
setup time, you may use this function to retrieve it inside a fixture
or test function body.

This method can be used during the test setup phase or the test run
phase, but during the test teardown phase a fixture's value may not
be available.

:param argname:
    The fixture name.
:raises pytest.FixtureLookupError:
    If the given fixture could not be found.

**Param√®tres :**

- `argname`

##### _iter_chain

Yield all SubRequests in the chain, from self up.

Note: does *not* yield the TopRequest.

##### _get_active_fixturedef

**Param√®tres :**

- `argname`

##### _check_fixturedef_without_param

Check that this request is allowed to execute this fixturedef without
a param.

**Param√®tres :**

- `fixturedef`

##### _get_fixturestack

##### __init__

**Param√®tres :**

- `pyfuncitem`

##### _scope

##### _check_scope

**Param√®tres :**

- `requested_fixturedef`
- `requested_scope`

##### node

##### __repr__

##### _fillfixtures

##### addfinalizer

**Param√®tres :**

- `finalizer`

##### __init__

**Param√®tres :**

- `request`
- `scope`
- `param`
- `param_index`
- `fixturedef`

##### __repr__

##### _scope

##### node

##### _check_scope

**Param√®tres :**

- `requested_fixturedef`
- `requested_scope`

##### _format_fixturedef_line

**Param√®tres :**

- `fixturedef`

##### addfinalizer

**Param√®tres :**

- `finalizer`

##### __init__

**Param√®tres :**

- `argname`
- `request`
- `msg`

##### formatrepr

##### __init__

**Param√®tres :**

- `filename`
- `firstlineno`
- `tblines`
- `errorstring`
- `argname`

##### toterminal

**Param√®tres :**

- `tw`

##### __init__

**Param√®tres :**

- `config`
- `baseid`
- `argname`
- `func`
- `scope`
- `params`
- `ids`

##### scope

Scope string, one of "function", "class", "module", "package", "session".

##### addfinalizer

**Param√®tres :**

- `finalizer`

##### finish

**Param√®tres :**

- `request`

##### execute

Return the value of this fixture, executing it if not cached.

**Param√®tres :**

- `request`

##### cache_key

**Param√®tres :**

- `request`

##### __repr__

##### __post_init__

**Param√®tres :**

- `_ispytest`

##### __call__

**Param√®tres :**

- `function`

##### __init__

##### __repr__

##### __get__

Behave like a method if the function it was applied to was a method.

**Param√®tres :**

- `instance`
- `owner`

##### __call__

##### _get_wrapped_function

##### __init__

**Param√®tres :**

- `session`

##### getfixtureinfo

Calculate the :class:`FuncFixtureInfo` for an item.

If ``func`` is None, or if the item sets an attribute
``nofuncargs = True``, then ``func`` is not examined at all.

:param node:
    The item requesting the fixtures.
:param func:
    The item's function.
:param cls:
    If the function is a method, the method's class.

**Param√®tres :**

- `node`
- `func`
- `cls`

##### pytest_plugin_registered

**Param√®tres :**

- `plugin`
- `plugin_name`

##### _getautousenames

Return the names of autouse fixtures applicable to node.

**Param√®tres :**

- `node`

##### _getusefixturesnames

Return the names of usefixtures fixtures applicable to node.

**Param√®tres :**

- `node`

##### getfixtureclosure

**Param√®tres :**

- `parentnode`
- `initialnames`
- `ignore_args`

##### pytest_generate_tests

Generate new tests based on parametrized fixtures used by the given metafunc

**Param√®tres :**

- `metafunc`

##### pytest_collection_modifyitems

**Param√®tres :**

- `items`

##### _register_fixture

Register a fixture

:param name:
    The fixture's name.
:param func:
    The fixture's implementation function.
:param nodeid:
    The visibility of the fixture. The fixture will be available to the
    node with this nodeid and its children in the collection tree.
    None means that the fixture is visible to the entire collection tree,
    e.g. a fixture defined for general use in a plugin.
:param scope:
    The fixture's scope.
:param params:
    The fixture's parametrization params.
:param ids:
    The fixture's IDs.
:param autouse:
    Whether this is an autouse fixture.

##### parsefactories

**Param√®tres :**

- `node_or_obj`

##### parsefactories

**Param√®tres :**

- `node_or_obj`
- `nodeid`

##### parsefactories

Collect fixtures from a collection node or object.

Found fixtures are parsed into `FixtureDef`s and saved.

If `node_or_object` is a collection node (with an underlying Python
object), the node's object is traversed and the node's nodeid is used to
determine the fixtures' visibility. `nodeid` must not be specified in
this case.

If `node_or_object` is an object (e.g. a plugin), the object is
traversed and the given `nodeid` is used to determine the fixtures'
visibility. `nodeid` must be specified in this case; None and "" mean
total visibility.

**Param√®tres :**

- `node_or_obj`
- `nodeid`

##### getfixturedefs

Get FixtureDefs for a fixture name which are applicable
to a given node.

Returns None if there are no fixtures at all defined with the given
name. (This is different from the case in which there are fixtures
with the given name, but none applicable to the node. In this case,
an empty result is returned).

:param argname: Name of the fixture to search for.
:param node: The requesting Node.

**Param√®tres :**

- `argname`
- `node`

##### _matchfactories

**Param√®tres :**

- `fixturedefs`
- `node`

##### get_best_relpath

**Param√®tres :**

- `func`

##### write_fixture

**Param√®tres :**

- `fixture_def`

##### write_item

**Param√®tres :**

- `item`

##### sort_by_scope

**Param√®tres :**

- `arg_name`

##### get_parametrize_mark_argnames

**Param√®tres :**

- `mark`

---

### freeze_support

Provides a function to report all internal modules for using freezing
tools.

#### Fonctions

##### freeze_includes

Return a list of module names used by pytest that should be
included by cx_freeze.

##### _iter_all_modules

Iterate over the names of all modules that can be found in the given
package, recursively.

    >>> import _pytest
    >>> list(_iter_all_modules(_pytest))
    ['_pytest._argcomplete', '_pytest._code.code', ...]

**Param√®tres :**

- `package`
- `prefix`

---

### helpconfig

Version info, help messages, tracing configuration.

#### Classes

##### HelpAction

An argparse Action that will raise an exception in order to skip the
rest of the argument parsing when --help is passed.

This prevents argparse from quitting due to missing required arguments
when any are defined, for example by ``pytest_addoption``.
This is similar to the way that the builtin argparse --help option is
implemented by raising SystemExit.

**M√©thodes :**

- `__init__()`
- `__call__()`

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_cmdline_parse

##### showversion

**Param√®tres :**

- `config`

##### pytest_cmdline_main

**Param√®tres :**

- `config`

##### showhelp

**Param√®tres :**

- `config`

##### getpluginversioninfo

**Param√®tres :**

- `config`

##### pytest_report_header

**Param√®tres :**

- `config`

##### __init__

**Param√®tres :**

- `option_strings`
- `dest`
- `default`
- `help`

##### __call__

**Param√®tres :**

- `parser`
- `namespace`
- `values`
- `option_string`

##### unset_tracing

---

### hookspec

Hook specifications for pytest plugins which are invoked by pytest itself
and by builtin plugins.

#### Fonctions

##### pytest_addhooks

Called at plugin registration time to allow adding new hooks via a call to
:func:`pluginmanager.add_hookspecs(module_or_class, prefix) <pytest.PytestPluginManager.add_hookspecs>`.

:param pluginmanager: The pytest plugin manager.

.. note::
    This hook is incompatible with hook wrappers.

Use in conftest plugins
=======================

If a conftest plugin implements this hook, it will be called immediately
when the conftest is registered.

**Param√®tres :**

- `pluginmanager`

##### pytest_plugin_registered

A new pytest plugin got registered.

:param plugin: The plugin module or instance.
:param plugin_name: The name by which the plugin is registered.
:param manager: The pytest plugin manager.

.. note::
    This hook is incompatible with hook wrappers.

Use in conftest plugins
=======================

If a conftest plugin implements this hook, it will be called immediately
when the conftest is registered, once for each plugin registered thus far
(including itself!), and for all plugins thereafter when they are
registered.

**Param√®tres :**

- `plugin`
- `plugin_name`
- `manager`

##### pytest_addoption

Register argparse-style options and ini-style config values,
called once at the beginning of a test run.

:param parser:
    To add command line options, call
    :py:func:`parser.addoption(...) <pytest.Parser.addoption>`.
    To add ini-file values call :py:func:`parser.addini(...)
    <pytest.Parser.addini>`.

:param pluginmanager:
    The pytest plugin manager, which can be used to install :py:func:`~pytest.hookspec`'s
    or :py:func:`~pytest.hookimpl`'s and allow one plugin to call another plugin's hooks
    to change how command line options are added.

Options can later be accessed through the
:py:class:`config <pytest.Config>` object, respectively:

- :py:func:`config.getoption(name) <pytest.Config.getoption>` to
  retrieve the value of a command line option.

- :py:func:`config.getini(name) <pytest.Config.getini>` to retrieve
  a value read from an ini-style file.

The config object is passed around on many internal objects via the ``.config``
attribute or can be retrieved as the ``pytestconfig`` fixture.

.. note::
    This hook is incompatible with hook wrappers.

Use in conftest plugins
=======================

If a conftest plugin implements this hook, it will be called immediately
when the conftest is registered.

This hook is only called for :ref:`initial conftests <pluginorder>`.

**Param√®tres :**

- `parser`
- `pluginmanager`

##### pytest_configure

Allow plugins and conftest files to perform initial configuration.

.. note::
    This hook is incompatible with hook wrappers.

:param config: The pytest config object.

Use in conftest plugins
=======================

This hook is called for every :ref:`initial conftest <pluginorder>` file
after command line options have been parsed. After that, the hook is called
for other conftest files as they are registered.

**Param√®tres :**

- `config`

##### pytest_cmdline_parse

Return an initialized :class:`~pytest.Config`, parsing the specified args.

Stops at first non-None result, see :ref:`firstresult`.

.. note::
    This hook is only called for plugin classes passed to the
    ``plugins`` arg when using `pytest.main`_ to perform an in-process
    test run.

:param pluginmanager: The pytest plugin manager.
:param args: List of arguments passed on the command line.
:returns: A pytest config object.

Use in conftest plugins
=======================

This hook is not called for conftest files.

**Param√®tres :**

- `pluginmanager`
- `args`

##### pytest_load_initial_conftests

Called to implement the loading of :ref:`initial conftest files
<pluginorder>` ahead of command line option parsing.

:param early_config: The pytest config object.
:param args: Arguments passed on the command line.
:param parser: To add command line options.

Use in conftest plugins
=======================

This hook is not called for conftest files.

**Param√®tres :**

- `early_config`
- `parser`
- `args`

##### pytest_cmdline_main

Called for performing the main command line action.

The default implementation will invoke the configure hooks and
:hook:`pytest_runtestloop`.

Stops at first non-None result, see :ref:`firstresult`.

:param config: The pytest config object.
:returns: The exit code.

Use in conftest plugins
=======================

This hook is only called for :ref:`initial conftests <pluginorder>`.

**Param√®tres :**

- `config`

##### pytest_collection

Perform the collection phase for the given session.

Stops at first non-None result, see :ref:`firstresult`.
The return value is not used, but only stops further processing.

The default collection phase is this (see individual hooks for full details):

1. Starting from ``session`` as the initial collector:

  1. ``pytest_collectstart(collector)``
  2. ``report = pytest_make_collect_report(collector)``
  3. ``pytest_exception_interact(collector, call, report)`` if an interactive exception occurred
  4. For each collected node:

    1. If an item, ``pytest_itemcollected(item)``
    2. If a collector, recurse into it.

  5. ``pytest_collectreport(report)``

2. ``pytest_collection_modifyitems(session, config, items)``

  1. ``pytest_deselected(items)`` for any deselected items (may be called multiple times)

3. ``pytest_collection_finish(session)``
4. Set ``session.items`` to the list of collected items
5. Set ``session.testscollected`` to the number of collected items

You can implement this hook to only perform some action before collection,
for example the terminal plugin uses it to start displaying the collection
counter (and returns `None`).

:param session: The pytest session object.

Use in conftest plugins
=======================

This hook is only called for :ref:`initial conftests <pluginorder>`.

**Param√®tres :**

- `session`

##### pytest_collection_modifyitems

Called after collection has been performed. May filter or re-order
the items in-place.

When items are deselected (filtered out from ``items``),
the hook :hook:`pytest_deselected` must be called explicitly
with the deselected items to properly notify other plugins,
e.g. with ``config.hook.pytest_deselected(items=deselected_items)``.

:param session: The pytest session object.
:param config: The pytest config object.
:param items: List of item objects.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `session`
- `config`
- `items`

##### pytest_collection_finish

Called after collection has been performed and modified.

:param session: The pytest session object.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `session`

##### pytest_ignore_collect

Return ``True`` to ignore this path for collection.

Return ``None`` to let other plugins ignore the path for collection.

Returning ``False`` will forcefully *not* ignore this path for collection,
without giving a chance for other plugins to ignore this path.

This hook is consulted for all files and directories prior to calling
more specific hooks.

Stops at first non-None result, see :ref:`firstresult`.

:param collection_path: The path to analyze.
:type collection_path: pathlib.Path
:param path: The path to analyze (deprecated).
:param config: The pytest config object.

.. versionchanged:: 7.0.0
    The ``collection_path`` parameter was added as a :class:`pathlib.Path`
    equivalent of the ``path`` parameter. The ``path`` parameter
    has been deprecated.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given collection path, only
conftest files in parent directories of the collection path are consulted
(if the path is a directory, its own conftest file is *not* consulted - a
directory cannot ignore itself!).

**Param√®tres :**

- `collection_path`
- `path`
- `config`

##### pytest_collect_directory

Create a :class:`~pytest.Collector` for the given directory, or None if
not relevant.

.. versionadded:: 8.0

For best results, the returned collector should be a subclass of
:class:`~pytest.Directory`, but this is not required.

The new node needs to have the specified ``parent`` as a parent.

Stops at first non-None result, see :ref:`firstresult`.

:param path: The path to analyze.
:type path: pathlib.Path

See :ref:`custom directory collectors` for a simple example of use of this
hook.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given collection path, only
conftest files in parent directories of the collection path are consulted
(if the path is a directory, its own conftest file is *not* consulted - a
directory cannot collect itself!).

**Param√®tres :**

- `path`
- `parent`

##### pytest_collect_file

Create a :class:`~pytest.Collector` for the given path, or None if not relevant.

For best results, the returned collector should be a subclass of
:class:`~pytest.File`, but this is not required.

The new node needs to have the specified ``parent`` as a parent.

:param file_path: The path to analyze.
:type file_path: pathlib.Path
:param path: The path to collect (deprecated).

.. versionchanged:: 7.0.0
    The ``file_path`` parameter was added as a :class:`pathlib.Path`
    equivalent of the ``path`` parameter. The ``path`` parameter
    has been deprecated.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given file path, only
conftest files in parent directories of the file path are consulted.

**Param√®tres :**

- `file_path`
- `path`
- `parent`

##### pytest_collectstart

Collector starts collecting.

:param collector:
    The collector.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given collector, only
conftest files in the collector's directory and its parent directories are
consulted.

**Param√®tres :**

- `collector`

##### pytest_itemcollected

We just collected a test item.

:param item:
    The item.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `item`

##### pytest_collectreport

Collector finished collecting.

:param report:
    The collect report.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given collector, only
conftest files in the collector's directory and its parent directories are
consulted.

**Param√®tres :**

- `report`

##### pytest_deselected

Called for deselected test items, e.g. by keyword.

Note that this hook has two integration aspects for plugins:

- it can be *implemented* to be notified of deselected items
- it must be *called* from :hook:`pytest_collection_modifyitems`
  implementations when items are deselected (to properly notify other plugins).

May be called multiple times.

:param items:
    The items.

Use in conftest plugins
=======================

Any conftest file can implement this hook.

**Param√®tres :**

- `items`

##### pytest_make_collect_report

Perform :func:`collector.collect() <pytest.Collector.collect>` and return
a :class:`~pytest.CollectReport`.

Stops at first non-None result, see :ref:`firstresult`.

:param collector:
    The collector.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given collector, only
conftest files in the collector's directory and its parent directories are
consulted.

**Param√®tres :**

- `collector`

##### pytest_pycollect_makemodule

Return a :class:`pytest.Module` collector or None for the given path.

This hook will be called for each matching test module path.
The :hook:`pytest_collect_file` hook needs to be used if you want to
create test modules for files that do not match as a test module.

Stops at first non-None result, see :ref:`firstresult`.

:param module_path: The path of the module to collect.
:type module_path: pathlib.Path
:param path: The path of the module to collect (deprecated).

.. versionchanged:: 7.0.0
    The ``module_path`` parameter was added as a :class:`pathlib.Path`
    equivalent of the ``path`` parameter.

    The ``path`` parameter has been deprecated in favor of ``fspath``.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given parent collector,
only conftest files in the collector's directory and its parent directories
are consulted.

**Param√®tres :**

- `module_path`
- `path`
- `parent`

##### pytest_pycollect_makeitem

Return a custom item/collector for a Python object in a module, or None.

Stops at first non-None result, see :ref:`firstresult`.

:param collector:
    The module/class collector.
:param name:
    The name of the object in the module/class.
:param obj:
    The object.
:returns:
    The created items/collectors.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given collector, only
conftest files in the collector's directory and its parent directories
are consulted.

**Param√®tres :**

- `collector`
- `name`
- `obj`

##### pytest_pyfunc_call

Call underlying test function.

Stops at first non-None result, see :ref:`firstresult`.

:param pyfuncitem:
    The function item.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only
conftest files in the item's directory and its parent directories
are consulted.

**Param√®tres :**

- `pyfuncitem`

##### pytest_generate_tests

Generate (multiple) parametrized calls to a test function.

:param metafunc:
    The :class:`~pytest.Metafunc` helper for the test function.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given function definition,
only conftest files in the functions's directory and its parent directories
are consulted.

**Param√®tres :**

- `metafunc`

##### pytest_make_parametrize_id

Return a user-friendly string representation of the given ``val``
that will be used by @pytest.mark.parametrize calls, or None if the hook
doesn't know about ``val``.

The parameter name is available as ``argname``, if required.

Stops at first non-None result, see :ref:`firstresult`.

:param config: The pytest config object.
:param val: The parametrized value.
:param argname: The automatic parameter name produced by pytest.

Use in conftest plugins
=======================

Any conftest file can implement this hook.

**Param√®tres :**

- `config`
- `val`
- `argname`

##### pytest_runtestloop

Perform the main runtest loop (after collection finished).

The default hook implementation performs the runtest protocol for all items
collected in the session (``session.items``), unless the collection failed
or the ``collectonly`` pytest option is set.

If at any point :py:func:`pytest.exit` is called, the loop is
terminated immediately.

If at any point ``session.shouldfail`` or ``session.shouldstop`` are set, the
loop is terminated after the runtest protocol for the current item is finished.

:param session: The pytest session object.

Stops at first non-None result, see :ref:`firstresult`.
The return value is not used, but only stops further processing.

Use in conftest plugins
=======================

Any conftest file can implement this hook.

**Param√®tres :**

- `session`

##### pytest_runtest_protocol

Perform the runtest protocol for a single test item.

The default runtest protocol is this (see individual hooks for full details):

- ``pytest_runtest_logstart(nodeid, location)``

- Setup phase:
    - ``call = pytest_runtest_setup(item)`` (wrapped in ``CallInfo(when="setup")``)
    - ``report = pytest_runtest_makereport(item, call)``
    - ``pytest_runtest_logreport(report)``
    - ``pytest_exception_interact(call, report)`` if an interactive exception occurred

- Call phase, if the setup passed and the ``setuponly`` pytest option is not set:
    - ``call = pytest_runtest_call(item)`` (wrapped in ``CallInfo(when="call")``)
    - ``report = pytest_runtest_makereport(item, call)``
    - ``pytest_runtest_logreport(report)``
    - ``pytest_exception_interact(call, report)`` if an interactive exception occurred

- Teardown phase:
    - ``call = pytest_runtest_teardown(item, nextitem)`` (wrapped in ``CallInfo(when="teardown")``)
    - ``report = pytest_runtest_makereport(item, call)``
    - ``pytest_runtest_logreport(report)``
    - ``pytest_exception_interact(call, report)`` if an interactive exception occurred

- ``pytest_runtest_logfinish(nodeid, location)``

:param item: Test item for which the runtest protocol is performed.
:param nextitem: The scheduled-to-be-next test item (or None if this is the end my friend).

Stops at first non-None result, see :ref:`firstresult`.
The return value is not used, but only stops further processing.

Use in conftest plugins
=======================

Any conftest file can implement this hook.

**Param√®tres :**

- `item`
- `nextitem`

##### pytest_runtest_logstart

Called at the start of running the runtest protocol for a single item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

:param nodeid: Full node ID of the item.
:param location: A tuple of ``(filename, lineno, testname)``
    where ``filename`` is a file path relative to ``config.rootpath``
    and ``lineno`` is 0-based.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `nodeid`
- `location`

##### pytest_runtest_logfinish

Called at the end of running the runtest protocol for a single item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

:param nodeid: Full node ID of the item.
:param location: A tuple of ``(filename, lineno, testname)``
    where ``filename`` is a file path relative to ``config.rootpath``
    and ``lineno`` is 0-based.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `nodeid`
- `location`

##### pytest_runtest_setup

Called to perform the setup phase for a test item.

The default implementation runs ``setup()`` on ``item`` and all of its
parents (which haven't been setup yet). This includes obtaining the
values of fixtures required by the item (which haven't been obtained
yet).

:param item:
    The item.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `item`

##### pytest_runtest_call

Called to run the test for test item (the call phase).

The default implementation calls ``item.runtest()``.

:param item:
    The item.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

Called to perform the teardown phase for a test item.

The default implementation runs the finalizers and calls ``teardown()``
on ``item`` and all of its parents (which need to be torn down). This
includes running the teardown phase of fixtures required by the item (if
they go out of scope).

:param item:
    The item.
:param nextitem:
    The scheduled-to-be-next test item (None if no further test item is
    scheduled). This argument is used to perform exact teardowns, i.e.
    calling just enough finalizers so that nextitem only needs to call
    setup functions.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `item`
- `nextitem`

##### pytest_runtest_makereport

Called to create a :class:`~pytest.TestReport` for each of
the setup, call and teardown runtest phases of a test item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

:param item: The item.
:param call: The :class:`~pytest.CallInfo` for the phase.

Stops at first non-None result, see :ref:`firstresult`.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `item`
- `call`

##### pytest_runtest_logreport

Process the :class:`~pytest.TestReport` produced for each
of the setup, call and teardown runtest phases of an item.

See :hook:`pytest_runtest_protocol` for a description of the runtest protocol.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `report`

##### pytest_report_to_serializable

Serialize the given report object into a data structure suitable for
sending over the wire, e.g. converted to JSON.

:param config: The pytest config object.
:param report: The report.

Use in conftest plugins
=======================

Any conftest file can implement this hook. The exact details may depend
on the plugin which calls the hook.

**Param√®tres :**

- `config`
- `report`

##### pytest_report_from_serializable

Restore a report object previously serialized with
:hook:`pytest_report_to_serializable`.

:param config: The pytest config object.

Use in conftest plugins
=======================

Any conftest file can implement this hook. The exact details may depend
on the plugin which calls the hook.

**Param√®tres :**

- `config`
- `data`

##### pytest_fixture_setup

Perform fixture setup execution.

:param fixturedef:
    The fixture definition object.
:param request:
    The fixture request object.
:returns:
    The return value of the call to the fixture function.

Stops at first non-None result, see :ref:`firstresult`.

.. note::
    If the fixture function returns None, other implementations of
    this hook function will continue to be called, according to the
    behavior of the :ref:`firstresult` option.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given fixture, only
conftest files in the fixture scope's directory and its parent directories
are consulted.

**Param√®tres :**

- `fixturedef`
- `request`

##### pytest_fixture_post_finalizer

Called after fixture teardown, but before the cache is cleared, so
the fixture result ``fixturedef.cached_result`` is still available (not
``None``).

:param fixturedef:
    The fixture definition object.
:param request:
    The fixture request object.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given fixture, only
conftest files in the fixture scope's directory and its parent directories
are consulted.

**Param√®tres :**

- `fixturedef`
- `request`

##### pytest_sessionstart

Called after the ``Session`` object has been created and before performing collection
and entering the run test loop.

:param session: The pytest session object.

Use in conftest plugins
=======================

This hook is only called for :ref:`initial conftests <pluginorder>`.

**Param√®tres :**

- `session`

##### pytest_sessionfinish

Called after whole test run finished, right before returning the exit status to the system.

:param session: The pytest session object.
:param exitstatus: The status which pytest will return to the system.

Use in conftest plugins
=======================

Any conftest file can implement this hook.

**Param√®tres :**

- `session`
- `exitstatus`

##### pytest_unconfigure

Called before test process is exited.

:param config: The pytest config object.

Use in conftest plugins
=======================

Any conftest file can implement this hook.

**Param√®tres :**

- `config`

##### pytest_assertrepr_compare

Return explanation for comparisons in failing assert expressions.

Return None for no custom explanation, otherwise return a list
of strings. The strings will be joined by newlines but any newlines
*in* a string will be escaped. Note that all but the first line will
be indented slightly, the intention is for the first line to be a summary.

:param config: The pytest config object.
:param op: The operator, e.g. `"=="`, `"!="`, `"not in"`.
:param left: The left operand.
:param right: The right operand.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `config`
- `op`
- `left`
- `right`

##### pytest_assertion_pass

Called whenever an assertion passes.

.. versionadded:: 5.0

Use this hook to do some processing after a passing assertion.
The original assertion information is available in the `orig` string
and the pytest introspected assertion information is available in the
`expl` string.

This hook must be explicitly enabled by the ``enable_assertion_pass_hook``
ini-file option:

.. code-block:: ini

    [pytest]
    enable_assertion_pass_hook=true

You need to **clean the .pyc** files in your project directory and interpreter libraries
when enabling this option, as assertions will require to be re-written.

:param item: pytest item object of current test.
:param lineno: Line number of the assert statement.
:param orig: String with the original assertion.
:param expl: String with the assert explanation.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in the item's directory and its parent directories are consulted.

**Param√®tres :**

- `item`
- `lineno`
- `orig`
- `expl`

##### pytest_report_header

Return a string or list of strings to be displayed as header info for terminal reporting.

:param config: The pytest config object.
:param start_path: The starting dir.
:type start_path: pathlib.Path
:param startdir: The starting dir (deprecated).

.. note::

    Lines returned by a plugin are displayed before those of plugins which
    ran before it.
    If you want to have your line(s) displayed first, use
    :ref:`trylast=True <plugin-hookorder>`.

.. versionchanged:: 7.0.0
    The ``start_path`` parameter was added as a :class:`pathlib.Path`
    equivalent of the ``startdir`` parameter. The ``startdir`` parameter
    has been deprecated.

Use in conftest plugins
=======================

This hook is only called for :ref:`initial conftests <pluginorder>`.

**Param√®tres :**

- `config`
- `start_path`
- `startdir`

##### pytest_report_collectionfinish

Return a string or list of strings to be displayed after collection
has finished successfully.

These strings will be displayed after the standard "collected X items" message.

.. versionadded:: 3.2

:param config: The pytest config object.
:param start_path: The starting dir.
:type start_path: pathlib.Path
:param startdir: The starting dir (deprecated).
:param items: List of pytest items that are going to be executed; this list should not be modified.

.. note::

    Lines returned by a plugin are displayed before those of plugins which
    ran before it.
    If you want to have your line(s) displayed first, use
    :ref:`trylast=True <plugin-hookorder>`.

.. versionchanged:: 7.0.0
    The ``start_path`` parameter was added as a :class:`pathlib.Path`
    equivalent of the ``startdir`` parameter. The ``startdir`` parameter
    has been deprecated.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `config`
- `start_path`
- `startdir`
- `items`

##### pytest_report_teststatus

Return result-category, shortletter and verbose word for status
reporting.

The result-category is a category in which to count the result, for
example "passed", "skipped", "error" or the empty string.

The shortletter is shown as testing progresses, for example ".", "s",
"E" or the empty string.

The verbose word is shown as testing progresses in verbose mode, for
example "PASSED", "SKIPPED", "ERROR" or the empty string.

pytest may style these implicitly according to the report outcome.
To provide explicit styling, return a tuple for the verbose word,
for example ``"rerun", "R", ("RERUN", {"yellow": True})``.

:param report: The report object whose status is to be returned.
:param config: The pytest config object.
:returns: The test status.

Stops at first non-None result, see :ref:`firstresult`.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `report`
- `config`

##### pytest_terminal_summary

Add a section to terminal summary reporting.

:param terminalreporter: The internal terminal reporter object.
:param exitstatus: The exit status that will be reported back to the OS.
:param config: The pytest config object.

.. versionadded:: 4.2
    The ``config`` parameter.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `terminalreporter`
- `exitstatus`
- `config`

##### pytest_warning_recorded

Process a warning captured by the internal pytest warnings plugin.

:param warning_message:
    The captured warning. This is the same object produced by :class:`warnings.catch_warnings`,
    and contains the same attributes as the parameters of :py:func:`warnings.showwarning`.

:param when:
    Indicates when the warning was captured. Possible values:

    * ``"config"``: during pytest configuration/initialization stage.
    * ``"collect"``: during test collection.
    * ``"runtest"``: during test execution.

:param nodeid:
    Full id of the item. Empty string for warnings that are not specific to
    a particular node.

:param location:
    When available, holds information about the execution context of the captured
    warning (filename, linenumber, function). ``function`` evaluates to <module>
    when the execution context is at the module level.

.. versionadded:: 6.0

Use in conftest plugins
=======================

Any conftest file can implement this hook. If the warning is specific to a
particular node, only conftest files in parent directories of the node are
consulted.

**Param√®tres :**

- `warning_message`
- `when`
- `nodeid`
- `location`

##### pytest_markeval_namespace

Called when constructing the globals dictionary used for
evaluating string conditions in xfail/skipif markers.

This is useful when the condition for a marker requires
objects that are expensive or impossible to obtain during
collection time, which is required by normal boolean
conditions.

.. versionadded:: 6.2

:param config: The pytest config object.
:returns: A dictionary of additional globals to add.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given item, only conftest
files in parent directories of the item are consulted.

**Param√®tres :**

- `config`

##### pytest_internalerror

Called for internal errors.

Return True to suppress the fallback handling of printing an
INTERNALERROR message directly to sys.stderr.

:param excrepr: The exception repr object.
:param excinfo: The exception info.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `excrepr`
- `excinfo`

##### pytest_keyboard_interrupt

Called for keyboard interrupt.

:param excinfo: The exception info.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `excinfo`

##### pytest_exception_interact

Called when an exception was raised which can potentially be
interactively handled.

May be called during collection (see :hook:`pytest_make_collect_report`),
in which case ``report`` is a :class:`~pytest.CollectReport`.

May be called during runtest of an item (see :hook:`pytest_runtest_protocol`),
in which case ``report`` is a :class:`~pytest.TestReport`.

This hook is not called if the exception that was raised is an internal
exception like ``skip.Exception``.

:param node:
    The item or collector.
:param call:
    The call information. Contains the exception.
:param report:
    The collection or test report.

Use in conftest plugins
=======================

Any conftest file can implement this hook. For a given node, only conftest
files in parent directories of the node are consulted.

**Param√®tres :**

- `node`
- `call`
- `report`

##### pytest_enter_pdb

Called upon pdb.set_trace().

Can be used by plugins to take special action just before the python
debugger enters interactive mode.

:param config: The pytest config object.
:param pdb: The Pdb instance.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `config`
- `pdb`

##### pytest_leave_pdb

Called when leaving pdb (e.g. with continue after pdb.set_trace()).

Can be used by plugins to take special action just after the python
debugger leaves interactive mode.

:param config: The pytest config object.
:param pdb: The Pdb instance.

Use in conftest plugins
=======================

Any conftest plugin can implement this hook.

**Param√®tres :**

- `config`
- `pdb`

---

### junitxml

Report test results in JUnit-XML format, for use with Jenkins and build
integration servers.

Based on initial code from Ross Lawley.

Output conforms to
https://github.com/jenkinsci/xunit-plugin/blob/master/src/main/resources/org/jenkinsci/plugins/xunit/types/model/xsd/junit-10.xsd

#### Classes

##### _NodeReporter

**M√©thodes :**

- `__init__()`
- `append()`
- `add_property()`
- `add_attribute()`
- `make_properties_node()`
- `record_testreport()`
- `to_xml()`
- `_add_simple()`
- `write_captured_output()`
- `_prepare_content()`
- `_write_content()`
- `append_pass()`
- `append_failure()`
- `append_collect_error()`
- `append_collect_skipped()`
- `append_error()`
- `append_skipped()`
- `finalize()`

##### LogXML

**M√©thodes :**

- `__init__()`
- `finalize()`
- `node_reporter()`
- `add_stats()`
- `_opentestcase()`
- `pytest_runtest_logreport()`
- `update_testcase_duration()`
- `pytest_collectreport()`
- `pytest_internalerror()`
- `pytest_sessionstart()`
- `pytest_sessionfinish()`
- `pytest_terminal_summary()`
- `add_global_property()`
- `_get_global_properties_node()`

#### Fonctions

##### bin_xml_escape

Visually escape invalid XML characters.

For example, transforms
    'hello\aworld\b'
into
    'hello#x07world#x08'
Note that the #xABs are *not* XML escapes - missing the ampersand &#xAB.
The idea is to escape visually for the user rather than for XML itself.

**Param√®tres :**

- `arg`

##### merge_family

**Param√®tres :**

- `left`
- `right`

##### _warn_incompatibility_with_xunit2

Emit a PytestWarning about the given fixture being incompatible with newer xunit revisions.

**Param√®tres :**

- `request`
- `fixture_name`

##### record_property

Add extra properties to the calling test.

User properties become part of the test report and are available to the
configured reporters, like JUnit XML.

The fixture is callable with ``name, value``. The value is automatically
XML-encoded.

Example::

    def test_function(record_property):
        record_property("example_key", 1)

**Param√®tres :**

- `request`

##### record_xml_attribute

Add extra xml attributes to the tag for the calling test.

The fixture is callable with ``name, value``. The value is
automatically XML-encoded.

**Param√®tres :**

- `request`

##### _check_record_param_type

Used by record_testsuite_property to check that the given parameter name is of the proper
type.

**Param√®tres :**

- `param`
- `v`

##### record_testsuite_property

Record a new ``<property>`` tag as child of the root ``<testsuite>``.

This is suitable to writing global information regarding the entire test
suite, and is compatible with ``xunit2`` JUnit family.

This is a ``session``-scoped fixture which is called with ``(name, value)``. Example:

.. code-block:: python

    def test_foo(record_testsuite_property):
        record_testsuite_property("ARCH", "PPC")
        record_testsuite_property("STORAGE_TYPE", "CEPH")

:param name:
    The property name.
:param value:
    The property value. Will be converted to a string.

.. warning::

    Currently this fixture **does not work** with the
    `pytest-xdist <https://github.com/pytest-dev/pytest-xdist>`__ plugin. See
    :issue:`7767` for details.

**Param√®tres :**

- `request`

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### pytest_unconfigure

**Param√®tres :**

- `config`

##### mangle_test_address

**Param√®tres :**

- `address`

##### repl

**Param√®tres :**

- `matchobj`

##### __init__

**Param√®tres :**

- `nodeid`
- `xml`

##### append

**Param√®tres :**

- `node`

##### add_property

**Param√®tres :**

- `name`
- `value`

##### add_attribute

**Param√®tres :**

- `name`
- `value`

##### make_properties_node

Return a Junit node containing custom properties, if any.

##### record_testreport

**Param√®tres :**

- `testreport`

##### to_xml

##### _add_simple

**Param√®tres :**

- `tag`
- `message`
- `data`

##### write_captured_output

**Param√®tres :**

- `report`

##### _prepare_content

**Param√®tres :**

- `content`
- `header`

##### _write_content

**Param√®tres :**

- `report`
- `content`
- `jheader`

##### append_pass

**Param√®tres :**

- `report`

##### append_failure

**Param√®tres :**

- `report`

##### append_collect_error

**Param√®tres :**

- `report`

##### append_collect_skipped

**Param√®tres :**

- `report`

##### append_error

**Param√®tres :**

- `report`

##### append_skipped

**Param√®tres :**

- `report`

##### finalize

##### append_property

**Param√®tres :**

- `name`
- `value`

##### add_attr_noop

**Param√®tres :**

- `name`
- `value`

##### record_func

No-op function in case --junit-xml was not passed in the command-line.

**Param√®tres :**

- `name`
- `value`

##### __init__

**Param√®tres :**

- `logfile`
- `prefix`
- `suite_name`
- `logging`
- `report_duration`
- `family`
- `log_passing_tests`

##### finalize

**Param√®tres :**

- `report`

##### node_reporter

**Param√®tres :**

- `report`

##### add_stats

**Param√®tres :**

- `key`

##### _opentestcase

**Param√®tres :**

- `report`

##### pytest_runtest_logreport

Handle a setup/call/teardown report, generating the appropriate
XML tags as necessary.

Note: due to plugins like xdist, this hook may be called in interlaced
order with reports from other nodes. For example:

Usual call order:
    -> setup node1
    -> call node1
    -> teardown node1
    -> setup node2
    -> call node2
    -> teardown node2

Possible call order in xdist:
    -> setup node1
    -> call node1
    -> setup node2
    -> call node2
    -> teardown node2
    -> teardown node1

**Param√®tres :**

- `report`

##### update_testcase_duration

Accumulate total duration for nodeid from given report and update
the Junit.testcase with the new total if already created.

**Param√®tres :**

- `report`

##### pytest_collectreport

**Param√®tres :**

- `report`

##### pytest_internalerror

**Param√®tres :**

- `excrepr`

##### pytest_sessionstart

##### pytest_sessionfinish

##### pytest_terminal_summary

**Param√®tres :**

- `terminalreporter`

##### add_global_property

**Param√®tres :**

- `name`
- `value`

##### _get_global_properties_node

Return a Junit node containing custom properties, if any.

---

### legacypath

Add backward compatibility support for the legacy py path type.

#### Classes

##### Testdir

Similar to :class:`Pytester`, but this class works with legacy legacy_path objects instead.

All methods just forward to an internal :class:`Pytester` instance, converting results
to `legacy_path` objects as necessary.

**M√©thodes :**

- `__init__()`
- `tmpdir()`
- `test_tmproot()`
- `request()`
- `plugins()`
- `plugins()`
- `monkeypatch()`
- `make_hook_recorder()`
- `chdir()`
- `finalize()`
- `makefile()`
- `makeconftest()`
- `makeini()`
- `getinicfg()`
- `makepyprojecttoml()`
- `makepyfile()`
- `maketxtfile()`
- `syspathinsert()`
- `mkdir()`
- `mkpydir()`
- `copy_example()`
- `getnode()`
- `getpathnode()`
- `genitems()`
- `runitem()`
- `inline_runsource()`
- `inline_genitems()`
- `inline_run()`
- `runpytest_inprocess()`
- `runpytest()`
- `parseconfig()`
- `parseconfigure()`
- `getitem()`
- `getitems()`
- `getmodulecol()`
- `collect_by_name()`
- `popen()`
- `run()`
- `runpython()`
- `runpython_c()`
- `runpytest_subprocess()`
- `spawn_pytest()`
- `spawn()`
- `__repr__()`
- `__str__()`

##### LegacyTestdirPlugin

**M√©thodes :**

- `testdir()`

##### TempdirFactory

Backward compatibility wrapper that implements ``py.path.local``
for :class:`TempPathFactory`.

.. note::
    These days, it is preferred to use ``tmp_path_factory``.

    :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.

**M√©thodes :**

- `__init__()`
- `mktemp()`
- `getbasetemp()`

##### LegacyTmpdirPlugin

**M√©thodes :**

- `tmpdir_factory()`
- `tmpdir()`

#### Fonctions

##### Cache_makedir

Return a directory path object with the given name.

Same as :func:`mkdir`, but returns a legacy py path instance.

**Param√®tres :**

- `name`

##### FixtureRequest_fspath

(deprecated) The file system path of the test module which collected this test.

##### TerminalReporter_startdir

The directory from which pytest was invoked.

Prefer to use ``startpath`` which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

##### Config_invocation_dir

The directory from which pytest was invoked.

Prefer to use :attr:`invocation_params.dir <InvocationParams.dir>`,
which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

##### Config_rootdir

The path to the :ref:`rootdir <rootdir>`.

Prefer to use :attr:`rootpath`, which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

##### Config_inifile

The path to the :ref:`configfile <configfiles>`.

Prefer to use :attr:`inipath`, which is a :class:`pathlib.Path`.

:type: Optional[LEGACY_PATH]

##### Session_startdir

The path from which pytest was invoked.

Prefer to use ``startpath`` which is a :class:`pathlib.Path`.

:type: LEGACY_PATH

##### Config__getini_unknown_type

**Param√®tres :**

- `name`
- `type`
- `value`

##### Node_fspath

(deprecated) returns a legacy_path copy of self.path

##### Node_fspath_set

**Param√®tres :**

- `value`

##### pytest_load_initial_conftests

Monkeypatch legacy path attributes in several classes, as early as possible.

**Param√®tres :**

- `early_config`

##### pytest_configure

Installs the LegacyTmpdirPlugin if the ``tmpdir`` plugin is also installed.

**Param√®tres :**

- `config`

##### pytest_plugin_registered

**Param√®tres :**

- `plugin`
- `manager`

##### __init__

**Param√®tres :**

- `pytester`

##### tmpdir

Temporary directory where tests are executed.

##### test_tmproot

##### request

##### plugins

##### plugins

**Param√®tres :**

- `plugins`

##### monkeypatch

##### make_hook_recorder

See :meth:`Pytester.make_hook_recorder`.

**Param√®tres :**

- `pluginmanager`

##### chdir

See :meth:`Pytester.chdir`.

##### finalize

##### makefile

See :meth:`Pytester.makefile`.

**Param√®tres :**

- `ext`

##### makeconftest

See :meth:`Pytester.makeconftest`.

**Param√®tres :**

- `source`

##### makeini

See :meth:`Pytester.makeini`.

**Param√®tres :**

- `source`

##### getinicfg

See :meth:`Pytester.getinicfg`.

**Param√®tres :**

- `source`

##### makepyprojecttoml

See :meth:`Pytester.makepyprojecttoml`.

**Param√®tres :**

- `source`

##### makepyfile

See :meth:`Pytester.makepyfile`.

##### maketxtfile

See :meth:`Pytester.maketxtfile`.

##### syspathinsert

See :meth:`Pytester.syspathinsert`.

**Param√®tres :**

- `path`

##### mkdir

See :meth:`Pytester.mkdir`.

**Param√®tres :**

- `name`

##### mkpydir

See :meth:`Pytester.mkpydir`.

**Param√®tres :**

- `name`

##### copy_example

See :meth:`Pytester.copy_example`.

**Param√®tres :**

- `name`

##### getnode

See :meth:`Pytester.getnode`.

**Param√®tres :**

- `config`
- `arg`

##### getpathnode

See :meth:`Pytester.getpathnode`.

**Param√®tres :**

- `path`

##### genitems

See :meth:`Pytester.genitems`.

**Param√®tres :**

- `colitems`

##### runitem

See :meth:`Pytester.runitem`.

**Param√®tres :**

- `source`

##### inline_runsource

See :meth:`Pytester.inline_runsource`.

**Param√®tres :**

- `source`

##### inline_genitems

See :meth:`Pytester.inline_genitems`.

##### inline_run

See :meth:`Pytester.inline_run`.

##### runpytest_inprocess

See :meth:`Pytester.runpytest_inprocess`.

##### runpytest

See :meth:`Pytester.runpytest`.

##### parseconfig

See :meth:`Pytester.parseconfig`.

##### parseconfigure

See :meth:`Pytester.parseconfigure`.

##### getitem

See :meth:`Pytester.getitem`.

**Param√®tres :**

- `source`
- `funcname`

##### getitems

See :meth:`Pytester.getitems`.

**Param√®tres :**

- `source`

##### getmodulecol

See :meth:`Pytester.getmodulecol`.

**Param√®tres :**

- `source`
- `configargs`
- `withinit`

##### collect_by_name

See :meth:`Pytester.collect_by_name`.

**Param√®tres :**

- `modcol`
- `name`

##### popen

See :meth:`Pytester.popen`.

**Param√®tres :**

- `cmdargs`
- `stdout`
- `stderr`
- `stdin`

##### run

See :meth:`Pytester.run`.

##### runpython

See :meth:`Pytester.runpython`.

**Param√®tres :**

- `script`

##### runpython_c

See :meth:`Pytester.runpython_c`.

**Param√®tres :**

- `command`

##### runpytest_subprocess

See :meth:`Pytester.runpytest_subprocess`.

##### spawn_pytest

See :meth:`Pytester.spawn_pytest`.

**Param√®tres :**

- `string`
- `expect_timeout`

##### spawn

See :meth:`Pytester.spawn`.

**Param√®tres :**

- `cmd`
- `expect_timeout`

##### __repr__

##### __str__

##### testdir

Identical to :fixture:`pytester`, and provides an instance whose methods return
legacy ``LEGACY_PATH`` objects instead when applicable.

New code should avoid using :fixture:`testdir` in favor of :fixture:`pytester`.

**Param√®tres :**

- `pytester`

##### __init__

**Param√®tres :**

- `tmppath_factory`

##### mktemp

Same as :meth:`TempPathFactory.mktemp`, but returns a ``py.path.local`` object.

**Param√®tres :**

- `basename`
- `numbered`

##### getbasetemp

Same as :meth:`TempPathFactory.getbasetemp`, but returns a ``py.path.local`` object.

##### tmpdir_factory

Return a :class:`pytest.TempdirFactory` instance for the test session.

**Param√®tres :**

- `request`

##### tmpdir

Return a temporary directory (as `legacy_path`_ object)
which is unique to each test function invocation.
The temporary directory is created as a subdirectory
of the base temporary directory, with configurable retention,
as discussed in :ref:`temporary directory location and retention`.

.. note::
    These days, it is preferred to use ``tmp_path``.

    :ref:`About the tmpdir and tmpdir_factory fixtures<tmpdir and tmpdir_factory>`.

.. _legacy_path: https://py.readthedocs.io/en/latest/path.html

**Param√®tres :**

- `tmp_path`

---

### logging

Access and control log capturing.

#### Classes

##### DatetimeFormatter

A logging formatter which formats record with
:func:`datetime.datetime.strftime` formatter instead of
:func:`time.strftime` in case of microseconds in format string.

**M√©thodes :**

- `formatTime()`

##### ColoredLevelFormatter

A logging formatter which colorizes the %(levelname)..s part of the
log format passed to __init__.

**M√©thodes :**

- `__init__()`
- `add_color_level()`
- `format()`

##### PercentStyleMultiline

A logging style with special support for multiline messages.

If the message of a record consists of multiple lines, this style
formats the message as if each line were logged separately.

**M√©thodes :**

- `__init__()`
- `_get_auto_indent()`
- `format()`

##### catching_logs

Context manager that prepares the whole logging machinery properly.

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### LogCaptureHandler

A logging handler that stores log records and the log text.

**M√©thodes :**

- `__init__()`
- `emit()`
- `reset()`
- `clear()`
- `handleError()`

##### LogCaptureFixture

Provides access and control of log capturing.

**M√©thodes :**

- `__init__()`
- `_finalize()`
- `handler()`
- `get_records()`
- `text()`
- `records()`
- `record_tuples()`
- `messages()`
- `clear()`
- `_force_enable_logging()`
- `set_level()`
- `at_level()`
- `filtering()`

##### LoggingPlugin

Attaches to the logging module and captures log messages for each test.

**M√©thodes :**

- `__init__()`
- `_disable_loggers()`
- `_create_formatter()`
- `set_log_path()`
- `_log_cli_enabled()`
- `pytest_sessionstart()`
- `pytest_collection()`
- `pytest_runtestloop()`
- `pytest_runtest_logstart()`
- `pytest_runtest_logreport()`
- `_runtest_for()`
- `pytest_runtest_setup()`
- `pytest_runtest_call()`
- `pytest_runtest_teardown()`
- `pytest_runtest_logfinish()`
- `pytest_sessionfinish()`
- `pytest_unconfigure()`

##### _FileHandler

A logging FileHandler with pytest tweaks.

**M√©thodes :**

- `handleError()`

##### _LiveLoggingStreamHandler

A logging StreamHandler used by the live logging feature: it will
write a newline before the first log message in each test.

During live logging we must also explicitly disable stdout/stderr
capturing otherwise it will get captured and won't appear in the
terminal.

**M√©thodes :**

- `__init__()`
- `reset()`
- `set_when()`
- `emit()`
- `handleError()`

##### _LiveLoggingNullHandler

A logging handler used when live logging is disabled.

**M√©thodes :**

- `reset()`
- `set_when()`
- `handleError()`

#### Fonctions

##### _remove_ansi_escape_sequences

**Param√®tres :**

- `text`

##### get_option_ini

**Param√®tres :**

- `config`

##### pytest_addoption

Add options to control log capturing.

**Param√®tres :**

- `parser`

##### caplog

Access and control log capturing.

Captured logs are available through the following properties/methods::

* caplog.messages        -> list of format-interpolated log messages
* caplog.text            -> string containing formatted log output
* caplog.records         -> list of logging.LogRecord instances
* caplog.record_tuples   -> list of (logger_name, level, message) tuples
* caplog.clear()         -> clear captured records and formatted log output string

**Param√®tres :**

- `request`

##### get_log_level_for_setting

**Param√®tres :**

- `config`

##### pytest_configure

**Param√®tres :**

- `config`

##### formatTime

**Param√®tres :**

- `record`
- `datefmt`

##### __init__

**Param√®tres :**

- `terminalwriter`

##### add_color_level

Add or update color opts for a log level.

:param level:
    Log level to apply a style to, e.g. ``logging.INFO``.
:param color_opts:
    ANSI escape sequence color options. Capitalized colors indicates
    background color, i.e. ``'green', 'Yellow', 'bold'`` will give bold
    green text on yellow background.

.. warning::
    This is an experimental API.

**Param√®tres :**

- `level`

##### format

**Param√®tres :**

- `record`

##### __init__

**Param√®tres :**

- `fmt`
- `auto_indent`

##### _get_auto_indent

Determine the current auto indentation setting.

Specify auto indent behavior (on/off/fixed) by passing in
extra={"auto_indent": [value]} to the call to logging.log() or
using a --log-auto-indent [value] command line or the
log_auto_indent [value] config option.

Default behavior is auto-indent off.

Using the string "True" or "on" or the boolean True as the value
turns auto indent on, using the string "False" or "off" or the
boolean False or the int 0 turns it off, and specifying a
positive integer fixes the indentation position to the value
specified.

Any other values for the option are invalid, and will silently be
converted to the default.

:param None|bool|int|str auto_indent_option:
    User specified option for indentation from command line, config
    or extra kwarg. Accepts int, bool or str. str option accepts the
    same range of values as boolean config options, as well as
    positive integers represented in str form.

:returns:
    Indentation value, which can be
    -1 (automatically determine indentation) or
    0 (auto-indent turned off) or
    >0 (explicitly set indentation position).

**Param√®tres :**

- `auto_indent_option`

##### format

**Param√®tres :**

- `record`

##### add_option_ini

**Param√®tres :**

- `option`
- `dest`
- `default`
- `type`

##### __init__

**Param√®tres :**

- `handler`
- `level`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

Create a new log handler.

##### emit

Keep the log records in a list in addition to the log text.

**Param√®tres :**

- `record`

##### reset

##### clear

##### handleError

**Param√®tres :**

- `record`

##### __init__

**Param√®tres :**

- `item`

##### _finalize

Finalize the fixture.

This restores the log levels and the disabled logging levels changed by :meth:`set_level`.

##### handler

Get the logging handler used by the fixture.

##### get_records

Get the logging records for one of the possible test phases.

:param when:
    Which test phase to obtain the records from.
    Valid values are: "setup", "call" and "teardown".

:returns: The list of captured records at the given stage.

.. versionadded:: 3.4

**Param√®tres :**

- `when`

##### text

The formatted log text.

##### records

The list of log records.

##### record_tuples

A list of a stripped down version of log records intended
for use in assertion comparison.

The format of the tuple is:

    (logger_name, log_level, message)

##### messages

A list of format-interpolated log messages.

Unlike 'records', which contains the format string and parameters for
interpolation, log messages in this list are all interpolated.

Unlike 'text', which contains the output from the handler, log
messages in this list are unadorned with levels, timestamps, etc,
making exact comparisons more reliable.

Note that traceback or stack info (from :func:`logging.exception` or
the `exc_info` or `stack_info` arguments to the logging functions) is
not included, as this is added by the formatter in the handler.

.. versionadded:: 3.7

##### clear

Reset the list of log records and the captured log text.

##### _force_enable_logging

Enable the desired logging level if the global level was disabled via ``logging.disabled``.

Only enables logging levels greater than or equal to the requested ``level``.

Does nothing if the desired ``level`` wasn't disabled.

:param level:
    The logger level caplog should capture.
    All logging is enabled if a non-standard logging level string is supplied.
    Valid level strings are in :data:`logging._nameToLevel`.
:param logger_obj: The logger object to check.

:return: The original disabled logging level.

**Param√®tres :**

- `level`
- `logger_obj`

##### set_level

Set the threshold level of a logger for the duration of a test.

Logging messages which are less severe than this level will not be captured.

.. versionchanged:: 3.4
    The levels of the loggers changed by this function will be
    restored to their initial values at the end of the test.

Will enable the requested logging level if it was disabled via :func:`logging.disable`.

:param level: The level.
:param logger: The logger to update. If not given, the root logger.

**Param√®tres :**

- `level`
- `logger`

##### at_level

Context manager that sets the level for capturing of logs. After
the end of the 'with' statement the level is restored to its original
value.

Will enable the requested logging level if it was disabled via :func:`logging.disable`.

:param level: The level.
:param logger: The logger to update. If not given, the root logger.

**Param√®tres :**

- `level`
- `logger`

##### filtering

Context manager that temporarily adds the given filter to the caplog's
:meth:`handler` for the 'with' statement block, and removes that filter at the
end of the block.

:param filter_: A custom :class:`logging.Filter` object.

.. versionadded:: 7.5

**Param√®tres :**

- `filter_`

##### __init__

Create a new plugin to capture log messages.

The formatter can be safely shared across all handlers so
create a single one for the entire test session here.

**Param√®tres :**

- `config`

##### _disable_loggers

**Param√®tres :**

- `loggers_to_disable`

##### _create_formatter

**Param√®tres :**

- `log_format`
- `log_date_format`
- `auto_indent`

##### set_log_path

Set the filename parameter for Logging.FileHandler().

Creates parent directory if it does not exist.

.. warning::
    This is an experimental API.

**Param√®tres :**

- `fname`

##### _log_cli_enabled

Return whether live logging is enabled.

##### pytest_sessionstart

##### pytest_collection

##### pytest_runtestloop

**Param√®tres :**

- `session`

##### pytest_runtest_logstart

##### pytest_runtest_logreport

##### _runtest_for

Implement the internals of the pytest_runtest_xxx() hooks.

**Param√®tres :**

- `item`
- `when`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

**Param√®tres :**

- `item`

##### pytest_runtest_logfinish

##### pytest_sessionfinish

##### pytest_unconfigure

##### handleError

**Param√®tres :**

- `record`

##### __init__

**Param√®tres :**

- `terminal_reporter`
- `capture_manager`

##### reset

Reset the handler; should be called before the start of each test.

##### set_when

Prepare for the given test phase (setup/call/teardown).

**Param√®tres :**

- `when`

##### emit

**Param√®tres :**

- `record`

##### handleError

**Param√®tres :**

- `record`

##### reset

##### set_when

**Param√®tres :**

- `when`

##### handleError

**Param√®tres :**

- `record`

---

### main

Core implementation of the testing process: init, session, runtest loop.

#### Classes

##### FSHookProxy

**M√©thodes :**

- `__init__()`
- `__getattr__()`

##### Interrupted

Signals that the test run was interrupted.

##### Failed

Signals a stop as failed test run.

##### _bestrelpath_cache

**M√©thodes :**

- `__missing__()`

##### Dir

Collector of files in a file system directory.

.. versionadded:: 8.0

.. note::

    Python directories with an `__init__.py` file are instead collected by
    :class:`~pytest.Package` by default. Both are :class:`~pytest.Directory`
    collectors.

**M√©thodes :**

- `from_parent()`
- `collect()`

##### Session

The root of the collection tree.

``Session`` collects the initial paths given as arguments to pytest.

**M√©thodes :**

- `__init__()`
- `from_config()`
- `__repr__()`
- `shouldstop()`
- `shouldstop()`
- `shouldfail()`
- `shouldfail()`
- `startpath()`
- `_node_location_to_relpath()`
- `pytest_collectstart()`
- `pytest_runtest_logreport()`
- `isinitpath()`
- `gethookproxy()`
- `_collect_path()`
- `perform_collect()`
- `perform_collect()`
- `perform_collect()`
- `_collect_one_node()`
- `collect()`
- `genitems()`

##### CollectionArgument

A resolved collection argument.

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### validate_basetemp

**Param√®tres :**

- `path`

##### wrap_session

Skeleton command line program.

**Param√®tres :**

- `config`
- `doit`

##### pytest_cmdline_main

**Param√®tres :**

- `config`

##### _main

Default command line protocol for initialization, session,
running tests and reporting.

**Param√®tres :**

- `config`
- `session`

##### pytest_collection

**Param√®tres :**

- `session`

##### pytest_runtestloop

**Param√®tres :**

- `session`

##### _in_venv

Attempt to detect if ``path`` is the root of a Virtual Environment by
checking for the existence of the pyvenv.cfg file.

[https://peps.python.org/pep-0405/]

For regression protection we also check for conda environments that do not include pyenv.cfg yet --
https://github.com/conda/conda/issues/13337 is the conda issue tracking adding pyenv.cfg.

Checking for the `conda-meta/history` file per https://github.com/pytest-dev/pytest/issues/12652#issuecomment-2246336902.

**Param√®tres :**

- `path`

##### pytest_ignore_collect

**Param√®tres :**

- `collection_path`
- `config`

##### pytest_collect_directory

**Param√®tres :**

- `path`
- `parent`

##### pytest_collection_modifyitems

**Param√®tres :**

- `items`
- `config`

##### search_pypath

Search sys.path for the given a dotted module name, and return its file
system path if found.

**Param√®tres :**

- `module_name`

##### resolve_collection_argument

Parse path arguments optionally containing selection parts and return (fspath, names).

Command-line arguments can point to files and/or directories, and optionally contain
parts for specific tests selection, for example:

    "pkg/tests/test_foo.py::TestClass::test_foo"

This function ensures the path exists, and returns a resolved `CollectionArgument`:

    CollectionArgument(
        path=Path("/full/path/to/pkg/tests/test_foo.py"),
        parts=["TestClass", "test_foo"],
        module_name=None,
    )

When as_pypath is True, expects that the command-line argument actually contains
module paths instead of file-system paths:

    "pkg.tests.test_foo::TestClass::test_foo"

In which case we search sys.path for a matching module, and then return the *path* to the
found module, which may look like this:

    CollectionArgument(
        path=Path("/home/u/myvenv/lib/site-packages/pkg/tests/test_foo.py"),
        parts=["TestClass", "test_foo"],
        module_name="pkg.tests.test_foo",
    )

If the path doesn't exist, raise UsageError.
If the path is a directory and selection parts are present, raise UsageError.

**Param√®tres :**

- `invocation_path`
- `arg`

##### is_ancestor

Return whether query is an ancestor of base.

**Param√®tres :**

- `base`
- `query`

##### __init__

**Param√®tres :**

- `pm`
- `remove_mods`

##### __getattr__

**Param√®tres :**

- `name`

##### __missing__

**Param√®tres :**

- `path`

##### from_parent

The public constructor.

:param parent: The parent collector of this Dir.
:param path: The directory's path.
:type path: pathlib.Path

**Param√®tres :**

- `cls`
- `parent`

##### collect

##### __init__

**Param√®tres :**

- `config`

##### from_config

**Param√®tres :**

- `cls`
- `config`

##### __repr__

##### shouldstop

##### shouldstop

**Param√®tres :**

- `value`

##### shouldfail

##### shouldfail

**Param√®tres :**

- `value`

##### startpath

The path from which pytest was invoked.

.. versionadded:: 7.0.0

##### _node_location_to_relpath

**Param√®tres :**

- `node_path`

##### pytest_collectstart

##### pytest_runtest_logreport

**Param√®tres :**

- `report`

##### isinitpath

Is path an initial path?

An initial path is a path explicitly given to pytest on the command
line.

:param with_parents:
    If set, also return True if the path is a parent of an initial path.

.. versionchanged:: 8.0
    Added the ``with_parents`` parameter.

**Param√®tres :**

- `path`

##### gethookproxy

**Param√®tres :**

- `fspath`

##### _collect_path

Create a Collector for the given path.

`path_cache` makes it so the same Collectors are returned for the same
path.

**Param√®tres :**

- `path`
- `path_cache`

##### perform_collect

**Param√®tres :**

- `args`
- `genitems`

##### perform_collect

**Param√®tres :**

- `args`
- `genitems`

##### perform_collect

Perform the collection phase for this session.

This is called by the default :hook:`pytest_collection` hook
implementation; see the documentation of this hook for more details.
For testing purposes, it may also be called directly on a fresh
``Session``.

This function normally recursively expands any collectors collected
from the session to their items, and only items are returned. For
testing purposes, this may be suppressed by passing ``genitems=False``,
in which case the return value contains these collectors unexpanded,
and ``session.items`` is empty.

**Param√®tres :**

- `args`
- `genitems`

##### _collect_one_node

**Param√®tres :**

- `node`
- `handle_dupes`

##### collect

##### genitems

**Param√®tres :**

- `node`

---

### monkeypatch

Monkeypatching and mocking functionality.

#### Classes

##### Notset

**M√©thodes :**

- `__repr__()`

##### MonkeyPatch

Helper to conveniently monkeypatch attributes/items/environment
variables/syspath.

Returned by the :fixture:`monkeypatch` fixture.

.. versionchanged:: 6.2
    Can now also be used directly as `pytest.MonkeyPatch()`, for when
    the fixture is not available. In this case, use
    :meth:`with MonkeyPatch.context() as mp: <context>` or remember to call
    :meth:`undo` explicitly.

**M√©thodes :**

- `__init__()`
- `context()`
- `setattr()`
- `setattr()`
- `setattr()`
- `delattr()`
- `setitem()`
- `delitem()`
- `setenv()`
- `delenv()`
- `syspath_prepend()`
- `chdir()`
- `undo()`

#### Fonctions

##### monkeypatch

A convenient fixture for monkey-patching.

The fixture provides these methods to modify objects, dictionaries, or
:data:`os.environ`:

* :meth:`monkeypatch.setattr(obj, name, value, raising=True) <pytest.MonkeyPatch.setattr>`
* :meth:`monkeypatch.delattr(obj, name, raising=True) <pytest.MonkeyPatch.delattr>`
* :meth:`monkeypatch.setitem(mapping, name, value) <pytest.MonkeyPatch.setitem>`
* :meth:`monkeypatch.delitem(obj, name, raising=True) <pytest.MonkeyPatch.delitem>`
* :meth:`monkeypatch.setenv(name, value, prepend=None) <pytest.MonkeyPatch.setenv>`
* :meth:`monkeypatch.delenv(name, raising=True) <pytest.MonkeyPatch.delenv>`
* :meth:`monkeypatch.syspath_prepend(path) <pytest.MonkeyPatch.syspath_prepend>`
* :meth:`monkeypatch.chdir(path) <pytest.MonkeyPatch.chdir>`
* :meth:`monkeypatch.context() <pytest.MonkeyPatch.context>`

All modifications will be undone after the requesting test function or
fixture has finished. The ``raising`` parameter determines if a :class:`KeyError`
or :class:`AttributeError` will be raised if the set/deletion operation does not have the
specified target.

To undo modifications done by the fixture in a contained scope,
use :meth:`context() <pytest.MonkeyPatch.context>`.

##### resolve

**Param√®tres :**

- `name`

##### annotated_getattr

**Param√®tres :**

- `obj`
- `name`
- `ann`

##### derive_importpath

**Param√®tres :**

- `import_path`
- `raising`

##### __repr__

##### __init__

##### context

Context manager that returns a new :class:`MonkeyPatch` object
which undoes any patching done inside the ``with`` block upon exit.

Example:

.. code-block:: python

    import functools


    def test_partial(monkeypatch):
        with monkeypatch.context() as m:
            m.setattr(functools, "partial", 3)

Useful in situations where it is desired to undo some patches before the test ends,
such as mocking ``stdlib`` functions that might break pytest itself if mocked (for examples
of this see :issue:`3290`).

**Param√®tres :**

- `cls`

##### setattr

**Param√®tres :**

- `target`
- `name`
- `value`
- `raising`

##### setattr

**Param√®tres :**

- `target`
- `name`
- `value`
- `raising`

##### setattr

Set attribute value on target, memorizing the old value.

For example:

.. code-block:: python

    import os

    monkeypatch.setattr(os, "getcwd", lambda: "/")

The code above replaces the :func:`os.getcwd` function by a ``lambda`` which
always returns ``"/"``.

For convenience, you can specify a string as ``target`` which
will be interpreted as a dotted import path, with the last part
being the attribute name:

.. code-block:: python

    monkeypatch.setattr("os.getcwd", lambda: "/")

Raises :class:`AttributeError` if the attribute does not exist, unless
``raising`` is set to False.

**Where to patch**

``monkeypatch.setattr`` works by (temporarily) changing the object that a name points to with another one.
There can be many names pointing to any individual object, so for patching to work you must ensure
that you patch the name used by the system under test.

See the section :ref:`Where to patch <python:where-to-patch>` in the :mod:`unittest.mock`
docs for a complete explanation, which is meant for :func:`unittest.mock.patch` but
applies to ``monkeypatch.setattr`` as well.

**Param√®tres :**

- `target`
- `name`
- `value`
- `raising`

##### delattr

Delete attribute ``name`` from ``target``.

If no ``name`` is specified and ``target`` is a string
it will be interpreted as a dotted import path with the
last part being the attribute name.

Raises AttributeError it the attribute does not exist, unless
``raising`` is set to False.

**Param√®tres :**

- `target`
- `name`
- `raising`

##### setitem

Set dictionary entry ``name`` to value.

**Param√®tres :**

- `dic`
- `name`
- `value`

##### delitem

Delete ``name`` from dict.

Raises ``KeyError`` if it doesn't exist, unless ``raising`` is set to
False.

**Param√®tres :**

- `dic`
- `name`
- `raising`

##### setenv

Set environment variable ``name`` to ``value``.

If ``prepend`` is a character, read the current environment variable
value and prepend the ``value`` adjoined with the ``prepend``
character.

**Param√®tres :**

- `name`
- `value`
- `prepend`

##### delenv

Delete ``name`` from the environment.

Raises ``KeyError`` if it does not exist, unless ``raising`` is set to
False.

**Param√®tres :**

- `name`
- `raising`

##### syspath_prepend

Prepend ``path`` to ``sys.path`` list of import locations.

**Param√®tres :**

- `path`

##### chdir

Change the current working directory to the specified path.

:param path:
    The path to change into.

**Param√®tres :**

- `path`

##### undo

Undo previous changes.

This call consumes the undo stack. Calling it a second time has no
effect unless you do more monkeypatching after the undo call.

There is generally no need to call `undo()`, since it is
called automatically during tear-down.

.. note::
    The same `monkeypatch` fixture is used across a
    single test function invocation. If `monkeypatch` is used both by
    the test function itself and one of the test fixtures,
    calling `undo()` will undo all of the changes made in
    both functions.

    Prefer to use :meth:`context() <pytest.MonkeyPatch.context>` instead.

---

### nodes

#### Classes

##### NodeMeta

Metaclass used by :class:`Node` to enforce that direct construction raises
:class:`Failed`.

This behaviour supports the indirection introduced with :meth:`Node.from_parent`,
the named constructor to be used instead of direct construction. The design
decision to enforce indirection with :class:`NodeMeta` was made as a
temporary aid for refactoring the collection tree, which was diagnosed to
have :class:`Node` objects whose creational patterns were overly entangled.
Once the refactoring is complete, this metaclass can be removed.

See https://github.com/pytest-dev/pytest/projects/3 for an overview of the
progress on detangling the :class:`Node` classes.

**M√©thodes :**

- `__call__()`
- `_create()`

##### Node

Base class of :class:`Collector` and :class:`Item`, the components of
the test collection tree.

``Collector``\'s are the internal nodes of the tree, and ``Item``\'s are the
leaf nodes.

**M√©thodes :**

- `__init__()`
- `from_parent()`
- `ihook()`
- `__repr__()`
- `warn()`
- `nodeid()`
- `__hash__()`
- `setup()`
- `teardown()`
- `iter_parents()`
- `listchain()`
- `add_marker()`
- `iter_markers()`
- `iter_markers_with_node()`
- `get_closest_marker()`
- `get_closest_marker()`
- `get_closest_marker()`
- `listextrakeywords()`
- `listnames()`
- `addfinalizer()`
- `getparent()`
- `_traceback_filter()`
- `_repr_failure_py()`
- `repr_failure()`

##### Collector

Base class of all collectors.

Collector create children through `collect()` and thus iteratively build
the collection tree.

**M√©thodes :**

- `collect()`
- `repr_failure()`
- `_traceback_filter()`

##### FSCollector

Base class for filesystem collectors.

**M√©thodes :**

- `__init__()`
- `from_parent()`

##### File

Base class for collecting tests from a file.

:ref:`non-python tests`.

##### Directory

Base class for collecting files from a directory.

A basic directory collector does the following: goes over the files and
sub-directories in the directory and creates collectors for them by calling
the hooks :hook:`pytest_collect_directory` and :hook:`pytest_collect_file`,
after checking that they are not ignored using
:hook:`pytest_ignore_collect`.

The default directory collectors are :class:`~pytest.Dir` and
:class:`~pytest.Package`.

.. versionadded:: 8.0

:ref:`custom directory collectors`.

##### Item

Base class of all test invocation items.

Note that for a single function there might be multiple test invocation items.

**M√©thodes :**

- `__init__()`
- `_check_item_and_collector_diamond_inheritance()`
- `runtest()`
- `add_report_section()`
- `reportinfo()`
- `location()`

##### CollectError

An error during collection, contains a custom message.

#### Fonctions

##### _imply_path

**Param√®tres :**

- `node_type`
- `path`
- `fspath`

##### get_fslocation_from_item

Try to extract the actual location from a node, depending on available attributes:

* "location": a pair (path, lineno)
* "obj": a Python object that the node wraps.
* "path": just a path

:rtype: A tuple of (str|Path, int) with filename and 0-based line number.

**Param√®tres :**

- `node`

##### _check_initialpaths_for_relpath

**Param√®tres :**

- `initial_paths`
- `path`

##### __call__

**Param√®tres :**

- `cls`

##### _create

**Param√®tres :**

- `cls`

##### __init__

**Param√®tres :**

- `name`
- `parent`
- `config`
- `session`
- `fspath`
- `path`
- `nodeid`

##### from_parent

Public constructor for Nodes.

This indirection got introduced in order to enable removing
the fragile logic from the node constructors.

Subclasses can use ``super().from_parent(...)`` when overriding the
construction.

:param parent: The parent node of this Node.

**Param√®tres :**

- `cls`
- `parent`

##### ihook

fspath-sensitive hook proxy used to call pytest hooks.

##### __repr__

##### warn

Issue a warning for this Node.

Warnings will be displayed after the test session, unless explicitly suppressed.

:param Warning warning:
    The warning instance to issue.

:raises ValueError: If ``warning`` instance is not a subclass of Warning.

Example usage:

.. code-block:: python

    node.warn(PytestWarning("some message"))
    node.warn(UserWarning("some message"))

.. versionchanged:: 6.2
    Any subclass of :class:`Warning` is now accepted, rather than only
    :class:`PytestWarning <pytest.PytestWarning>` subclasses.

**Param√®tres :**

- `warning`

##### nodeid

A ::-separated string denoting its collection tree address.

##### __hash__

##### setup

##### teardown

##### iter_parents

Iterate over all parent collectors starting from and including self
up to the root of the collection tree.

.. versionadded:: 8.1

##### listchain

Return a list of all parent collectors starting from the root of the
collection tree down to and including self.

##### add_marker

Dynamically add a marker object to the node.

:param marker:
    The marker.
:param append:
    Whether to append the marker, or prepend it.

**Param√®tres :**

- `marker`
- `append`

##### iter_markers

Iterate over all markers of the node.

:param name: If given, filter the results by the name attribute.
:returns: An iterator of the markers of the node.

**Param√®tres :**

- `name`

##### iter_markers_with_node

Iterate over all markers of the node.

:param name: If given, filter the results by the name attribute.
:returns: An iterator of (node, mark) tuples.

**Param√®tres :**

- `name`

##### get_closest_marker

**Param√®tres :**

- `name`

##### get_closest_marker

**Param√®tres :**

- `name`
- `default`

##### get_closest_marker

Return the first marker matching the name, from closest (for
example function) to farther level (for example module level).

:param default: Fallback return value if no marker was found.
:param name: Name to filter by.

**Param√®tres :**

- `name`
- `default`

##### listextrakeywords

Return a set of all extra keywords in self and any parents.

##### listnames

##### addfinalizer

Register a function to be called without arguments when this node is
finalized.

This method can only be called when this node is active
in a setup chain, for example during self.setup().

**Param√®tres :**

- `fin`

##### getparent

Get the closest parent node (including self) which is an instance of
the given class.

:param cls: The node class to search for.
:returns: The node, if found.

**Param√®tres :**

- `cls`

##### _traceback_filter

**Param√®tres :**

- `excinfo`

##### _repr_failure_py

**Param√®tres :**

- `excinfo`
- `style`

##### repr_failure

Return a representation of a collection or test failure.

.. seealso:: :ref:`non-python tests`

:param excinfo: Exception information for the failure.

**Param√®tres :**

- `excinfo`
- `style`

##### collect

Collect children (items and collectors) for this collector.

##### repr_failure

Return a representation of a collection failure.

:param excinfo: Exception information for the failure.

**Param√®tres :**

- `excinfo`

##### _traceback_filter

**Param√®tres :**

- `excinfo`

##### __init__

**Param√®tres :**

- `fspath`
- `path_or_parent`
- `path`
- `name`
- `parent`
- `config`
- `session`
- `nodeid`

##### from_parent

The public constructor.

**Param√®tres :**

- `cls`
- `parent`

##### __init__

**Param√®tres :**

- `name`
- `parent`
- `config`
- `session`
- `nodeid`

##### _check_item_and_collector_diamond_inheritance

Check if the current type inherits from both File and Collector
at the same time, emitting a warning accordingly (#8447).

##### runtest

Run the test case for this item.

Must be implemented by subclasses.

.. seealso:: :ref:`non-python tests`

##### add_report_section

Add a new report section, similar to what's done internally to add
stdout and stderr captured output::

    item.add_report_section("call", "stdout", "report section contents")

:param str when:
    One of the possible capture states, ``"setup"``, ``"call"``, ``"teardown"``.
:param str key:
    Name of the section, can be customized at will. Pytest uses ``"stdout"`` and
    ``"stderr"`` internally.
:param str content:
    The full contents as a string.

**Param√®tres :**

- `when`
- `key`
- `content`

##### reportinfo

Get location information for this item for test reports.

Returns a tuple with three elements:

- The path of the test (default ``self.path``)
- The 0-based line number of the test (default ``None``)
- A name of the test to be shown (default ``""``)

.. seealso:: :ref:`non-python tests`

##### location

Returns a tuple of ``(relfspath, lineno, testname)`` for this item
where ``relfspath`` is file path relative to ``config.rootpath``
and lineno is a 0-based line number.

---

### outcomes

Exception classes and constants handling test outcomes as well as
functions creating them.

#### Classes

##### OutcomeException

OutcomeException and its subclass instances indicate and contain info
about test and collection outcomes.

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### Skipped

**M√©thodes :**

- `__init__()`

##### Failed

Raised from an explicit call to pytest.fail().

##### Exit

Raised for immediate program exits (no tracebacks/summaries).

**M√©thodes :**

- `__init__()`

##### _WithException

##### XFailed

Raised from an explicit call to pytest.xfail().

#### Fonctions

##### _with_exception

**Param√®tres :**

- `exception_type`

##### exit

Exit testing process.

:param reason:
    The message to show as the reason for exiting pytest.  reason has a default value
    only because `msg` is deprecated.

:param returncode:
    Return code to be used when exiting pytest. None means the same as ``0`` (no error), same as :func:`sys.exit`.

:raises pytest.exit.Exception:
    The exception that is raised.

**Param√®tres :**

- `reason`
- `returncode`

##### skip

Skip an executing test with the given message.

This function should be called only during testing (setup, call or teardown) or
during collection by using the ``allow_module_level`` flag.  This function can
be called in doctests as well.

:param reason:
    The message to show the user as reason for the skip.

:param allow_module_level:
    Allows this function to be called at module level.
    Raising the skip exception at module level will stop
    the execution of the module and prevent the collection of all tests in the module,
    even those defined before the `skip` call.

    Defaults to False.

:raises pytest.skip.Exception:
    The exception that is raised.

.. note::
    It is better to use the :ref:`pytest.mark.skipif ref` marker when
    possible to declare a test to be skipped under certain conditions
    like mismatching platforms or dependencies.
    Similarly, use the ``# doctest: +SKIP`` directive (see :py:data:`doctest.SKIP`)
    to skip a doctest statically.

**Param√®tres :**

- `reason`

##### fail

Explicitly fail an executing test with the given message.

:param reason:
    The message to show the user as reason for the failure.

:param pytrace:
    If False, msg represents the full failure information and no
    python traceback will be reported.

:raises pytest.fail.Exception:
    The exception that is raised.

**Param√®tres :**

- `reason`
- `pytrace`

##### xfail

Imperatively xfail an executing test or setup function with the given reason.

This function should be called only during testing (setup, call or teardown).

No other code is executed after using ``xfail()`` (it is implemented
internally by raising an exception).

:param reason:
    The message to show the user as reason for the xfail.

.. note::
    It is better to use the :ref:`pytest.mark.xfail ref` marker when
    possible to declare a test to be xfailed under certain conditions
    like known bugs or missing features.

:raises pytest.xfail.Exception:
    The exception that is raised.

**Param√®tres :**

- `reason`

##### importorskip

Import and return the requested module ``modname``, or skip the
current test if the module cannot be imported.

:param modname:
    The name of the module to import.
:param minversion:
    If given, the imported module's ``__version__`` attribute must be at
    least this minimal version, otherwise the test is still skipped.
:param reason:
    If given, this reason is shown as the message when the module cannot
    be imported.
:param exc_type:
    The exception that should be captured in order to skip modules.
    Must be :py:class:`ImportError` or a subclass.

    If the module can be imported but raises :class:`ImportError`, pytest will
    issue a warning to the user, as often users expect the module not to be
    found (which would raise :class:`ModuleNotFoundError` instead).

    This warning can be suppressed by passing ``exc_type=ImportError`` explicitly.

    See :ref:`import-or-skip-import-error` for details.


:returns:
    The imported module. This should be assigned to its canonical name.

:raises pytest.skip.Exception:
    If the module cannot be imported.

Example::

    docutils = pytest.importorskip("docutils")

.. versionadded:: 8.2

    The ``exc_type`` parameter.

**Param√®tres :**

- `modname`
- `minversion`
- `reason`

##### __init__

**Param√®tres :**

- `msg`
- `pytrace`

##### __repr__

##### __init__

**Param√®tres :**

- `msg`
- `pytrace`
- `allow_module_level`

##### __init__

**Param√®tres :**

- `msg`
- `returncode`

##### decorate

**Param√®tres :**

- `func`

---

### pastebin

Submit failure or test session information to a pastebin service.

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### pytest_unconfigure

**Param√®tres :**

- `config`

##### create_new_paste

Create a new paste using the bpaste.net service.

:contents: Paste contents string.
:returns: URL to the pasted contents, or an error message.

**Param√®tres :**

- `contents`

##### pytest_terminal_summary

**Param√®tres :**

- `terminalreporter`

##### tee_write

**Param√®tres :**

- `s`

---

### pathlib

#### Classes

##### ImportMode

Possible values for `mode` parameter of `import_path`.

##### ImportPathMismatchError

Raised on import_path() if there is a mismatch of __file__'s.

This can happen when `import_path` is called multiple times with different filenames that has
the same basename but reside in packages
(for example "/tests1/test_foo.py" and "/tests2/test_foo.py").

##### CouldNotResolvePathError

Custom exception raised by resolve_pkg_root_and_module_name.

#### Fonctions

##### _ignore_error

**Param√®tres :**

- `exception`

##### get_lock_path

**Param√®tres :**

- `path`

##### on_rm_rf_error

Handle known read-only errors during rmtree.

The returned value is used only by our own tests.

**Param√®tres :**

- `func`
- `path`
- `excinfo`

##### ensure_extended_length_path

Get the extended-length version of a path (Windows).

On Windows, by default, the maximum length of a path (MAX_PATH) is 260
characters, and operations on paths longer than that fail. But it is possible
to overcome this by converting the path to "extended-length" form before
performing the operation:
https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file#maximum-path-length-limitation

On Windows, this function returns the extended-length absolute version of path.
On other platforms it returns path unchanged.

**Param√®tres :**

- `path`

##### get_extended_length_path_str

Convert a path to a Windows extended length path.

**Param√®tres :**

- `path`

##### rm_rf

Remove the path contents recursively, even if some elements
are read-only.

**Param√®tres :**

- `path`

##### find_prefixed

Find all elements in root that begin with the prefix, case-insensitive.

**Param√®tres :**

- `root`
- `prefix`

##### extract_suffixes

Return the parts of the paths following the prefix.

:param iter: Iterator over path names.
:param prefix: Expected prefix of the path names.

**Param√®tres :**

- `iter`
- `prefix`

##### find_suffixes

Combine find_prefixes and extract_suffixes.

**Param√®tres :**

- `root`
- `prefix`

##### parse_num

Parse number path suffixes, returns -1 on error.

**Param√®tres :**

- `maybe_num`

##### _force_symlink

Helper to create the current symlink.

It's full of race conditions that are reasonably OK to ignore
for the context of best effort linking to the latest test run.

The presumption being that in case of much parallelism
the inaccuracy is going to be acceptable.

**Param√®tres :**

- `root`
- `target`
- `link_to`

##### make_numbered_dir

Create a directory with an increased number as suffix for the given prefix.

**Param√®tres :**

- `root`
- `prefix`
- `mode`

##### create_cleanup_lock

Create a lock to prevent premature folder cleanup.

**Param√®tres :**

- `p`

##### register_cleanup_lock_removal

Register a cleanup function for removing a lock, by default on atexit.

**Param√®tres :**

- `lock_path`
- `register`

##### maybe_delete_a_numbered_dir

Remove a numbered directory if its lock can be obtained and it does
not seem to be in use.

**Param√®tres :**

- `path`

##### ensure_deletable

Check if `path` is deletable based on whether the lock file is expired.

**Param√®tres :**

- `path`
- `consider_lock_dead_if_created_before`

##### try_cleanup

Try to cleanup a folder if we can ensure it's deletable.

**Param√®tres :**

- `path`
- `consider_lock_dead_if_created_before`

##### cleanup_candidates

List candidates for numbered directories to be removed - follows py.path.

**Param√®tres :**

- `root`
- `prefix`
- `keep`

##### cleanup_dead_symlinks

**Param√®tres :**

- `root`

##### cleanup_numbered_dir

Cleanup for lock driven numbered directories.

**Param√®tres :**

- `root`
- `prefix`
- `keep`
- `consider_lock_dead_if_created_before`

##### make_numbered_dir_with_cleanup

Create a numbered dir with a cleanup lock and remove old ones.

**Param√®tres :**

- `root`
- `prefix`
- `keep`
- `lock_timeout`
- `mode`

##### resolve_from_str

**Param√®tres :**

- `input`
- `rootpath`

##### fnmatch_ex

A port of FNMatcher from py.path.common which works with PurePath() instances.

The difference between this algorithm and PurePath.match() is that the
latter matches "**" glob expressions for each part of the path, while
this algorithm uses the whole path instead.

For example:
    "tests/foo/bar/doc/test_foo.py" matches pattern "tests/**/doc/test*.py"
    with this algorithm, but not with PurePath.match().

This algorithm was ported to keep backward-compatibility with existing
settings which assume paths match according this logic.

References:
* https://bugs.python.org/issue29249
* https://bugs.python.org/issue34731

**Param√®tres :**

- `pattern`
- `path`

##### parts

**Param√®tres :**

- `s`

##### symlink_or_skip

Make a symlink, or skip the test in case symlinks are not supported.

**Param√®tres :**

- `src`
- `dst`

##### import_path

Import and return a module from the given path, which can be a file (a module) or
a directory (a package).

:param path:
    Path to the file to import.

:param mode:
    Controls the underlying import mechanism that will be used:

    * ImportMode.prepend: the directory containing the module (or package, taking
      `__init__.py` files into account) will be put at the *start* of `sys.path` before
      being imported with `importlib.import_module`.

    * ImportMode.append: same as `prepend`, but the directory will be appended
      to the end of `sys.path`, if not already in `sys.path`.

    * ImportMode.importlib: uses more fine control mechanisms provided by `importlib`
      to import the module, which avoids having to muck with `sys.path` at all. It effectively
      allows having same-named test modules in different places.

:param root:
    Used as an anchor when mode == ImportMode.importlib to obtain
    a unique name for the module being imported so it can safely be stored
    into ``sys.modules``.

:param consider_namespace_packages:
    If True, consider namespace packages when resolving module names.

:raises ImportPathMismatchError:
    If after importing the given `path` and the module `__file__`
    are different. Only raised in `prepend` and `append` modes.

**Param√®tres :**

- `path`

##### _import_module_using_spec

Tries to import a module by its canonical name, path, and its parent location.

:param module_name:
    The expected module name, will become the key of `sys.modules`.

:param module_path:
    The file path of the module, for example `/foo/bar/test_demo.py`.
    If module is a package, pass the path to the  `__init__.py` of the package.
    If module is a namespace package, pass directory path.

:param module_location:
    The parent location of the module.
    If module is a package, pass the directory containing the `__init__.py` file.

:param insert_modules:
    If True, will call `insert_missing_modules` to create empty intermediate modules
    with made-up module names (when importing test files not reachable from `sys.path`).

Example 1 of parent_module_*:

    module_name:        "a.b.c.demo"
    module_path:        Path("a/b/c/demo.py")
    module_location:    Path("a/b/c/")
    if "a.b.c" is package ("a/b/c/__init__.py" exists), then
        parent_module_name:         "a.b.c"
        parent_module_path:         Path("a/b/c/__init__.py")
        parent_module_location:     Path("a/b/c/")
    else:
        parent_module_name:         "a.b.c"
        parent_module_path:         Path("a/b/c")
        parent_module_location:     Path("a/b/")

Example 2 of parent_module_*:

    module_name:        "a.b.c"
    module_path:        Path("a/b/c/__init__.py")
    module_location:    Path("a/b/c/")
    if  "a.b" is package ("a/b/__init__.py" exists), then
        parent_module_name:         "a.b"
        parent_module_path:         Path("a/b/__init__.py")
        parent_module_location:     Path("a/b/")
    else:
        parent_module_name:         "a.b"
        parent_module_path:         Path("a/b/")
        parent_module_location:     Path("a/")

**Param√®tres :**

- `module_name`
- `module_path`
- `module_location`

##### spec_matches_module_path

Return true if the given ModuleSpec can be used to import the given module path.

**Param√®tres :**

- `module_spec`
- `module_path`

##### module_name_from_path

Return a dotted module name based on the given path, anchored on root.

For example: path="projects/src/tests/test_foo.py" and root="/projects", the
resulting module name will be "src.tests.test_foo".

**Param√®tres :**

- `path`
- `root`

##### insert_missing_modules

Used by ``import_path`` to create intermediate modules when using mode=importlib.

When we want to import a module as "src.tests.test_foo" for example, we need
to create empty modules "src" and "src.tests" after inserting "src.tests.test_foo",
otherwise "src.tests.test_foo" is not importable by ``__import__``.

**Param√®tres :**

- `modules`
- `module_name`

##### resolve_package_path

Return the Python package path by looking for the last
directory upwards which still contains an __init__.py.

Returns None if it cannot be determined.

**Param√®tres :**

- `path`

##### resolve_pkg_root_and_module_name

Return the path to the directory of the root package that contains the
given Python file, and its module name:

    src/
        app/
            __init__.py
            core/
                __init__.py
                models.py

Passing the full path to `models.py` will yield Path("src") and "app.core.models".

If consider_namespace_packages is True, then we additionally check upwards in the hierarchy
for namespace packages:

https://packaging.python.org/en/latest/guides/packaging-namespace-packages

Raises CouldNotResolvePathError if the given path does not belong to a package (missing any __init__.py files).

**Param√®tres :**

- `path`

##### is_importable

Return if the given module path could be imported normally by Python, akin to the user
entering the REPL and importing the corresponding module name directly, and corresponds
to the module_path specified.

:param module_name:
    Full module name that we want to check if is importable.
    For example, "app.models".

:param module_path:
    Full path to the python module/package we want to check if is importable.
    For example, "/projects/src/app/models.py".

**Param√®tres :**

- `module_name`
- `module_path`

##### compute_module_name

Compute a module name based on a path and a root anchor.

**Param√®tres :**

- `root`
- `module_path`

##### scandir

Scan a directory recursively, in breadth-first order.

The returned entries are sorted according to the given key.
The default is to sort by name.
If the directory does not exist, return an empty list.

**Param√®tres :**

- `path`
- `sort_key`

##### visit

Walk a directory recursively, in breadth-first order.

The `recurse` predicate determines whether a directory is recursed.

Entries at each directory level are sorted.

**Param√®tres :**

- `path`
- `recurse`

##### absolutepath

Convert a path to an absolute path using os.path.abspath.

Prefer this over Path.resolve() (see #6523).
Prefer this over Path.absolute() (not public, doesn't normalize).

**Param√®tres :**

- `path`

##### commonpath

Return the common part shared with the other path, or None if there is
no common part.

If one path is relative and one is absolute, returns None.

**Param√®tres :**

- `path1`
- `path2`

##### bestrelpath

Return a string which is a relative path from directory to dest such
that directory/bestrelpath == dest.

The paths must be either both absolute or both relative.

If no such path can be determined, returns dest.

**Param√®tres :**

- `directory`
- `dest`

##### safe_exists

Like Path.exists(), but account for input arguments that might be too long (#11394).

**Param√®tres :**

- `p`

##### chmod_rw

**Param√®tres :**

- `p`

##### cleanup_on_exit

**Param√®tres :**

- `lock_path`
- `original_pid`

##### _is_same

**Param√®tres :**

- `f1`
- `f2`

##### _is_same

**Param√®tres :**

- `f1`
- `f2`

---

### pytester

(Disabled by default) support for testing pytest and pytest plugins.

PYTEST_DONT_REWRITE

#### Classes

##### LsofFdLeakChecker

**M√©thodes :**

- `get_open_files()`
- `matching_platform()`
- `pytest_runtest_protocol()`

##### PytestArg

**M√©thodes :**

- `__init__()`
- `gethookrecorder()`

##### RecordedHookCall

A recorded call to a hook.

The arguments to the hook call are set as attributes.
For example:

.. code-block:: python

    calls = hook_recorder.getcalls("pytest_runtest_setup")
    # Suppose pytest_runtest_setup was called once with `item=an_item`.
    assert calls[0].item is an_item

**M√©thodes :**

- `__init__()`
- `__repr__()`

##### HookRecorder

Record all hooks called in a plugin manager.

Hook recorders are created by :class:`Pytester`.

This wraps all the hook calls in the plugin manager, recording each call
before propagating the normal calls.

**M√©thodes :**

- `__init__()`
- `finish_recording()`
- `getcalls()`
- `assert_contains()`
- `popcall()`
- `getcall()`
- `getreports()`
- `getreports()`
- `getreports()`
- `getreports()`
- `matchreport()`
- `getfailures()`
- `getfailures()`
- `getfailures()`
- `getfailures()`
- `getfailedcollections()`
- `listoutcomes()`
- `countoutcomes()`
- `assertoutcome()`
- `clear()`

##### RunResult

The result of running a command from :class:`~pytest.Pytester`.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `parseoutcomes()`
- `parse_summary_nouns()`
- `assert_outcomes()`

##### SysModulesSnapshot

**M√©thodes :**

- `__init__()`
- `restore()`

##### SysPathsSnapshot

**M√©thodes :**

- `__init__()`
- `restore()`

##### Pytester

Facilities to write tests/configuration files, execute pytest in isolation, and match
against expected output, perfect for black-box testing of pytest plugins.

It attempts to isolate the test run from external factors as much as possible, modifying
the current working directory to :attr:`path` and environment variables during initialization.

**M√©thodes :**

- `__init__()`
- `path()`
- `__repr__()`
- `_finalize()`
- `__take_sys_modules_snapshot()`
- `make_hook_recorder()`
- `chdir()`
- `_makefile()`
- `makefile()`
- `makeconftest()`
- `makeini()`
- `getinicfg()`
- `makepyprojecttoml()`
- `makepyfile()`
- `maketxtfile()`
- `syspathinsert()`
- `mkdir()`
- `mkpydir()`
- `copy_example()`
- `getnode()`
- `getpathnode()`
- `genitems()`
- `runitem()`
- `inline_runsource()`
- `inline_genitems()`
- `inline_run()`
- `runpytest_inprocess()`
- `runpytest()`
- `_ensure_basetemp()`
- `parseconfig()`
- `parseconfigure()`
- `getitem()`
- `getitems()`
- `getmodulecol()`
- `collect_by_name()`
- `popen()`
- `run()`
- `_dump_lines()`
- `_getpytestargs()`
- `runpython()`
- `runpython_c()`
- `runpytest_subprocess()`
- `spawn_pytest()`
- `spawn()`

##### LineComp

**M√©thodes :**

- `__init__()`
- `assert_contains_lines()`

##### LineMatcher

Flexible matching of text.

This is a convenience class to test large texts like the output of
commands.

The constructor takes a list of lines without their trailing newlines, i.e.
``text.splitlines()``.

**M√©thodes :**

- `__init__()`
- `__str__()`
- `_getlines()`
- `fnmatch_lines_random()`
- `re_match_lines_random()`
- `_match_lines_random()`
- `get_lines_after()`
- `_log()`
- `_log_text()`
- `fnmatch_lines()`
- `re_match_lines()`
- `_match_lines()`
- `no_fnmatch_line()`
- `no_re_match_line()`
- `_no_match_line()`
- `_fail()`
- `str()`

##### TimeoutExpired

##### PytesterHelperPlugin

**M√©thodes :**

- `pytest_configure()`

##### reprec

##### reprec

##### reprec

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### _pytest

Return a helper which offers a gethookrecorder(hook) method which
returns a HookRecorder instance which helps to make assertions about called
hooks.

**Param√®tres :**

- `request`

##### get_public_names

Only return names from iterator values without a leading underscore.

**Param√®tres :**

- `values`

##### linecomp

A :class: `LineComp` instance for checking that an input linearly
contains a sequence of strings.

##### LineMatcher_fixture

A reference to the :class: `LineMatcher`.

This is instantiable with a list of lines (without their trailing newlines).
This is useful for testing large texts, such as the output of commands.

**Param√®tres :**

- `request`

##### pytester

Facilities to write tests/configuration files, execute pytest in isolation, and match
against expected output, perfect for black-box testing of pytest plugins.

It attempts to isolate the test run from external factors as much as possible, modifying
the current working directory to ``path`` and environment variables during initialization.

It is particularly useful for testing plugins. It is similar to the :fixture:`tmp_path`
fixture but provides methods which aid in testing pytest itself.

**Param√®tres :**

- `request`
- `tmp_path_factory`
- `monkeypatch`

##### _sys_snapshot

##### _config_for_test

##### get_open_files

##### matching_platform

##### pytest_runtest_protocol

**Param√®tres :**

- `item`

##### __init__

**Param√®tres :**

- `request`

##### gethookrecorder

**Param√®tres :**

- `hook`

##### __init__

**Param√®tres :**

- `name`
- `kwargs`

##### __repr__

##### __init__

**Param√®tres :**

- `pluginmanager`

##### finish_recording

##### getcalls

Get all recorded calls to hooks with the given names (or name).

**Param√®tres :**

- `names`

##### assert_contains

**Param√®tres :**

- `entries`

##### popcall

**Param√®tres :**

- `name`

##### getcall

**Param√®tres :**

- `name`

##### getreports

**Param√®tres :**

- `names`

##### getreports

**Param√®tres :**

- `names`

##### getreports

**Param√®tres :**

- `names`

##### getreports

**Param√®tres :**

- `names`

##### matchreport

Return a testreport whose dotted import path matches.

**Param√®tres :**

- `inamepart`
- `names`
- `when`

##### getfailures

**Param√®tres :**

- `names`

##### getfailures

**Param√®tres :**

- `names`

##### getfailures

**Param√®tres :**

- `names`

##### getfailures

**Param√®tres :**

- `names`

##### getfailedcollections

##### listoutcomes

##### countoutcomes

##### assertoutcome

**Param√®tres :**

- `passed`
- `skipped`
- `failed`

##### clear

##### __init__

**Param√®tres :**

- `ret`
- `outlines`
- `errlines`
- `duration`

##### __repr__

##### parseoutcomes

Return a dictionary of outcome noun -> count from parsing the terminal
output that the test process produced.

The returned nouns will always be in plural form::

    ======= 1 failed, 1 passed, 1 warning, 1 error in 0.13s ====

Will return ``{"failed": 1, "passed": 1, "warnings": 1, "errors": 1}``.

##### parse_summary_nouns

Extract the nouns from a pytest terminal summary line.

It always returns the plural noun for consistency::

    ======= 1 failed, 1 passed, 1 warning, 1 error in 0.13s ====

Will return ``{"failed": 1, "passed": 1, "warnings": 1, "errors": 1}``.

**Param√®tres :**

- `cls`
- `lines`

##### assert_outcomes

Assert that the specified outcomes appear with the respective
numbers (0 means it didn't occur) in the text output from a test run.

``warnings`` and ``deselected`` are only checked if not None.

**Param√®tres :**

- `passed`
- `skipped`
- `failed`
- `errors`
- `xpassed`
- `xfailed`
- `warnings`
- `deselected`

##### __init__

**Param√®tres :**

- `preserve`

##### restore

##### __init__

##### restore

##### __init__

**Param√®tres :**

- `request`
- `tmp_path_factory`
- `monkeypatch`

##### path

Temporary directory path used to create files/run tests from, etc.

##### __repr__

##### _finalize

Clean up global state artifacts.

Some methods modify the global interpreter state and this tries to
clean this up. It does not remove the temporary directory however so
it can be looked at after the test run has finished.

##### __take_sys_modules_snapshot

##### make_hook_recorder

Create a new :class:`HookRecorder` for a :class:`PytestPluginManager`.

**Param√®tres :**

- `pluginmanager`

##### chdir

Cd into the temporary directory.

This is done automatically upon instantiation.

##### _makefile

**Param√®tres :**

- `ext`
- `lines`
- `files`
- `encoding`

##### makefile

Create new text file(s) in the test directory.

:param ext:
    The extension the file(s) should use, including the dot, e.g. `.py`.
:param args:
    All args are treated as strings and joined using newlines.
    The result is written as contents to the file.  The name of the
    file is based on the test function requesting this fixture.
:param kwargs:
    Each keyword is the name of a file, while the value of it will
    be written as contents of the file.
:returns:
    The first created file.

Examples:

.. code-block:: python

    pytester.makefile(".txt", "line1", "line2")

    pytester.makefile(".ini", pytest="[pytest]\naddopts=-rs\n")

To create binary files, use :meth:`pathlib.Path.write_bytes` directly:

.. code-block:: python

    filename = pytester.path.joinpath("foo.bin")
    filename.write_bytes(b"...")

**Param√®tres :**

- `ext`

##### makeconftest

Write a conftest.py file.

:param source: The contents.
:returns: The conftest.py file.

**Param√®tres :**

- `source`

##### makeini

Write a tox.ini file.

:param source: The contents.
:returns: The tox.ini file.

**Param√®tres :**

- `source`

##### getinicfg

Return the pytest section from the tox.ini config file.

**Param√®tres :**

- `source`

##### makepyprojecttoml

Write a pyproject.toml file.

:param source: The contents.
:returns: The pyproject.ini file.

.. versionadded:: 6.0

**Param√®tres :**

- `source`

##### makepyfile

Shortcut for .makefile() with a .py extension.

Defaults to the test name with a '.py' extension, e.g test_foobar.py, overwriting
existing files.

Examples:

.. code-block:: python

    def test_something(pytester):
        # Initial file is created test_something.py.
        pytester.makepyfile("foobar")
        # To create multiple files, pass kwargs accordingly.
        pytester.makepyfile(custom="foobar")
        # At this point, both 'test_something.py' & 'custom.py' exist in the test directory.

##### maketxtfile

Shortcut for .makefile() with a .txt extension.

Defaults to the test name with a '.txt' extension, e.g test_foobar.txt, overwriting
existing files.

Examples:

.. code-block:: python

    def test_something(pytester):
        # Initial file is created test_something.txt.
        pytester.maketxtfile("foobar")
        # To create multiple files, pass kwargs accordingly.
        pytester.maketxtfile(custom="foobar")
        # At this point, both 'test_something.txt' & 'custom.txt' exist in the test directory.

##### syspathinsert

Prepend a directory to sys.path, defaults to :attr:`path`.

This is undone automatically when this object dies at the end of each
test.

:param path:
    The path.

**Param√®tres :**

- `path`

##### mkdir

Create a new (sub)directory.

:param name:
    The name of the directory, relative to the pytester path.
:returns:
    The created directory.
:rtype: pathlib.Path

**Param√®tres :**

- `name`

##### mkpydir

Create a new python package.

This creates a (sub)directory with an empty ``__init__.py`` file so it
gets recognised as a Python package.

**Param√®tres :**

- `name`

##### copy_example

Copy file from project's directory into the testdir.

:param name:
    The name of the file to copy.
:return:
    Path to the copied directory (inside ``self.path``).
:rtype: pathlib.Path

**Param√®tres :**

- `name`

##### getnode

Get the collection node of a file.

:param config:
   A pytest config.
   See :py:meth:`parseconfig` and :py:meth:`parseconfigure` for creating it.
:param arg:
    Path to the file.
:returns:
    The node.

**Param√®tres :**

- `config`
- `arg`

##### getpathnode

Return the collection node of a file.

This is like :py:meth:`getnode` but uses :py:meth:`parseconfigure` to
create the (configured) pytest Config instance.

:param path:
    Path to the file.
:returns:
    The node.

**Param√®tres :**

- `path`

##### genitems

Generate all test items from a collection node.

This recurses into the collection node and returns a list of all the
test items contained within.

:param colitems:
    The collection nodes.
:returns:
    The collected items.

**Param√®tres :**

- `colitems`

##### runitem

Run the "test_func" Item.

The calling test instance (class containing the test method) must
provide a ``.getrunner()`` method which should return a runner which
can run the test protocol for a single item, e.g.
``_pytest.runner.runtestprotocol``.

**Param√®tres :**

- `source`

##### inline_runsource

Run a test module in process using ``pytest.main()``.

This run writes "source" into a temporary file and runs
``pytest.main()`` on it, returning a :py:class:`HookRecorder` instance
for the result.

:param source: The source code of the test module.
:param cmdlineargs: Any extra command line arguments to use.

**Param√®tres :**

- `source`

##### inline_genitems

Run ``pytest.main(['--collect-only'])`` in-process.

Runs the :py:func:`pytest.main` function to run all of pytest inside
the test process itself like :py:meth:`inline_run`, but returns a
tuple of the collected items and a :py:class:`HookRecorder` instance.

##### inline_run

Run ``pytest.main()`` in-process, returning a HookRecorder.

Runs the :py:func:`pytest.main` function to run all of pytest inside
the test process itself.  This means it can return a
:py:class:`HookRecorder` instance which gives more detailed results
from that run than can be done by matching stdout/stderr from
:py:meth:`runpytest`.

:param args:
    Command line arguments to pass to :py:func:`pytest.main`.
:param plugins:
    Extra plugin instances the ``pytest.main()`` instance should use.
:param no_reraise_ctrlc:
    Typically we reraise keyboard interrupts from the child run. If
    True, the KeyboardInterrupt exception is captured.

##### runpytest_inprocess

Return result of running pytest in-process, providing a similar
interface to what self.runpytest() provides.

##### runpytest

Run pytest inline or in a subprocess, depending on the command line
option "--runpytest" and return a :py:class:`~pytest.RunResult`.

##### _ensure_basetemp

**Param√®tres :**

- `args`

##### parseconfig

Return a new pytest :class:`pytest.Config` instance from given
commandline args.

This invokes the pytest bootstrapping code in _pytest.config to create a
new :py:class:`pytest.PytestPluginManager` and call the
:hook:`pytest_cmdline_parse` hook to create a new :class:`pytest.Config`
instance.

If :attr:`plugins` has been populated they should be plugin modules
to be registered with the plugin manager.

##### parseconfigure

Return a new pytest configured Config instance.

Returns a new :py:class:`pytest.Config` instance like
:py:meth:`parseconfig`, but also calls the :hook:`pytest_configure`
hook.

##### getitem

Return the test item for a test function.

Writes the source to a python file and runs pytest's collection on
the resulting module, returning the test item for the requested
function name.

:param source:
    The module source.
:param funcname:
    The name of the test function for which to return a test item.
:returns:
    The test item.

**Param√®tres :**

- `source`
- `funcname`

##### getitems

Return all test items collected from the module.

Writes the source to a Python file and runs pytest's collection on
the resulting module, returning all test items contained within.

**Param√®tres :**

- `source`

##### getmodulecol

Return the module collection node for ``source``.

Writes ``source`` to a file using :py:meth:`makepyfile` and then
runs the pytest collection on it, returning the collection node for the
test module.

:param source:
    The source code of the module to collect.

:param configargs:
    Any extra arguments to pass to :py:meth:`parseconfigure`.

:param withinit:
    Whether to also write an ``__init__.py`` file to the same
    directory to ensure it is a package.

**Param√®tres :**

- `source`
- `configargs`

##### collect_by_name

Return the collection node for name from the module collection.

Searches a module collection node for a collection node matching the
given name.

:param modcol: A module collection node; see :py:meth:`getmodulecol`.
:param name: The name of the node to return.

**Param√®tres :**

- `modcol`
- `name`

##### popen

Invoke :py:class:`subprocess.Popen`.

Calls :py:class:`subprocess.Popen` making sure the current working
directory is in ``PYTHONPATH``.

You probably want to use :py:meth:`run` instead.

**Param√®tres :**

- `cmdargs`
- `stdout`
- `stderr`
- `stdin`

##### run

Run a command with arguments.

Run a process using :py:class:`subprocess.Popen` saving the stdout and
stderr.

:param cmdargs:
    The sequence of arguments to pass to :py:class:`subprocess.Popen`,
    with path-like objects being converted to :py:class:`str`
    automatically.
:param timeout:
    The period in seconds after which to timeout and raise
    :py:class:`Pytester.TimeoutExpired`.
:param stdin:
    Optional standard input.

    - If it is ``CLOSE_STDIN`` (Default), then this method calls
      :py:class:`subprocess.Popen` with ``stdin=subprocess.PIPE``, and
      the standard input is closed immediately after the new command is
      started.

    - If it is of type :py:class:`bytes`, these bytes are sent to the
      standard input of the command.

    - Otherwise, it is passed through to :py:class:`subprocess.Popen`.
      For further information in this case, consult the document of the
      ``stdin`` parameter in :py:class:`subprocess.Popen`.
:type stdin: _pytest.compat.NotSetType | bytes | IO[Any] | int
:returns:
    The result.

##### _dump_lines

**Param√®tres :**

- `lines`
- `fp`

##### _getpytestargs

##### runpython

Run a python script using sys.executable as interpreter.

**Param√®tres :**

- `script`

##### runpython_c

Run ``python -c "command"``.

**Param√®tres :**

- `command`

##### runpytest_subprocess

Run pytest as a subprocess with given arguments.

Any plugins added to the :py:attr:`plugins` list will be added using the
``-p`` command line option.  Additionally ``--basetemp`` is used to put
any temporary files and directories in a numbered directory prefixed
with "runpytest-" to not conflict with the normal numbered pytest
location for temporary files and directories.

:param args:
    The sequence of arguments to pass to the pytest subprocess.
:param timeout:
    The period in seconds after which to timeout and raise
    :py:class:`Pytester.TimeoutExpired`.
:returns:
    The result.

##### spawn_pytest

Run pytest using pexpect.

This makes sure to use the right pytest and sets up the temporary
directory locations.

The pexpect child is returned.

**Param√®tres :**

- `string`
- `expect_timeout`

##### spawn

Run a command using pexpect.

The pexpect child is returned.

**Param√®tres :**

- `cmd`
- `expect_timeout`

##### __init__

##### assert_contains_lines

Assert that ``lines2`` are contained (linearly) in :attr:`stringio`'s value.

Lines are matched using :func:`LineMatcher.fnmatch_lines <pytest.LineMatcher.fnmatch_lines>`.

**Param√®tres :**

- `lines2`

##### __init__

**Param√®tres :**

- `lines`

##### __str__

Return the entire original text.

.. versionadded:: 6.2
    You can use :meth:`str` in older versions.

##### _getlines

**Param√®tres :**

- `lines2`

##### fnmatch_lines_random

Check lines exist in the output in any order (using :func:`python:fnmatch.fnmatch`).

**Param√®tres :**

- `lines2`

##### re_match_lines_random

Check lines exist in the output in any order (using :func:`python:re.match`).

**Param√®tres :**

- `lines2`

##### _match_lines_random

**Param√®tres :**

- `lines2`
- `match_func`

##### get_lines_after

Return all lines following the given line in the text.

The given line can contain glob wildcards.

**Param√®tres :**

- `fnline`

##### _log

##### _log_text

##### fnmatch_lines

Check lines exist in the output (using :func:`python:fnmatch.fnmatch`).

The argument is a list of lines which have to match and can use glob
wildcards.  If they do not match a pytest.fail() is called.  The
matches and non-matches are also shown as part of the error message.

:param lines2: String patterns to match.
:param consecutive: Match lines consecutively?

**Param√®tres :**

- `lines2`

##### re_match_lines

Check lines exist in the output (using :func:`python:re.match`).

The argument is a list of lines which have to match using ``re.match``.
If they do not match a pytest.fail() is called.

The matches and non-matches are also shown as part of the error message.

:param lines2: string patterns to match.
:param consecutive: match lines consecutively?

**Param√®tres :**

- `lines2`

##### _match_lines

Underlying implementation of ``fnmatch_lines`` and ``re_match_lines``.

:param Sequence[str] lines2:
    List of string patterns to match. The actual format depends on
    ``match_func``.
:param match_func:
    A callable ``match_func(line, pattern)`` where line is the
    captured line from stdout/stderr and pattern is the matching
    pattern.
:param str match_nickname:
    The nickname for the match function that will be logged to stdout
    when a match occurs.
:param consecutive:
    Match lines consecutively?

**Param√®tres :**

- `lines2`
- `match_func`
- `match_nickname`

##### no_fnmatch_line

Ensure captured lines do not match the given pattern, using ``fnmatch.fnmatch``.

:param str pat: The pattern to match lines.

**Param√®tres :**

- `pat`

##### no_re_match_line

Ensure captured lines do not match the given pattern, using ``re.match``.

:param str pat: The regular expression to match lines.

**Param√®tres :**

- `pat`

##### _no_match_line

Ensure captured lines does not have a the given pattern, using ``fnmatch.fnmatch``.

:param str pat: The pattern to match lines.

**Param√®tres :**

- `pat`
- `match_func`
- `match_nickname`

##### _fail

**Param√®tres :**

- `msg`

##### str

Return the entire original text.

##### isopen

**Param√®tres :**

- `line`

##### __getattr__

**Param√®tres :**

- `key`

##### before

**Param√®tres :**

- `hook_name`
- `hook_impls`
- `kwargs`

##### after

**Param√®tres :**

- `outcome`
- `hook_name`
- `hook_impls`
- `kwargs`

##### preserve_module

**Param√®tres :**

- `name`

##### to_text

**Param√®tres :**

- `s`

##### handle_timeout

##### pytest_configure

**Param√®tres :**

- `config`

---

### pytester_assertions

Helper plugin for pytester; should not be loaded on its own.

#### Fonctions

##### assertoutcome

**Param√®tres :**

- `outcomes`
- `passed`
- `skipped`
- `failed`

##### assert_outcomes

Assert that the specified outcomes appear with the respective
numbers (0 means it didn't occur) in the text output from a test run.

**Param√®tres :**

- `outcomes`
- `passed`
- `skipped`
- `failed`
- `errors`
- `xpassed`
- `xfailed`
- `warnings`
- `deselected`

---

### python

Python test discovery, setup and run of test functions.

#### Classes

##### PyobjMixin

this mix-in inherits from Node to carry over the typing information

as its intended to always mix in before a node
its position in the mro is unaffected

**M√©thodes :**

- `module()`
- `cls()`
- `instance()`
- `obj()`
- `obj()`
- `_getobj()`
- `getmodpath()`
- `reportinfo()`

##### _EmptyClass

##### PyCollector

**M√©thodes :**

- `funcnamefilter()`
- `isnosetest()`
- `classnamefilter()`
- `istestfunction()`
- `istestclass()`
- `_matches_prefix_or_glob_option()`
- `collect()`
- `_genfunctions()`

##### Module

Collector for test classes and functions in a Python module.

**M√©thodes :**

- `_getobj()`
- `collect()`
- `_register_setup_module_fixture()`
- `_register_setup_function_fixture()`

##### Package

Collector for files and directories in a Python packages -- directories
with an `__init__.py` file.

.. note::

    Directories without an `__init__.py` file are instead collected by
    :class:`~pytest.Dir` by default. Both are :class:`~pytest.Directory`
    collectors.

.. versionchanged:: 8.0

    Now inherits from :class:`~pytest.Directory`.

**M√©thodes :**

- `__init__()`
- `setup()`
- `collect()`

##### Class

Collector for test methods (and nested classes) in a Python class.

**M√©thodes :**

- `from_parent()`
- `newinstance()`
- `collect()`
- `_register_setup_class_fixture()`
- `_register_setup_method_fixture()`

##### IdMaker

Make IDs for a parametrization.

**M√©thodes :**

- `make_unique_parameterset_ids()`
- `_resolve_ids()`
- `_idval()`
- `_idval_from_function()`
- `_idval_from_hook()`
- `_idval_from_value()`
- `_idval_from_value_required()`
- `_idval_from_argname()`
- `_complain_multiple_hidden_parameter_sets()`
- `_make_error_prefix()`

##### CallSpec2

A planned parameterized invocation of a test function.

Calculated during collection for a given test function's Metafunc.
Once collection is over, each callspec is turned into a single Item
and stored in item.callspec.

**M√©thodes :**

- `setmulti()`
- `getparam()`
- `id()`

##### Metafunc

Objects passed to the :hook:`pytest_generate_tests` hook.

They help to inspect a test function and to generate tests according to
test configuration or values specified in the class or module where a
test function is defined.

**M√©thodes :**

- `__init__()`
- `parametrize()`
- `_resolve_parameter_set_ids()`
- `_validate_ids()`
- `_resolve_args_directness()`
- `_validate_if_using_arg_names()`
- `_recompute_direct_params_indices()`

##### Function

Item responsible for setting up and executing a Python test function.

:param name:
    The full function name, including any decorations like those
    added by parametrization (``my_func[my_param]``).
:param parent:
    The parent Node.
:param config:
    The pytest Config object.
:param callspec:
    If given, this function has been parametrized and the callspec contains
    meta information about the parametrization.
:param callobj:
    If given, the object which will be called when the Function is invoked,
    otherwise the callobj will be obtained from ``parent`` using ``originalname``.
:param keywords:
    Keywords bound to the function object for "-k" matching.
:param session:
    The pytest Session object.
:param fixtureinfo:
    Fixture information already resolved at this fixture node..
:param originalname:
    The attribute name to use for accessing the underlying function object.
    Defaults to ``name``. Set this if name is different from the original name,
    for example when it contains decorations like those added by parametrization
    (``my_func[my_param]``).

**M√©thodes :**

- `__init__()`
- `from_parent()`
- `_initrequest()`
- `function()`
- `instance()`
- `_getinstance()`
- `_getobj()`
- `_pyfuncitem()`
- `runtest()`
- `setup()`
- `_traceback_filter()`
- `repr_failure()`

##### FunctionDefinition

This class is a stop gap solution until we evolve to have actual function
definition nodes and manage to get rid of ``metafunc``.

**M√©thodes :**

- `runtest()`

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_generate_tests

**Param√®tres :**

- `metafunc`

##### pytest_configure

**Param√®tres :**

- `config`

##### async_fail

**Param√®tres :**

- `nodeid`

##### pytest_pyfunc_call

**Param√®tres :**

- `pyfuncitem`

##### pytest_collect_directory

**Param√®tres :**

- `path`
- `parent`

##### pytest_collect_file

**Param√®tres :**

- `file_path`
- `parent`

##### path_matches_patterns

Return whether path matches any of the patterns in the list of globs given.

**Param√®tres :**

- `path`
- `patterns`

##### pytest_pycollect_makemodule

**Param√®tres :**

- `module_path`
- `parent`

##### pytest_pycollect_makeitem

**Param√®tres :**

- `collector`
- `name`
- `obj`

##### importtestmodule

**Param√®tres :**

- `path`
- `config`

##### _call_with_optional_argument

Call the given function with the given argument if func accepts one argument, otherwise
calls func without arguments.

**Param√®tres :**

- `func`
- `arg`

##### _get_first_non_fixture_func

Return the attribute from the given object to be used as a setup/teardown
xunit-style function, but only if not marked as a fixture to avoid calling it twice.

**Param√®tres :**

- `obj`
- `names`

##### hasinit

**Param√®tres :**

- `obj`

##### hasnew

**Param√®tres :**

- `obj`

##### get_direct_param_fixture_func

**Param√®tres :**

- `request`

##### _find_parametrized_scope

Find the most appropriate scope for a parametrized call based on its arguments.

When there's at least one direct argument, always use "function" scope.

When a test function is parametrized and all its arguments are indirect
(e.g. fixtures), return the most narrow scope based on the fixtures used.

Related to issue #1832, based on code posted by @Kingdread.

**Param√®tres :**

- `argnames`
- `arg2fixturedefs`
- `indirect`

##### _ascii_escaped_by_config

**Param√®tres :**

- `val`
- `config`

##### module

Python module object this node was collected from (can be None).

##### cls

Python class object this node was collected from (can be None).

##### instance

Python instance object the function is bound to.

Returns None if not a test method, e.g. for a standalone test function,
a class or a module.

##### obj

Underlying Python object.

##### obj

**Param√®tres :**

- `value`

##### _getobj

Get the underlying Python object. May be overwritten by subclasses.

##### getmodpath

Return Python path relative to the containing module.

**Param√®tres :**

- `stopatmodule`
- `includemodule`

##### reportinfo

##### funcnamefilter

**Param√®tres :**

- `name`

##### isnosetest

Look for the __test__ attribute, which is applied by the
@nose.tools.istest decorator.

**Param√®tres :**

- `obj`

##### classnamefilter

**Param√®tres :**

- `name`

##### istestfunction

**Param√®tres :**

- `obj`
- `name`

##### istestclass

**Param√®tres :**

- `obj`
- `name`

##### _matches_prefix_or_glob_option

Check if the given name matches the prefix or glob-pattern defined
in ini configuration.

**Param√®tres :**

- `option_name`
- `name`

##### collect

##### _genfunctions

**Param√®tres :**

- `name`
- `funcobj`

##### _getobj

##### collect

##### _register_setup_module_fixture

Register an autouse, module-scoped fixture for the collected module object
that invokes setUpModule/tearDownModule if either or both are available.

Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with
other fixtures (#517).

##### _register_setup_function_fixture

Register an autouse, function-scoped fixture for the collected module object
that invokes setup_function/teardown_function if either or both are available.

Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with
other fixtures (#517).

##### __init__

**Param√®tres :**

- `fspath`
- `parent`
- `config`
- `session`
- `nodeid`
- `path`

##### setup

##### collect

##### from_parent

The public constructor.

**Param√®tres :**

- `cls`
- `parent`

##### newinstance

##### collect

##### _register_setup_class_fixture

Register an autouse, class scoped fixture into the collected class object
that invokes setup_class/teardown_class if either or both are available.

Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with
other fixtures (#517).

##### _register_setup_method_fixture

Register an autouse, function scoped fixture into the collected class object
that invokes setup_method/teardown_method if either or both are available.

Using a fixture to invoke these methods ensures we play nicely and unsurprisingly with
other fixtures (#517).

##### make_unique_parameterset_ids

Make a unique identifier for each ParameterSet, that may be used to
identify the parametrization in a node ID.

Format is <prm_1_token>-...-<prm_n_token>[counter], where prm_x_token is
- user-provided id, if given
- else an id derived from the value, applicable for certain types
- else <argname><parameterset index>
The counter suffix is appended only in case a string wouldn't be unique
otherwise.

##### _resolve_ids

Resolve IDs for all ParameterSets (may contain duplicates).

##### _idval

Make an ID for a parameter in a ParameterSet.

**Param√®tres :**

- `val`
- `argname`
- `idx`

##### _idval_from_function

Try to make an ID for a parameter in a ParameterSet using the
user-provided id callable, if given.

**Param√®tres :**

- `val`
- `argname`
- `idx`

##### _idval_from_hook

Try to make an ID for a parameter in a ParameterSet by calling the
:hook:`pytest_make_parametrize_id` hook.

**Param√®tres :**

- `val`
- `argname`

##### _idval_from_value

Try to make an ID for a parameter in a ParameterSet from its value,
if the value type is supported.

**Param√®tres :**

- `val`

##### _idval_from_value_required

Like _idval_from_value(), but fails if the type is not supported.

**Param√®tres :**

- `val`
- `idx`

##### _idval_from_argname

Make an ID for a parameter in a ParameterSet from the argument name
and the index of the ParameterSet.

**Param√®tres :**

- `argname`
- `idx`

##### _complain_multiple_hidden_parameter_sets

##### _make_error_prefix

##### setmulti

##### getparam

**Param√®tres :**

- `name`

##### id

##### __init__

**Param√®tres :**

- `definition`
- `fixtureinfo`
- `config`
- `cls`
- `module`

##### parametrize

Add new invocations to the underlying test function using the list
of argvalues for the given argnames. Parametrization is performed
during the collection phase. If you need to setup expensive resources
see about setting ``indirect`` to do it at test setup time instead.

Can be called multiple times per test function (but only on different
argument names), in which case each call parametrizes all previous
parametrizations, e.g.

::

    unparametrized:         t
    parametrize ["x", "y"]: t[x], t[y]
    parametrize [1, 2]:     t[x-1], t[x-2], t[y-1], t[y-2]

:param argnames:
    A comma-separated string denoting one or more argument names, or
    a list/tuple of argument strings.

:param argvalues:
    The list of argvalues determines how often a test is invoked with
    different argument values.

    If only one argname was specified argvalues is a list of values.
    If N argnames were specified, argvalues must be a list of
    N-tuples, where each tuple-element specifies a value for its
    respective argname.

:param indirect:
    A list of arguments' names (subset of argnames) or a boolean.
    If True the list contains all names from the argnames. Each
    argvalue corresponding to an argname in this list will
    be passed as request.param to its respective argname fixture
    function so that it can perform more expensive setups during the
    setup phase of a test rather than at collection time.

:param ids:
    Sequence of (or generator for) ids for ``argvalues``,
    or a callable to return part of the id for each argvalue.

    With sequences (and generators like ``itertools.count()``) the
    returned ids should be of type ``string``, ``int``, ``float``,
    ``bool``, or ``None``.
    They are mapped to the corresponding index in ``argvalues``.
    ``None`` means to use the auto-generated id.

    .. versionadded:: 8.4
        :ref:`hidden-param` means to hide the parameter set
        from the test name. Can only be used at most 1 time, as
        test names need to be unique.

    If it is a callable it will be called for each entry in
    ``argvalues``, and the return value is used as part of the
    auto-generated id for the whole set (where parts are joined with
    dashes ("-")).
    This is useful to provide more specific ids for certain items, e.g.
    dates.  Returning ``None`` will use an auto-generated id.

    If no ids are provided they will be generated automatically from
    the argvalues.

:param scope:
    If specified it denotes the scope of the parameters.
    The scope is used for grouping tests by parameter instances.
    It will also override any fixture-function defined scope, allowing
    to set a dynamic scope using test context or configuration.

**Param√®tres :**

- `argnames`
- `argvalues`
- `indirect`
- `ids`
- `scope`

##### _resolve_parameter_set_ids

Resolve the actual ids for the given parameter sets.

:param argnames:
    Argument names passed to ``parametrize()``.
:param ids:
    The `ids` parameter of the ``parametrize()`` call (see docs).
:param parametersets:
    The parameter sets, each containing a set of values corresponding
    to ``argnames``.
:param nodeid str:
    The nodeid of the definition item that generated this
    parametrization.
:returns:
    List with ids for each parameter set given.

**Param√®tres :**

- `argnames`
- `ids`
- `parametersets`
- `nodeid`

##### _validate_ids

**Param√®tres :**

- `ids`
- `parametersets`
- `func_name`

##### _resolve_args_directness

Resolve if each parametrized argument must be considered an indirect
parameter to a fixture of the same name, or a direct parameter to the
parametrized function, based on the ``indirect`` parameter of the
parametrized() call.

:param argnames:
    List of argument names passed to ``parametrize()``.
:param indirect:
    Same as the ``indirect`` parameter of ``parametrize()``.
:returns
    A dict mapping each arg name to either "indirect" or "direct".

**Param√®tres :**

- `argnames`
- `indirect`

##### _validate_if_using_arg_names

Check if all argnames are being used, by default values, or directly/indirectly.

:param List[str] argnames: List of argument names passed to ``parametrize()``.
:param indirect: Same as the ``indirect`` parameter of ``parametrize()``.
:raises ValueError: If validation fails.

**Param√®tres :**

- `argnames`
- `indirect`

##### _recompute_direct_params_indices

##### __init__

**Param√®tres :**

- `name`
- `parent`
- `config`
- `callspec`
- `callobj`
- `keywords`
- `session`
- `fixtureinfo`
- `originalname`

##### from_parent

The public constructor.

**Param√®tres :**

- `cls`
- `parent`

##### _initrequest

##### function

Underlying python 'function' object.

##### instance

##### _getinstance

##### _getobj

##### _pyfuncitem

(compatonly) for code expecting pytest-2.2 style request objects.

##### runtest

Execute the underlying test function.

##### setup

##### _traceback_filter

**Param√®tres :**

- `excinfo`

##### repr_failure

**Param√®tres :**

- `excinfo`

##### runtest

##### xunit_setup_module_fixture

**Param√®tres :**

- `request`

##### xunit_setup_function_fixture

**Param√®tres :**

- `request`

##### sort_key

**Param√®tres :**

- `entry`

##### xunit_setup_class_fixture

**Param√®tres :**

- `request`

##### xunit_setup_method_fixture

**Param√®tres :**

- `request`

---

### python_api

#### Classes

##### ApproxBase

Provide shared utilities for making approximate comparisons between
numbers or sequences of numbers.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `_repr_compare()`
- `__eq__()`
- `__bool__()`
- `__ne__()`
- `_approx_scalar()`
- `_yield_comparisons()`
- `_check_type()`

##### ApproxNumpy

Perform approximate comparisons where the expected value is numpy array.

**M√©thodes :**

- `__repr__()`
- `_repr_compare()`
- `__eq__()`
- `_yield_comparisons()`

##### ApproxMapping

Perform approximate comparisons where the expected value is a mapping
with numeric values (the keys can be anything).

**M√©thodes :**

- `__repr__()`
- `_repr_compare()`
- `__eq__()`
- `_yield_comparisons()`
- `_check_type()`

##### ApproxSequenceLike

Perform approximate comparisons where the expected value is a sequence of numbers.

**M√©thodes :**

- `__repr__()`
- `_repr_compare()`
- `__eq__()`
- `_yield_comparisons()`
- `_check_type()`

##### ApproxScalar

Perform approximate comparisons where the expected value is a single number.

**M√©thodes :**

- `__repr__()`
- `__eq__()`
- `tolerance()`

##### ApproxDecimal

Perform approximate comparisons where the expected value is a Decimal.

#### Fonctions

##### _compare_approx

**Param√®tres :**

- `full_object`
- `message_data`
- `number_of_elements`
- `different_ids`
- `max_abs_diff`
- `max_rel_diff`

##### _recursive_sequence_map

Recursively map a function over a sequence of arbitrary depth

**Param√®tres :**

- `f`
- `x`

##### approx

Assert that two numbers (or two ordered sequences of numbers) are equal to each other
within some tolerance.

Due to the :doc:`python:tutorial/floatingpoint`, numbers that we
would intuitively expect to be equal are not always so::

    >>> 0.1 + 0.2 == 0.3
    False

This problem is commonly encountered when writing tests, e.g. when making
sure that floating-point values are what you expect them to be.  One way to
deal with this problem is to assert that two floating-point numbers are
equal to within some appropriate tolerance::

    >>> abs((0.1 + 0.2) - 0.3) < 1e-6
    True

However, comparisons like this are tedious to write and difficult to
understand.  Furthermore, absolute comparisons like the one above are
usually discouraged because there's no tolerance that works well for all
situations.  ``1e-6`` is good for numbers around ``1``, but too small for
very big numbers and too big for very small ones.  It's better to express
the tolerance as a fraction of the expected value, but relative comparisons
like that are even more difficult to write correctly and concisely.

The ``approx`` class performs floating-point comparisons using a syntax
that's as intuitive as possible::

    >>> from pytest import approx
    >>> 0.1 + 0.2 == approx(0.3)
    True

The same syntax also works for ordered sequences of numbers::

    >>> (0.1 + 0.2, 0.2 + 0.4) == approx((0.3, 0.6))
    True

``numpy`` arrays::

    >>> import numpy as np                                                          # doctest: +SKIP
    >>> np.array([0.1, 0.2]) + np.array([0.2, 0.4]) == approx(np.array([0.3, 0.6])) # doctest: +SKIP
    True

And for a ``numpy`` array against a scalar::

    >>> import numpy as np                                         # doctest: +SKIP
    >>> np.array([0.1, 0.2]) + np.array([0.2, 0.1]) == approx(0.3) # doctest: +SKIP
    True

Only ordered sequences are supported, because ``approx`` needs
to infer the relative position of the sequences without ambiguity. This means
``sets`` and other unordered sequences are not supported.

Finally, dictionary *values* can also be compared::

    >>> {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6})
    True

The comparison will be true if both mappings have the same keys and their
respective values match the expected tolerances.

**Tolerances**

By default, ``approx`` considers numbers within a relative tolerance of
``1e-6`` (i.e. one part in a million) of its expected value to be equal.
This treatment would lead to surprising results if the expected value was
``0.0``, because nothing but ``0.0`` itself is relatively close to ``0.0``.
To handle this case less surprisingly, ``approx`` also considers numbers
within an absolute tolerance of ``1e-12`` of its expected value to be
equal.  Infinity and NaN are special cases.  Infinity is only considered
equal to itself, regardless of the relative tolerance.  NaN is not
considered equal to anything by default, but you can make it be equal to
itself by setting the ``nan_ok`` argument to True.  (This is meant to
facilitate comparing arrays that use NaN to mean "no data".)

Both the relative and absolute tolerances can be changed by passing
arguments to the ``approx`` constructor::

    >>> 1.0001 == approx(1)
    False
    >>> 1.0001 == approx(1, rel=1e-3)
    True
    >>> 1.0001 == approx(1, abs=1e-3)
    True

If you specify ``abs`` but not ``rel``, the comparison will not consider
the relative tolerance at all.  In other words, two numbers that are within
the default relative tolerance of ``1e-6`` will still be considered unequal
if they exceed the specified absolute tolerance.  If you specify both
``abs`` and ``rel``, the numbers will be considered equal if either
tolerance is met::

    >>> 1 + 1e-8 == approx(1)
    True
    >>> 1 + 1e-8 == approx(1, abs=1e-12)
    False
    >>> 1 + 1e-8 == approx(1, rel=1e-6, abs=1e-12)
    True

**Non-numeric types**

You can also use ``approx`` to compare non-numeric types, or dicts and
sequences containing non-numeric types, in which case it falls back to
strict equality. This can be useful for comparing dicts and sequences that
can contain optional values::

    >>> {"required": 1.0000005, "optional": None} == approx({"required": 1, "optional": None})
    True
    >>> [None, 1.0000005] == approx([None,1])
    True
    >>> ["foo", 1.0000005] == approx([None,1])
    False

If you're thinking about using ``approx``, then you might want to know how
it compares to other good ways of comparing floating-point numbers.  All of
these algorithms are based on relative and absolute tolerances and should
agree for the most part, but they do have meaningful differences:

- ``math.isclose(a, b, rel_tol=1e-9, abs_tol=0.0)``:  True if the relative
  tolerance is met w.r.t. either ``a`` or ``b`` or if the absolute
  tolerance is met.  Because the relative tolerance is calculated w.r.t.
  both ``a`` and ``b``, this test is symmetric (i.e.  neither ``a`` nor
  ``b`` is a "reference value").  You have to specify an absolute tolerance
  if you want to compare to ``0.0`` because there is no tolerance by
  default.  More information: :py:func:`math.isclose`.

- ``numpy.isclose(a, b, rtol=1e-5, atol=1e-8)``: True if the difference
  between ``a`` and ``b`` is less that the sum of the relative tolerance
  w.r.t. ``b`` and the absolute tolerance.  Because the relative tolerance
  is only calculated w.r.t. ``b``, this test is asymmetric and you can
  think of ``b`` as the reference value.  Support for comparing sequences
  is provided by :py:func:`numpy.allclose`.  More information:
  :std:doc:`numpy:reference/generated/numpy.isclose`.

- ``unittest.TestCase.assertAlmostEqual(a, b)``: True if ``a`` and ``b``
  are within an absolute tolerance of ``1e-7``.  No relative tolerance is
  considered , so this function is not appropriate for very large or very
  small numbers.  Also, it's only available in subclasses of ``unittest.TestCase``
  and it's ugly because it doesn't follow PEP8.  More information:
  :py:meth:`unittest.TestCase.assertAlmostEqual`.

- ``a == pytest.approx(b, rel=1e-6, abs=1e-12)``: True if the relative
  tolerance is met w.r.t. ``b`` or if the absolute tolerance is met.
  Because the relative tolerance is only calculated w.r.t. ``b``, this test
  is asymmetric and you can think of ``b`` as the reference value.  In the
  special case that you explicitly specify an absolute tolerance but not a
  relative tolerance, only the absolute tolerance is considered.

.. note::

    ``approx`` can handle numpy arrays, but we recommend the
    specialised test helpers in :std:doc:`numpy:reference/routines.testing`
    if you need support for comparisons, NaNs, or ULP-based tolerances.

    To match strings using regex, you can use
    `Matches <https://github.com/asottile/re-assert#re_assertmatchespattern-str-args-kwargs>`_
    from the
    `re_assert package <https://github.com/asottile/re-assert>`_.


.. note::

    Unlike built-in equality, this function considers
    booleans unequal to numeric zero or one. For example::

       >>> 1 == approx(True)
       False

.. warning::

   .. versionchanged:: 3.2

   In order to avoid inconsistent behavior, :py:exc:`TypeError` is
   raised for ``>``, ``>=``, ``<`` and ``<=`` comparisons.
   The example below illustrates the problem::

       assert approx(0.1) > 0.1 + 1e-10  # calls approx(0.1).__gt__(0.1 + 1e-10)
       assert 0.1 + 1e-10 > approx(0.1)  # calls approx(0.1).__lt__(0.1 + 1e-10)

   In the second example one expects ``approx(0.1).__le__(0.1 + 1e-10)``
   to be called. But instead, ``approx(0.1).__lt__(0.1 + 1e-10)`` is used to
   comparison. This is because the call hierarchy of rich comparisons
   follows a fixed behavior. More information: :py:meth:`object.__ge__`

.. versionchanged:: 3.7.1
   ``approx`` raises ``TypeError`` when it encounters a dict value or
   sequence element of non-numeric type.

.. versionchanged:: 6.1.0
   ``approx`` falls back to strict equality for non-numeric types instead
   of raising ``TypeError``.

**Param√®tres :**

- `expected`
- `rel`
- `abs`
- `nan_ok`

##### _is_sequence_like

**Param√®tres :**

- `expected`

##### _is_numpy_array

Return true if the given object is implicitly convertible to ndarray,
and numpy is already imported.

**Param√®tres :**

- `obj`

##### _as_numpy_array

Return an ndarray if the given object is implicitly convertible to ndarray,
and numpy is already imported, otherwise None.

**Param√®tres :**

- `obj`

##### __init__

**Param√®tres :**

- `expected`
- `rel`
- `abs`
- `nan_ok`

##### __repr__

##### _repr_compare

**Param√®tres :**

- `other_side`

##### __eq__

**Param√®tres :**

- `actual`

##### __bool__

##### __ne__

**Param√®tres :**

- `actual`

##### _approx_scalar

**Param√®tres :**

- `x`

##### _yield_comparisons

Yield all the pairs of numbers to be compared.

This is used to implement the `__eq__` method.

**Param√®tres :**

- `actual`

##### _check_type

Raise a TypeError if the expected value is not a valid type.

##### __repr__

##### _repr_compare

**Param√®tres :**

- `other_side`

##### __eq__

**Param√®tres :**

- `actual`

##### _yield_comparisons

**Param√®tres :**

- `actual`

##### __repr__

##### _repr_compare

**Param√®tres :**

- `other_side`

##### __eq__

**Param√®tres :**

- `actual`

##### _yield_comparisons

**Param√®tres :**

- `actual`

##### _check_type

##### __repr__

##### _repr_compare

**Param√®tres :**

- `other_side`

##### __eq__

**Param√®tres :**

- `actual`

##### _yield_comparisons

**Param√®tres :**

- `actual`

##### _check_type

##### __repr__

Return a string communicating both the expected value and the
tolerance for the comparison being made.

For example, ``1.0 ¬± 1e-6``, ``(3+4j) ¬± 5e-6 ‚à† ¬±180¬∞``.

##### __eq__

Return whether the given value is equal to the expected value
within the pre-specified tolerance.

**Param√®tres :**

- `actual`

##### tolerance

Return the tolerance for the comparison.

This could be either an absolute tolerance or a relative tolerance,
depending on what the user specified or which would be larger.

##### get_value_from_nested_list

Helper function to get the value out of a nested list, given an n-dimensional index.
This mimics numpy's indexing, but for raw nested python lists.

**Param√®tres :**

- `nested_list`
- `nd_index`

##### is_bool

**Param√®tres :**

- `val`

##### set_default

**Param√®tres :**

- `x`
- `default`

---

### raises

#### Classes

##### AbstractRaises

ABC with common functionality shared between RaisesExc and RaisesGroup

**M√©thodes :**

- `__init__()`
- `_parse_exc()`
- `fail_reason()`
- `_check_check()`
- `_check_match()`
- `matches()`

##### RaisesExc

.. versionadded:: 8.4


This is the class constructed when calling :func:`pytest.raises`, but may be used
directly as a helper class with :class:`RaisesGroup` when you want to specify
requirements on sub-exceptions.

You don't need this if you only want to specify the type, since :class:`RaisesGroup`
accepts ``type[BaseException]``.

:param type[BaseException] | tuple[type[BaseException]] | None expected_exception:
    The expected type, or one of several possible types.
    May be ``None`` in order to only make use of ``match`` and/or ``check``

    The type is checked with :func:`isinstance`, and does not need to be an exact match.
    If that is wanted you can use the ``check`` parameter.

:kwparam str | Pattern[str] match
    A regex to match.

:kwparam Callable[[BaseException], bool] check:
    If specified, a callable that will be called with the exception as a parameter
    after checking the type and the match regex if specified.
    If it returns ``True`` it will be considered a match, if not it will
    be considered a failed match.

:meth:`RaisesExc.matches` can also be used standalone to check individual exceptions.

Examples::

    with RaisesGroup(RaisesExc(ValueError, match="string"))
        ...
    with RaisesGroup(RaisesExc(check=lambda x: x.args == (3, "hello"))):
        ...
    with RaisesGroup(RaisesExc(check=lambda x: type(x) is ValueError)):
        ...

**M√©thodes :**

- `__init__()`
- `__init__()`
- `__init__()`
- `__init__()`
- `matches()`
- `__repr__()`
- `_check_type()`
- `__enter__()`
- `__exit__()`

##### RaisesGroup

.. versionadded:: 8.4

Contextmanager for checking for an expected :exc:`ExceptionGroup`.
This works similar to :func:`pytest.raises`, but allows for specifying the structure of an :exc:`ExceptionGroup`.
:meth:`ExceptionInfo.group_contains` also tries to handle exception groups,
but it is very bad at checking that you *didn't* get unexpected exceptions.

The catching behaviour differs from :ref:`except* <except_star>`, being much
stricter about the structure by default.
By using ``allow_unwrapped=True`` and ``flatten_subgroups=True`` you can match
:ref:`except* <except_star>` fully when expecting a single exception.

:param args:
    Any number of exception types, :class:`RaisesGroup` or :class:`RaisesExc`
    to specify the exceptions contained in this exception.
    All specified exceptions must be present in the raised group, *and no others*.

    If you expect a variable number of exceptions you need to use
    :func:`pytest.raises(ExceptionGroup) <pytest.raises>` and manually check
    the contained exceptions. Consider making use of :meth:`RaisesExc.matches`.

    It does not care about the order of the exceptions, so
    ``RaisesGroup(ValueError, TypeError)``
    is equivalent to
    ``RaisesGroup(TypeError, ValueError)``.
:kwparam str | re.Pattern[str] | None match:
    If specified, a string containing a regular expression,
    or a regular expression object, that is tested against the string
    representation of the exception group and its :pep:`678` `__notes__`
    using :func:`re.search`.

    To match a literal string that may contain :ref:`special characters
    <re-syntax>`, the pattern can first be escaped with :func:`re.escape`.

    Note that " (5 subgroups)" will be stripped from the ``repr`` before matching.
:kwparam Callable[[E], bool] check:
    If specified, a callable that will be called with the group as a parameter
    after successfully matching the expected exceptions. If it returns ``True``
    it will be considered a match, if not it will be considered a failed match.
:kwparam bool allow_unwrapped:
    If expecting a single exception or :class:`RaisesExc` it will match even
    if the exception is not inside an exceptiongroup.

    Using this together with ``match``, ``check`` or expecting multiple exceptions
    will raise an error.
:kwparam bool flatten_subgroups:
    "flatten" any groups inside the raised exception group, extracting all exceptions
    inside any nested groups, before matching. Without this it expects you to
    fully specify the nesting structure by passing :class:`RaisesGroup` as expected
    parameter.

Examples::

    with RaisesGroup(ValueError):
        raise ExceptionGroup("", (ValueError(),))
    # match
    with RaisesGroup(
        ValueError,
        ValueError,
        RaisesExc(TypeError, match="^expected int$"),
        match="^my group$",
    ):
        raise ExceptionGroup(
            "my group",
            [
                ValueError(),
                TypeError("expected int"),
                ValueError(),
            ],
        )
    # check
    with RaisesGroup(
        KeyboardInterrupt,
        match="^hello$",
        check=lambda x: isinstance(x.__cause__, ValueError),
    ):
        raise BaseExceptionGroup("hello", [KeyboardInterrupt()]) from ValueError
    # nested groups
    with RaisesGroup(RaisesGroup(ValueError)):
        raise ExceptionGroup("", (ExceptionGroup("", (ValueError(),)),))

    # flatten_subgroups
    with RaisesGroup(ValueError, flatten_subgroups=True):
        raise ExceptionGroup("", (ExceptionGroup("", (ValueError(),)),))

    # allow_unwrapped
    with RaisesGroup(ValueError, allow_unwrapped=True):
        raise ValueError


:meth:`RaisesGroup.matches` can also be used directly to check a standalone exception group.


The matching algorithm is greedy, which means cases such as this may fail::

    with RaisesGroup(ValueError, RaisesExc(ValueError, match="hello")):
        raise ExceptionGroup("", (ValueError("hello"), ValueError("goodbye")))

even though it generally does not care about the order of the exceptions in the group.
To avoid the above you should specify the first :exc:`ValueError` with a :class:`RaisesExc` as well.

.. note::
    When raised exceptions don't match the expected ones, you'll get a detailed error
    message explaining why. This includes ``repr(check)`` if set, which in Python can be
    overly verbose, showing memory locations etc etc.

    If installed and imported (in e.g. ``conftest.py``), the ``hypothesis`` library will
    monkeypatch this output to provide shorter & more readable repr's.

**M√©thodes :**

- `__init__()`
- `__init__()`
- `__init__()`
- `__init__()`
- `__init__()`
- `__init__()`
- `__init__()`
- `__init__()`
- `__init__()`
- `_parse_excgroup()`
- `__enter__()`
- `__enter__()`
- `__enter__()`
- `__repr__()`
- `_unroll_exceptions()`
- `matches()`
- `matches()`
- `matches()`
- `_check_expected()`
- `_repr_expected()`
- `_check_exceptions()`
- `_check_exceptions()`
- `_check_exceptions()`
- `__exit__()`
- `expected_type()`

##### NotChecked

Singleton for unchecked values in ResultHolder

##### ResultHolder

Container for results of checking exceptions.
Used in RaisesGroup._check_exceptions and possible_match.

**M√©thodes :**

- `__init__()`
- `set_result()`
- `get_result()`
- `has_result()`
- `no_match_for_expected()`
- `no_match_for_actual()`

#### Fonctions

##### raises

**Param√®tres :**

- `expected_exception`

##### raises

##### raises

##### raises

**Param√®tres :**

- `expected_exception`
- `func`

##### raises

Assert that a code block/function call raises an exception type, or one of its subclasses.

:param expected_exception:
    The expected exception type, or a tuple if one of multiple possible
    exception types are expected. Note that subclasses of the passed exceptions
    will also match.

    This is not a required parameter, you may opt to only use ``match`` and/or
    ``check`` for verifying the raised exception.

:kwparam str | re.Pattern[str] | None match:
    If specified, a string containing a regular expression,
    or a regular expression object, that is tested against the string
    representation of the exception and its :pep:`678` `__notes__`
    using :func:`re.search`.

    To match a literal string that may contain :ref:`special characters
    <re-syntax>`, the pattern can first be escaped with :func:`re.escape`.

    (This is only used when ``pytest.raises`` is used as a context manager,
    and passed through to the function otherwise.
    When using ``pytest.raises`` as a function, you can use:
    ``pytest.raises(Exc, func, match="passed on").match("my pattern")``.)

:kwparam Callable[[BaseException], bool] check:

    .. versionadded:: 8.4

    If specified, a callable that will be called with the exception as a parameter
    after checking the type and the match regex if specified.
    If it returns ``True`` it will be considered a match, if not it will
    be considered a failed match.


Use ``pytest.raises`` as a context manager, which will capture the exception of the given
type, or any of its subclasses::

    >>> import pytest
    >>> with pytest.raises(ZeroDivisionError):
    ...    1/0

If the code block does not raise the expected exception (:class:`ZeroDivisionError` in the example
above), or no exception at all, the check will fail instead.

You can also use the keyword argument ``match`` to assert that the
exception matches a text or regex::

    >>> with pytest.raises(ValueError, match='must be 0 or None'):
    ...     raise ValueError("value must be 0 or None")

    >>> with pytest.raises(ValueError, match=r'must be \d+$'):
    ...     raise ValueError("value must be 42")

The ``match`` argument searches the formatted exception string, which includes any
`PEP-678 <https://peps.python.org/pep-0678/>`__ ``__notes__``:

    >>> with pytest.raises(ValueError, match=r"had a note added"):  # doctest: +SKIP
    ...     e = ValueError("value must be 42")
    ...     e.add_note("had a note added")
    ...     raise e

The ``check`` argument, if provided, must return True when passed the raised exception
for the match to be successful, otherwise an :exc:`AssertionError` is raised.

    >>> import errno
    >>> with pytest.raises(OSError, check=lambda e: e.errno == errno.EACCES):
    ...     raise OSError(errno.EACCES, "no permission to view")

The context manager produces an :class:`ExceptionInfo` object which can be used to inspect the
details of the captured exception::

    >>> with pytest.raises(ValueError) as exc_info:
    ...     raise ValueError("value must be 42")
    >>> assert exc_info.type is ValueError
    >>> assert exc_info.value.args[0] == "value must be 42"

.. warning::

   Given that ``pytest.raises`` matches subclasses, be wary of using it to match :class:`Exception` like this::

       # Careful, this will catch ANY exception raised.
       with pytest.raises(Exception):
           some_function()

   Because :class:`Exception` is the base class of almost all exceptions, it is easy for this to hide
   real bugs, where the user wrote this expecting a specific exception, but some other exception is being
   raised due to a bug introduced during a refactoring.

   Avoid using ``pytest.raises`` to catch :class:`Exception` unless certain that you really want to catch
   **any** exception raised.

.. note::

   When using ``pytest.raises`` as a context manager, it's worthwhile to
   note that normal context manager rules apply and that the exception
   raised *must* be the final line in the scope of the context manager.
   Lines of code after that, within the scope of the context manager will
   not be executed. For example::

       >>> value = 15
       >>> with pytest.raises(ValueError) as exc_info:
       ...     if value > 10:
       ...         raise ValueError("value must be <= 10")
       ...     assert exc_info.type is ValueError  # This will not execute.

   Instead, the following approach must be taken (note the difference in
   scope)::

       >>> with pytest.raises(ValueError) as exc_info:
       ...     if value > 10:
       ...         raise ValueError("value must be <= 10")
       ...
       >>> assert exc_info.type is ValueError

**Expecting exception groups**

When expecting exceptions wrapped in :exc:`BaseExceptionGroup` or
:exc:`ExceptionGroup`, you should instead use :class:`pytest.RaisesGroup`.

**Using with** ``pytest.mark.parametrize``

When using :ref:`pytest.mark.parametrize ref`
it is possible to parametrize tests such that
some runs raise an exception and others do not.

See :ref:`parametrizing_conditional_raising` for an example.

.. seealso::

    :ref:`assertraises` for more examples and detailed discussion.

**Legacy form**

It is possible to specify a callable by passing a to-be-called lambda::

    >>> raises(ZeroDivisionError, lambda: 1/0)
    <ExceptionInfo ...>

or you can specify an arbitrary callable with arguments::

    >>> def f(x): return 1/x
    ...
    >>> raises(ZeroDivisionError, f, 0)
    <ExceptionInfo ...>
    >>> raises(ZeroDivisionError, f, x=0)
    <ExceptionInfo ...>

The form above is fully supported but discouraged for new code because the
context manager form is regarded as more readable and less error-prone.

.. note::
    Similar to caught exception objects in Python, explicitly clearing
    local references to returned ``ExceptionInfo`` objects can
    help the Python interpreter speed up its garbage collection.

    Clearing those references breaks a reference cycle
    (``ExceptionInfo`` --> caught exception --> frame stack raising
    the exception --> current frame stack --> local variables -->
    ``ExceptionInfo``) which makes Python keep all objects referenced
    from that cycle (including all local variables in the current
    frame) alive until the next cyclic garbage collection run.
    More detailed information can be found in the official Python
    documentation for :ref:`the try statement <python:try>`.

**Param√®tres :**

- `expected_exception`

##### _match_pattern

Helper function to remove redundant `re.compile` calls when printing regex

**Param√®tres :**

- `match`

##### repr_callable

Get the repr of a ``check`` parameter.

Split out so it can be monkeypatched (e.g. by hypothesis)

**Param√®tres :**

- `fun`

##### backquote

**Param√®tres :**

- `s`

##### _exception_type_name

**Param√®tres :**

- `e`

##### _check_raw_type

**Param√®tres :**

- `expected_type`
- `exception`

##### is_fully_escaped

**Param√®tres :**

- `s`

##### unescape

**Param√®tres :**

- `s`

##### possible_match

**Param√®tres :**

- `results`
- `used`

##### __init__

##### _parse_exc

**Param√®tres :**

- `exc`
- `expected`

##### fail_reason

Set after a call to :meth:`matches` to give a human-readable reason for why the match failed.
When used as a context manager the string will be printed as the reason for the
test failing.

##### _check_check

**Param√®tres :**

- `exception`

##### _check_match

**Param√®tres :**

- `e`

##### matches

Check if an exception matches the requirements of this AbstractRaises.
If it fails, :meth:`AbstractRaises.fail_reason` should be set.

**Param√®tres :**

- `exception`

##### __init__

##### __init__

##### __init__

##### __init__

##### matches

Check if an exception matches the requirements of this :class:`RaisesExc`.
If it fails, :attr:`RaisesExc.fail_reason` will be set.

Examples::

    assert RaisesExc(ValueError).matches(my_exception):
    # is equivalent to
    assert isinstance(my_exception, ValueError)

    # this can be useful when checking e.g. the ``__cause__`` of an exception.
    with pytest.raises(ValueError) as excinfo:
        ...
    assert RaisesExc(SyntaxError, match="foo").matches(excinfo.value.__cause__)
    # above line is equivalent to
    assert isinstance(excinfo.value.__cause__, SyntaxError)
    assert re.search("foo", str(excinfo.value.__cause__)

**Param√®tres :**

- `exception`

##### __repr__

##### _check_type

**Param√®tres :**

- `exception`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

##### __init__

##### __init__

##### __init__

##### __init__

##### __init__

##### __init__

##### __init__

##### __init__

##### _parse_excgroup

**Param√®tres :**

- `exc`
- `expected`

##### __enter__

##### __enter__

##### __enter__

##### __repr__

##### _unroll_exceptions

Used if `flatten_subgroups=True`.

**Param√®tres :**

- `exceptions`

##### matches

**Param√®tres :**

- `exception`

##### matches

**Param√®tres :**

- `exception`

##### matches

Check if an exception matches the requirements of this RaisesGroup.
If it fails, `RaisesGroup.fail_reason` will be set.

Example::

    with pytest.raises(TypeError) as excinfo:
        ...
    assert RaisesGroup(ValueError).matches(excinfo.value.__cause__)
    # the above line is equivalent to
    myexc = excinfo.value.__cause
    assert isinstance(myexc, BaseExceptionGroup)
    assert len(myexc.exceptions) == 1
    assert isinstance(myexc.exceptions[0], ValueError)

**Param√®tres :**

- `exception`

##### _check_expected

Helper method for `RaisesGroup.matches` and `RaisesGroup._check_exceptions`
to check one of potentially several expected exceptions.

**Param√®tres :**

- `expected_type`
- `exception`

##### _repr_expected

Get the repr of an expected type/RaisesExc/RaisesGroup, but we only want
the name if it's a type

**Param√®tres :**

- `e`

##### _check_exceptions

**Param√®tres :**

- `_exception`
- `actual_exceptions`

##### _check_exceptions

**Param√®tres :**

- `_exception`
- `actual_exceptions`

##### _check_exceptions

Helper method for RaisesGroup.matches that attempts to pair up expected and actual exceptions

**Param√®tres :**

- `_exception`
- `actual_exceptions`

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### expected_type

##### __init__

**Param√®tres :**

- `expected_exceptions`
- `actual_exceptions`

##### set_result

**Param√®tres :**

- `expected`
- `actual`
- `result`

##### get_result

**Param√®tres :**

- `expected`
- `actual`

##### has_result

**Param√®tres :**

- `expected`
- `actual`

##### no_match_for_expected

**Param√®tres :**

- `expected`

##### no_match_for_actual

**Param√®tres :**

- `actual`

---

### recwarn

Record warnings during test function execution.

#### Classes

##### WarningsRecorder

A context manager to record raised warnings.

Each recorded warning is an instance of :class:`warnings.WarningMessage`.

Adapted from `warnings.catch_warnings`.

.. note::
    ``DeprecationWarning`` and ``PendingDeprecationWarning`` are treated
    differently; see :ref:`ensuring_function_triggers`.

**M√©thodes :**

- `__init__()`
- `list()`
- `__getitem__()`
- `__iter__()`
- `__len__()`
- `pop()`
- `clear()`
- `__enter__()`
- `__exit__()`

##### WarningsChecker

**M√©thodes :**

- `__init__()`
- `matches()`
- `__exit__()`

#### Fonctions

##### recwarn

Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.

See :ref:`warnings` for information on warning categories.

##### deprecated_call

##### deprecated_call

**Param√®tres :**

- `func`

##### deprecated_call

Assert that code produces a ``DeprecationWarning`` or ``PendingDeprecationWarning`` or ``FutureWarning``.

This function can be used as a context manager::

    >>> import warnings
    >>> def api_call_v2():
    ...     warnings.warn('use v3 of this api', DeprecationWarning)
    ...     return 200

    >>> import pytest
    >>> with pytest.deprecated_call():
    ...    assert api_call_v2() == 200

It can also be used by passing a function and ``*args`` and ``**kwargs``,
in which case it will ensure calling ``func(*args, **kwargs)`` produces one of
the warnings types above. The return value is the return value of the function.

In the context manager form you may use the keyword argument ``match`` to assert
that the warning matches a text or regex.

The context manager produces a list of :class:`warnings.WarningMessage` objects,
one for each warning raised.

**Param√®tres :**

- `func`

##### warns

**Param√®tres :**

- `expected_warning`

##### warns

**Param√®tres :**

- `expected_warning`
- `func`

##### warns

Assert that code raises a particular class of warning.

Specifically, the parameter ``expected_warning`` can be a warning class or tuple
of warning classes, and the code inside the ``with`` block must issue at least one
warning of that class or classes.

This helper produces a list of :class:`warnings.WarningMessage` objects, one for
each warning emitted (regardless of whether it is an ``expected_warning`` or not).
Since pytest 8.0, unmatched warnings are also re-emitted when the context closes.

This function can be used as a context manager::

    >>> import pytest
    >>> with pytest.warns(RuntimeWarning):
    ...    warnings.warn("my warning", RuntimeWarning)

In the context manager form you may use the keyword argument ``match`` to assert
that the warning matches a text or regex::

    >>> with pytest.warns(UserWarning, match='must be 0 or None'):
    ...     warnings.warn("value must be 0 or None", UserWarning)

    >>> with pytest.warns(UserWarning, match=r'must be \d+$'):
    ...     warnings.warn("value must be 42", UserWarning)

    >>> with pytest.warns(UserWarning):  # catch re-emitted warning
    ...     with pytest.warns(UserWarning, match=r'must be \d+$'):
    ...         warnings.warn("this is not here", UserWarning)
    Traceback (most recent call last):
      ...
    Failed: DID NOT WARN. No warnings of type ...UserWarning... were emitted...

**Using with** ``pytest.mark.parametrize``

When using :ref:`pytest.mark.parametrize ref` it is possible to parametrize tests
such that some runs raise a warning and others do not.

This could be achieved in the same way as with exceptions, see
:ref:`parametrizing_conditional_raising` for an example.

**Param√®tres :**

- `expected_warning`

##### __init__

##### list

The list of recorded warnings.

##### __getitem__

Get a recorded warning by index.

**Param√®tres :**

- `i`

##### __iter__

Iterate through the recorded warnings.

##### __len__

The number of recorded warnings.

##### pop

Pop the first recorded warning which is an instance of ``cls``,
but not an instance of a child class of any other match.
Raises ``AssertionError`` if there is no match.

**Param√®tres :**

- `cls`

##### clear

Clear the list of recorded warnings.

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __init__

**Param√®tres :**

- `expected_warning`
- `match_expr`

##### matches

**Param√®tres :**

- `warning`

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### found_str

---

### reports

#### Classes

##### BaseReport

**M√©thodes :**

- `__init__()`
- `toterminal()`
- `get_sections()`
- `longreprtext()`
- `caplog()`
- `capstdout()`
- `capstderr()`
- `passed()`
- `failed()`
- `skipped()`
- `fspath()`
- `count_towards_summary()`
- `head_line()`
- `_get_verbose_word_with_markup()`
- `_to_json()`
- `_from_json()`

##### TestReport

Basic test report object (also used for setup and teardown calls if
they fail).

Reports can contain arbitrary extra attributes.

**M√©thodes :**

- `__init__()`
- `__repr__()`
- `from_item_and_call()`

##### CollectReport

Collection report object.

Reports can contain arbitrary extra attributes.

**M√©thodes :**

- `__init__()`
- `location()`
- `__repr__()`

##### CollectErrorRepr

**M√©thodes :**

- `__init__()`
- `toterminal()`

#### Fonctions

##### getworkerinfoline

**Param√®tres :**

- `node`

##### _report_unserialization_failure

**Param√®tres :**

- `type_name`
- `report_class`
- `reportdict`

##### pytest_report_to_serializable

**Param√®tres :**

- `report`

##### pytest_report_from_serializable

**Param√®tres :**

- `data`

##### _report_to_json

Return the contents of this report as a dict of builtin entries,
suitable for serialization.

This was originally the serialize_report() function from xdist (ca03269).

**Param√®tres :**

- `report`

##### _report_kwargs_from_json

Return **kwargs that can be used to construct a TestReport or
CollectReport instance.

This was originally the serialize_report() function from xdist (ca03269).

**Param√®tres :**

- `reportdict`

##### __init__

##### toterminal

**Param√®tres :**

- `out`

##### get_sections

**Param√®tres :**

- `prefix`

##### longreprtext

Read-only property that returns the full string representation of
``longrepr``.

.. versionadded:: 3.0

##### caplog

Return captured log lines, if log capturing is enabled.

.. versionadded:: 3.5

##### capstdout

Return captured text from stdout, if capturing is enabled.

.. versionadded:: 3.0

##### capstderr

Return captured text from stderr, if capturing is enabled.

.. versionadded:: 3.0

##### passed

Whether the outcome is passed.

##### failed

Whether the outcome is failed.

##### skipped

Whether the outcome is skipped.

##### fspath

The path portion of the reported node, as a string.

##### count_towards_summary

**Experimental** Whether this report should be counted towards the
totals shown at the end of the test session: "1 passed, 1 failure, etc".

.. note::

    This function is considered **experimental**, so beware that it is subject to changes
    even in patch releases.

##### head_line

**Experimental** The head line shown with longrepr output for this
report, more commonly during traceback representation during
failures::

    ________ Test.foo ________


In the example above, the head_line is "Test.foo".

.. note::

    This function is considered **experimental**, so beware that it is subject to changes
    even in patch releases.

##### _get_verbose_word_with_markup

**Param√®tres :**

- `config`
- `default_markup`

##### _to_json

Return the contents of this report as a dict of builtin entries,
suitable for serialization.

This was originally the serialize_report() function from xdist (ca03269).

Experimental method.

##### _from_json

Create either a TestReport or CollectReport, depending on the calling class.

It is the callers responsibility to know which class to pass here.

This was originally the serialize_report() function from xdist (ca03269).

Experimental method.

**Param√®tres :**

- `cls`
- `reportdict`

##### __init__

**Param√®tres :**

- `nodeid`
- `location`
- `keywords`
- `outcome`
- `longrepr`
- `when`
- `sections`
- `duration`
- `start`
- `stop`
- `user_properties`

##### __repr__

##### from_item_and_call

Create and fill a TestReport with standard item and call info.

:param item: The item.
:param call: The call info.

**Param√®tres :**

- `cls`
- `item`
- `call`

##### __init__

**Param√®tres :**

- `nodeid`
- `outcome`
- `longrepr`
- `result`
- `sections`

##### location

##### __repr__

##### __init__

**Param√®tres :**

- `msg`

##### toterminal

**Param√®tres :**

- `out`

##### serialize_repr_entry

**Param√®tres :**

- `entry`

##### serialize_repr_traceback

**Param√®tres :**

- `reprtraceback`

##### serialize_repr_crash

**Param√®tres :**

- `reprcrash`

##### serialize_exception_longrepr

**Param√®tres :**

- `rep`

##### deserialize_repr_entry

**Param√®tres :**

- `entry_data`

##### deserialize_repr_traceback

**Param√®tres :**

- `repr_traceback_dict`

##### deserialize_repr_crash

**Param√®tres :**

- `repr_crash_dict`

##### __getattr__

**Param√®tres :**

- `key`

---

### runner

Basic collect and runtest protocol implementations.

#### Classes

##### CallInfo

Result/Exception info of a function invocation.

**M√©thodes :**

- `__init__()`
- `result()`
- `from_call()`
- `__repr__()`

##### SetupState

Shared state for setting up/tearing down test items or collectors
in a session.

Suppose we have a collection tree as follows:

<Session session>
    <Module mod1>
        <Function item1>
    <Module mod2>
        <Function item2>

The SetupState maintains a stack. The stack starts out empty:

    []

During the setup phase of item1, setup(item1) is called. What it does
is:

    push session to stack, run session.setup()
    push mod1 to stack, run mod1.setup()
    push item1 to stack, run item1.setup()

The stack is:

    [session, mod1, item1]

While the stack is in this shape, it is allowed to add finalizers to
each of session, mod1, item1 using addfinalizer().

During the teardown phase of item1, teardown_exact(item2) is called,
where item2 is the next item to item1. What it does is:

    pop item1 from stack, run its teardowns
    pop mod1 from stack, run its teardowns

mod1 was popped because it ended its purpose with item1. The stack is:

    [session]

During the setup phase of item2, setup(item2) is called. What it does
is:

    push mod2 to stack, run mod2.setup()
    push item2 to stack, run item2.setup()

Stack:

    [session, mod2, item2]

During the teardown phase of item2, teardown_exact(None) is called,
because item2 is the last item. What it does is:

    pop item2 from stack, run its teardowns
    pop mod2 from stack, run its teardowns
    pop session from stack, run its teardowns

Stack:

    []

The end!

**M√©thodes :**

- `__init__()`
- `setup()`
- `addfinalizer()`
- `teardown_exact()`

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_terminal_summary

**Param√®tres :**

- `terminalreporter`

##### pytest_sessionstart

**Param√®tres :**

- `session`

##### pytest_sessionfinish

**Param√®tres :**

- `session`

##### pytest_runtest_protocol

**Param√®tres :**

- `item`
- `nextitem`

##### runtestprotocol

**Param√®tres :**

- `item`
- `log`
- `nextitem`

##### show_test_item

Show test function, parameters and the fixtures of the test item.

**Param√®tres :**

- `item`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

**Param√®tres :**

- `item`
- `nextitem`

##### _update_current_test_var

Update :envvar:`PYTEST_CURRENT_TEST` to reflect the current item and stage.

If ``when`` is None, delete ``PYTEST_CURRENT_TEST`` from the environment.

**Param√®tres :**

- `item`
- `when`

##### pytest_report_teststatus

**Param√®tres :**

- `report`

##### call_and_report

**Param√®tres :**

- `item`
- `when`
- `log`

##### check_interactive_exception

Check whether the call raised an exception that should be reported as
interactive.

**Param√®tres :**

- `call`
- `report`

##### pytest_runtest_makereport

**Param√®tres :**

- `item`
- `call`

##### pytest_make_collect_report

**Param√®tres :**

- `collector`

##### collect_one_node

**Param√®tres :**

- `collector`

##### __init__

**Param√®tres :**

- `result`
- `excinfo`
- `start`
- `stop`
- `duration`
- `when`

##### result

The return value of the call, if it didn't raise.

Can only be accessed if excinfo is None.

##### from_call

Call func, wrapping the result in a CallInfo.

:param func:
    The function to call. Called without arguments.
:type func: Callable[[], _pytest.runner.TResult]
:param when:
    The phase in which the function is called.
:param reraise:
    Exception or exceptions that shall propagate if raised by the
    function, instead of being wrapped in the CallInfo.

**Param√®tres :**

- `cls`
- `func`
- `when`
- `reraise`

##### __repr__

##### collect

##### __init__

##### setup

Setup objects along the collector chain to the item.

**Param√®tres :**

- `item`

##### addfinalizer

Attach a finalizer to the given node.

The node must be currently active in the stack.

**Param√®tres :**

- `finalizer`
- `node`

##### teardown_exact

Teardown the current stack up until reaching nodes that nextitem
also descends from.

When nextitem is None (meaning we're at the last item), the entire
stack is torn down.

**Param√®tres :**

- `nextitem`

---

### scope

Scope definition and related utilities.

Those are defined here, instead of in the 'fixtures' module because
their use is spread across many other pytest modules, and centralizing it in 'fixtures'
would cause circular references.

Also this makes the module light to import, as it should.

#### Classes

##### Scope

Represents one of the possible fixture scopes in pytest.

Scopes are ordered from lower to higher, that is:

          ->>> higher ->>>

Function < Class < Module < Package < Session

          <<<- lower  <<<-

**M√©thodes :**

- `next_lower()`
- `next_higher()`
- `__lt__()`
- `from_user()`

#### Fonctions

##### next_lower

Return the next lower scope.

##### next_higher

Return the next higher scope.

##### __lt__

**Param√®tres :**

- `other`

##### from_user

Given a scope name from the user, return the equivalent Scope enum. Should be used
whenever we want to convert a user provided scope name to its enum object.

If the scope name is invalid, construct a user friendly message and call pytest.fail.

**Param√®tres :**

- `cls`
- `scope_name`
- `descr`
- `where`

---

### setuponly

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_fixture_setup

**Param√®tres :**

- `fixturedef`
- `request`

##### pytest_fixture_post_finalizer

**Param√®tres :**

- `fixturedef`
- `request`

##### _show_fixture_action

**Param√®tres :**

- `fixturedef`
- `config`
- `msg`

##### pytest_cmdline_main

**Param√®tres :**

- `config`

---

### setupplan

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_fixture_setup

**Param√®tres :**

- `fixturedef`
- `request`

##### pytest_cmdline_main

**Param√®tres :**

- `config`

---

### skipping

Support for skip/xfail functions and markers.

#### Classes

##### Skip

The result of evaluate_skip_marks().

##### Xfail

The result of evaluate_xfail_marks().

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### evaluate_condition

Evaluate a single skipif/xfail condition.

If an old-style string condition is given, it is eval()'d, otherwise the
condition is bool()'d. If this fails, an appropriately formatted pytest.fail
is raised.

Returns (result, reason). The reason is only relevant if the result is True.

**Param√®tres :**

- `item`
- `mark`
- `condition`

##### evaluate_skip_marks

Evaluate skip and skipif marks on item, returning Skip if triggered.

**Param√®tres :**

- `item`

##### evaluate_xfail_marks

Evaluate xfail marks on item, returning Xfail if triggered.

**Param√®tres :**

- `item`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### pytest_runtest_makereport

**Param√®tres :**

- `item`
- `call`

##### pytest_report_teststatus

**Param√®tres :**

- `report`

##### nop

---

### stash

#### Classes

##### StashKey

``StashKey`` is an object used as a key to a :class:`Stash`.

A ``StashKey`` is associated with the type ``T`` of the value of the key.

A ``StashKey`` is unique and cannot conflict with another key.

.. versionadded:: 7.0

##### Stash

``Stash`` is a type-safe heterogeneous mutable mapping that
allows keys and value types to be defined separately from
where it (the ``Stash``) is created.

Usually you will be given an object which has a ``Stash``, for example
:class:`~pytest.Config` or a :class:`~_pytest.nodes.Node`:

.. code-block:: python

    stash: Stash = some_object.stash

If a module or plugin wants to store data in this ``Stash``, it creates
:class:`StashKey`\s for its keys (at the module level):

.. code-block:: python

    # At the top-level of the module
    some_str_key = StashKey[str]()
    some_bool_key = StashKey[bool]()

To store information:

.. code-block:: python

    # Value type must match the key.
    stash[some_str_key] = "value"
    stash[some_bool_key] = True

To retrieve the information:

.. code-block:: python

    # The static type of some_str is str.
    some_str = stash[some_str_key]
    # The static type of some_bool is bool.
    some_bool = stash[some_bool_key]

.. versionadded:: 7.0

**M√©thodes :**

- `__init__()`
- `__setitem__()`
- `__getitem__()`
- `get()`
- `setdefault()`
- `__delitem__()`
- `__contains__()`
- `__len__()`

#### Fonctions

##### __init__

##### __setitem__

Set a value for key.

**Param√®tres :**

- `key`
- `value`

##### __getitem__

Get the value for key.

Raises ``KeyError`` if the key wasn't set before.

**Param√®tres :**

- `key`

##### get

Get the value for key, or return default if the key wasn't set
before.

**Param√®tres :**

- `key`
- `default`

##### setdefault

Return the value of key if already set, otherwise set the value
of key to default and return default.

**Param√®tres :**

- `key`
- `default`

##### __delitem__

Delete the value for key.

Raises ``KeyError`` if the key wasn't set before.

**Param√®tres :**

- `key`

##### __contains__

Return whether key was set.

**Param√®tres :**

- `key`

##### __len__

Return how many items exist in the stash.

---

### stepwise

#### Classes

##### StepwiseCacheInfo

**M√©thodes :**

- `last_cache_date()`
- `empty()`
- `update_date_to_now()`

##### StepwisePlugin

**M√©thodes :**

- `__init__()`
- `_load_cached_info()`
- `pytest_sessionstart()`
- `pytest_collection_modifyitems()`
- `pytest_runtest_logreport()`
- `pytest_report_collectionfinish()`
- `pytest_sessionfinish()`

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### pytest_sessionfinish

**Param√®tres :**

- `session`

##### last_cache_date

##### empty

**Param√®tres :**

- `cls`

##### update_date_to_now

##### __init__

**Param√®tres :**

- `config`

##### _load_cached_info

##### pytest_sessionstart

**Param√®tres :**

- `session`

##### pytest_collection_modifyitems

**Param√®tres :**

- `config`
- `items`

##### pytest_runtest_logreport

**Param√®tres :**

- `report`

##### pytest_report_collectionfinish

##### pytest_sessionfinish

---

### terminal

Terminal reporting of the full testing process.

This is a good source for looking at the various reporting hooks.

#### Classes

##### MoreQuietAction

A modified copy of the argparse count action which counts down and updates
the legacy quiet attribute at the same time.

Used to unify verbosity handling.

**M√©thodes :**

- `__init__()`
- `__call__()`

##### TestShortLogReport

Used to store the test status result category, shortletter and verbose word.
For example ``"rerun", "R", ("RERUN", {"yellow": True})``.

:ivar category:
    The class of result, for example ``‚Äúpassed‚Äù``, ``‚Äúskipped‚Äù``, ``‚Äúerror‚Äù``, or the empty string.

:ivar letter:
    The short letter shown as testing progresses, for example ``"."``, ``"s"``, ``"E"``, or the empty string.

:ivar word:
    Verbose word is shown as testing progresses in verbose mode, for example ``"PASSED"``, ``"SKIPPED"``,
    ``"ERROR"``, or the empty string.

##### WarningReport

Simple structure to hold warnings information captured by ``pytest_warning_recorded``.

:ivar str message:
    User friendly message about the warning.
:ivar str|None nodeid:
    nodeid that generated the warning (see ``get_location``).
:ivar tuple fslocation:
    File system location of the source of the warning (see ``get_location``).

**M√©thodes :**

- `get_location()`

##### TerminalReporter

**M√©thodes :**

- `__init__()`
- `_determine_show_progress_info()`
- `verbosity()`
- `showheader()`
- `no_header()`
- `no_summary()`
- `showfspath()`
- `showfspath()`
- `showlongtestinfo()`
- `hasopt()`
- `write_fspath_result()`
- `write_ensure_prefix()`
- `ensure_newline()`
- `wrap_write()`
- `write()`
- `flush()`
- `write_line()`
- `rewrite()`
- `write_sep()`
- `section()`
- `line()`
- `_add_stats()`
- `pytest_internalerror()`
- `pytest_warning_recorded()`
- `pytest_plugin_registered()`
- `pytest_deselected()`
- `pytest_runtest_logstart()`
- `pytest_runtest_logreport()`
- `_is_last_item()`
- `pytest_runtestloop()`
- `_get_progress_information_message()`
- `_write_progress_information_if_past_edge()`
- `_write_progress_information_filling_space()`
- `_width_of_current_line()`
- `pytest_collection()`
- `pytest_collectreport()`
- `report_collect()`
- `pytest_sessionstart()`
- `_write_report_lines_from_hooks()`
- `pytest_report_header()`
- `pytest_collection_finish()`
- `_printcollecteditems()`
- `pytest_sessionfinish()`
- `pytest_terminal_summary()`
- `pytest_keyboard_interrupt()`
- `pytest_unconfigure()`
- `_report_keyboardinterrupt()`
- `_locationline()`
- `_getfailureheadline()`
- `_getcrashline()`
- `getreports()`
- `summary_warnings()`
- `summary_passes()`
- `summary_xpasses()`
- `summary_passes_combined()`
- `_get_teardown_reports()`
- `_handle_teardown_sections()`
- `print_teardown_sections()`
- `summary_failures()`
- `summary_xfailures()`
- `summary_failures_combined()`
- `summary_errors()`
- `_outrep_summary()`
- `summary_stats()`
- `short_test_summary()`
- `_get_main_color()`
- `_determine_main_color()`
- `_set_main_color()`
- `build_summary_stats_line()`
- `_get_reports_to_display()`
- `_build_normal_summary_stats_line()`
- `_build_collect_only_summary_stats_line()`

#### Fonctions

##### pytest_addoption

**Param√®tres :**

- `parser`

##### pytest_configure

**Param√®tres :**

- `config`

##### getreportopt

**Param√®tres :**

- `config`

##### pytest_report_teststatus

**Param√®tres :**

- `report`

##### _get_node_id_with_markup

**Param√®tres :**

- `tw`
- `config`
- `rep`

##### _format_trimmed

Format msg into format, ellipsizing it if doesn't fit in available_width.

Returns None if even the ellipsis can't fit.

**Param√®tres :**

- `format`
- `msg`
- `available_width`

##### _get_line_with_reprcrash_message

Get summary line for a report, trying to add reprcrash message.

**Param√®tres :**

- `config`
- `rep`
- `tw`
- `word_markup`

##### _folded_skips

**Param√®tres :**

- `startpath`
- `skipped`

##### pluralize

**Param√®tres :**

- `count`
- `noun`

##### _plugin_nameversions

**Param√®tres :**

- `plugininfo`

##### format_session_duration

Format the given seconds in a human readable manner to show in the final summary.

**Param√®tres :**

- `seconds`

##### format_node_duration

Format the given seconds in a human readable manner to show in the test progress.

**Param√®tres :**

- `seconds`

##### _get_raw_skip_reason

Get the reason string of a skip/xfail/xpass test report.

The string is just the part given by the user.

**Param√®tres :**

- `report`

##### __init__

**Param√®tres :**

- `option_strings`
- `dest`
- `default`
- `required`
- `help`

##### __call__

**Param√®tres :**

- `parser`
- `namespace`
- `values`
- `option_string`

##### get_location

Return the more user-friendly information about the location of a warning, or None.

**Param√®tres :**

- `config`

##### __init__

**Param√®tres :**

- `config`
- `file`

##### _determine_show_progress_info

Return whether we should display progress information based on the current config.

##### verbosity

##### showheader

##### no_header

##### no_summary

##### showfspath

##### showfspath

**Param√®tres :**

- `value`

##### showlongtestinfo

##### hasopt

**Param√®tres :**

- `char`

##### write_fspath_result

**Param√®tres :**

- `nodeid`
- `res`

##### write_ensure_prefix

**Param√®tres :**

- `prefix`
- `extra`

##### ensure_newline

##### wrap_write

Wrap message with margin for progress info.

**Param√®tres :**

- `content`

##### write

**Param√®tres :**

- `content`

##### flush

##### write_line

**Param√®tres :**

- `line`

##### rewrite

Rewinds the terminal cursor to the beginning and writes the given line.

:param erase:
    If True, will also add spaces until the full terminal width to ensure
    previous lines are properly erased.

The rest of the keyword arguments are markup instructions.

**Param√®tres :**

- `line`

##### write_sep

**Param√®tres :**

- `sep`
- `title`
- `fullwidth`

##### section

**Param√®tres :**

- `title`
- `sep`

##### line

**Param√®tres :**

- `msg`

##### _add_stats

**Param√®tres :**

- `category`
- `items`

##### pytest_internalerror

**Param√®tres :**

- `excrepr`

##### pytest_warning_recorded

**Param√®tres :**

- `warning_message`
- `nodeid`

##### pytest_plugin_registered

**Param√®tres :**

- `plugin`

##### pytest_deselected

**Param√®tres :**

- `items`

##### pytest_runtest_logstart

**Param√®tres :**

- `nodeid`
- `location`

##### pytest_runtest_logreport

**Param√®tres :**

- `report`

##### _is_last_item

##### pytest_runtestloop

##### _get_progress_information_message

##### _write_progress_information_if_past_edge

##### _write_progress_information_filling_space

##### _width_of_current_line

Return the width of the current line.

##### pytest_collection

##### pytest_collectreport

**Param√®tres :**

- `report`

##### report_collect

**Param√®tres :**

- `final`

##### pytest_sessionstart

**Param√®tres :**

- `session`

##### _write_report_lines_from_hooks

**Param√®tres :**

- `lines`

##### pytest_report_header

**Param√®tres :**

- `config`

##### pytest_collection_finish

**Param√®tres :**

- `session`

##### _printcollecteditems

**Param√®tres :**

- `items`

##### pytest_sessionfinish

**Param√®tres :**

- `session`
- `exitstatus`

##### pytest_terminal_summary

##### pytest_keyboard_interrupt

**Param√®tres :**

- `excinfo`

##### pytest_unconfigure

##### _report_keyboardinterrupt

##### _locationline

**Param√®tres :**

- `nodeid`
- `fspath`
- `lineno`
- `domain`

##### _getfailureheadline

**Param√®tres :**

- `rep`

##### _getcrashline

**Param√®tres :**

- `rep`

##### getreports

**Param√®tres :**

- `name`

##### summary_warnings

##### summary_passes

##### summary_xpasses

##### summary_passes_combined

**Param√®tres :**

- `which_reports`
- `sep_title`
- `needed_opt`

##### _get_teardown_reports

**Param√®tres :**

- `nodeid`

##### _handle_teardown_sections

**Param√®tres :**

- `nodeid`

##### print_teardown_sections

**Param√®tres :**

- `rep`

##### summary_failures

##### summary_xfailures

##### summary_failures_combined

**Param√®tres :**

- `which_reports`
- `sep_title`

##### summary_errors

##### _outrep_summary

**Param√®tres :**

- `rep`

##### summary_stats

##### short_test_summary

##### _get_main_color

##### _determine_main_color

**Param√®tres :**

- `unknown_type_seen`

##### _set_main_color

##### build_summary_stats_line

Build the parts used in the last summary stats line.

The summary stats line is the line shown at the end, "=== 12 passed, 2 errors in Xs===".

This function builds a list of the "parts" that make up for the text in that line, in
the example above it would be::

    [
        ("12 passed", {"green": True}),
        ("2 errors", {"red": True}
    ]

That last dict for each line is a "markup dictionary", used by TerminalWriter to
color output.

The final color of the line is also determined by this function, and is the second
element of the returned tuple.

##### _get_reports_to_display

Get test/collection reports for the given status key, such as `passed` or `error`.

**Param√®tres :**

- `key`

##### _build_normal_summary_stats_line

##### _build_collect_only_summary_stats_line

##### mywriter

**Param√®tres :**

- `tags`
- `args`

##### mkrel

**Param√®tres :**

- `nodeid`

##### show_simple

**Param√®tres :**

- `lines`

##### show_xfailed

**Param√®tres :**

- `lines`

##### show_xpassed

**Param√®tres :**

- `lines`

##### show_skipped_folded

**Param√®tres :**

- `lines`

##### show_skipped_unfolded

**Param√®tres :**

- `lines`

##### show_skipped

**Param√®tres :**

- `lines`

##### collapsed_location_report

**Param√®tres :**

- `reports`

---

### threadexception

#### Classes

##### ThreadExceptionMeta

#### Fonctions

##### collect_thread_exception

**Param√®tres :**

- `config`

##### cleanup

##### thread_exception_hook

##### pytest_configure

**Param√®tres :**

- `config`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

**Param√®tres :**

- `item`

---

### timing

Indirection for time functions.

We intentionally grab some "time" functions internally to avoid tests mocking "time" to affect
pytest runtime information (issue #185).

Fixture "mock_timing" also interacts with this module for pytest's own tests.

#### Classes

##### Instant

Represents an instant in time, used to both get the timestamp value and to measure
the duration of a time span.

Inspired by Rust's `std::time::Instant`.

**M√©thodes :**

- `elapsed()`
- `as_utc()`

##### Duration

A span of time as measured by `Instant.elapsed()`.

**M√©thodes :**

- `seconds()`

##### MockTiming

Mocks _pytest.timing with a known object that can be used to control timing in tests
deterministically.

pytest itself should always use functions from `_pytest.timing` instead of `time` directly.

This then allows us more control over time during testing, if testing code also
uses `_pytest.timing` functions.

Time is static, and only advances through `sleep` calls, thus tests might sleep over large
numbers and obtain accurate time() calls at the end, making tests reliable and instant.

**M√©thodes :**

- `sleep()`
- `time()`
- `patch()`

#### Fonctions

##### elapsed

Measure the duration since `Instant` was created.

##### as_utc

Instant as UTC datetime.

##### seconds

Elapsed time of the duration in seconds, measured using a performance counter for precise timing.

##### sleep

**Param√®tres :**

- `seconds`

##### time

##### patch

**Param√®tres :**

- `monkeypatch`

---

### tmpdir

Support for providing temporary directories to test functions.

#### Classes

##### TempPathFactory

Factory for temporary directories under the common base temp directory,
as discussed at :ref:`temporary directory location and retention`.

**M√©thodes :**

- `__init__()`
- `from_config()`
- `_ensure_relative_to_basetemp()`
- `mktemp()`
- `getbasetemp()`

#### Fonctions

##### get_user

Return the current user name, or None if getuser() does not work
in the current environment (see #1010).

##### pytest_configure

Create a TempPathFactory and attach it to the config object.

This is to comply with existing plugins which expect the handler to be
available at pytest_configure time, but ideally should be moved entirely
to the tmp_path_factory session fixture.

**Param√®tres :**

- `config`

##### pytest_addoption

**Param√®tres :**

- `parser`

##### tmp_path_factory

Return a :class:`pytest.TempPathFactory` instance for the test session.

**Param√®tres :**

- `request`

##### _mk_tmp

**Param√®tres :**

- `request`
- `factory`

##### tmp_path

Return a temporary directory (as :class:`pathlib.Path` object)
which is unique to each test function invocation.
The temporary directory is created as a subdirectory
of the base temporary directory, with configurable retention,
as discussed in :ref:`temporary directory location and retention`.

**Param√®tres :**

- `request`
- `tmp_path_factory`

##### pytest_sessionfinish

After each session, remove base directory if all the tests passed,
the policy is "failed", and the basetemp is not specified by a user.

**Param√®tres :**

- `session`
- `exitstatus`

##### pytest_runtest_makereport

**Param√®tres :**

- `item`
- `call`

##### __init__

**Param√®tres :**

- `given_basetemp`
- `retention_count`
- `retention_policy`
- `trace`
- `basetemp`

##### from_config

Create a factory according to pytest configuration.

:meta private:

**Param√®tres :**

- `cls`
- `config`

##### _ensure_relative_to_basetemp

**Param√®tres :**

- `basename`

##### mktemp

Create a new temporary directory managed by the factory.

:param basename:
    Directory base name, must be a relative path.

:param numbered:
    If ``True``, ensure the directory is unique by adding a numbered
    suffix greater than any existing one: ``basename="foo-"`` and ``numbered=True``
    means that this function will create directories named ``"foo-0"``,
    ``"foo-1"``, ``"foo-2"`` and so on.

:returns:
    The path to the new directory.

**Param√®tres :**

- `basename`
- `numbered`

##### getbasetemp

Return the base temporary directory, creating it if needed.

:returns:
    The base temporary directory.

---

### tracemalloc

#### Fonctions

##### tracemalloc_message

**Param√®tres :**

- `source`

---

### unittest

Discover and run std-library "unittest" style tests.

#### Classes

##### UnitTestCase

**M√©thodes :**

- `newinstance()`
- `collect()`
- `_register_unittest_setup_class_fixture()`
- `_register_unittest_setup_method_fixture()`

##### TestCaseFunction

**M√©thodes :**

- `_getinstance()`
- `_testcase()`
- `setup()`
- `teardown()`
- `startTest()`
- `_addexcinfo()`
- `addError()`
- `addFailure()`
- `addSkip()`
- `addExpectedFailure()`
- `addUnexpectedSuccess()`
- `addSuccess()`
- `stopTest()`
- `addDuration()`
- `runtest()`
- `_traceback_filter()`

##### TwistedVersion

The Twisted version installed in the environment.

We have different workarounds in place for different versions of Twisted.

#### Fonctions

##### pytest_pycollect_makeitem

**Param√®tres :**

- `collector`
- `name`
- `obj`

##### pytest_runtest_makereport

**Param√®tres :**

- `item`
- `call`

##### _is_skipped

Return True if the given object has been marked with @unittest.skip.

**Param√®tres :**

- `obj`

##### pytest_configure

Register the TestCaseFunction class as an IReporter if twisted.trial is available.

##### _get_twisted_version

##### pytest_runtest_protocol

**Param√®tres :**

- `item`

##### _handle_twisted_exc_info

Twisted passes a custom Failure instance to `addError()` instead of using `sys.exc_info()`.
Therefore, if `rawexcinfo` is a `Failure` instance, convert it into the equivalent `sys.exc_info()` tuple
as expected by pytest.

**Param√®tres :**

- `rawexcinfo`

##### newinstance

##### collect

##### _register_unittest_setup_class_fixture

Register an auto-use fixture to invoke setUpClass and
tearDownClass (#517).

**Param√®tres :**

- `cls`

##### _register_unittest_setup_method_fixture

Register an auto-use fixture to invoke setup_method and
teardown_method (#517).

**Param√®tres :**

- `cls`

##### _getinstance

##### _testcase

##### setup

##### teardown

##### startTest

**Param√®tres :**

- `testcase`

##### _addexcinfo

**Param√®tres :**

- `rawexcinfo`

##### addError

**Param√®tres :**

- `testcase`
- `rawexcinfo`

##### addFailure

**Param√®tres :**

- `testcase`
- `rawexcinfo`

##### addSkip

**Param√®tres :**

- `testcase`
- `reason`

##### addExpectedFailure

**Param√®tres :**

- `testcase`
- `rawexcinfo`
- `reason`

##### addUnexpectedSuccess

**Param√®tres :**

- `testcase`
- `reason`

##### addSuccess

**Param√®tres :**

- `testcase`

##### stopTest

**Param√®tres :**

- `testcase`

##### addDuration

**Param√®tres :**

- `testcase`
- `elapsed`

##### runtest

##### _traceback_filter

**Param√®tres :**

- `excinfo`

##### process_teardown_exceptions

##### unittest_setup_class_fixture

**Param√®tres :**

- `request`

##### unittest_setup_method_fixture

**Param√®tres :**

- `request`

##### store_raw_exception_info

**Param√®tres :**

- `exc_value`
- `exc_type`
- `exc_tb`
- `captureVars`

---

### unraisableexception

#### Classes

##### UnraisableMeta

#### Fonctions

##### gc_collect_harder

**Param√®tres :**

- `iterations`

##### collect_unraisable

**Param√®tres :**

- `config`

##### cleanup

##### unraisable_hook

##### pytest_configure

**Param√®tres :**

- `config`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

**Param√®tres :**

- `item`

---

### warning_types

#### Classes

##### PytestWarning

Base class for all warnings emitted by pytest.

##### PytestAssertRewriteWarning

Warning emitted by the pytest assert rewrite module.

##### PytestCacheWarning

Warning emitted by the cache plugin in various situations.

##### PytestConfigWarning

Warning emitted for configuration issues.

##### PytestCollectionWarning

Warning emitted when pytest is not able to collect a file or symbol in a module.

##### PytestDeprecationWarning

Warning class for features that will be removed in a future version.

##### PytestRemovedIn9Warning

Warning class for features that will be removed in pytest 9.

##### PytestExperimentalApiWarning

Warning category used to denote experiments in pytest.

Use sparingly as the API might change or even be removed completely in a
future version.

**M√©thodes :**

- `simple()`

##### PytestReturnNotNoneWarning

Warning emitted when a test function returns a value other than ``None``.

See :ref:`return-not-none` for details.

##### PytestUnknownMarkWarning

Warning emitted on use of unknown markers.

See :ref:`mark` for details.

##### PytestUnraisableExceptionWarning

An unraisable exception was reported.

Unraisable exceptions are exceptions raised in :meth:`__del__ <object.__del__>`
implementations and similar situations when the exception cannot be raised
as normal.

##### PytestUnhandledThreadExceptionWarning

An unhandled exception occurred in a :class:`~threading.Thread`.

Such exceptions don't propagate normally.

##### UnformattedWarning

A warning meant to be formatted during runtime.

This is used to hold warnings that need to format their message at runtime,
as opposed to a direct message.

**M√©thodes :**

- `format()`

##### PytestFDWarning

When the lsof plugin finds leaked fds.

#### Fonctions

##### warn_explicit_for

Issue the warning :param:`message` for the definition of the given :param:`method`

this helps to log warnings for functions defined prior to finding an issue with them
(like hook wrappers being marked in a legacy mechanism)

**Param√®tres :**

- `method`
- `message`

##### simple

**Param√®tres :**

- `cls`
- `apiname`

##### format

Return an instance of the warning category, formatted with given kwargs.

---

### warnings

#### Fonctions

##### catch_warnings_for_item

Context manager that catches warnings generated in the contained execution block.

``item`` can be None if we are not in the context of an item execution.

Each warning captured triggers the ``pytest_warning_recorded`` hook.

**Param√®tres :**

- `config`
- `ihook`
- `when`
- `item`

##### warning_record_to_str

Convert a warnings.WarningMessage to a string.

**Param√®tres :**

- `warning_message`

##### pytest_runtest_protocol

**Param√®tres :**

- `item`

##### pytest_collection

**Param√®tres :**

- `session`

##### pytest_terminal_summary

**Param√®tres :**

- `terminalreporter`

##### pytest_sessionfinish

**Param√®tres :**

- `session`

##### pytest_load_initial_conftests

**Param√®tres :**

- `early_config`

##### pytest_configure

**Param√®tres :**

- `config`

---

### .!34819!__init__

---

### .!34823!_argcomplete

---

### .!34827!_version

---

### .!34831!cacheprovider

---

### .!34835!capture

---

### .!34839!compat

---

### .!34842!debugging

---

### .!34846!deprecated

---

### .!34847!doctest

---

### .!34851!faulthandler

---

### .!34853!fixtures

---

### .!34856!freeze_support

---

### .!34859!helpconfig

---

### .!34861!hookspec

---

### .!34866!junitxml

---

### .!34871!legacypath

---

### .!34874!logging

---

### .!34881!monkeypatch

---

### .!34883!nodes

---

### .!34885!outcomes

---

### .!34888!pastebin

---

### .!34892!pathlib

---

### .!34893!pytester

---

### .!34897!pytester_assertions

---

### .!34901!python

---

### .!34904!python_api

---

### .!34907!raises

---

### .!34911!recwarn

---

### .!34914!reports

---

### .!34917!runner

---

### .!34920!scope

---

### .!34922!setuponly

---

### .!34925!setupplan

---

### .!34929!skipping

---

### .!34932!stash

---

### .!34934!stepwise

---

### .!34937!terminal

---

### .!34940!threadexception

---

### .!34944!timing

---

### .!34948!tmpdir

---

### .!34951!tracemalloc

---

### .!34954!unittest

---

### .!34958!unraisableexception

---

### .!34961!warning_types

---

### .!34966!warnings

---

### code

#### Classes

##### Code

Wrapper around Python code objects.

**M√©thodes :**

- `__init__()`
- `from_function()`
- `__eq__()`
- `firstlineno()`
- `name()`
- `path()`
- `fullsource()`
- `source()`
- `getargs()`

##### Frame

Wrapper around a Python frame holding f_locals and f_globals
in which expressions can be evaluated.

**M√©thodes :**

- `__init__()`
- `lineno()`
- `f_globals()`
- `f_locals()`
- `code()`
- `statement()`
- `eval()`
- `repr()`
- `getargs()`

##### TracebackEntry

A single entry in a Traceback.

**M√©thodes :**

- `__init__()`
- `with_repr_style()`
- `lineno()`
- `get_python_framesummary()`
- `frame()`
- `relline()`
- `__repr__()`
- `statement()`
- `path()`
- `locals()`
- `getfirstlinesource()`
- `getsource()`
- `ishidden()`
- `__str__()`
- `name()`

##### Traceback

Traceback objects encapsulate and offer higher level access to Traceback entries.

**M√©thodes :**

- `__init__()`
- `cut()`
- `__getitem__()`
- `__getitem__()`
- `__getitem__()`
- `filter()`
- `recursionindex()`

##### ExceptionInfo

Wraps sys.exc_info() objects and offers help for navigating the traceback.

**M√©thodes :**

- `__init__()`
- `from_exception()`
- `from_exc_info()`
- `from_current()`
- `for_later()`
- `fill_unfilled()`
- `type()`
- `value()`
- `tb()`
- `typename()`
- `traceback()`
- `traceback()`
- `__repr__()`
- `exconly()`
- `errisinstance()`
- `_getreprcrash()`
- `getrepr()`
- `match()`
- `_group_contains()`
- `group_contains()`

##### FormattedExcinfo

Presenting information about failing Functions and Generators.

**M√©thodes :**

- `_getindent()`
- `_getentrysource()`
- `repr_args()`
- `get_source()`
- `get_highlight_arrows_for_line()`
- `get_exconly()`
- `repr_locals()`
- `repr_traceback_entry()`
- `_makepath()`
- `repr_traceback()`
- `_truncate_recursive_traceback()`
- `repr_excinfo()`

##### TerminalRepr

**M√©thodes :**

- `__str__()`
- `__repr__()`
- `toterminal()`

##### ExceptionRepr

**M√©thodes :**

- `addsection()`
- `toterminal()`

##### ExceptionChainRepr

**M√©thodes :**

- `__init__()`
- `toterminal()`

##### ReprExceptionInfo

**M√©thodes :**

- `toterminal()`

##### ReprTraceback

**M√©thodes :**

- `toterminal()`

##### ReprTracebackNative

**M√©thodes :**

- `__init__()`

##### ReprEntryNative

**M√©thodes :**

- `toterminal()`

##### ReprEntry

**M√©thodes :**

- `_write_entry_lines()`
- `toterminal()`
- `__str__()`

##### ReprFileLocation

**M√©thodes :**

- `__post_init__()`
- `toterminal()`

##### ReprLocals

**M√©thodes :**

- `toterminal()`

##### ReprFuncArgs

**M√©thodes :**

- `toterminal()`

#### Fonctions

##### stringify_exception

**Param√®tres :**

- `exc`
- `include_subexception_msg`

##### getfslineno

Return source location (path, lineno) for the given object.

If the source cannot be determined return ("", -1).

The line number is 0-based.

**Param√®tres :**

- `obj`

##### _byte_offset_to_character_offset

Converts a byte based offset in a string to a code-point.

**Param√®tres :**

- `str`
- `offset`

##### filter_traceback

Return True if a TracebackEntry instance should be included in tracebacks.

We hide traceback entries of:

* dynamically generated code (no code to show up for it);
* internal traceback from pytest or its internal libraries, py and pluggy.

**Param√®tres :**

- `entry`

##### filter_excinfo_traceback

Filter the exception traceback in ``excinfo`` according to ``tbfilter``.

**Param√®tres :**

- `tbfilter`
- `excinfo`

##### __init__

**Param√®tres :**

- `obj`

##### from_function

**Param√®tres :**

- `cls`
- `obj`

##### __eq__

**Param√®tres :**

- `other`

##### firstlineno

##### name

##### path

Return a path object pointing to source code, or an ``str`` in
case of ``OSError`` / non-existing file.

##### fullsource

Return a _pytest._code.Source object for the full source file of the code.

##### source

Return a _pytest._code.Source object for the code object's source only.

##### getargs

Return a tuple with the argument names for the code object.

If 'var' is set True also return the names of the variable and
keyword arguments when present.

**Param√®tres :**

- `var`

##### __init__

**Param√®tres :**

- `frame`

##### lineno

##### f_globals

##### f_locals

##### code

##### statement

Statement this frame is at.

##### eval

Evaluate 'code' in the frame.

'vars' are optional additional local variables.

Returns the result of the evaluation.

**Param√®tres :**

- `code`

##### repr

Return a 'safe' (non-recursive, one-line) string repr for 'object'.

**Param√®tres :**

- `object`

##### getargs

Return a list of tuples (name, value) for all arguments.

If 'var' is set True, also include the variable and keyword arguments
when present.

**Param√®tres :**

- `var`

##### __init__

**Param√®tres :**

- `rawentry`
- `repr_style`

##### with_repr_style

**Param√®tres :**

- `repr_style`

##### lineno

##### get_python_framesummary

##### frame

##### relline

##### __repr__

##### statement

_pytest._code.Source object for the current statement.

##### path

Path to the source code.

##### locals

Locals of underlying frame.

##### getfirstlinesource

##### getsource

Return failing source code.

**Param√®tres :**

- `astcache`

##### ishidden

Return True if the current frame has a var __tracebackhide__
resolving to True.

If __tracebackhide__ is a callable, it gets called with the
ExceptionInfo instance and can decide whether to hide the traceback.

Mostly for internal use.

**Param√®tres :**

- `excinfo`

##### __str__

##### name

co_name of underlying code.

##### __init__

Initialize from given python traceback object and ExceptionInfo.

**Param√®tres :**

- `tb`

##### cut

Return a Traceback instance wrapping part of this Traceback.

By providing any combination of path, lineno and firstlineno, the
first frame to start the to-be-returned traceback is determined.

This allows cutting the first part of a Traceback instance e.g.
for formatting reasons (removing some uninteresting bits that deal
with handling of the exception/traceback).

**Param√®tres :**

- `path`
- `lineno`
- `firstlineno`
- `excludepath`

##### __getitem__

**Param√®tres :**

- `key`

##### __getitem__

**Param√®tres :**

- `key`

##### __getitem__

**Param√®tres :**

- `key`

##### filter

Return a Traceback instance with certain items removed.

If the filter is an `ExceptionInfo`, removes all the ``TracebackEntry``s
which are hidden (see ishidden() above).

Otherwise, the filter is a function that gets a single argument, a
``TracebackEntry`` instance, and should return True when the item should
be added to the ``Traceback``, False when not.

##### recursionindex

Return the index of the frame/TracebackEntry where recursion originates if
appropriate, None if no recursion occurred.

##### __init__

**Param√®tres :**

- `excinfo`
- `striptext`
- `traceback`

##### from_exception

Return an ExceptionInfo for an existing exception.

The exception must have a non-``None`` ``__traceback__`` attribute,
otherwise this function fails with an assertion error. This means that
the exception must have been raised, or added a traceback with the
:py:meth:`~BaseException.with_traceback()` method.

:param exprinfo:
    A text string helping to determine if we should strip
    ``AssertionError`` from the output. Defaults to the exception
    message/``__str__()``.

.. versionadded:: 7.4

**Param√®tres :**

- `cls`
- `exception`
- `exprinfo`

##### from_exc_info

Like :func:`from_exception`, but using old-style exc_info tuple.

**Param√®tres :**

- `cls`
- `exc_info`
- `exprinfo`

##### from_current

Return an ExceptionInfo matching the current traceback.

.. warning::

    Experimental API

:param exprinfo:
    A text string helping to determine if we should strip
    ``AssertionError`` from the output. Defaults to the exception
    message/``__str__()``.

**Param√®tres :**

- `cls`
- `exprinfo`

##### for_later

Return an unfilled ExceptionInfo.

**Param√®tres :**

- `cls`

##### fill_unfilled

Fill an unfilled ExceptionInfo created with ``for_later()``.

**Param√®tres :**

- `exc_info`

##### type

The exception class.

##### value

The exception value.

##### tb

The exception raw traceback.

##### typename

The type name of the exception.

##### traceback

The traceback.

##### traceback

**Param√®tres :**

- `value`

##### __repr__

##### exconly

Return the exception as a string.

When 'tryshort' resolves to True, and the exception is an
AssertionError, only the actual exception part of the exception
representation is returned (so 'AssertionError: ' is removed from
the beginning).

**Param√®tres :**

- `tryshort`

##### errisinstance

Return True if the exception is an instance of exc.

Consider using ``isinstance(excinfo.value, exc)`` instead.

**Param√®tres :**

- `exc`

##### _getreprcrash

##### getrepr

Return str()able representation of this exception info.

:param bool showlocals:
    Show locals per traceback entry.
    Ignored if ``style=="native"``.

:param str style:
    long|short|line|no|native|value traceback style.

:param bool abspath:
    If paths should be changed to absolute or left unchanged.

:param tbfilter:
    A filter for traceback entries.

    * If false, don't hide any entries.
    * If true, hide internal entries and entries that contain a local
      variable ``__tracebackhide__ = True``.
    * If a callable, delegates the filtering to the callable.

    Ignored if ``style`` is ``"native"``.

:param bool funcargs:
    Show fixtures ("funcargs" for legacy purposes) per traceback entry.

:param bool truncate_locals:
    With ``showlocals==True``, make sure locals can be safely represented as strings.

:param bool truncate_args:
    With ``showargs==True``, make sure args can be safely represented as strings.

:param bool chain:
    If chained exceptions in Python 3 should be shown.

.. versionchanged:: 3.9

    Added the ``chain`` parameter.

**Param√®tres :**

- `showlocals`
- `style`
- `abspath`
- `tbfilter`
- `funcargs`
- `truncate_locals`
- `truncate_args`
- `chain`

##### match

Check whether the regular expression `regexp` matches the string
representation of the exception using :func:`python:re.search`.

If it matches `True` is returned, otherwise an `AssertionError` is raised.

**Param√®tres :**

- `regexp`

##### _group_contains

Return `True` if a `BaseExceptionGroup` contains a matching exception.

**Param√®tres :**

- `exc_group`
- `expected_exception`
- `match`
- `target_depth`
- `current_depth`

##### group_contains

Check whether a captured exception group contains a matching exception.

:param Type[BaseException] | Tuple[Type[BaseException]] expected_exception:
    The expected exception type, or a tuple if one of multiple possible
    exception types are expected.

:param str | re.Pattern[str] | None match:
    If specified, a string containing a regular expression,
    or a regular expression object, that is tested against the string
    representation of the exception and its `PEP-678 <https://peps.python.org/pep-0678/>` `__notes__`
    using :func:`re.search`.

    To match a literal string that may contain :ref:`special characters
    <re-syntax>`, the pattern can first be escaped with :func:`re.escape`.

:param Optional[int] depth:
    If `None`, will search for a matching exception at any nesting depth.
    If >= 1, will only match an exception if it's at the specified depth (depth = 1 being
    the exceptions contained within the topmost exception group).

.. versionadded:: 8.0

.. warning::
   This helper makes it easy to check for the presence of specific exceptions,
   but it is very bad for checking that the group does *not* contain
   *any other exceptions*.
   You should instead consider using :class:`pytest.RaisesGroup`

**Param√®tres :**

- `expected_exception`

##### _getindent

**Param√®tres :**

- `source`

##### _getentrysource

**Param√®tres :**

- `entry`

##### repr_args

**Param√®tres :**

- `entry`

##### get_source

Return formatted and marked up source lines.

**Param√®tres :**

- `source`
- `line_index`
- `excinfo`
- `short`
- `end_line_index`
- `colno`
- `end_colno`

##### get_highlight_arrows_for_line

Return characters highlighting a source line.

Example with colno and end_colno pointing to the bar expression:
           "foo() + bar()"
returns    "        ^^^^^"

**Param√®tres :**

- `line`
- `raw_line`
- `lineno`
- `end_lineno`
- `colno`
- `end_colno`

##### get_exconly

**Param√®tres :**

- `excinfo`
- `indent`
- `markall`

##### repr_locals

**Param√®tres :**

- `locals`

##### repr_traceback_entry

**Param√®tres :**

- `entry`
- `excinfo`

##### _makepath

**Param√®tres :**

- `path`

##### repr_traceback

**Param√®tres :**

- `excinfo`

##### _truncate_recursive_traceback

Truncate the given recursive traceback trying to find the starting
point of the recursion.

The detection is done by going through each traceback entry and
finding the point in which the locals of the frame are equal to the
locals of a previous frame (see ``recursionindex()``).

Handle the situation where the recursion process might raise an
exception (for example comparing numpy arrays using equality raises a
TypeError), in which case we do our best to warn the user of the
error and show a limited traceback.

**Param√®tres :**

- `traceback`

##### repr_excinfo

**Param√®tres :**

- `excinfo`

##### __str__

##### __repr__

##### toterminal

**Param√®tres :**

- `tw`

##### addsection

**Param√®tres :**

- `name`
- `content`
- `sep`

##### toterminal

**Param√®tres :**

- `tw`

##### __init__

**Param√®tres :**

- `chain`

##### toterminal

**Param√®tres :**

- `tw`

##### toterminal

**Param√®tres :**

- `tw`

##### toterminal

**Param√®tres :**

- `tw`

##### __init__

**Param√®tres :**

- `tblines`

##### toterminal

**Param√®tres :**

- `tw`

##### _write_entry_lines

Write the source code portions of a list of traceback entries with syntax highlighting.

Usually entries are lines like these:

    "     x = 1"
    ">    assert x == 2"
    "E    assert 1 == 2"

This function takes care of rendering the "source" portions of it (the lines without
the "E" prefix) using syntax highlighting, taking care to not highlighting the ">"
character, as doing so might break line continuations.

**Param√®tres :**

- `tw`

##### toterminal

**Param√®tres :**

- `tw`

##### __str__

##### __post_init__

##### toterminal

**Param√®tres :**

- `tw`

##### toterminal

**Param√®tres :**

- `tw`
- `indent`

##### toterminal

**Param√®tres :**

- `tw`

##### end_lineno_relative

##### colno

##### end_colno

##### end_lineno_relative

##### colno

Starting byte offset of the expression in the traceback entry.

##### end_colno

Ending byte offset of the expression in the traceback entry.

##### _get_single_subexc

**Param√®tres :**

- `eg`

##### f

**Param√®tres :**

- `cur`

---

### source

#### Classes

##### Source

An immutable object holding a source code fragment.

When using Source(...), the source lines are deindented.

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `__getitem__()`
- `__getitem__()`
- `__getitem__()`
- `__iter__()`
- `__len__()`
- `strip()`
- `indent()`
- `getstatement()`
- `getstatementrange()`
- `deindent()`
- `__str__()`

#### Fonctions

##### findsource

**Param√®tres :**

- `obj`

##### getrawcode

Return code object for given function.

**Param√®tres :**

- `obj`
- `trycall`

##### deindent

**Param√®tres :**

- `lines`

##### get_statement_startend2

**Param√®tres :**

- `lineno`
- `node`

##### getstatementrange_ast

**Param√®tres :**

- `lineno`
- `source`
- `assertion`
- `astnode`

##### __init__

**Param√®tres :**

- `obj`

##### __eq__

**Param√®tres :**

- `other`

##### __getitem__

**Param√®tres :**

- `key`

##### __getitem__

**Param√®tres :**

- `key`

##### __getitem__

**Param√®tres :**

- `key`

##### __iter__

##### __len__

##### strip

Return new Source object with trailing and leading blank lines removed.

##### indent

Return a copy of the source object with all lines indented by the
given indent-string.

**Param√®tres :**

- `indent`

##### getstatement

Return Source statement which contains the given linenumber
(counted from 0).

**Param√®tres :**

- `lineno`

##### getstatementrange

Return (start, end) tuple which spans the minimal statement region
which containing the given lineno.

**Param√®tres :**

- `lineno`

##### deindent

Return a new Source object deindented.

##### __str__

---

### .!34969!__init__

---

### .!34974!code

---

### .!34977!source

---

### pprint

#### Classes

##### _safe_key

Helper function for key functions when sorting unorderable objects.

The wrapped-object will fallback to a Py2.x style comparison for
unorderable types (sorting first comparing the type name and then by
the obj ids).  Does not work recursively, so dict.items() must have
_safe_key applied to both the key and the value.

**M√©thodes :**

- `__init__()`
- `__lt__()`

##### PrettyPrinter

**M√©thodes :**

- `__init__()`
- `pformat()`
- `_format()`
- `_pprint_dataclass()`
- `_pprint_dict()`
- `_pprint_ordered_dict()`
- `_pprint_list()`
- `_pprint_tuple()`
- `_pprint_set()`
- `_pprint_str()`
- `_pprint_bytes()`
- `_pprint_bytearray()`
- `_pprint_mappingproxy()`
- `_pprint_simplenamespace()`
- `_format_dict_items()`
- `_format_namespace_items()`
- `_format_items()`
- `_repr()`
- `_pprint_default_dict()`
- `_pprint_counter()`
- `_pprint_chain_map()`
- `_pprint_deque()`
- `_pprint_user_dict()`
- `_pprint_user_list()`
- `_pprint_user_string()`
- `_safe_repr()`

#### Fonctions

##### _safe_tuple

Helper function for comparing 2-tuples

**Param√®tres :**

- `t`

##### _recursion

**Param√®tres :**

- `object`

##### _wrap_bytes_repr

**Param√®tres :**

- `object`
- `width`
- `allowance`

##### __init__

**Param√®tres :**

- `obj`

##### __lt__

**Param√®tres :**

- `other`

##### __init__

Handle pretty printing operations onto a stream using a set of
configured parameters.

indent
    Number of spaces to indent for each level of nesting.

width
    Attempted maximum number of columns in the output.

depth
    The maximum depth to print out nested structures.

**Param√®tres :**

- `indent`
- `width`
- `depth`

##### pformat

**Param√®tres :**

- `object`

##### _format

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_dataclass

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_dict

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_ordered_dict

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_list

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_tuple

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_set

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_str

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_bytes

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_bytearray

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_mappingproxy

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_simplenamespace

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _format_dict_items

**Param√®tres :**

- `items`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _format_namespace_items

**Param√®tres :**

- `items`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _format_items

**Param√®tres :**

- `items`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _repr

**Param√®tres :**

- `object`
- `context`
- `level`

##### _pprint_default_dict

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_counter

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_chain_map

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_deque

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_user_dict

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_user_list

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _pprint_user_string

**Param√®tres :**

- `object`
- `stream`
- `indent`
- `allowance`
- `context`
- `level`

##### _safe_repr

**Param√®tres :**

- `object`
- `context`
- `maxlevels`
- `level`

---

### saferepr

#### Classes

##### SafeRepr

repr.Repr that limits the resulting size of repr() and includes
information on exceptions raised during the call.

**M√©thodes :**

- `__init__()`
- `repr()`
- `repr_instance()`

#### Fonctions

##### _try_repr_or_str

**Param√®tres :**

- `obj`

##### _format_repr_exception

**Param√®tres :**

- `exc`
- `obj`

##### _ellipsize

**Param√®tres :**

- `s`
- `maxsize`

##### safeformat

Return a pretty printed string for the given object.

Failing __repr__ functions of user instances will be represented
with a short exception info.

**Param√®tres :**

- `obj`

##### saferepr

Return a size-limited safe repr-string for the given object.

Failing __repr__ functions of user instances will be represented
with a short exception info and 'saferepr' generally takes
care to never raise exceptions itself.

This function is a wrapper around the Repr/reprlib functionality of the
stdlib.

**Param√®tres :**

- `obj`
- `maxsize`
- `use_ascii`

##### saferepr_unlimited

Return an unlimited-size safe repr-string for the given object.

As with saferepr, failing __repr__ functions of user instances
will be represented with a short exception info.

This function is a wrapper around simple repr.

Note: a cleaner solution would be to alter ``saferepr``this way
when maxsize=None, but that might affect some other code.

**Param√®tres :**

- `obj`
- `use_ascii`

##### __init__

:param maxsize:
    If not None, will truncate the resulting repr to that specific size, using ellipsis
    somewhere in the middle to hide the extra text.
    If None, will not impose any size limits on the returning repr.

**Param√®tres :**

- `maxsize`
- `use_ascii`

##### repr

**Param√®tres :**

- `x`

##### repr_instance

**Param√®tres :**

- `x`
- `level`

---

### terminalwriter

Helper functions for writing to terminals and files.

#### Classes

##### TerminalWriter

**M√©thodes :**

- `__init__()`
- `fullwidth()`
- `fullwidth()`
- `width_of_current_line()`
- `markup()`
- `sep()`
- `write()`
- `line()`
- `flush()`
- `_write_source()`
- `_get_pygments_lexer()`
- `_get_pygments_formatter()`
- `_highlight()`

#### Fonctions

##### get_terminal_width

##### should_do_markup

**Param√®tres :**

- `file`

##### __init__

**Param√®tres :**

- `file`

##### fullwidth

##### fullwidth

**Param√®tres :**

- `value`

##### width_of_current_line

Return an estimate of the width so far in the current line.

##### markup

**Param√®tres :**

- `text`

##### sep

**Param√®tres :**

- `sepchar`
- `title`
- `fullwidth`

##### write

**Param√®tres :**

- `msg`

##### line

**Param√®tres :**

- `s`

##### flush

##### _write_source

Write lines of source code possibly highlighted.

Keeping this private for now because the API is clunky. We should discuss how
to evolve the terminal writer so we can have more precise color support, for example
being able to write part of a line in one color and the rest in another, and so on.

**Param√®tres :**

- `lines`
- `indents`

##### _get_pygments_lexer

**Param√®tres :**

- `lexer`

##### _get_pygments_formatter

##### _highlight

Highlight the given source if we have markup support.

**Param√®tres :**

- `source`
- `lexer`

---

### wcwidth

#### Fonctions

##### wcwidth

Determine how many columns are needed to display a character in a terminal.

Returns -1 if the character is not printable.
Returns 0, 1 or 2 for other characters.

**Param√®tres :**

- `c`

##### wcswidth

Determine how many columns are needed to display a string in a terminal.

Returns -1 if the string contains non-printable characters.

**Param√®tres :**

- `s`

---

### .!34981!__init__

---

### .!34986!pprint

---

### .!34989!saferepr

---

### .!34991!terminalwriter

---

### .!34994!wcwidth

---

### error

create errno-specific classes for IO or os calls.

#### Classes

##### Error

**M√©thodes :**

- `__repr__()`
- `__str__()`

##### ErrorMaker

lazily provides Exception classes for each possible POSIX errno
(as defined per the 'errno' module).  All such instances
subclass EnvironmentError.

**M√©thodes :**

- `__getattr__()`
- `_geterrnoclass()`
- `checked_call()`

#### Fonctions

##### __getattr__

**Param√®tres :**

- `attr`

##### __repr__

##### __str__

##### __getattr__

**Param√®tres :**

- `name`

##### _geterrnoclass

**Param√®tres :**

- `eno`

##### checked_call

Call a function and raise an errno-exception if applicable.

**Param√®tres :**

- `func`

---

### path

local path implementation.

#### Classes

##### Checkers

**M√©thodes :**

- `__init__()`
- `dotfile()`
- `ext()`
- `basename()`
- `basestarts()`
- `relto()`
- `fnmatch()`
- `endswith()`
- `_evaluate()`
- `_stat()`
- `dir()`
- `file()`
- `exists()`
- `link()`

##### NeverRaised

##### Visitor

**M√©thodes :**

- `__init__()`
- `gen()`

##### FNMatcher

**M√©thodes :**

- `__init__()`
- `__call__()`

##### Stat

**M√©thodes :**

- `__getattr__()`
- `__init__()`
- `owner()`
- `group()`
- `isdir()`
- `isfile()`
- `islink()`

##### LocalPath

Object oriented interface to os.path and other local filesystem
related information.

**M√©thodes :**

- `__init__()`
- `__div__()`
- `basename()`
- `dirname()`
- `purebasename()`
- `ext()`
- `read_binary()`
- `read_text()`
- `read()`
- `readlines()`
- `load()`
- `move()`
- `fnmatch()`
- `relto()`
- `ensure_dir()`
- `bestrelpath()`
- `exists()`
- `isdir()`
- `isfile()`
- `parts()`
- `common()`
- `__add__()`
- `visit()`
- `_sortlist()`
- `__fspath__()`
- `__hash__()`
- `__eq__()`
- `__ne__()`
- `__lt__()`
- `__gt__()`
- `samefile()`
- `remove()`
- `computehash()`
- `new()`
- `_getbyspec()`
- `dirpath()`
- `join()`
- `open()`
- `_fastjoin()`
- `islink()`
- `check()`
- `listdir()`
- `size()`
- `mtime()`
- `copy()`
- `rename()`
- `dump()`
- `mkdir()`
- `write_binary()`
- `write_text()`
- `write()`
- `_ensuredirs()`
- `ensure()`
- `stat()`
- `stat()`
- `stat()`
- `lstat()`
- `setmtime()`
- `chdir()`
- `as_cwd()`
- `realpath()`
- `atime()`
- `__repr__()`
- `__str__()`
- `chmod()`
- `pypkgpath()`
- `_ensuresyspath()`
- `pyimport()`
- `sysexec()`
- `sysfind()`
- `_gethomedir()`
- `get_temproot()`
- `mkdtemp()`
- `make_numbered_dir()`

##### ImportMismatchError

raised on pyimport() if there is a mismatch of __file__'s

#### Fonctions

##### map_as_list

**Param√®tres :**

- `func`
- `iter`

##### getuserid

**Param√®tres :**

- `user`

##### getgroupid

**Param√®tres :**

- `group`

##### copymode

Copy permission from src to dst.

**Param√®tres :**

- `src`
- `dest`

##### copystat

Copy permission,  last modification time,
last access time, and flags from src to dst.

**Param√®tres :**

- `src`
- `dest`

##### copychunked

**Param√®tres :**

- `src`
- `dest`

##### isimportable

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `path`

##### dotfile

##### ext

**Param√®tres :**

- `arg`

##### basename

**Param√®tres :**

- `arg`

##### basestarts

**Param√®tres :**

- `arg`

##### relto

**Param√®tres :**

- `arg`

##### fnmatch

**Param√®tres :**

- `arg`

##### endswith

**Param√®tres :**

- `arg`

##### _evaluate

**Param√®tres :**

- `kw`

##### _stat

##### dir

##### file

##### exists

##### link

##### __init__

**Param√®tres :**

- `fil`
- `rec`
- `ignore`
- `bf`
- `sort`

##### gen

**Param√®tres :**

- `path`

##### __init__

**Param√®tres :**

- `pattern`

##### __call__

**Param√®tres :**

- `path`

##### __getattr__

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `path`
- `osstatresult`

##### owner

##### group

Return group name of file.

##### isdir

##### isfile

##### islink

##### __init__

Initialize and return a local Path instance.

Path can be relative to the current directory.
If path is None it defaults to the current working directory.
If expanduser is True, tilde-expansion is performed.
Note that Path instances always carry an absolute path.
Note also that passing in a local path object will simply return
the exact same path object. Use new() to get a new copy.

**Param√®tres :**

- `path`
- `expanduser`

##### __div__

**Param√®tres :**

- `other`

##### basename

Basename part of path.

##### dirname

Dirname part of path.

##### purebasename

Pure base name of the path.

##### ext

Extension of the path (including the '.').

##### read_binary

Read and return a bytestring from reading the path.

##### read_text

Read and return a Unicode string from reading the path.

**Param√®tres :**

- `encoding`

##### read

Read and return a bytestring from reading the path.

**Param√®tres :**

- `mode`

##### readlines

Read and return a list of lines from the path. if cr is False, the
newline will be removed from the end of each line.

**Param√®tres :**

- `cr`

##### load

(deprecated) return object unpickled from self.read()

##### move

Move this path to target.

**Param√®tres :**

- `target`

##### fnmatch

Return true if the basename/fullname matches the glob-'pattern'.

valid pattern characters::

    *       matches everything
    ?       matches any single character
    [seq]   matches any character in seq
    [!seq]  matches any char not in seq

If the pattern contains a path-separator then the full path
is used for pattern matching and a '*' is prepended to the
pattern.

if the pattern doesn't contain a path-separator the pattern
is only matched against the basename.

**Param√®tres :**

- `pattern`

##### relto

Return a string which is the relative part of the path
to the given 'relpath'.

**Param√®tres :**

- `relpath`

##### ensure_dir

Ensure the path joined with args is a directory.

##### bestrelpath

Return a string which is a relative path from self
(assumed to be a directory) to dest such that
self.join(bestrelpath) == dest and if not such
path can be determined return dest.

**Param√®tres :**

- `dest`

##### exists

##### isdir

##### isfile

##### parts

Return a root-first list of all ancestor directories
plus the path itself.

**Param√®tres :**

- `reverse`

##### common

Return the common part shared with the other path
or None if there is no common part.

**Param√®tres :**

- `other`

##### __add__

Return new path object with 'other' added to the basename

**Param√®tres :**

- `other`

##### visit

Yields all paths below the current one

fil is a filter (glob pattern or callable), if not matching the
path will not be yielded, defaulting to None (everything is
returned)

rec is a filter (glob pattern or callable) that controls whether
a node is descended, defaulting to None

ignore is an Exception class that is ignoredwhen calling dirlist()
on any of the paths (by default, all exceptions are reported)

bf if True will cause a breadthfirst search instead of the
default depthfirst. Default: False

sort if True will sort entries within each directory level.

**Param√®tres :**

- `fil`
- `rec`
- `ignore`
- `bf`
- `sort`

##### _sortlist

**Param√®tres :**

- `res`
- `sort`

##### __fspath__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __ne__

**Param√®tres :**

- `other`

##### __lt__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### samefile

Return True if 'other' references the same file as 'self'.

**Param√®tres :**

- `other`

##### remove

Remove a file or directory (or a directory tree if rec=1).
if ignore_errors is True, errors while removing directories will
be ignored.

**Param√®tres :**

- `rec`
- `ignore_errors`

##### computehash

Return hexdigest of hashvalue for this file.

**Param√®tres :**

- `hashtype`
- `chunksize`

##### new

Create a modified version of this path.
the following keyword arguments modify various path parts::

  a:/some/path/to/a/file.ext
  xx                           drive
  xxxxxxxxxxxxxxxxx            dirname
                    xxxxxxxx   basename
                    xxxx       purebasename
                         xxx   ext

##### _getbyspec

See new for what 'spec' can be.

**Param√®tres :**

- `spec`

##### dirpath

Return the directory path joined with any given path arguments.

##### join

Return a new path by appending all 'args' as path
components.  if abs=1 is used restart from root if any
of the args is an absolute path.

##### open

Return an opened file with the given mode.

If ensure is True, create parent directories if needed.

**Param√®tres :**

- `mode`
- `ensure`
- `encoding`

##### _fastjoin

**Param√®tres :**

- `name`

##### islink

##### check

Check a path for existence and properties.

Without arguments, return True if the path exists, otherwise False.

valid checkers::

    file = 1  # is a file
    file = 0  # is not a file (may not even exist)
    dir = 1  # is a dir
    link = 1  # is a link
    exists = 1  # exists

You can specify multiple checker definitions, for example::

    path.check(file=1, link=1)  # a link pointing to a file

##### listdir

List directory contents, possibly filter by the given fil func
and possibly sorted.

**Param√®tres :**

- `fil`
- `sort`

##### size

Return size of the underlying file object

##### mtime

Return last modification time of the path.

##### copy

Copy path to target.

If mode is True, will copy permission from path to target.
If stat is True, copy permission, last modification
time, last access time, and flags from path to target.

**Param√®tres :**

- `target`
- `mode`
- `stat`

##### rename

Rename this path to target.

**Param√®tres :**

- `target`

##### dump

Pickle object into path location

**Param√®tres :**

- `obj`
- `bin`

##### mkdir

Create & return the directory joined with args.

##### write_binary

Write binary data into path.   If ensure is True create
missing parent directories.

**Param√®tres :**

- `data`
- `ensure`

##### write_text

Write text data into path using the specified encoding.
If ensure is True create missing parent directories.

**Param√®tres :**

- `data`
- `encoding`
- `ensure`

##### write

Write data into path.   If ensure is True create
missing parent directories.

**Param√®tres :**

- `data`
- `mode`
- `ensure`

##### _ensuredirs

##### ensure

Ensure that an args-joined path exists (by default as
a file). if you specify a keyword argument 'dir=True'
then the path is forced to be a directory path.

##### stat

**Param√®tres :**

- `raising`

##### stat

**Param√®tres :**

- `raising`

##### stat

Return an os.stat() tuple.

**Param√®tres :**

- `raising`

##### lstat

Return an os.lstat() tuple.

##### setmtime

Set modification time for the given path.  if 'mtime' is None
(the default) then the file's mtime is set to current time.

Note that the resolution for 'mtime' is platform dependent.

**Param√®tres :**

- `mtime`

##### chdir

Change directory to self and return old current directory

##### as_cwd

Return a context manager, which changes to the path's dir during the
managed "with" context.
On __enter__ it returns the old dir, which might be ``None``.

##### realpath

Return a new path which contains no symbolic links.

##### atime

Return last access time of the path.

##### __repr__

##### __str__

Return string representation of the Path.

##### chmod

Change permissions to the given mode. If mode is an
integer it directly encodes the os-specific modes.
if rec is True perform recursively.

**Param√®tres :**

- `mode`
- `rec`

##### pypkgpath

Return the Python package path by looking for the last
directory upwards which still contains an __init__.py.
Return None if a pkgpath cannot be determined.

##### _ensuresyspath

**Param√®tres :**

- `ensuremode`
- `path`

##### pyimport

Return path as an imported python module.

If modname is None, look for the containing package
and construct an according module name.
The module will be put/looked up in sys.modules.
if ensuresyspath is True then the root dir for importing
the file (taking __init__.py files into account) will
be prepended to sys.path if it isn't there already.
If ensuresyspath=="append" the root dir will be appended
if it isn't already contained in sys.path.
if ensuresyspath is False no modification of syspath happens.

Special value of ensuresyspath=="importlib" is intended
purely for using in pytest, it is capable only of importing
separate .py files outside packages, e.g. for test suite
without any __init__.py file. It effectively allows having
same-named test modules in different places and offers
mild opt-in via this option. Note that it works only in
recent versions of python.

**Param√®tres :**

- `modname`
- `ensuresyspath`

##### sysexec

Return stdout text from executing a system child process,
where the 'self' path points to executable.
The process is directly invoked and not through a system shell.

##### sysfind

Return a path object found by looking at the systems
underlying PATH specification. If the checker is not None
it will be invoked to filter matching paths.  If a binary
cannot be found, None is returned
Note: This is probably not working on plain win32 systems
but may work on cygwin.

**Param√®tres :**

- `cls`
- `name`
- `checker`
- `paths`

##### _gethomedir

**Param√®tres :**

- `cls`

##### get_temproot

Return the system's temporary directory
(where tempfiles are usually created in)

**Param√®tres :**

- `cls`

##### mkdtemp

Return a Path object pointing to a fresh new temporary directory
(which we created ourselves).

**Param√®tres :**

- `cls`
- `rootdir`

##### make_numbered_dir

Return unique directory with a number greater than the current
maximum one.  The number is assumed to start directly after prefix.
if keep is true directories with a number less than (maxnum-keep)
will be removed. If .lock files are used (lock_timeout non-zero),
algorithm is multi-process safe.

**Param√®tres :**

- `cls`
- `prefix`
- `rootdir`
- `keep`
- `lock_timeout`

##### size

##### mtime

##### chown

Change ownership to the given user and group.
user and group may be specified by a number or
by a name.  if rec is True change ownership
recursively.

**Param√®tres :**

- `user`
- `group`
- `rec`

##### readlink

Return value of a symbolic link.

##### mklinkto

Posix style hard link to another name.

**Param√®tres :**

- `oldname`

##### mksymlinkto

Create a symbolic link with the given value (pointing to another name).

**Param√®tres :**

- `value`
- `absolute`

##### parse_num

Parse the number out of a path (if it matches the prefix)

**Param√®tres :**

- `path`

##### create_lockfile

Exclusively create lockfile. Throws when failed

**Param√®tres :**

- `path`

##### atexit_remove_lockfile

Ensure lockfile is removed at process exit

**Param√®tres :**

- `lockfile`

##### get_mtime

Read file modification time

**Param√®tres :**

- `path`

##### is_garbage

Check if path denotes directory scheduled for removal

**Param√®tres :**

- `path`

##### rec

**Param√®tres :**

- `p`

##### try_remove_lockfile

---

### .!34999!error

---

### .!35001!path

---

### rewrite

Rewrite assertion AST to produce nice error messages.

#### Classes

##### Sentinel

##### AssertionRewritingHook

PEP302/PEP451 import hook which rewrites asserts.

**M√©thodes :**

- `__init__()`
- `set_session()`
- `find_spec()`
- `create_module()`
- `exec_module()`
- `_early_rewrite_bailout()`
- `_should_rewrite()`
- `_is_marked_for_rewrite()`
- `mark_rewrite()`
- `_warn_already_imported()`
- `get_data()`

##### AssertionRewriter

Assertion rewriting implementation.

The main entrypoint is to call .run() with an ast.Module instance,
this will then find all the assert statements and rewrite them to
provide intermediate values and a detailed assertion error.  See
http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html
for an overview of how this works.

The entry point here is .run() which will iterate over all the
statements in an ast.Module and for each ast.Assert statement it
finds call .visit() with it.  Then .visit_Assert() takes over and
is responsible for creating new ast statements to replace the
original assert statement: it rewrites the test of an assertion
to provide intermediate values and replace it with an if statement
which raises an assertion error with a detailed explanation in
case the expression is false and calls pytest_assertion_pass hook
if expression is true.

For this .visit_Assert() uses the visitor pattern to visit all the
AST nodes of the ast.Assert.test field, each visit call returning
an AST node and the corresponding explanation string.  During this
state is kept in several instance attributes:

:statements: All the AST statements which will replace the assert
   statement.

:variables: This is populated by .variable() with each variable
   used by the statements so that they can all be set to None at
   the end of the statements.

:variable_counter: Counter to create new unique variables needed
   by statements.  Variables are created using .variable() and
   have the form of "@py_assert0".

:expl_stmts: The AST statements which will be executed to get
   data from the assertion.  This is the code which will construct
   the detailed assertion message that is used in the AssertionError
   or for the pytest_assertion_pass hook.

:explanation_specifiers: A dict filled by .explanation_param()
   with %-formatting placeholders and their corresponding
   expressions to use in the building of an assertion message.
   This is used by .pop_format_context() to build a message.

:stack: A stack of the explanation_specifiers dicts maintained by
   .push_format_context() and .pop_format_context() which allows
   to build another %-formatted string while already building one.

:scope: A tuple containing the current scope used for variables_overwrite.

:variables_overwrite: A dict filled with references to variables
   that change value within an assert. This happens when a variable is
   reassigned with the walrus operator

This state, except the variables_overwrite,  is reset on every new assert
statement visited and used by the other visitors.

**M√©thodes :**

- `__init__()`
- `run()`
- `is_rewrite_disabled()`
- `variable()`
- `assign()`
- `display()`
- `helper()`
- `builtin()`
- `explanation_param()`
- `push_format_context()`
- `pop_format_context()`
- `generic_visit()`
- `visit_Assert()`
- `visit_NamedExpr()`
- `visit_Name()`
- `visit_BoolOp()`
- `visit_UnaryOp()`
- `visit_BinOp()`
- `visit_Call()`
- `visit_Starred()`
- `visit_Attribute()`
- `visit_Compare()`

#### Fonctions

##### _write_pyc_fp

**Param√®tres :**

- `fp`
- `source_stat`
- `co`

##### _write_pyc

**Param√®tres :**

- `state`
- `co`
- `source_stat`
- `pyc`

##### _rewrite_test

Read and rewrite *fn* and return the code object.

**Param√®tres :**

- `fn`
- `config`

##### _read_pyc

Possibly read a pytest pyc containing rewritten code.

Return rewritten code if successful or None if not.

**Param√®tres :**

- `source`
- `pyc`
- `trace`

##### rewrite_asserts

Rewrite the assert statements in mod.

**Param√®tres :**

- `mod`
- `source`
- `module_path`
- `config`

##### _saferepr

Get a safe repr of an object for assertion error messages.

The assertion formatting (util.format_explanation()) requires
newlines to be escaped since they are a special character for it.
Normally assertion.util.format_explanation() does this but for a
custom repr it is possible to contain one of the special escape
sequences, especially '\n{' and '\n}' are likely to be present in
JSON reprs.

**Param√®tres :**

- `obj`

##### _get_maxsize_for_saferepr

Get `maxsize` configuration for saferepr based on the given config object.

**Param√®tres :**

- `config`

##### _format_assertmsg

Format the custom assertion message given.

For strings this simply replaces newlines with '\n~' so that
util.format_explanation() will preserve them instead of escaping
newlines.  For other objects saferepr() is used first.

**Param√®tres :**

- `obj`

##### _should_repr_global_name

**Param√®tres :**

- `obj`

##### _format_boolop

**Param√®tres :**

- `explanations`
- `is_or`

##### _call_reprcompare

**Param√®tres :**

- `ops`
- `results`
- `expls`
- `each_obj`

##### _call_assertion_pass

**Param√®tres :**

- `lineno`
- `orig`
- `expl`

##### _check_if_assertion_pass_impl

Check if any plugins implement the pytest_assertion_pass hook
in order not to generate explanation unnecessarily (might be expensive).

##### traverse_node

Recursively yield node and all its children in depth-first order.

**Param√®tres :**

- `node`

##### _get_assertion_exprs

Return a mapping from {lineno: "assertion test expression"}.

**Param√®tres :**

- `src`

##### try_makedirs

Attempt to create the given directory and sub-directories exist.

Returns True if successful or if it already exists.

**Param√®tres :**

- `cache_dir`

##### get_cache_dir

Return the cache directory to write .pyc files for the given .py file path.

**Param√®tres :**

- `file_path`

##### __init__

**Param√®tres :**

- `config`

##### set_session

**Param√®tres :**

- `session`

##### find_spec

**Param√®tres :**

- `name`
- `path`
- `target`

##### create_module

**Param√®tres :**

- `spec`

##### exec_module

**Param√®tres :**

- `module`

##### _early_rewrite_bailout

A fast way to get out of rewriting modules.

Profiling has shown that the call to PathFinder.find_spec (inside of
the find_spec from this class) is a major slowdown, so, this method
tries to filter what we're sure won't be rewritten before getting to
it.

**Param√®tres :**

- `name`
- `state`

##### _should_rewrite

**Param√®tres :**

- `name`
- `fn`
- `state`

##### _is_marked_for_rewrite

**Param√®tres :**

- `name`
- `state`

##### mark_rewrite

Mark import names as needing to be rewritten.

The named module or package as well as any nested modules will
be rewritten on import.

##### _warn_already_imported

**Param√®tres :**

- `name`

##### get_data

Optional PEP302 get_data API.

**Param√®tres :**

- `pathname`

##### _write_and_reset

##### __init__

**Param√®tres :**

- `module_path`
- `config`
- `source`

##### run

Find all assert statements in *mod* and rewrite them.

**Param√®tres :**

- `mod`

##### is_rewrite_disabled

**Param√®tres :**

- `docstring`

##### variable

Get a new variable.

##### assign

Give *expr* a name.

**Param√®tres :**

- `expr`

##### display

Call saferepr on the expression.

**Param√®tres :**

- `expr`

##### helper

Call a helper in this module.

**Param√®tres :**

- `name`

##### builtin

Return the builtin called *name*.

**Param√®tres :**

- `name`

##### explanation_param

Return a new named %-formatting placeholder for expr.

This creates a %-formatting placeholder for expr in the
current formatting context, e.g. ``%(py0)s``.  The placeholder
and expr are placed in the current format context so that it
can be used on the next call to .pop_format_context().

**Param√®tres :**

- `expr`

##### push_format_context

Create a new formatting context.

The format context is used for when an explanation wants to
have a variable value formatted in the assertion message.  In
this case the value required can be added using
.explanation_param().  Finally .pop_format_context() is used
to format a string of %-formatted values as added by
.explanation_param().

##### pop_format_context

Format the %-formatted string with current format context.

The expl_expr should be an str ast.expr instance constructed from
the %-placeholders created by .explanation_param().  This will
add the required code to format said string to .expl_stmts and
return the ast.Name instance of the formatted string.

**Param√®tres :**

- `expl_expr`

##### generic_visit

Handle expressions we don't have custom code for.

**Param√®tres :**

- `node`

##### visit_Assert

Return the AST statements to replace the ast.Assert instance.

This rewrites the test of an assertion to provide
intermediate values and replace it with an if statement which
raises an assertion error with a detailed explanation in case
the expression is false.

**Param√®tres :**

- `assert_`

##### visit_NamedExpr

**Param√®tres :**

- `name`

##### visit_Name

**Param√®tres :**

- `name`

##### visit_BoolOp

**Param√®tres :**

- `boolop`

##### visit_UnaryOp

**Param√®tres :**

- `unary`

##### visit_BinOp

**Param√®tres :**

- `binop`

##### visit_Call

**Param√®tres :**

- `call`

##### visit_Starred

**Param√®tres :**

- `starred`

##### visit_Attribute

**Param√®tres :**

- `attr`

##### visit_Compare

**Param√®tres :**

- `comp`

##### get_resource_reader

**Param√®tres :**

- `name`

---

### truncate

Utilities for truncating assertion output.

Current default behaviour is to truncate assertion explanations at
terminal lines, unless running with an assertions verbosity level of at least 2 or running on CI.

#### Fonctions

##### truncate_if_required

Truncate this assertion explanation if the given test item is eligible.

**Param√®tres :**

- `explanation`
- `item`

##### _get_truncation_parameters

Return the truncation parameters related to the given item, as (should truncate, max lines, max chars).

**Param√®tres :**

- `item`

##### _truncate_explanation

Truncate given list of strings that makes up the assertion explanation.

Truncates to either max_lines, or max_chars - whichever the input reaches
first, taking the truncation explanation into account. The remaining lines
will be replaced by a usage message.

**Param√®tres :**

- `input_lines`
- `max_lines`
- `max_chars`

##### _truncate_by_char_count

**Param√®tres :**

- `input_lines`
- `max_chars`

---

### .!35016!util

---

### util

Utilities for assertion debugging.

#### Classes

##### _HighlightFunc

**M√©thodes :**

- `__call__()`

#### Fonctions

##### dummy_highlighter

Dummy highlighter that returns the text unprocessed.

Needed for _notin_text, as the diff gets post-processed to only show the "+" part.

**Param√®tres :**

- `source`
- `lexer`

##### format_explanation

Format an explanation.

Normally all embedded newlines are escaped, however there are
three exceptions: \n{, \n} and \n~.  The first two are intended
cover nested explanations, see function and attribute explanations
for examples (.visit_Call(), visit_Attribute()).  The last one is
for when one explanation needs to span multiple lines, e.g. when
displaying diffs.

**Param√®tres :**

- `explanation`

##### _split_explanation

Return a list of individual lines in the explanation.

This will return a list of lines split on '\n{', '\n}' and '\n~'.
Any other newlines will be escaped and appear in the line as the
literal '\n' characters.

**Param√®tres :**

- `explanation`

##### _format_lines

Format the individual lines.

This will replace the '{', '}' and '~' characters of our mini formatting
language with the proper 'where ...', 'and ...' and ' + ...' text, taking
care of indentation along the way.

Return a list of formatted lines.

**Param√®tres :**

- `lines`

##### issequence

**Param√®tres :**

- `x`

##### istext

**Param√®tres :**

- `x`

##### isdict

**Param√®tres :**

- `x`

##### isset

**Param√®tres :**

- `x`

##### isnamedtuple

**Param√®tres :**

- `obj`

##### isdatacls

**Param√®tres :**

- `obj`

##### isattrs

**Param√®tres :**

- `obj`

##### isiterable

**Param√®tres :**

- `obj`

##### has_default_eq

Check if an instance of an object contains the default eq

First, we check if the object's __eq__ attribute has __code__,
if so, we check the equally of the method code filename (__code__.co_filename)
to the default one generated by the dataclass and attr module
for dataclasses the default co_filename is <string>, for attrs class, the __eq__ should contain "attrs eq generated"

**Param√®tres :**

- `obj`

##### assertrepr_compare

Return specialised explanations for some operators/operands.

**Param√®tres :**

- `config`
- `op`
- `left`
- `right`
- `use_ascii`

##### _compare_eq_any

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _diff_text

Return the explanation for the diff between text.

Unless --verbose is used this will skip leading and trailing
characters which are identical to keep the diff minimal.

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_eq_iterable

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_eq_sequence

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_eq_set

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_gt_set

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_lt_set

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_gte_set

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_lte_set

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _set_one_sided_diff

**Param√®tres :**

- `posn`
- `set1`
- `set2`
- `highlighter`

##### _compare_eq_dict

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _compare_eq_cls

**Param√®tres :**

- `left`
- `right`
- `highlighter`
- `verbose`

##### _notin_text

**Param√®tres :**

- `term`
- `text`
- `verbose`

##### running_on_ci

Check if we're currently running on a CI system.

##### __call__

Apply highlighting to the given source.

**Param√®tres :**

- `source`
- `lexer`

---

### .!35005!__init__

---

### .!35008!rewrite

---

### .!35011!truncate

---

### argparsing

#### Classes

##### NotSet

**M√©thodes :**

- `__repr__()`

##### Parser

Parser for command line arguments and ini-file values.

:ivar extra_info: Dict of generic param -> value to display in case
    there's an error processing the command line arguments.

**M√©thodes :**

- `__init__()`
- `processoption()`
- `getgroup()`
- `addoption()`
- `parse()`
- `_getparser()`
- `parse_setoption()`
- `parse_known_args()`
- `parse_known_and_unknown_args()`
- `addini()`

##### ArgumentError

Raised if an Argument instance is created with invalid or
inconsistent arguments.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### Argument

Class that mimics the necessary behaviour of optparse.Option.

It's currently a least effort implementation and ignoring choices
and integer prefixes.

https://docs.python.org/3/library/optparse.html#optparse-standard-option-types

**M√©thodes :**

- `__init__()`
- `names()`
- `attrs()`
- `_set_opt_strings()`
- `__repr__()`

##### OptionGroup

A group of options shown in its own section.

**M√©thodes :**

- `__init__()`
- `addoption()`
- `_addoption()`
- `_addoption_instance()`

##### MyOptionParser

**M√©thodes :**

- `__init__()`
- `error()`
- `parse_args()`

##### DropShorterLongHelpFormatter

Shorten help for long options that differ only in extra hyphens.

- Collapse **long** options that are the same except for extra hyphens.
- Shortcut if there are only two options and one of them is a short one.
- Cache result on the action object as this is called at least 2 times.

**M√©thodes :**

- `__init__()`
- `_format_action_invocation()`
- `_split_lines()`

#### Fonctions

##### get_ini_default_for_type

Used by addini to get the default value for a given ini-option type, when
default is not supplied.

**Param√®tres :**

- `type`

##### __repr__

##### __init__

**Param√®tres :**

- `usage`
- `processopt`

##### processoption

**Param√®tres :**

- `option`

##### getgroup

Get (or create) a named option Group.

:param name: Name of the option group.
:param description: Long description for --help output.
:param after: Name of another group, used for ordering --help output.
:returns: The option group.

The returned group object has an ``addoption`` method with the same
signature as :func:`parser.addoption <pytest.Parser.addoption>` but
will be shown in the respective group in the output of
``pytest --help``.

**Param√®tres :**

- `name`
- `description`
- `after`

##### addoption

Register a command line option.

:param opts:
    Option names, can be short or long options.
:param attrs:
    Same attributes as the argparse library's :meth:`add_argument()
    <argparse.ArgumentParser.add_argument>` function accepts.

After command line parsing, options are available on the pytest config
object via ``config.option.NAME`` where ``NAME`` is usually set
by passing a ``dest`` attribute, for example
``addoption("--long", dest="NAME", ...)``.

##### parse

**Param√®tres :**

- `args`
- `namespace`

##### _getparser

##### parse_setoption

**Param√®tres :**

- `args`
- `option`
- `namespace`

##### parse_known_args

Parse the known arguments at this point.

:returns: An argparse namespace object.

**Param√®tres :**

- `args`
- `namespace`

##### parse_known_and_unknown_args

Parse the known arguments at this point, and also return the
remaining unknown arguments.

:returns:
    A tuple containing an argparse namespace object for the known
    arguments, and a list of the unknown arguments.

**Param√®tres :**

- `args`
- `namespace`

##### addini

Register an ini-file option.

:param name:
    Name of the ini-variable.
:param type:
    Type of the variable. Can be:

        * ``string``: a string
        * ``bool``: a boolean
        * ``args``: a list of strings, separated as in a shell
        * ``linelist``: a list of strings, separated by line breaks
        * ``paths``: a list of :class:`pathlib.Path`, separated as in a shell
        * ``pathlist``: a list of ``py.path``, separated as in a shell
        * ``int``: an integer
        * ``float``: a floating-point number

        .. versionadded:: 8.4

            The ``float`` and ``int`` types.

    For ``paths`` and ``pathlist`` types, they are considered relative to the ini-file.
    In case the execution is happening without an ini-file defined,
    they will be considered relative to the current working directory (for example with ``--override-ini``).

    .. versionadded:: 7.0
        The ``paths`` variable type.

    .. versionadded:: 8.1
        Use the current working directory to resolve ``paths`` and ``pathlist`` in the absence of an ini-file.

    Defaults to ``string`` if ``None`` or not passed.
:param default:
    Default value if no ini-file option exists but is queried.

The value of ini-variables can be retrieved via a call to
:py:func:`config.getini(name) <pytest.Config.getini>`.

**Param√®tres :**

- `name`
- `help`
- `type`
- `default`

##### __init__

**Param√®tres :**

- `msg`
- `option`

##### __str__

##### __init__

Store params in private vars for use in add_argument.

##### names

##### attrs

##### _set_opt_strings

Directly from optparse.

Might not be necessary as this is passed to argparse later on.

**Param√®tres :**

- `opts`

##### __repr__

##### __init__

**Param√®tres :**

- `name`
- `description`
- `parser`

##### addoption

Add an option to this group.

If a shortened version of a long option is specified, it will
be suppressed in the help. ``addoption('--twowords', '--two-words')``
results in help showing ``--two-words`` only, but ``--twowords`` gets
accepted **and** the automatic destination is in ``args.twowords``.

:param opts:
    Option names, can be short or long options.
:param attrs:
    Same attributes as the argparse library's :meth:`add_argument()
    <argparse.ArgumentParser.add_argument>` function accepts.

##### _addoption

##### _addoption_instance

**Param√®tres :**

- `option`
- `shortupper`

##### __init__

**Param√®tres :**

- `parser`
- `extra_info`
- `prog`

##### error

Transform argparse error message into UsageError.

**Param√®tres :**

- `message`

##### parse_args

Allow splitting of positional arguments.

**Param√®tres :**

- `args`
- `namespace`

##### __init__

##### _format_action_invocation

**Param√®tres :**

- `action`

##### _split_lines

Wrap lines after splitting on original newlines.

This allows to have explicit line breaks in the help text.

**Param√®tres :**

- `text`
- `width`

---

### compat

#### Classes

##### PathAwareHookProxy

this helper wraps around hook callers
until pluggy supports fixingcalls, this one will do

it currently doesn't return full hook caller proxies for fixed hooks,
this may have to be changed later depending on bugs

**M√©thodes :**

- `__init__()`
- `__dir__()`
- `__getattr__()`

#### Fonctions

##### _check_path

**Param√®tres :**

- `path`
- `fspath`

##### __init__

**Param√®tres :**

- `hook_relay`

##### __dir__

##### __getattr__

**Param√®tres :**

- `key`

##### fixed_hook

---

### exceptions

#### Classes

##### UsageError

Error in pytest usage or invocation.

##### PrintHelp

Raised when pytest should print its help to skip the rest of the
argument parsing and validation.

---

### findpaths

#### Fonctions

##### _parse_ini_config

Parse the given generic '.ini' file using legacy IniConfig parser, returning
the parsed object.

Raise UsageError if the file cannot be parsed.

**Param√®tres :**

- `path`

##### load_config_dict_from_file

Load pytest configuration from the given file path, if supported.

Return None if the file does not contain valid pytest configuration.

**Param√®tres :**

- `filepath`

##### locate_config

Search in the list of arguments for a valid ini-file for pytest,
and return a tuple of (rootdir, inifile, cfg-dict).

**Param√®tres :**

- `invocation_dir`
- `args`

##### get_common_ancestor

**Param√®tres :**

- `invocation_dir`
- `paths`

##### get_dirs_from_args

**Param√®tres :**

- `args`

##### determine_setup

Determine the rootdir, inifile and ini configuration values from the
command line arguments.

:param inifile:
    The `--inifile` command line argument, if given.
:param args:
    The free command line arguments.
:param rootdir_cmd_arg:
    The `--rootdir` command line argument, if given.
:param invocation_dir:
    The working directory when pytest was invoked.

##### is_fs_root

Return True if the given path is pointing to the root of the
file system ("/" on Unix and "C:\\" on Windows for example).

**Param√®tres :**

- `p`

##### is_option

**Param√®tres :**

- `x`

##### get_file_part_from_node_id

**Param√®tres :**

- `x`

##### get_dir_from_path

**Param√®tres :**

- `path`

##### make_scalar

**Param√®tres :**

- `v`

---

### .!35020!__init__

---

### .!35023!argparsing

---

### .!35026!compat

---

### .!35029!exceptions

---

### .!35031!findpaths

---

### expression

Evaluate match expressions, as used by `-k` and `-m`.

The grammar is:

expression: expr? EOF
expr:       and_expr ('or' and_expr)*
and_expr:   not_expr ('and' not_expr)*
not_expr:   'not' not_expr | '(' expr ')' | ident kwargs?

ident:      (\w|:|\+|-|\.|\[|\]|\\|/)+
kwargs:     ('(' name '=' value ( ', ' name '=' value )*  ')')
name:       a valid ident, but not a reserved keyword
value:      (unescaped) string literal | (-)?[0-9]+ | 'False' | 'True' | 'None'

The semantics are:

- Empty expression evaluates to False.
- ident evaluates to True or False according to a provided matcher function.
- or/and/not evaluate according to the usual boolean semantics.
- ident with parentheses and keyword arguments evaluates to True or False according to a provided matcher function.

#### Classes

##### TokenType

##### Token

##### ParseError

The expression contains invalid syntax.

:param column: The column in the line where the error occurred (1-based).
:param message: A description of the error.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### Scanner

**M√©thodes :**

- `__init__()`
- `lex()`
- `accept()`
- `accept()`
- `accept()`
- `reject()`

##### MatcherCall

**M√©thodes :**

- `__call__()`

##### MatcherNameAdapter

**M√©thodes :**

- `__bool__()`
- `__call__()`

##### MatcherAdapter

Adapts a matcher function to a locals mapping as required by eval().

**M√©thodes :**

- `__init__()`
- `__getitem__()`
- `__iter__()`
- `__len__()`

##### Expression

A compiled match expression as used by -k and -m.

The expression can be evaluated against different matchers.

**M√©thodes :**

- `__init__()`
- `compile()`
- `evaluate()`

#### Fonctions

##### expression

**Param√®tres :**

- `s`

##### expr

**Param√®tres :**

- `s`

##### and_expr

**Param√®tres :**

- `s`

##### not_expr

**Param√®tres :**

- `s`

##### single_kwarg

**Param√®tres :**

- `s`

##### all_kwargs

**Param√®tres :**

- `s`

##### __init__

**Param√®tres :**

- `column`
- `message`

##### __str__

##### __init__

**Param√®tres :**

- `input`

##### lex

**Param√®tres :**

- `input`

##### accept

**Param√®tres :**

- `type`

##### accept

**Param√®tres :**

- `type`

##### accept

**Param√®tres :**

- `type`

##### reject

**Param√®tres :**

- `expected`

##### __call__

##### __bool__

##### __call__

##### __init__

**Param√®tres :**

- `matcher`

##### __getitem__

**Param√®tres :**

- `key`

##### __iter__

##### __len__

##### __init__

**Param√®tres :**

- `code`

##### compile

Compile a match expression.

:param input: The input expression - one line.

**Param√®tres :**

- `cls`
- `input`

##### evaluate

Evaluate the match expression.

:param matcher:
    Given an identifier, should return whether it matches or not.
    Should be prepared to handle arbitrary strings as input.

:returns: Whether the expression matches or not.

**Param√®tres :**

- `matcher`

---

### structures

#### Classes

##### _HiddenParam

##### ParameterSet

A set of values for a set of parameters along with associated marks and
an optional ID for the set.

Examples::

    pytest.param(1, 2, 3)
    # ParameterSet(values=(1, 2, 3), marks=(), id=None)

    pytest.param("hello", id="greeting")
    # ParameterSet(values=("hello",), marks=(), id="greeting")

    # Parameter set with marks
    pytest.param(42, marks=pytest.mark.xfail)
    # ParameterSet(values=(42,), marks=(MarkDecorator(...),), id=None)

    # From parametrize mark (parameter names + list of parameter sets)
    pytest.mark.parametrize(
        ("a", "b", "expected"),
        [
            (1, 2, 3),
            pytest.param(40, 2, 42, id="everything"),
        ],
    )
    # ParameterSet(values=(1, 2, 3), marks=(), id=None)
    # ParameterSet(values=(2, 2, 3), marks=(), id="everything")

**M√©thodes :**

- `param()`
- `extract_from()`
- `_parse_parametrize_args()`
- `_parse_parametrize_parameters()`
- `_for_parametrize()`

##### Mark

A pytest mark.

**M√©thodes :**

- `__init__()`
- `_has_param_ids()`
- `combined_with()`

##### MarkDecorator

A decorator for applying a mark on test functions and classes.

``MarkDecorators`` are created with ``pytest.mark``::

    mark1 = pytest.mark.NAME  # Simple MarkDecorator
    mark2 = pytest.mark.NAME(name1=value)  # Parametrized MarkDecorator

and can then be applied as decorators to test functions::

    @mark2
    def test_function():
        pass

When a ``MarkDecorator`` is called, it does the following:

1. If called with a single class as its only positional argument and no
   additional keyword arguments, it attaches the mark to the class so it
   gets applied automatically to all test cases found in that class.

2. If called with a single function as its only positional argument and
   no additional keyword arguments, it attaches the mark to the function,
   containing all the arguments already stored internally in the
   ``MarkDecorator``.

3. When called in any other case, it returns a new ``MarkDecorator``
   instance with the original ``MarkDecorator``'s content updated with
   the arguments passed to this call.

Note: The rules above prevent a ``MarkDecorator`` from storing only a
single function or class reference as its positional argument with no
additional keyword or positional arguments. You can work around this by
using `with_args()`.

**M√©thodes :**

- `__init__()`
- `name()`
- `args()`
- `kwargs()`
- `markname()`
- `with_args()`
- `__call__()`
- `__call__()`
- `__call__()`

##### MarkGenerator

Factory for :class:`MarkDecorator` objects - exposed as
a ``pytest.mark`` singleton instance.

Example::

     import pytest


     @pytest.mark.slowtest
     def test_function():
         pass

applies a 'slowtest' :class:`Mark` on ``test_function``.

**M√©thodes :**

- `__init__()`
- `__getattr__()`

##### NodeKeywords

**M√©thodes :**

- `__init__()`
- `__getitem__()`
- `__setitem__()`
- `__contains__()`
- `update()`
- `__delitem__()`
- `__iter__()`
- `__len__()`
- `__repr__()`

##### _SkipMarkDecorator

**M√©thodes :**

- `__call__()`
- `__call__()`

##### _SkipifMarkDecorator

**M√©thodes :**

- `__call__()`

##### _XfailMarkDecorator

**M√©thodes :**

- `__call__()`
- `__call__()`

##### _ParametrizeMarkDecorator

**M√©thodes :**

- `__call__()`

##### _UsefixturesMarkDecorator

**M√©thodes :**

- `__call__()`

##### _FilterwarningsMarkDecorator

**M√©thodes :**

- `__call__()`

#### Fonctions

##### istestfunc

**Param√®tres :**

- `func`

##### get_empty_parameterset_mark

**Param√®tres :**

- `config`
- `argnames`
- `func`

##### get_unpacked_marks

Obtain the unpacked marks that are stored on an object.

If obj is a class and consider_mro is true, return marks applied to
this class and all of its super-classes in MRO order. If consider_mro
is false, only return marks applied directly to this class.

**Param√®tres :**

- `obj`

##### normalize_mark_list

Normalize an iterable of Mark or MarkDecorator objects into a list of marks
by retrieving the `mark` attribute on MarkDecorator instances.

:param mark_list: marks to normalize
:returns: A new list of the extracted Mark objects

**Param√®tres :**

- `mark_list`

##### store_mark

Store a Mark on an object.

This is used to implement the Mark declarations/decorators correctly.

**Param√®tres :**

- `obj`
- `mark`

##### param

**Param√®tres :**

- `cls`

##### extract_from

Extract from an object or objects.

:param parameterset:
    A legacy style parameterset that may or may not be a tuple,
    and may or may not be wrapped into a mess of mark objects.

:param force_tuple:
    Enforce tuple wrapping so single argument tuple values
    don't get decomposed and break tests.

**Param√®tres :**

- `cls`
- `parameterset`
- `force_tuple`

##### _parse_parametrize_args

**Param√®tres :**

- `argnames`
- `argvalues`

##### _parse_parametrize_parameters

**Param√®tres :**

- `argvalues`
- `force_tuple`

##### _for_parametrize

**Param√®tres :**

- `cls`
- `argnames`
- `argvalues`
- `func`
- `config`
- `nodeid`

##### __init__

:meta private:

**Param√®tres :**

- `name`
- `args`
- `kwargs`
- `param_ids_from`
- `param_ids_generated`

##### _has_param_ids

##### combined_with

Return a new Mark which is a combination of this
Mark and another Mark.

Combines by appending args and merging kwargs.

:param Mark other: The mark to combine with.
:rtype: Mark

**Param√®tres :**

- `other`

##### __init__

:meta private:

**Param√®tres :**

- `mark`

##### name

Alias for mark.name.

##### args

Alias for mark.args.

##### kwargs

Alias for mark.kwargs.

##### markname

:meta private:

##### with_args

Return a MarkDecorator with extra arguments added.

Unlike calling the MarkDecorator, with_args() can be used even
if the sole argument is a callable/class.

##### __call__

**Param√®tres :**

- `arg`

##### __call__

##### __call__

Call the MarkDecorator.

##### __init__

##### __getattr__

Generate a new :class:`MarkDecorator` with the given name.

**Param√®tres :**

- `name`

##### __init__

**Param√®tres :**

- `node`

##### __getitem__

**Param√®tres :**

- `key`

##### __setitem__

**Param√®tres :**

- `key`
- `value`

##### __contains__

**Param√®tres :**

- `key`

##### update

**Param√®tres :**

- `other`

##### __delitem__

**Param√®tres :**

- `key`

##### __iter__

##### __len__

##### __repr__

##### __call__

**Param√®tres :**

- `arg`

##### __call__

**Param√®tres :**

- `reason`

##### __call__

**Param√®tres :**

- `condition`

##### __call__

**Param√®tres :**

- `arg`

##### __call__

**Param√®tres :**

- `condition`

##### __call__

**Param√®tres :**

- `argnames`
- `argvalues`

##### __call__

##### __call__

---

### .!35035!__init__

---

### .!35037!expression

---

### .!35041!structures

---

### __main__

The pytest entry point.

---

### .!35045!__init__

---

### .!35048!__main__

---

### .!35050!__init__

---

### .!35052!_version

---

### .!35054!frontend_semver

---

### .!35059!settings

---

### .!35067!deck

---

### .!35082!view

---

### .!35061!__init__

---

### .!35063!base_map_provider

---

### .!35071!json_tools

---

### .!35073!layer

---

### .!35076!light_settings

---

### .!35079!map_styles

---

### .!35085!view_state

---

### .!35089!__init__

---

### .!35094!binary_transfer

---

### .!35096!color_scales

---

### .!35100!type_checking

---

### .!35103!viewport_helpers

---

### .!35106!__init__

---

### .!35109!exceptions

---

### .!35116!html

---

### .!35119!__init__

---

### .!35125!base

---

### .!35122!__init__

---

### .!35129!function

---

### .!35132!image

---

### .!35135!string

---

### .!35139!__init__

---

### .!35142!_frontend

---

### .!35144!debounce

---

### .!35147!widget

---

### .!35149!conftest

---

### .!35153!_typing

---

### .!35156!_version

---

### .!35159!__init__

---

### .!35161!_version_meson

---

### .!35165!testing

---

### .!35167!_constants

---

### .!35170!_optional

---

### .!35174!pyarrow

---

### .!35179!__init__

---

### .!35184!pickle_compat

---

### .!35187!compressors

---

### .!35192!__init__

---

### .!35196!function

---

### .!35254!api

---

### .!35278!base

---

### .!35258!common

---

### .!35199!accessor

---

### .!35203!nanops

---

### .!35207!roperator

---

### .!35211!missing

---

### .!35216!algorithms

---

### .!35220!resample

---

### .!35223!arraylike

---

### .!35227!construction

---

### .!35232!config_init

---

### .!35235!flags

---

### .!35239!generic

---

### .!35243!series

---

### .!35247!sorting

---

### .!35262!frame

---

### .!35267!shared_docs

---

### .!35270!sample

---

### .!35274!indexing

---

### .!35281!apply

---

### .!35285!__init__

---

### .!35290!utils

---

### .!35293!objects

---

### .!35297!tile

---

### .!35311!util

---

### .!35320!api

---

### .!35301!merge

---

### .!35305!encoding

---

### .!35308!concat

---

### .!35314!reshape

---

### .!35325!melt

---

### .!35329!pivot

---

### .!35343!base

---

### .!35333!accessor

---

### .!35336!object_array

---

### .!35339!__init__

---

### .!35347!timedeltas

---

### .!35350!datetimes

---

### .!35359!times

---

### .!35363!numeric

---

### .!35366!describe

---

### .!35375!selectn

---

### .!35379!to_dict

---

### .!35387!hashing

---

### .!35391!numba_

---

### .!35414!take

---

### .!35395!transforms

---

### .!35399!masked_accumulations

---

### .!35403!quantile

---

### .!35407!__init__

---

### .!35411!masked_reductions

---

### .!35419!datetimelike_accumulations

---

### .!35422!putmask

---

### .!35426!replace

---

### .!35430!from_dataframe

---

### .!35433!dataframe

---

### .!35442!dataframe_protocol

---

### .!35446!utils

---

### .!35449!buffer

---

### .!35454!column

---

### .!35462!cast

---

### .!35485!api

---

### .!35497!base

---

### .!35458!astype

---

### .!35465!missing

---

### .!35470!concat

---

### .!35474!generic

---

### .!35481!dtypes

---

### .!35489!common

---

### .!35492!inference

---

### .!35512!ops

---

### .!35531!base

---

### .!35500!categorical

---

### .!35504!generic

---

### .!35508!__init__

---

### .!35515!grouper

---

### .!35519!indexing

---

### .!35523!groupby

---

### .!35527!numba_

---

### .!35549!api

---

### .!35552!ops

---

### .!35561!base

---

### .!35535!concat

---

### .!35538!construction

---

### .!35542!__init__

---

### .!35546!array_manager

---

### .!35556!blocks

---

### .!35564!managers

---

### .!35595!api

---

### .!35599!ops

---

### .!35606!eval

---

### .!35614!expr

---

### .!35568!parsing

---

### .!35572!check

---

### .!35575!align

---

### .!35580!pytables

---

### .!35584!engines

---

### .!35587!expressions

---

### .!35602!common

---

### .!35609!scope

---

### .!35622!extensions

---

### .!35625!executor

---

### .!35628!sum_

---

### .!35647!var_

---

### .!35632!min_max_

---

### .!35634!__init__

---

### .!35639!mean_

---

### .!35642!shared

---

### .!35650!ewm

---

### .!35669!doc

---

### .!35653!online

---

### .!35658!__init__

---

### .!35662!rolling

---

### .!35665!common

---

### .!35672!numba_

---

### .!35676!expanding

---

### .!35744!base

---

### .!35680!floating

---

### .!35684!categorical

---

### .!35688!interval

---

### .!35691!_arrow_string_mixins

---

### .!35695!timedeltas

---

### .!35699!datetimes

---

### .!35703!string_

---

### .!35707!__init__

---

### .!35710!numpy_

---

### .!35713!_ranges

---

### .!35719!string_arrow

---

### .!35721!boolean

---

### .!35725!integer

---

### .!35729!masked

---

### .!35734!period

---

### .!35736!numeric

---

### .!35740!datetimelike

---

### .!35748!_mixins

---

### .!35752!_utils

---

### .!35756!accessors

---

### .!35760!_arrow_utils

---

### .!35764!__init__

---

### .!35767!extension_types

---

### .!35771!array

---

### .!35775!accessor

---

### .!35779!scipy_sparse

---

### .!35782!__init__

---

### .!35786!array

---

### .!35790!array_ops

---

### .!35795!missing

---

### .!35798!dispatch

---

### .!35802!invalid

---

### .!35807!__init__

---

### .!35810!docstrings

---

### .!35814!mask_ops

---

### .!35818!common

---

### .!35827!api

---

### .!35858!api

---

### .!35878!base

---

### .!35831!accessors

---

### .!35834!interval

---

### .!35839!timedeltas

---

### .!35842!range

---

### .!35847!datetimes

---

### .!35850!multi

---

### .!35862!period

---

### .!35866!frozen

---

### .!35871!extension

---

### .!35875!datetimelike

---

### .!35883!category

---

### .!35887!_test_decorators

---

### .!35890!_validators

---

### .!35895!_print_versions

---

### .!35898!__init__

---

### .!35903!_decorators

---

### .!35907!_doctools

---

### .!35910!_exceptions

---

### .!35914!_tester

---

### .!35918!__init__

---

### .!35923!orc

---

### .!35937!html

---

### .!35942!xml

---

### .!35953!api

---

### .!35967!sql

---

### .!35975!gbq

---

### .!35979!spss

---

### .!35926!feather_format

---

### .!35930!parquet

---

### .!35934!pytables

---

### .!35946!__init__

---

### .!35949!clipboards

---

### .!35956!common

---

### .!35960!_util

---

### .!35963!pickle

---

### .!35971!stata

---

### .!35983!readers

---

### .!35986!__init__

---

### .!35990!python_parser

---

### .!35994!base_parser

---

### .!35997!arrow_parser_wrapper

---

### .!36001!c_parser_wrapper

---

### .!36013!html

---

### .!36016!xml

---

### .!36034!css

---

### .!36043!csvs

---

### .!36050!info

---

### .!36004!console

---

### .!36009!style

---

### .!36020!__init__

---

### .!36023!format

---

### .!36027!excel

---

### .!36030!style_render

---

### .!36039!_color_data

---

### .!36046!string

---

### .!36054!printing

---

### .!36057!_openpyxl

---

### .!36061!_base

---

### .!36065!_calamine

---

### .!36069!_xlrd

---

### .!36073!__init__

---

### .!36077!_pyxlsb

---

### .!36080!_odswriter

---

### .!36084!_util

---

### .!36088!_odfreader

---

### .!36091!_xlsxwriter

---

### .!36096!_json

---

### .!36100!_normalize

---

### .!36103!_table_schema

---

### .!36108!__init__

---

### .!36111!sas7bdat

---

### .!36115!sas_constants

---

### .!36120!sasreader

---

### .!36124!__init__

---

### .!36127!sas_xport

---

### .!36132!__init__

---

### .!36140!api

---

### .!36135!__init__

---

### .!36144!offsets

---

### .!36148!frequencies

---

### .!36151!holiday

---

### .!36155!test_optional_dependency

---

### .!36158!test_expressions

---

### .!36163!test_register_accessor

---

### .!36166!test_common

---

### .!36170!test_downstream

---

### .!36174!test_errors

---

### .!36177!test_sorting

---

### .!36181!test_aggregation

---

### .!36190!test_nanops

---

### .!36193!test_take

---

### .!36197!test_algos

---

### .!36201!test_multilevel

---

### .!36205!test_flags

---

### .!36209!test_logical_ops

---

### .!36213!test_reductions

---

### .!36217!test_constructors

---

### .!36220!test_missing

---

### .!36225!test_unary

---

### .!36229!test_cumulative

---

### .!36237!test_subclass

---

### .!36240!test_formats

---

### .!36246!test_ufunc

---

### .!36249!test_iteration

---

### .!36253!test_validate

---

### .!36256!test_npfuncs

---

### .!36261!test_api

---

### .!36265!test_arithmetic

---

### .!36269!test_autocorr

---

### .!36273!test_value_counts

---

### .!36276!test_combine

---

### .!36280!test_convert_dtypes

---

### .!36285!test_cov_corr

---

### .!36289!test_repeat

---

### .!36293!test_searchsorted

---

### .!36296!test_add_prefix_suffix

---

### .!36301!test_round

---

### .!36304!test_combine_first

---

### .!36308!test_infer_objects

---

### .!36312!test_sort_values

---

### .!36316!test_to_frame

---

### .!36320!test_nunique

---

### .!36323!test_argsort

---

### .!36326!test_reset_index

---

### .!36330!test_describe

---

### .!36333!test_size

---

### .!36337!test_reindex_like

---

### .!36341!test_copy

---

### .!36345!test_set_name

---

### .!36348!test_truncate

---

### .!36352!test_drop_duplicates

---

### .!36356!__init__

---

### .!36359!test_head_tail

---

### .!36363!test_unstack

---

### .!36368!test_count

---

### .!36371!test_quantile

---

### .!36375!test_between

---

### .!36379!test_equals

---

### .!36382!test_nlargest

---

### .!36386!test_tz_localize

---

### .!36390!test_update

---

### .!36394!test_diff

---

### .!36396!test_astype

---

### .!36401!test_dropna

---

### .!36405!test_explode

---

### .!36408!test_matmul

---

### .!36414!test_values

---

### .!36416!test_view

---

### .!36421!test_duplicated

---

### .!36425!test_case_when

---

### .!36429!test_align

---

### .!36434!test_pop

---

### .!36437!test_pct_change

---

### .!36441!test_tolist

---

### .!36445!test_isin

---

### .!36448!test_rename

---

### .!36453!test_fillna

---

### .!36457!test_sort_index

---

### .!36461!test_map

---

### .!36463!test_drop

---

### .!36468!test_is_unique

---

### .!36471!test_item

---

### .!36474!test_is_monotonic

---

### .!36478!test_asof

---

### .!36482!test_get_numeric_data

---

### .!36486!test_compare

---

### .!36490!test_to_dict

---

### .!36494!test_rename_axis

---

### .!36498!test_rank

---

### .!36501!test_replace

---

### .!36505!test_unique

---

### .!36510!test_clip

---

### .!36513!test_info

---

### .!36519!test_dtypes

---

### .!36523!test_isna

---

### .!36527!test_to_numpy

---

### .!36530!test_interpolate

---

### .!36536!test_reindex

---

### .!36538!test_to_csv

---

### .!36543!test_dt_accessor

---

### .!36546!test_str_accessor

---

### .!36555!test_list_accessor

---

### .!36558!test_cat_accessor

---

### .!36562!test_sparse_accessor

---

### .!36566!test_struct_accessor

---

### .!36571!test_set_value

---

### .!36575!test_mask

---

### .!36578!test_xs

---

### .!36582!test_getitem

---

### .!36586!test_setitem

---

### .!36595!test_indexing

---

### .!36600!test_take

---

### .!36603!test_datetime

---

### .!36607!test_get

---

### .!36611!test_where

---

### .!36614!test_delitem

---

### .!36618!test_pivot_multilevel

---

### .!36622!test_cut

---

### .!36626!test_get_dummies

---

### .!36631!test_union_categoricals

---

### .!36634!test_qcut

---

### .!36642!test_pivot

---

### .!36646!test_util

---

### .!36650!test_melt

---

### .!36654!test_from_dummies

---

### .!36657!test_crosstab

---

### .!36661!conftest

---

### .!36666!test_categorical

---

### .!36669!test_append

---

### .!36678!test_invalid

---

### .!36683!test_sort

---

### .!36685!test_concat

---

### .!36690!test_index

---

### .!36694!test_empty

---

### .!36698!test_datetimes

---

### .!36704!test_series

---

### .!36709!test_append_common

---

### .!36712!test_dataframe

---

### .!36716!test_merge_index_as_string

---

### .!36720!test_merge_asof

---

### .!36724!test_join

---

### .!36732!test_merge

---

### .!36736!test_merge_cross

---

### .!36740!test_multi

---

### .!36743!test_merge_ordered

---

### .!36748!test_invalid_arg

---

### .!36756!test_series_transform

---

### .!36759!test_str

---

### .!36763!test_series_apply

---

### .!36767!common

---

### .!36771!test_series_apply_relabeling

---

### .!36775!test_numba

---

### .!36779!test_frame_apply

---

### .!36782!test_frame_apply_relabeling

---

### .!36787!test_frame_transform

---

### .!36791!test_cat

---

### .!36795!test_string_array

---

### .!36798!test_split_partition

---

### .!36803!conftest

---

### .!36806!test_get_dummies

---

### .!36810!test_find_replace

---

### .!36814!__init__

---

### .!36817!test_case_justify

---

### .!36821!test_strings

---

### .!36825!test_api

---

### .!36829!test_extract

---

### .!36832!test_to_time

---

### .!36841!test_to_timedelta

---

### .!36844!test_to_datetime

---

### .!36847!test_to_numeric

---

### .!36851!test_period

---

### .!36855!test_masked

---

### .!36858!test_extension

---

### .!36862!conftest

---

### .!36865!test_common

---

### .!36868!test_sparse

---

### .!36873!test_string

---

### .!36876!test_categorical

---

### .!36886!test_interval

---

### .!36888!test_numpy

---

### .!36893!test_datetime

---

### .!36897!test_arrow

---

### .!36901!test_decimal

---

### .!36906!__init__

---

### .!36909!array

---

### .!36913!test_array_with_attr

---

### .!36917!__init__

---

### .!36920!array

---

### .!36924!__init__

---

### .!36929!array

---

### .!36933!__init__

---

### .!36936!test_json

---

### .!36940!array

---

### .!36945!test_list

---

### .!36948!__init__

---

### .!36952!array

---

### .!36983!io

---

### .!37001!ops

---

### .!37006!dim2

---

### .!37018!base

---

### .!36956!missing

---

### .!36958!reshaping

---

### .!36963!index

---

### .!36966!methods

---

### .!36971!reduce

---

### .!36974!setitem

---

### .!36978!dtype

---

### .!36987!accumulate

---

### .!36990!interface

---

### .!36994!__init__

---

### .!36997!getitem

---

### .!37011!casting

---

### .!37014!groupby

---

### .!37021!constructors

---

### .!37026!printing

---

### .!37030!conftest

---

### .!37034!test_resampler_grouper

---

### .!37041!test_timedelta

---

### .!37044!test_base

---

### .!37049!test_period_index

---

### .!37053!test_datetime_index

---

### .!37057!test_time_grouper

---

### .!37060!test_resample_api

---

### .!37064!test_deprecate_nonkeyword_arguments

---

### .!37066!test_validate_args_and_kwargs

---

### .!37070!test_assert_series_equal

---

### .!37074!conftest

---

### .!37078!test_assert_frame_equal

---

### .!37082!test_show_versions

---

### .!37087!test_assert_interval_array_equal

---

### .!37096!test_assert_attr_equal

---

### .!37100!test_util

---

### .!37104!test_assert_index_equal

---

### .!37106!test_hashing

---

### .!37108!test_shares_memory

---

### .!37111!test_validate_args

---

### .!37115!test_validate_kwargs

---

### .!37120!test_assert_categorical_equal

---

### .!37124!test_assert_numpy_array_equal

---

### .!37127!test_assert_extension_array_equal

---

### .!37131!test_deprecate

---

### .!37135!test_numba

---

### .!37138!test_validate_inclusive

---

### .!37142!test_assert_produces_warning

---

### .!37145!test_doc

---

### .!37149!test_deprecate_kwarg

---

### .!37154!test_assert_almost_equal

---

### .!37158!test_rewrite_warning

---

### .!37162!test_localization

---

### .!37169!test_config

---

### .!37173!test_parquet

---

### .!37176!test_fsspec

---

### .!37179!test_compression

---

### .!37183!conftest

---

### .!37188!test_common

---

### .!37190!test_pickle

---

### .!37195!test_orc

---

### .!37198!test_clipboard

---

### .!37207!test_stata

---

### .!37211!test_html

---

### compat

#### Classes

##### SessionWrapper

**M√©thodes :**

- `__init__()`
- `testsfailed()`
- `testsfailed()`

#### Fonctions

##### __init__

**Param√®tres :**

- `session`

##### testsfailed

##### testsfailed

**Param√®tres :**

- `value`

---

### embed

Activate coverage at python startup if appropriate.

The python site initialisation will ensure that anything we import
will be removed and not visible at the end of python startup.  However
we minimise all work by putting these init actions in this separate
module and only importing what is needed when needed.

For normal python startup when coverage should not be activated the pth
file checks a single env var and does not import or call the init fn
here.

For python startup when an ancestor process has set the env indicating
that code coverage is being collected we activate coverage based on
info passed via env vars.

#### Fonctions

##### init

##### _cleanup

**Param√®tres :**

- `cov`

##### cleanup

##### _signal_cleanup_handler

**Param√®tres :**

- `signum`
- `frame`

##### cleanup_on_signal

**Param√®tres :**

- `signum`

##### cleanup_on_sigterm

---

### engine

Coverage controllers for use by pytest-cov and nose-cov.

#### Classes

##### BrokenCovConfigError

##### _NullFile

**M√©thodes :**

- `write()`

##### CovController

Base class for different plugin implementations.

**M√©thodes :**

- `__init__()`
- `ensure_topdir()`
- `pause()`
- `resume()`
- `start()`
- `finish()`
- `set_env()`
- `unset_env()`
- `get_node_desc()`
- `get_width()`
- `sep()`
- `summary()`

##### Central

Implementation for centralised operation.

**M√©thodes :**

- `start()`
- `finish()`

##### DistMaster

Implementation for distributed master.

**M√©thodes :**

- `start()`
- `configure_node()`
- `testnodedown()`
- `finish()`

##### DistWorker

Implementation for distributed workers.

**M√©thodes :**

- `start()`
- `finish()`
- `summary()`

#### Fonctions

##### _backup

**Param√®tres :**

- `obj`
- `attr`

##### _ensure_topdir

**Param√®tres :**

- `meth`

##### _data_suffix

**Param√®tres :**

- `name`

##### write

**Param√®tres :**

- `v`

##### ensure_topdir_wrapper

##### __init__

Get some common config used by multiple derived classes.

**Param√®tres :**

- `options`
- `config`
- `nodeid`

##### ensure_topdir

##### pause

##### resume

##### start

##### finish

##### set_env

Put info about coverage into the env so that subprocesses can activate coverage.

##### unset_env

Remove coverage info from env.

##### get_node_desc

Return a description of this node.

**Param√®tres :**

- `platform`
- `version_info`

##### get_width

##### sep

**Param√®tres :**

- `stream`
- `s`
- `txt`

##### summary

Produce coverage reports.

**Param√®tres :**

- `stream`

##### start

##### finish

Stop coverage, save data to file and set the list of coverage objects to report on.

##### start

##### configure_node

Workers need to know if they are collocated and what files have moved.

**Param√®tres :**

- `node`

##### testnodedown

Collect data file name from worker.

**Param√®tres :**

- `node`
- `error`

##### finish

Combines coverage data and sets the list of coverage objects to report on.

##### start

##### finish

Stop coverage and send relevant info back to the master.

##### summary

Only the master reports so do nothing.

**Param√®tres :**

- `stream`

---

### plugin

Coverage plugin for pytest.

#### Classes

##### StoreReport

**M√©thodes :**

- `__call__()`

##### CovPlugin

Use coverage package to produce code coverage reports.

Delegates all work to a particular implementation based on whether
this test process is centralised, a distributed master or a
distributed worker.

**M√©thodes :**

- `__init__()`
- `start()`
- `_is_worker()`
- `pytest_sessionstart()`
- `pytest_configure_node()`
- `pytest_testnodedown()`
- `_should_report()`
- `pytest_runtestloop()`
- `write_heading()`
- `pytest_terminal_summary()`
- `pytest_runtest_setup()`
- `pytest_runtest_teardown()`
- `pytest_runtest_call()`

##### TestContextPlugin

**M√©thodes :**

- `__init__()`
- `pytest_runtest_setup()`
- `pytest_runtest_teardown()`
- `pytest_runtest_call()`
- `switch_context()`

##### Config

#### Fonctions

##### validate_report

**Param√®tres :**

- `arg`

##### validate_fail_under

**Param√®tres :**

- `num_str`

##### validate_context

**Param√®tres :**

- `arg`

##### pytest_addoption

Add options to control coverage.

**Param√®tres :**

- `parser`

##### _prepare_cov_source

Prepare cov_source so that:

 --cov --cov=foobar is equivalent to --cov (cov_source=None)
 --cov=foo --cov=bar is equivalent to cov_source=['foo', 'bar']

**Param√®tres :**

- `cov_source`

##### pytest_load_initial_conftests

**Param√®tres :**

- `early_config`
- `parser`
- `args`

##### no_cover

A pytest fixture to disable coverage.

##### cov

A pytest fixture to provide access to the underlying coverage object.

**Param√®tres :**

- `request`

##### pytest_configure

**Param√®tres :**

- `config`

##### __call__

**Param√®tres :**

- `parser`
- `namespace`
- `values`
- `option_string`

##### __init__

Creates a coverage pytest plugin.

We read the rc file that coverage uses to get the data file
name.  This is needed since we give coverage through it's API
the data file name.

**Param√®tres :**

- `options`
- `pluginmanager`
- `start`
- `no_cov_should_warn`

##### start

**Param√®tres :**

- `controller_cls`
- `config`
- `nodeid`

##### _is_worker

**Param√®tres :**

- `session`

##### pytest_sessionstart

At session start determine our implementation and delegate to it.

**Param√®tres :**

- `session`

##### pytest_configure_node

Delegate to our implementation.

Mark this hook as optional in case xdist is not installed.

**Param√®tres :**

- `node`

##### pytest_testnodedown

Delegate to our implementation.

Mark this hook as optional in case xdist is not installed.

**Param√®tres :**

- `node`
- `error`

##### _should_report

##### pytest_runtestloop

**Param√®tres :**

- `session`

##### write_heading

**Param√®tres :**

- `terminalreporter`

##### pytest_terminal_summary

**Param√®tres :**

- `terminalreporter`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### __init__

**Param√®tres :**

- `cov_controller`

##### pytest_runtest_setup

**Param√®tres :**

- `item`

##### pytest_runtest_teardown

**Param√®tres :**

- `item`

##### pytest_runtest_call

**Param√®tres :**

- `item`

##### switch_context

**Param√®tres :**

- `item`
- `when`

---

### _impl

#### Classes

##### _ThreadLocal

##### AsyncLibraryNotFoundError

#### Fonctions

##### current_async_library

Detect which async library is currently running.

The following libraries are currently supported:

================   ===========  ============================
Library             Requires     Magic string
================   ===========  ============================
**Trio**            Trio v0.6+   ``"trio"``
**Curio**           -            ``"curio"``
**asyncio**                      ``"asyncio"``
**Trio-asyncio**    v0.8.2+     ``"trio"`` or ``"asyncio"``,
                                depending on current mode
================   ===========  ============================

Returns:
  A string like ``"trio"``.

Raises:
  AsyncLibraryNotFoundError: if called from synchronous context,
    or if the current async library was not recognized.

Examples:

    .. code-block:: python3

       from sniffio import current_async_library

       async def generic_sleep(seconds):
           library = current_async_library()
           if library == "trio":
               import trio
               await trio.sleep(seconds)
           elif library == "asyncio":
               import asyncio
               await asyncio.sleep(seconds)
           # ... and so on ...
           else:
               raise RuntimeError(f"Unsupported library {library!r}")

---

### _version

---

### test_sniffio

#### Fonctions

##### test_basics_cvar

##### test_basics_tlocal

##### test_asyncio

##### test_curio

---

### from_thread

#### Classes

##### _BlockingAsyncContextManager

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

##### _BlockingPortalTaskStatus

**M√©thodes :**

- `__init__()`
- `started()`

##### BlockingPortal

An object that lets external threads run code in an asynchronous event loop.

**M√©thodes :**

- `__new__()`
- `__init__()`
- `_check_running()`
- `_spawn_task_from_thread()`
- `call()`
- `call()`
- `call()`
- `start_task_soon()`
- `start_task_soon()`
- `start_task_soon()`
- `start_task()`
- `wrap_async_context_manager()`

##### BlockingPortalProvider

A manager for a blocking portal. Used as a context manager. The first thread to
enter this context manager causes a blocking portal to be started with the specific
parameters, and the last thread to exit causes the portal to be shut down. Thus,
there will be exactly one blocking portal running in this context as long as at
least one thread has entered this context manager.

The parameters are the same as for :func:`~anyio.run`.

:param backend: name of the backend
:param backend_options: backend options

.. versionadded:: 4.4

**M√©thodes :**

- `__enter__()`
- `__exit__()`

#### Fonctions

##### run

Call a coroutine function from a worker thread.

:param func: a coroutine function
:param args: positional arguments for the callable
:return: the return value of the coroutine function

**Param√®tres :**

- `func`

##### run_sync

Call a function in the event loop thread from a worker thread.

:param func: a callable
:param args: positional arguments for the callable
:return: the return value of the callable

**Param√®tres :**

- `func`

##### start_blocking_portal

Start a new event loop in a new thread and run a blocking portal in its main task.

The parameters are the same as for :func:`~anyio.run`.

:param backend: name of the backend
:param backend_options: backend options
:return: a context manager that yields a blocking portal

.. versionchanged:: 3.0
    Usage as a context manager is now required.

**Param√®tres :**

- `backend`
- `backend_options`

##### check_cancelled

Check if the cancel scope of the host task's running the current worker thread has
been cancelled.

If the host task's current cancel scope has indeed been cancelled, the
backend-specific cancellation exception will be raised.

:raises RuntimeError: if the current thread was not spawned by
    :func:`.to_thread.run_sync`

##### __init__

**Param√®tres :**

- `async_cm`
- `portal`

##### __enter__

##### __exit__

**Param√®tres :**

- `__exc_type`
- `__exc_value`
- `__traceback`

##### __init__

**Param√®tres :**

- `future`

##### started

**Param√®tres :**

- `value`

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### _check_running

##### _spawn_task_from_thread

Spawn a new task using the given callable.

Implementers must ensure that the future is resolved when the task finishes.

:param func: a callable
:param args: positional arguments to be passed to the callable
:param kwargs: keyword arguments to be passed to the callable
:param name: name of the task (will be coerced to a string if not ``None``)
:param future: a future that will resolve to the return value of the callable,
    or the exception raised during its execution

**Param√®tres :**

- `func`
- `args`
- `kwargs`
- `name`
- `future`

##### call

**Param√®tres :**

- `func`

##### call

**Param√®tres :**

- `func`

##### call

Call the given function in the event loop thread.

If the callable returns a coroutine object, it is awaited on.

:param func: any callable
:raises RuntimeError: if the portal is not running or if this method is called
    from within the event loop thread

**Param√®tres :**

- `func`

##### start_task_soon

**Param√®tres :**

- `func`

##### start_task_soon

**Param√®tres :**

- `func`

##### start_task_soon

Start a task in the portal's task group.

The task will be run inside a cancel scope which can be cancelled by cancelling
the returned future.

:param func: the target function
:param args: positional arguments passed to ``func``
:param name: name of the task (will be coerced to a string if not ``None``)
:return: a future that resolves with the return value of the callable if the
    task completes successfully, or with the exception raised in the task
:raises RuntimeError: if the portal is not running or if this method is called
    from within the event loop thread
:rtype: concurrent.futures.Future[T_Retval]

.. versionadded:: 3.0

**Param√®tres :**

- `func`

##### start_task

Start a task in the portal's task group and wait until it signals for readiness.

This method works the same way as :meth:`.abc.TaskGroup.start`.

:param func: the target function
:param args: positional arguments passed to ``func``
:param name: name of the task (will be coerced to a string if not ``None``)
:return: a tuple of (future, task_status_value) where the ``task_status_value``
    is the value passed to ``task_status.started()`` from within the target
    function
:rtype: tuple[concurrent.futures.Future[T_Retval], Any]

.. versionadded:: 3.0

**Param√®tres :**

- `func`

##### wrap_async_context_manager

Wrap an async context manager as a synchronous context manager via this portal.

Spawns a task that will call both ``__aenter__()`` and ``__aexit__()``, stopping
in the middle until the synchronous context manager exits.

:param cm: an asynchronous context manager
:return: a synchronous context manager

.. versionadded:: 2.1

**Param√®tres :**

- `cm`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### run_blocking_portal

##### callback

**Param√®tres :**

- `f`

##### task_done

**Param√®tres :**

- `future`

---

### lowlevel

#### Classes

##### _TokenWrapper

##### _NoValueSet

##### RunvarToken

**M√©thodes :**

- `__init__()`

##### RunVar

Like a :class:`~contextvars.ContextVar`, except scoped to the running event loop.

**M√©thodes :**

- `__init__()`
- `_current_vars()`
- `get()`
- `get()`
- `get()`
- `set()`
- `reset()`
- `__repr__()`

#### Fonctions

##### current_token

Return a backend specific token object that can be used to get back to the event
loop.

##### __init__

**Param√®tres :**

- `var`
- `value`

##### __init__

**Param√®tres :**

- `name`
- `default`

##### _current_vars

##### get

**Param√®tres :**

- `default`

##### get

##### get

**Param√®tres :**

- `default`

##### set

**Param√®tres :**

- `value`

##### reset

**Param√®tres :**

- `token`

##### __repr__

---

### pytest_plugin

#### Classes

##### FreePortFactory

Manages port generation based on specified socket kind, ensuring no duplicate
ports are generated.

This class provides functionality for generating available free ports on the
system. It is initialized with a specific socket kind and can generate ports
for given address families while avoiding reuse of previously generated ports.

Users should not instantiate this class directly, but use the
``free_tcp_port_factory`` and ``free_udp_port_factory`` fixtures instead. For simple
uses cases, ``free_tcp_port`` and ``free_udp_port`` can be used instead.

**M√©thodes :**

- `__init__()`
- `kind()`
- `__call__()`

#### Fonctions

##### extract_backend_and_options

**Param√®tres :**

- `backend`

##### get_runner

**Param√®tres :**

- `backend_name`
- `backend_options`

##### pytest_configure

**Param√®tres :**

- `config`

##### pytest_fixture_setup

**Param√®tres :**

- `fixturedef`
- `request`

##### pytest_pycollect_makeitem

**Param√®tres :**

- `collector`
- `name`
- `obj`

##### pytest_pyfunc_call

**Param√®tres :**

- `pyfuncitem`

##### anyio_backend

**Param√®tres :**

- `request`

##### anyio_backend_name

**Param√®tres :**

- `anyio_backend`

##### anyio_backend_options

**Param√®tres :**

- `anyio_backend`

##### free_tcp_port_factory

##### free_udp_port_factory

##### free_tcp_port

**Param√®tres :**

- `free_tcp_port_factory`

##### free_udp_port

**Param√®tres :**

- `free_udp_port_factory`

##### wrapper

##### run_with_hypothesis

##### __init__

**Param√®tres :**

- `kind`

##### kind

The type of socket connection (e.g., :data:`~socket.SOCK_STREAM` or
:data:`~socket.SOCK_DGRAM`) used to bind for checking port availability

##### __call__

Return an unbound port for the given address family.

:param family: if omitted, both IPv4 and IPv6 addresses will be tried
:return: a port number

**Param√®tres :**

- `family`

---

### to_interpreter

#### Classes

##### Worker

**M√©thodes :**

- `initialize()`
- `destroy()`
- `_call()`

#### Fonctions

##### _stop_workers

**Param√®tres :**

- `workers`

##### current_default_interpreter_limiter

Return the capacity limiter that is used by default to limit the number of
concurrently running subinterpreters.

Defaults to the number of CPU cores.

:return: a capacity limiter object

##### initialize

##### destroy

##### _call

**Param√®tres :**

- `func`
- `args`

---

### to_process

#### Fonctions

##### current_default_process_limiter

Return the capacity limiter that is used by default to limit the number of worker
processes.

:return: a capacity limiter object

##### process_worker

---

### to_thread

#### Fonctions

##### current_default_thread_limiter

Return the capacity limiter that is used by default to limit the number of
concurrent threads.

:return: a capacity limiter object

---

### _asyncio

#### Classes

##### CancelScope

**M√©thodes :**

- `__new__()`
- `__init__()`
- `__enter__()`
- `__exit__()`
- `_effectively_cancelled()`
- `_parent_cancellation_is_visible_to_us()`
- `_timeout()`
- `_deliver_cancellation()`
- `_restart_cancellation_in_parent()`
- `cancel()`
- `deadline()`
- `deadline()`
- `cancel_called()`
- `cancelled_caught()`
- `shield()`
- `shield()`

##### TaskState

Encapsulates auxiliary task information that cannot be added to the Task instance
itself because there are no guarantees about its implementation.

**M√©thodes :**

- `__init__()`

##### _AsyncioTaskStatus

**M√©thodes :**

- `__init__()`
- `started()`

##### TaskGroup

**M√©thodes :**

- `__init__()`
- `_spawn()`
- `start_soon()`

##### WorkerThread

**M√©thodes :**

- `__init__()`
- `_report_result()`
- `run()`
- `stop()`

##### BlockingPortal

**M√©thodes :**

- `__new__()`
- `__init__()`
- `_spawn_task_from_thread()`

##### StreamReaderWrapper

##### StreamWriterWrapper

##### Process

**M√©thodes :**

- `terminate()`
- `kill()`
- `send_signal()`
- `pid()`
- `returncode()`
- `stdin()`
- `stdout()`
- `stderr()`

##### StreamProtocol

**M√©thodes :**

- `connection_made()`
- `connection_lost()`
- `data_received()`
- `eof_received()`
- `pause_writing()`
- `resume_writing()`

##### DatagramProtocol

**M√©thodes :**

- `connection_made()`
- `connection_lost()`
- `datagram_received()`
- `error_received()`
- `pause_writing()`
- `resume_writing()`

##### SocketStream

**M√©thodes :**

- `__init__()`
- `_raw_socket()`

##### _RawSocketMixin

**M√©thodes :**

- `__init__()`
- `_raw_socket()`
- `_wait_until_readable()`
- `_wait_until_writable()`

##### UNIXSocketStream

##### TCPSocketListener

**M√©thodes :**

- `__init__()`
- `_raw_socket()`

##### UNIXSocketListener

**M√©thodes :**

- `__init__()`
- `_raw_socket()`

##### UDPSocket

**M√©thodes :**

- `__init__()`
- `_raw_socket()`

##### ConnectedUDPSocket

**M√©thodes :**

- `__init__()`
- `_raw_socket()`

##### UNIXDatagramSocket

##### ConnectedUNIXDatagramSocket

##### Event

**M√©thodes :**

- `__new__()`
- `__init__()`
- `set()`
- `is_set()`
- `statistics()`

##### Lock

**M√©thodes :**

- `__new__()`
- `__init__()`
- `acquire_nowait()`
- `locked()`
- `release()`
- `statistics()`

##### Semaphore

**M√©thodes :**

- `__new__()`
- `__init__()`
- `acquire_nowait()`
- `release()`
- `value()`
- `max_value()`
- `statistics()`

##### CapacityLimiter

**M√©thodes :**

- `__new__()`
- `__init__()`
- `total_tokens()`
- `total_tokens()`
- `borrowed_tokens()`
- `available_tokens()`
- `acquire_nowait()`
- `acquire_on_behalf_of_nowait()`
- `release()`
- `release_on_behalf_of()`
- `statistics()`

##### _SignalReceiver

**M√©thodes :**

- `__init__()`
- `_deliver()`
- `__enter__()`
- `__exit__()`
- `__aiter__()`

##### AsyncIOTaskInfo

**M√©thodes :**

- `__init__()`
- `has_pending_cancellation()`

##### TestRunner

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `get_loop()`
- `_exception_handler()`
- `_raise_async_exceptions()`
- `run_asyncgen_fixture()`
- `run_fixture()`
- `run_test()`

##### AsyncIOBackend

**M√©thodes :**

- `run()`
- `current_token()`
- `current_time()`
- `cancelled_exception_class()`
- `create_cancel_scope()`
- `current_effective_deadline()`
- `create_task_group()`
- `create_event()`
- `create_lock()`
- `create_semaphore()`
- `create_capacity_limiter()`
- `check_cancelled()`
- `run_async_from_thread()`
- `run_sync_from_thread()`
- `create_blocking_portal()`
- `setup_process_pool_exit_at_shutdown()`
- `create_tcp_listener()`
- `create_unix_listener()`
- `current_default_thread_limiter()`
- `open_signal_receiver()`
- `get_current_task()`
- `get_running_tasks()`
- `create_test_runner()`

##### _State

##### Runner

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `close()`
- `get_loop()`
- `run()`
- `_lazy_init()`
- `_on_sigint()`

#### Fonctions

##### find_root_task

##### get_callable_name

**Param√®tres :**

- `func`

##### _task_started

Return ``True`` if the task has been started and has not finished.

**Param√®tres :**

- `task`

##### is_anyio_cancellation

**Param√®tres :**

- `exc`

##### _forcibly_shutdown_process_pool_on_exit

Forcibly shuts down worker processes belonging to this event loop.

**Param√®tres :**

- `workers`
- `_task`

##### _cancel_all_tasks

**Param√®tres :**

- `loop`

##### __new__

**Param√®tres :**

- `cls`

##### __init__

**Param√®tres :**

- `deadline`
- `shield`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### _effectively_cancelled

##### _parent_cancellation_is_visible_to_us

##### _timeout

##### _deliver_cancellation

Deliver cancellation to directly contained tasks and nested cancel scopes.

Schedule another run at the end if we still have tasks eligible for
cancellation.

:param origin: the cancel scope that originated the cancellation
:return: ``True`` if the delivery needs to be retried on the next cycle

**Param√®tres :**

- `origin`

##### _restart_cancellation_in_parent

Restart the cancellation effort in the closest directly cancelled parent scope.

##### cancel

##### deadline

##### deadline

**Param√®tres :**

- `value`

##### cancel_called

##### cancelled_caught

##### shield

##### shield

**Param√®tres :**

- `value`

##### __init__

**Param√®tres :**

- `parent_id`
- `cancel_scope`

##### __init__

**Param√®tres :**

- `future`
- `parent_id`

##### started

**Param√®tres :**

- `value`

##### __init__

##### _spawn

**Param√®tres :**

- `func`
- `args`
- `name`
- `task_status_future`

##### start_soon

**Param√®tres :**

- `func`

##### __init__

**Param√®tres :**

- `root_task`
- `workers`
- `idle_workers`

##### _report_result

**Param√®tres :**

- `future`
- `result`
- `exc`

##### run

##### stop

**Param√®tres :**

- `f`

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### _spawn_task_from_thread

**Param√®tres :**

- `func`
- `args`
- `kwargs`
- `name`
- `future`

##### terminate

##### kill

##### send_signal

**Param√®tres :**

- `signal`

##### pid

##### returncode

##### stdin

##### stdout

##### stderr

##### connection_made

**Param√®tres :**

- `transport`

##### connection_lost

**Param√®tres :**

- `exc`

##### data_received

**Param√®tres :**

- `data`

##### eof_received

##### pause_writing

##### resume_writing

##### connection_made

**Param√®tres :**

- `transport`

##### connection_lost

**Param√®tres :**

- `exc`

##### datagram_received

**Param√®tres :**

- `data`
- `addr`

##### error_received

**Param√®tres :**

- `exc`

##### pause_writing

##### resume_writing

##### __init__

**Param√®tres :**

- `transport`
- `protocol`

##### _raw_socket

##### __init__

**Param√®tres :**

- `raw_socket`

##### _raw_socket

##### _wait_until_readable

**Param√®tres :**

- `loop`

##### _wait_until_writable

**Param√®tres :**

- `loop`

##### __init__

**Param√®tres :**

- `raw_socket`

##### _raw_socket

##### __init__

**Param√®tres :**

- `raw_socket`

##### _raw_socket

##### __init__

**Param√®tres :**

- `transport`
- `protocol`

##### _raw_socket

##### __init__

**Param√®tres :**

- `transport`
- `protocol`

##### _raw_socket

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### set

##### is_set

##### statistics

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### acquire_nowait

##### locked

##### release

##### statistics

##### __new__

**Param√®tres :**

- `cls`
- `initial_value`

##### __init__

**Param√®tres :**

- `initial_value`

##### acquire_nowait

##### release

##### value

##### max_value

##### statistics

##### __new__

**Param√®tres :**

- `cls`
- `total_tokens`

##### __init__

**Param√®tres :**

- `total_tokens`

##### total_tokens

##### total_tokens

**Param√®tres :**

- `value`

##### borrowed_tokens

##### available_tokens

##### acquire_nowait

##### acquire_on_behalf_of_nowait

**Param√®tres :**

- `borrower`

##### release

##### release_on_behalf_of

**Param√®tres :**

- `borrower`

##### statistics

##### __init__

**Param√®tres :**

- `signals`

##### _deliver

**Param√®tres :**

- `signum`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __aiter__

##### __init__

**Param√®tres :**

- `task`

##### has_pending_cancellation

##### __init__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### get_loop

##### _exception_handler

**Param√®tres :**

- `loop`
- `context`

##### _raise_async_exceptions

##### run_asyncgen_fixture

**Param√®tres :**

- `fixture_func`
- `kwargs`

##### run_fixture

**Param√®tres :**

- `fixture_func`
- `kwargs`

##### run_test

**Param√®tres :**

- `test_func`
- `kwargs`

##### run

**Param√®tres :**

- `cls`
- `func`
- `args`
- `kwargs`
- `options`

##### current_token

**Param√®tres :**

- `cls`

##### current_time

**Param√®tres :**

- `cls`

##### cancelled_exception_class

**Param√®tres :**

- `cls`

##### create_cancel_scope

**Param√®tres :**

- `cls`

##### current_effective_deadline

**Param√®tres :**

- `cls`

##### create_task_group

**Param√®tres :**

- `cls`

##### create_event

**Param√®tres :**

- `cls`

##### create_lock

**Param√®tres :**

- `cls`

##### create_semaphore

**Param√®tres :**

- `cls`
- `initial_value`

##### create_capacity_limiter

**Param√®tres :**

- `cls`
- `total_tokens`

##### check_cancelled

**Param√®tres :**

- `cls`

##### run_async_from_thread

**Param√®tres :**

- `cls`
- `func`
- `args`
- `token`

##### run_sync_from_thread

**Param√®tres :**

- `cls`
- `func`
- `args`
- `token`

##### create_blocking_portal

**Param√®tres :**

- `cls`

##### setup_process_pool_exit_at_shutdown

**Param√®tres :**

- `cls`
- `workers`

##### create_tcp_listener

**Param√®tres :**

- `cls`
- `sock`

##### create_unix_listener

**Param√®tres :**

- `cls`
- `sock`

##### current_default_thread_limiter

**Param√®tres :**

- `cls`

##### open_signal_receiver

**Param√®tres :**

- `cls`

##### get_current_task

**Param√®tres :**

- `cls`

##### get_running_tasks

**Param√®tres :**

- `cls`

##### create_test_runner

**Param√®tres :**

- `cls`
- `options`

##### __init__

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### close

Shutdown and close event loop.

##### get_loop

Return embedded event loop.

##### run

Run a coroutine inside the embedded event loop.

**Param√®tres :**

- `coro`

##### _lazy_init

##### _on_sigint

**Param√®tres :**

- `signum`
- `frame`
- `main_task`

##### _do_shutdown

**Param√®tres :**

- `future`

##### task_done

**Param√®tres :**

- `_task`

##### callback

**Param√®tres :**

- `f`

##### callback

**Param√®tres :**

- `f`

##### wrapper

---

### _trio

#### Classes

##### CancelScope

**M√©thodes :**

- `__new__()`
- `__init__()`
- `__enter__()`
- `__exit__()`
- `cancel()`
- `deadline()`
- `deadline()`
- `cancel_called()`
- `cancelled_caught()`
- `shield()`
- `shield()`

##### TaskGroup

**M√©thodes :**

- `__init__()`
- `start_soon()`

##### BlockingPortal

**M√©thodes :**

- `__new__()`
- `__init__()`
- `_spawn_task_from_thread()`

##### ReceiveStreamWrapper

##### SendStreamWrapper

##### Process

**M√©thodes :**

- `terminate()`
- `kill()`
- `send_signal()`
- `pid()`
- `returncode()`
- `stdin()`
- `stdout()`
- `stderr()`

##### _ProcessPoolShutdownInstrument

**M√©thodes :**

- `after_run()`

##### _TrioSocketMixin

**M√©thodes :**

- `__init__()`
- `_check_closed()`
- `_raw_socket()`
- `_convert_socket_error()`

##### SocketStream

**M√©thodes :**

- `__init__()`

##### UNIXSocketStream

##### TCPSocketListener

**M√©thodes :**

- `__init__()`

##### UNIXSocketListener

**M√©thodes :**

- `__init__()`

##### UDPSocket

**M√©thodes :**

- `__init__()`

##### ConnectedUDPSocket

**M√©thodes :**

- `__init__()`

##### UNIXDatagramSocket

**M√©thodes :**

- `__init__()`

##### ConnectedUNIXDatagramSocket

**M√©thodes :**

- `__init__()`

##### Event

**M√©thodes :**

- `__new__()`
- `__init__()`
- `is_set()`
- `statistics()`
- `set()`

##### Lock

**M√©thodes :**

- `__new__()`
- `__init__()`
- `_convert_runtime_error_msg()`
- `acquire_nowait()`
- `locked()`
- `release()`
- `statistics()`

##### Semaphore

**M√©thodes :**

- `__new__()`
- `__init__()`
- `acquire_nowait()`
- `max_value()`
- `value()`
- `release()`
- `statistics()`

##### CapacityLimiter

**M√©thodes :**

- `__new__()`
- `__init__()`
- `total_tokens()`
- `total_tokens()`
- `borrowed_tokens()`
- `available_tokens()`
- `acquire_nowait()`
- `acquire_on_behalf_of_nowait()`
- `release()`
- `release_on_behalf_of()`
- `statistics()`

##### _SignalReceiver

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`
- `__aiter__()`

##### TestRunner

**M√©thodes :**

- `__init__()`
- `__exit__()`
- `_main_task_finished()`
- `_call_in_runner_task()`
- `run_asyncgen_fixture()`
- `run_fixture()`
- `run_test()`

##### TrioTaskInfo

**M√©thodes :**

- `__init__()`
- `has_pending_cancellation()`

##### TrioBackend

**M√©thodes :**

- `run()`
- `current_token()`
- `current_time()`
- `cancelled_exception_class()`
- `create_cancel_scope()`
- `current_effective_deadline()`
- `create_task_group()`
- `create_event()`
- `create_lock()`
- `create_semaphore()`
- `create_capacity_limiter()`
- `check_cancelled()`
- `run_async_from_thread()`
- `run_sync_from_thread()`
- `create_blocking_portal()`
- `setup_process_pool_exit_at_shutdown()`
- `create_tcp_listener()`
- `create_unix_listener()`
- `current_default_thread_limiter()`
- `open_signal_receiver()`
- `get_current_task()`
- `get_running_tasks()`
- `create_test_runner()`

#### Fonctions

##### __new__

**Param√®tres :**

- `cls`
- `original`

##### __init__

**Param√®tres :**

- `original`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### cancel

##### deadline

##### deadline

**Param√®tres :**

- `value`

##### cancel_called

##### cancelled_caught

##### shield

##### shield

**Param√®tres :**

- `value`

##### __init__

##### start_soon

**Param√®tres :**

- `func`

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### _spawn_task_from_thread

**Param√®tres :**

- `func`
- `args`
- `kwargs`
- `name`
- `future`

##### terminate

##### kill

##### send_signal

**Param√®tres :**

- `signal`

##### pid

##### returncode

##### stdin

##### stdout

##### stderr

##### after_run

##### __init__

**Param√®tres :**

- `trio_socket`

##### _check_closed

##### _raw_socket

##### _convert_socket_error

**Param√®tres :**

- `exc`

##### __init__

**Param√®tres :**

- `trio_socket`

##### __init__

**Param√®tres :**

- `raw_socket`

##### __init__

**Param√®tres :**

- `raw_socket`

##### __init__

**Param√®tres :**

- `trio_socket`

##### __init__

**Param√®tres :**

- `trio_socket`

##### __init__

**Param√®tres :**

- `trio_socket`

##### __init__

**Param√®tres :**

- `trio_socket`

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### is_set

##### statistics

##### set

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### _convert_runtime_error_msg

**Param√®tres :**

- `exc`

##### acquire_nowait

##### locked

##### release

##### statistics

##### __new__

**Param√®tres :**

- `cls`
- `initial_value`

##### __init__

**Param√®tres :**

- `initial_value`

##### acquire_nowait

##### max_value

##### value

##### release

##### statistics

##### __new__

**Param√®tres :**

- `cls`
- `total_tokens`

##### __init__

**Param√®tres :**

- `total_tokens`

##### total_tokens

##### total_tokens

**Param√®tres :**

- `value`

##### borrowed_tokens

##### available_tokens

##### acquire_nowait

##### acquire_on_behalf_of_nowait

**Param√®tres :**

- `borrower`

##### release

##### release_on_behalf_of

**Param√®tres :**

- `borrower`

##### statistics

##### __init__

**Param√®tres :**

- `signals`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __aiter__

##### __init__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### _main_task_finished

**Param√®tres :**

- `outcome`

##### _call_in_runner_task

**Param√®tres :**

- `func`

##### run_asyncgen_fixture

**Param√®tres :**

- `fixture_func`
- `kwargs`

##### run_fixture

**Param√®tres :**

- `fixture_func`
- `kwargs`

##### run_test

**Param√®tres :**

- `test_func`
- `kwargs`

##### __init__

**Param√®tres :**

- `task`

##### has_pending_cancellation

##### run

**Param√®tres :**

- `cls`
- `func`
- `args`
- `kwargs`
- `options`

##### current_token

**Param√®tres :**

- `cls`

##### current_time

**Param√®tres :**

- `cls`

##### cancelled_exception_class

**Param√®tres :**

- `cls`

##### create_cancel_scope

**Param√®tres :**

- `cls`

##### current_effective_deadline

**Param√®tres :**

- `cls`

##### create_task_group

**Param√®tres :**

- `cls`

##### create_event

**Param√®tres :**

- `cls`

##### create_lock

**Param√®tres :**

- `cls`

##### create_semaphore

**Param√®tres :**

- `cls`
- `initial_value`

##### create_capacity_limiter

**Param√®tres :**

- `cls`
- `total_tokens`

##### check_cancelled

**Param√®tres :**

- `cls`

##### run_async_from_thread

**Param√®tres :**

- `cls`
- `func`
- `args`
- `token`

##### run_sync_from_thread

**Param√®tres :**

- `cls`
- `func`
- `args`
- `token`

##### create_blocking_portal

**Param√®tres :**

- `cls`

##### setup_process_pool_exit_at_shutdown

**Param√®tres :**

- `cls`
- `workers`

##### create_tcp_listener

**Param√®tres :**

- `cls`
- `sock`

##### create_unix_listener

**Param√®tres :**

- `cls`
- `sock`

##### current_default_thread_limiter

**Param√®tres :**

- `cls`

##### open_signal_receiver

**Param√®tres :**

- `cls`

##### get_current_task

**Param√®tres :**

- `cls`

##### get_running_tasks

**Param√®tres :**

- `cls`

##### create_test_runner

**Param√®tres :**

- `cls`
- `options`

##### wrapper

##### convert_item

**Param√®tres :**

- `item`

---

### _asyncio_selector_thread

#### Classes

##### Selector

**M√©thodes :**

- `__init__()`
- `start()`
- `_stop()`
- `_notify_self()`
- `add_reader()`
- `add_writer()`
- `remove_reader()`
- `remove_writer()`
- `run()`

#### Fonctions

##### get_selector

##### __init__

##### start

##### _stop

##### _notify_self

##### add_reader

**Param√®tres :**

- `fd`
- `callback`

##### add_writer

**Param√®tres :**

- `fd`
- `callback`

##### remove_reader

**Param√®tres :**

- `fd`

##### remove_writer

**Param√®tres :**

- `fd`

##### run

---

### _eventloop

#### Fonctions

##### run

Run the given coroutine function in an asynchronous event loop.

The current thread must not be already running an event loop.

:param func: a coroutine function
:param args: positional arguments to ``func``
:param backend: name of the asynchronous event loop implementation ‚Äì currently
    either ``asyncio`` or ``trio``
:param backend_options: keyword arguments to call the backend ``run()``
    implementation with (documented :ref:`here <backend options>`)
:return: the return value of the coroutine function
:raises RuntimeError: if an asynchronous event loop is already running in this
    thread
:raises LookupError: if the named backend is not found

**Param√®tres :**

- `func`

##### current_time

Return the current value of the event loop's internal clock.

:return: the clock value (seconds)

##### get_all_backends

Return a tuple of the names of all built-in backends.

##### get_cancelled_exc_class

Return the current async library's cancellation exception class.

##### claim_worker_thread

**Param√®tres :**

- `backend_class`
- `token`

##### get_async_backend

**Param√®tres :**

- `asynclib_name`

---

### _exceptions

#### Classes

##### BrokenResourceError

Raised when trying to use a resource that has been rendered unusable due to external
causes (e.g. a send stream whose peer has disconnected).

##### BrokenWorkerProcess

Raised by :meth:`~anyio.to_process.run_sync` if the worker process terminates abruptly or
otherwise misbehaves.

##### BrokenWorkerIntepreter

Raised by :meth:`~anyio.to_interpreter.run_sync` if an unexpected exception is
raised in the subinterpreter.

**M√©thodes :**

- `__init__()`
- `__str__()`

##### BusyResourceError

Raised when two tasks are trying to read from or write to the same resource
concurrently.

**M√©thodes :**

- `__init__()`

##### ClosedResourceError

Raised when trying to use a resource that has been closed.

##### DelimiterNotFound

Raised during
:meth:`~anyio.streams.buffered.BufferedByteReceiveStream.receive_until` if the
maximum number of bytes has been read without the delimiter being found.

**M√©thodes :**

- `__init__()`

##### EndOfStream

Raised when trying to read from a stream that has been closed from the other end.

##### IncompleteRead

Raised during
:meth:`~anyio.streams.buffered.BufferedByteReceiveStream.receive_exactly` or
:meth:`~anyio.streams.buffered.BufferedByteReceiveStream.receive_until` if the
connection is closed before the requested amount of bytes has been read.

**M√©thodes :**

- `__init__()`

##### TypedAttributeLookupError

Raised by :meth:`~anyio.TypedAttributeProvider.extra` when the given typed attribute
is not found and no default value has been given.

##### WouldBlock

Raised by ``X_nowait`` functions if ``X()`` would block.

#### Fonctions

##### iterate_exceptions

**Param√®tres :**

- `exception`

##### __init__

**Param√®tres :**

- `excinfo`

##### __str__

##### __init__

**Param√®tres :**

- `action`

##### __init__

**Param√®tres :**

- `max_bytes`

##### __init__

---

### _fileio

#### Classes

##### AsyncFile

An asynchronous file object.

This class wraps a standard file object and provides async friendly versions of the
following blocking methods (where available on the original file object):

* read
* read1
* readline
* readlines
* readinto
* readinto1
* write
* writelines
* truncate
* seek
* tell
* flush

All other methods are directly passed through.

This class supports the asynchronous context manager protocol which closes the
underlying file at the end of the context block.

This class also supports asynchronous iteration::

    async with await open_file(...) as f:
        async for line in f:
            print(line)

**M√©thodes :**

- `__init__()`
- `__getattr__()`
- `wrapped()`

##### _PathIterator

##### Path

An asynchronous version of :class:`pathlib.Path`.

This class cannot be substituted for :class:`pathlib.Path` or
:class:`pathlib.PurePath`, but it is compatible with the :class:`os.PathLike`
interface.

It implements the Python 3.10 version of :class:`pathlib.Path` interface, except for
the deprecated :meth:`~pathlib.Path.link_to` method.

Some methods may be unavailable or have limited functionality, based on the Python
version:

* :meth:`~pathlib.Path.copy` (available on Python 3.14 or later)
* :meth:`~pathlib.Path.copy_into` (available on Python 3.14 or later)
* :meth:`~pathlib.Path.from_uri` (available on Python 3.13 or later)
* :meth:`~pathlib.PurePath.full_match` (available on Python 3.13 or later)
* :attr:`~pathlib.Path.info` (available on Python 3.14 or later)
* :meth:`~pathlib.Path.is_junction` (available on Python 3.12 or later)
* :meth:`~pathlib.PurePath.match` (the ``case_sensitive`` parameter is only
  available on Python 3.13 or later)
* :meth:`~pathlib.Path.move` (available on Python 3.14 or later)
* :meth:`~pathlib.Path.move_into` (available on Python 3.14 or later)
* :meth:`~pathlib.PurePath.relative_to` (the ``walk_up`` parameter is only available
  on Python 3.12 or later)
* :meth:`~pathlib.Path.walk` (available on Python 3.12 or later)

Any methods that do disk I/O need to be awaited on. These methods are:

* :meth:`~pathlib.Path.absolute`
* :meth:`~pathlib.Path.chmod`
* :meth:`~pathlib.Path.cwd`
* :meth:`~pathlib.Path.exists`
* :meth:`~pathlib.Path.expanduser`
* :meth:`~pathlib.Path.group`
* :meth:`~pathlib.Path.hardlink_to`
* :meth:`~pathlib.Path.home`
* :meth:`~pathlib.Path.is_block_device`
* :meth:`~pathlib.Path.is_char_device`
* :meth:`~pathlib.Path.is_dir`
* :meth:`~pathlib.Path.is_fifo`
* :meth:`~pathlib.Path.is_file`
* :meth:`~pathlib.Path.is_junction`
* :meth:`~pathlib.Path.is_mount`
* :meth:`~pathlib.Path.is_socket`
* :meth:`~pathlib.Path.is_symlink`
* :meth:`~pathlib.Path.lchmod`
* :meth:`~pathlib.Path.lstat`
* :meth:`~pathlib.Path.mkdir`
* :meth:`~pathlib.Path.open`
* :meth:`~pathlib.Path.owner`
* :meth:`~pathlib.Path.read_bytes`
* :meth:`~pathlib.Path.read_text`
* :meth:`~pathlib.Path.readlink`
* :meth:`~pathlib.Path.rename`
* :meth:`~pathlib.Path.replace`
* :meth:`~pathlib.Path.resolve`
* :meth:`~pathlib.Path.rmdir`
* :meth:`~pathlib.Path.samefile`
* :meth:`~pathlib.Path.stat`
* :meth:`~pathlib.Path.symlink_to`
* :meth:`~pathlib.Path.touch`
* :meth:`~pathlib.Path.unlink`
* :meth:`~pathlib.Path.walk`
* :meth:`~pathlib.Path.write_bytes`
* :meth:`~pathlib.Path.write_text`

Additionally, the following methods return an async iterator yielding
:class:`~.Path` objects:

* :meth:`~pathlib.Path.glob`
* :meth:`~pathlib.Path.iterdir`
* :meth:`~pathlib.Path.rglob`

**M√©thodes :**

- `__init__()`
- `__fspath__()`
- `__str__()`
- `__repr__()`
- `__bytes__()`
- `__hash__()`
- `__eq__()`
- `__lt__()`
- `__le__()`
- `__gt__()`
- `__ge__()`
- `__truediv__()`
- `__rtruediv__()`
- `parts()`
- `drive()`
- `root()`
- `anchor()`
- `parents()`
- `parent()`
- `name()`
- `suffix()`
- `suffixes()`
- `stem()`
- `as_posix()`
- `as_uri()`
- `is_relative_to()`
- `glob()`
- `is_absolute()`
- `is_reserved()`
- `joinpath()`
- `rglob()`
- `with_name()`
- `with_stem()`
- `with_suffix()`
- `with_segments()`

#### Fonctions

##### wrap_file

Wrap an existing file as an asynchronous file.

:param file: an existing file-like object
:return: an asynchronous file object

**Param√®tres :**

- `file`

##### __init__

**Param√®tres :**

- `fp`

##### __getattr__

**Param√®tres :**

- `name`

##### wrapped

The wrapped file object.

##### __init__

##### __fspath__

##### __str__

##### __repr__

##### __bytes__

##### __hash__

##### __eq__

**Param√®tres :**

- `other`

##### __lt__

**Param√®tres :**

- `other`

##### __le__

**Param√®tres :**

- `other`

##### __gt__

**Param√®tres :**

- `other`

##### __ge__

**Param√®tres :**

- `other`

##### __truediv__

**Param√®tres :**

- `other`

##### __rtruediv__

**Param√®tres :**

- `other`

##### parts

##### drive

##### root

##### anchor

##### parents

##### parent

##### name

##### suffix

##### suffixes

##### stem

##### as_posix

##### as_uri

##### is_relative_to

**Param√®tres :**

- `other`

##### glob

**Param√®tres :**

- `pattern`

##### is_absolute

##### is_reserved

##### joinpath

##### rglob

**Param√®tres :**

- `pattern`

##### with_name

**Param√®tres :**

- `name`

##### with_stem

**Param√®tres :**

- `stem`

##### with_suffix

**Param√®tres :**

- `suffix`

##### with_segments

##### from_uri

**Param√®tres :**

- `cls`
- `uri`

##### full_match

**Param√®tres :**

- `path_pattern`

##### match

**Param√®tres :**

- `path_pattern`

##### match

**Param√®tres :**

- `path_pattern`

##### info

##### relative_to

##### relative_to

##### sync_write_text

##### get_next_value

---

### _resources

---

### _signals

#### Fonctions

##### open_signal_receiver

Start receiving operating system signals.

:param signals: signals to receive (e.g. ``signal.SIGINT``)
:return: an asynchronous context manager for an asynchronous iterator which yields
    signal numbers

.. warning:: Windows does not support signals natively so it is best to avoid
    relying on this in cross-platform applications.

.. warning:: On asyncio, this permanently replaces any previous signal handler for
    the given signals, as set via :meth:`~asyncio.loop.add_signal_handler`.

---

### _sockets

#### Fonctions

##### getnameinfo

Look up the host name of an IP address.

:param sockaddr: socket address (e.g. (ipaddress, port) for IPv4)
:param flags: flags to pass to upstream ``getnameinfo()``
:return: a tuple of (host name, service name)

.. seealso:: :func:`socket.getnameinfo`

**Param√®tres :**

- `sockaddr`
- `flags`

##### wait_socket_readable

.. deprecated:: 4.7.0
   Use :func:`wait_readable` instead.

Wait until the given socket has data to be read.

.. warning:: Only use this on raw sockets that have not been wrapped by any higher
    level constructs like socket streams!

:param sock: a socket object
:raises ~anyio.ClosedResourceError: if the socket was closed while waiting for the
    socket to become readable
:raises ~anyio.BusyResourceError: if another task is already waiting for the socket
    to become readable

**Param√®tres :**

- `sock`

##### wait_socket_writable

.. deprecated:: 4.7.0
   Use :func:`wait_writable` instead.

Wait until the given socket can be written to.

This does **NOT** work on Windows when using the asyncio backend with a proactor
event loop (default on py3.8+).

.. warning:: Only use this on raw sockets that have not been wrapped by any higher
    level constructs like socket streams!

:param sock: a socket object
:raises ~anyio.ClosedResourceError: if the socket was closed while waiting for the
    socket to become writable
:raises ~anyio.BusyResourceError: if another task is already waiting for the socket
    to become writable

**Param√®tres :**

- `sock`

##### wait_readable

Wait until the given object has data to be read.

On Unix systems, ``obj`` must either be an integer file descriptor, or else an
object with a ``.fileno()`` method which returns an integer file descriptor. Any
kind of file descriptor can be passed, though the exact semantics will depend on
your kernel. For example, this probably won't do anything useful for on-disk files.

On Windows systems, ``obj`` must either be an integer ``SOCKET`` handle, or else an
object with a ``.fileno()`` method which returns an integer ``SOCKET`` handle. File
descriptors aren't supported, and neither are handles that refer to anything besides
a ``SOCKET``.

On backends where this functionality is not natively provided (asyncio
``ProactorEventLoop`` on Windows), it is provided using a separate selector thread
which is set to shut down when the interpreter shuts down.

.. warning:: Don't use this on raw sockets that have been wrapped by any higher
    level constructs like socket streams!

:param obj: an object with a ``.fileno()`` method or an integer handle
:raises ~anyio.ClosedResourceError: if the object was closed while waiting for the
    object to become readable
:raises ~anyio.BusyResourceError: if another task is already waiting for the object
    to become readable

**Param√®tres :**

- `obj`

##### wait_writable

Wait until the given object can be written to.

:param obj: an object with a ``.fileno()`` method or an integer handle
:raises ~anyio.ClosedResourceError: if the object was closed while waiting for the
    object to become writable
:raises ~anyio.BusyResourceError: if another task is already waiting for the object
    to become writable

.. seealso:: See the documentation of :func:`wait_readable` for the definition of
   ``obj`` and notes on backend compatibility.

.. warning:: Don't use this on raw sockets that have been wrapped by any higher
    level constructs like socket streams!

**Param√®tres :**

- `obj`

##### convert_ipv6_sockaddr

Convert a 4-tuple IPv6 socket address to a 2-tuple (address, port) format.

If the scope ID is nonzero, it is added to the address, separated with ``%``.
Otherwise the flow id and scope id are simply cut off from the tuple.
Any other kinds of socket addresses are returned as-is.

:param sockaddr: the result of :meth:`~socket.socket.getsockname`
:return: the converted socket address

**Param√®tres :**

- `sockaddr`

---

### _streams

#### Classes

##### create_memory_object_stream

Create a memory object stream.

The stream's item type can be annotated like
:func:`create_memory_object_stream[T_Item]`.

:param max_buffer_size: number of items held in the buffer until ``send()`` starts
    blocking
:param item_type: old way of marking the streams with the right generic type for
    static typing (does nothing on AnyIO 4)

    .. deprecated:: 4.0
      Use ``create_memory_object_stream[YourItemType](...)`` instead.
:return: a tuple of (send stream, receive stream)

**M√©thodes :**

- `__new__()`

#### Fonctions

##### __new__

**Param√®tres :**

- `cls`
- `max_buffer_size`
- `item_type`

---

### _subprocesses

---

### _synchronization

#### Classes

##### EventStatistics

:ivar int tasks_waiting: number of tasks waiting on :meth:`~.Event.wait`

##### CapacityLimiterStatistics

:ivar int borrowed_tokens: number of tokens currently borrowed by tasks
:ivar float total_tokens: total number of available tokens
:ivar tuple borrowers: tasks or other objects currently holding tokens borrowed from
    this limiter
:ivar int tasks_waiting: number of tasks waiting on
    :meth:`~.CapacityLimiter.acquire` or
    :meth:`~.CapacityLimiter.acquire_on_behalf_of`

##### LockStatistics

:ivar bool locked: flag indicating if this lock is locked or not
:ivar ~anyio.TaskInfo owner: task currently holding the lock (or ``None`` if the
    lock is not held by any task)
:ivar int tasks_waiting: number of tasks waiting on :meth:`~.Lock.acquire`

##### ConditionStatistics

:ivar int tasks_waiting: number of tasks blocked on :meth:`~.Condition.wait`
:ivar ~anyio.LockStatistics lock_statistics: statistics of the underlying
    :class:`~.Lock`

##### SemaphoreStatistics

:ivar int tasks_waiting: number of tasks waiting on :meth:`~.Semaphore.acquire`

##### Event

**M√©thodes :**

- `__new__()`
- `set()`
- `is_set()`
- `statistics()`

##### EventAdapter

**M√©thodes :**

- `__new__()`
- `_event()`
- `set()`
- `is_set()`
- `statistics()`

##### Lock

**M√©thodes :**

- `__new__()`
- `acquire_nowait()`
- `release()`
- `locked()`
- `statistics()`

##### LockAdapter

**M√©thodes :**

- `__new__()`
- `__init__()`
- `_lock()`
- `acquire_nowait()`
- `release()`
- `locked()`
- `statistics()`

##### Condition

**M√©thodes :**

- `__init__()`
- `_check_acquired()`
- `acquire_nowait()`
- `release()`
- `locked()`
- `notify()`
- `notify_all()`
- `statistics()`

##### Semaphore

**M√©thodes :**

- `__new__()`
- `__init__()`
- `acquire_nowait()`
- `release()`
- `value()`
- `max_value()`
- `statistics()`

##### SemaphoreAdapter

**M√©thodes :**

- `__new__()`
- `__init__()`
- `_semaphore()`
- `acquire_nowait()`
- `release()`
- `value()`
- `max_value()`
- `statistics()`

##### CapacityLimiter

**M√©thodes :**

- `__new__()`
- `total_tokens()`
- `total_tokens()`
- `borrowed_tokens()`
- `available_tokens()`
- `acquire_nowait()`
- `acquire_on_behalf_of_nowait()`
- `release()`
- `release_on_behalf_of()`
- `statistics()`

##### CapacityLimiterAdapter

**M√©thodes :**

- `__new__()`
- `__init__()`
- `_limiter()`
- `total_tokens()`
- `total_tokens()`
- `borrowed_tokens()`
- `available_tokens()`
- `acquire_nowait()`
- `acquire_on_behalf_of_nowait()`
- `release()`
- `release_on_behalf_of()`
- `statistics()`

##### ResourceGuard

A context manager for ensuring that a resource is only used by a single task at a
time.

Entering this context manager while the previous has not exited it yet will trigger
:exc:`BusyResourceError`.

:param action: the action to guard against (visible in the :exc:`BusyResourceError`
    when triggered, e.g. "Another task is already {action} this resource")

.. versionadded:: 4.1

**M√©thodes :**

- `__init__()`
- `__enter__()`
- `__exit__()`

#### Fonctions

##### __new__

**Param√®tres :**

- `cls`

##### set

Set the flag, notifying all listeners.

##### is_set

Return ``True`` if the flag is set, ``False`` if not.

##### statistics

Return statistics about the current state of this event.

##### __new__

**Param√®tres :**

- `cls`

##### _event

##### set

##### is_set

##### statistics

##### __new__

**Param√®tres :**

- `cls`

##### acquire_nowait

Acquire the lock, without blocking.

:raises ~anyio.WouldBlock: if the operation would block

##### release

Release the lock.

##### locked

Return True if the lock is currently held.

##### statistics

Return statistics about the current state of this lock.

.. versionadded:: 3.0

##### __new__

**Param√®tres :**

- `cls`

##### __init__

##### _lock

##### acquire_nowait

Acquire the lock, without blocking.

:raises ~anyio.WouldBlock: if the operation would block

##### release

Release the lock.

##### locked

Return True if the lock is currently held.

##### statistics

Return statistics about the current state of this lock.

.. versionadded:: 3.0

##### __init__

**Param√®tres :**

- `lock`

##### _check_acquired

##### acquire_nowait

Acquire the underlying lock, without blocking.

:raises ~anyio.WouldBlock: if the operation would block

##### release

Release the underlying lock.

##### locked

Return True if the lock is set.

##### notify

Notify exactly n listeners.

**Param√®tres :**

- `n`

##### notify_all

Notify all the listeners.

##### statistics

Return statistics about the current state of this condition.

.. versionadded:: 3.0

##### __new__

**Param√®tres :**

- `cls`
- `initial_value`

##### __init__

**Param√®tres :**

- `initial_value`

##### acquire_nowait

Acquire the underlying lock, without blocking.

:raises ~anyio.WouldBlock: if the operation would block

##### release

Increment the semaphore value.

##### value

The current value of the semaphore.

##### max_value

The maximum value of the semaphore.

##### statistics

Return statistics about the current state of this semaphore.

.. versionadded:: 3.0

##### __new__

**Param√®tres :**

- `cls`
- `initial_value`

##### __init__

**Param√®tres :**

- `initial_value`

##### _semaphore

##### acquire_nowait

##### release

##### value

##### max_value

##### statistics

##### __new__

**Param√®tres :**

- `cls`
- `total_tokens`

##### total_tokens

The total number of tokens available for borrowing.

This is a read-write property. If the total number of tokens is increased, the
proportionate number of tasks waiting on this limiter will be granted their
tokens.

.. versionchanged:: 3.0
    The property is now writable.

##### total_tokens

**Param√®tres :**

- `value`

##### borrowed_tokens

The number of tokens that have currently been borrowed.

##### available_tokens

The number of tokens currently available to be borrowed

##### acquire_nowait

Acquire a token for the current task without waiting for one to become
available.

:raises ~anyio.WouldBlock: if there are no tokens available for borrowing

##### acquire_on_behalf_of_nowait

Acquire a token without waiting for one to become available.

:param borrower: the entity borrowing a token
:raises ~anyio.WouldBlock: if there are no tokens available for borrowing

**Param√®tres :**

- `borrower`

##### release

Release the token held by the current task.

:raises RuntimeError: if the current task has not borrowed a token from this
    limiter.

##### release_on_behalf_of

Release the token held by the given borrower.

:raises RuntimeError: if the borrower has not borrowed a token from this
    limiter.

**Param√®tres :**

- `borrower`

##### statistics

Return statistics about the current state of this limiter.

.. versionadded:: 3.0

##### __new__

**Param√®tres :**

- `cls`
- `total_tokens`

##### __init__

**Param√®tres :**

- `total_tokens`

##### _limiter

##### total_tokens

##### total_tokens

**Param√®tres :**

- `value`

##### borrowed_tokens

##### available_tokens

##### acquire_nowait

##### acquire_on_behalf_of_nowait

**Param√®tres :**

- `borrower`

##### release

##### release_on_behalf_of

**Param√®tres :**

- `borrower`

##### statistics

##### __init__

**Param√®tres :**

- `action`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

---

### _tasks

#### Classes

##### _IgnoredTaskStatus

**M√©thodes :**

- `started()`

##### CancelScope

Wraps a unit of work that can be made separately cancellable.

:param deadline: The time (clock value) when this scope is cancelled automatically
:param shield: ``True`` to shield the cancel scope from external cancellation

**M√©thodes :**

- `__new__()`
- `cancel()`
- `deadline()`
- `deadline()`
- `cancel_called()`
- `cancelled_caught()`
- `shield()`
- `shield()`
- `__enter__()`
- `__exit__()`

#### Fonctions

##### fail_after

Create a context manager which raises a :class:`TimeoutError` if does not finish in
time.

:param delay: maximum allowed time (in seconds) before raising the exception, or
    ``None`` to disable the timeout
:param shield: ``True`` to shield the cancel scope from external cancellation
:return: a context manager that yields a cancel scope
:rtype: :class:`~typing.ContextManager`\[:class:`~anyio.CancelScope`\]

**Param√®tres :**

- `delay`
- `shield`

##### move_on_after

Create a cancel scope with a deadline that expires after the given delay.

:param delay: maximum allowed time (in seconds) before exiting the context block, or
    ``None`` to disable the timeout
:param shield: ``True`` to shield the cancel scope from external cancellation
:return: a cancel scope

**Param√®tres :**

- `delay`
- `shield`

##### current_effective_deadline

Return the nearest deadline among all the cancel scopes effective for the current
task.

:return: a clock value from the event loop's internal clock (or ``float('inf')`` if
    there is no deadline in effect, or ``float('-inf')`` if the current scope has
    been cancelled)
:rtype: float

##### create_task_group

Create a task group.

:return: a task group

##### started

**Param√®tres :**

- `value`

##### __new__

**Param√®tres :**

- `cls`

##### cancel

Cancel this scope immediately.

##### deadline

The time (clock value) when this scope is cancelled automatically.

Will be ``float('inf')`` if no timeout has been set.

##### deadline

**Param√®tres :**

- `value`

##### cancel_called

``True`` if :meth:`cancel` has been called.

##### cancelled_caught

``True`` if this scope suppressed a cancellation exception it itself raised.

This is typically used to check if any work was interrupted, or to see if the
scope was cancelled due to its deadline being reached. The value will, however,
only be ``True`` if the cancellation was triggered by the scope itself (and not
an outer scope).

##### shield

``True`` if this scope is shielded from external cancellation.

While a scope is shielded, it will not receive cancellations from outside.

##### shield

**Param√®tres :**

- `value`

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

---

### _tempfile

#### Classes

##### TemporaryFile

An asynchronous temporary file that is automatically created and cleaned up.

This class provides an asynchronous context manager interface to a temporary file.
The file is created using Python's standard `tempfile.TemporaryFile` function in a
background thread, and is wrapped as an asynchronous file using `AsyncFile`.

:param mode: The mode in which the file is opened. Defaults to "w+b".
:param buffering: The buffering policy (-1 means the default buffering).
:param encoding: The encoding used to decode or encode the file. Only applicable in
    text mode.
:param newline: Controls how universal newlines mode works (only applicable in text
    mode).
:param suffix: The suffix for the temporary file name.
:param prefix: The prefix for the temporary file name.
:param dir: The directory in which the temporary file is created.
:param errors: The error handling scheme used for encoding/decoding errors.

**M√©thodes :**

- `__init__()`
- `__init__()`
- `__init__()`

##### NamedTemporaryFile

An asynchronous named temporary file that is automatically created and cleaned up.

This class provides an asynchronous context manager for a temporary file with a
visible name in the file system. It uses Python's standard
:func:`~tempfile.NamedTemporaryFile` function and wraps the file object with
:class:`AsyncFile` for asynchronous operations.

:param mode: The mode in which the file is opened. Defaults to "w+b".
:param buffering: The buffering policy (-1 means the default buffering).
:param encoding: The encoding used to decode or encode the file. Only applicable in
    text mode.
:param newline: Controls how universal newlines mode works (only applicable in text
    mode).
:param suffix: The suffix for the temporary file name.
:param prefix: The prefix for the temporary file name.
:param dir: The directory in which the temporary file is created.
:param delete: Whether to delete the file when it is closed.
:param errors: The error handling scheme used for encoding/decoding errors.
:param delete_on_close: (Python 3.12+) Whether to delete the file on close.

**M√©thodes :**

- `__init__()`
- `__init__()`
- `__init__()`

##### SpooledTemporaryFile

An asynchronous spooled temporary file that starts in memory and is spooled to disk.

This class provides an asynchronous interface to a spooled temporary file, much like
Python's standard :class:`~tempfile.SpooledTemporaryFile`. It supports asynchronous
write operations and provides a method to force a rollover to disk.

:param max_size: Maximum size in bytes before the file is rolled over to disk.
:param mode: The mode in which the file is opened. Defaults to "w+b".
:param buffering: The buffering policy (-1 means the default buffering).
:param encoding: The encoding used to decode or encode the file (text mode only).
:param newline: Controls how universal newlines mode works (text mode only).
:param suffix: The suffix for the temporary file name.
:param prefix: The prefix for the temporary file name.
:param dir: The directory in which the temporary file is created.
:param errors: The error handling scheme used for encoding/decoding errors.

**M√©thodes :**

- `__init__()`
- `__init__()`
- `__init__()`
- `closed()`

##### TemporaryDirectory

An asynchronous temporary directory that is created and cleaned up automatically.

This class provides an asynchronous context manager for creating a temporary
directory. It wraps Python's standard :class:`~tempfile.TemporaryDirectory` to
perform directory creation and cleanup operations in a background thread.

:param suffix: Suffix to be added to the temporary directory name.
:param prefix: Prefix to be added to the temporary directory name.
:param dir: The parent directory where the temporary directory is created.
:param ignore_cleanup_errors: Whether to ignore errors during cleanup
    (Python 3.10+).
:param delete: Whether to delete the directory upon closing (Python 3.12+).

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`

##### __init__

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`

##### __init__

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`

##### __init__

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`
- `delete`

##### __init__

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`
- `delete`

##### __init__

**Param√®tres :**

- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`
- `delete`

##### __init__

**Param√®tres :**

- `max_size`
- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`

##### __init__

**Param√®tres :**

- `max_size`
- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`

##### __init__

**Param√®tres :**

- `max_size`
- `mode`
- `buffering`
- `encoding`
- `newline`
- `suffix`
- `prefix`
- `dir`

##### closed

##### __init__

**Param√®tres :**

- `suffix`
- `prefix`
- `dir`

---

### _testing

#### Classes

##### TaskInfo

Represents an asynchronous task.

:ivar int id: the unique identifier of the task
:ivar parent_id: the identifier of the parent task, if any
:vartype parent_id: Optional[int]
:ivar str name: the description of the task (if any)
:ivar ~collections.abc.Coroutine coro: the coroutine object of the task

**M√©thodes :**

- `__init__()`
- `__eq__()`
- `__hash__()`
- `__repr__()`
- `has_pending_cancellation()`

#### Fonctions

##### get_current_task

Return the current task.

:return: a representation of the current task

##### get_running_tasks

Return a list of running tasks in the current event loop.

:return: a list of task info objects

##### __init__

**Param√®tres :**

- `id`
- `parent_id`
- `name`
- `coro`

##### __eq__

**Param√®tres :**

- `other`

##### __hash__

##### __repr__

##### has_pending_cancellation

Return ``True`` if the task has a cancellation pending, ``False`` otherwise.

---

### _typedattr

#### Classes

##### TypedAttributeSet

Superclass for typed attribute collections.

Checks that every public attribute of every subclass has a type annotation.

**M√©thodes :**

- `__init_subclass__()`

##### TypedAttributeProvider

Base class for classes that wish to provide typed extra attributes.

**M√©thodes :**

- `extra_attributes()`
- `extra()`
- `extra()`
- `extra()`

#### Fonctions

##### typed_attribute

Return a unique object, used to mark typed attributes.

##### __init_subclass__

**Param√®tres :**

- `cls`

##### extra_attributes

A mapping of the extra attributes to callables that return the corresponding
values.

If the provider wraps another provider, the attributes from that wrapper should
also be included in the returned mapping (but the wrapper may override the
callables from the wrapped instance).

##### extra

**Param√®tres :**

- `attribute`

##### extra

**Param√®tres :**

- `attribute`
- `default`

##### extra

extra(attribute, default=undefined)

Return the value of the given typed extra attribute.

:param attribute: the attribute (member of a :class:`~TypedAttributeSet`) to
    look for
:param default: the value that should be returned if no value is found for the
    attribute
:raises ~anyio.TypedAttributeLookupError: if the search failed and no default
    value was given

**Param√®tres :**

- `attribute`
- `default`

---

### _eventloop

#### Classes

##### AsyncBackend

**M√©thodes :**

- `run()`
- `current_token()`
- `current_time()`
- `cancelled_exception_class()`
- `create_cancel_scope()`
- `current_effective_deadline()`
- `create_task_group()`
- `create_event()`
- `create_lock()`
- `create_semaphore()`
- `create_capacity_limiter()`
- `check_cancelled()`
- `run_async_from_thread()`
- `run_sync_from_thread()`
- `create_blocking_portal()`
- `setup_process_pool_exit_at_shutdown()`
- `create_tcp_listener()`
- `create_unix_listener()`
- `current_default_thread_limiter()`
- `open_signal_receiver()`
- `get_current_task()`
- `get_running_tasks()`
- `create_test_runner()`

#### Fonctions

##### run

Run the given coroutine function in an asynchronous event loop.

The current thread must not be already running an event loop.

:param func: a coroutine function
:param args: positional arguments to ``func``
:param kwargs: positional arguments to ``func``
:param options: keyword arguments to call the backend ``run()`` implementation
    with
:return: the return value of the coroutine function

**Param√®tres :**

- `cls`
- `func`
- `args`
- `kwargs`
- `options`

##### current_token

:return:

**Param√®tres :**

- `cls`

##### current_time

Return the current value of the event loop's internal clock.

:return: the clock value (seconds)

**Param√®tres :**

- `cls`

##### cancelled_exception_class

Return the exception class that is raised in a task if it's cancelled.

**Param√®tres :**

- `cls`

##### create_cancel_scope

**Param√®tres :**

- `cls`

##### current_effective_deadline

Return the nearest deadline among all the cancel scopes effective for the
current task.

:return:
    - a clock value from the event loop's internal clock
    - ``inf`` if there is no deadline in effect
    - ``-inf`` if the current scope has been cancelled
:rtype: float

**Param√®tres :**

- `cls`

##### create_task_group

**Param√®tres :**

- `cls`

##### create_event

**Param√®tres :**

- `cls`

##### create_lock

**Param√®tres :**

- `cls`

##### create_semaphore

**Param√®tres :**

- `cls`
- `initial_value`

##### create_capacity_limiter

**Param√®tres :**

- `cls`
- `total_tokens`

##### check_cancelled

**Param√®tres :**

- `cls`

##### run_async_from_thread

**Param√®tres :**

- `cls`
- `func`
- `args`
- `token`

##### run_sync_from_thread

**Param√®tres :**

- `cls`
- `func`
- `args`
- `token`

##### create_blocking_portal

**Param√®tres :**

- `cls`

##### setup_process_pool_exit_at_shutdown

**Param√®tres :**

- `cls`
- `workers`

##### create_tcp_listener

**Param√®tres :**

- `cls`
- `sock`

##### create_unix_listener

**Param√®tres :**

- `cls`
- `sock`

##### current_default_thread_limiter

**Param√®tres :**

- `cls`

##### open_signal_receiver

**Param√®tres :**

- `cls`

##### get_current_task

**Param√®tres :**

- `cls`

##### get_running_tasks

**Param√®tres :**

- `cls`

##### create_test_runner

**Param√®tres :**

- `cls`
- `options`

---

### _resources

#### Classes

##### AsyncResource

Abstract base class for all closeable asynchronous resources.

Works as an asynchronous context manager which returns the instance itself on enter,
and calls :meth:`aclose` on exit.

---

### _sockets

#### Classes

##### _NullAsyncContextManager

##### SocketAttribute

##### _SocketProvider

**M√©thodes :**

- `extra_attributes()`
- `_raw_socket()`

##### SocketStream

Transports bytes over a socket.

Supports all relevant extra attributes from :class:`~SocketAttribute`.

##### UNIXSocketStream

##### SocketListener

Listens to incoming socket connections.

Supports all relevant extra attributes from :class:`~SocketAttribute`.

##### UDPSocket

Represents an unconnected UDP socket.

Supports all relevant extra attributes from :class:`~SocketAttribute`.

##### ConnectedUDPSocket

Represents an connected UDP socket.

Supports all relevant extra attributes from :class:`~SocketAttribute`.

##### UNIXDatagramSocket

Represents an unconnected Unix datagram socket.

Supports all relevant extra attributes from :class:`~SocketAttribute`.

##### ConnectedUNIXDatagramSocket

Represents a connected Unix datagram socket.

Supports all relevant extra attributes from :class:`~SocketAttribute`.

#### Fonctions

##### extra_attributes

##### _raw_socket

---

### _streams

#### Classes

##### UnreliableObjectReceiveStream

An interface for receiving objects.

This interface makes no guarantees that the received messages arrive in the order in
which they were sent, or that no messages are missed.

Asynchronously iterating over objects of this type will yield objects matching the
given type parameter.

**M√©thodes :**

- `__aiter__()`

##### UnreliableObjectSendStream

An interface for sending objects.

This interface makes no guarantees that the messages sent will reach the
recipient(s) in the same order in which they were sent, or at all.

##### UnreliableObjectStream

A bidirectional message stream which does not guarantee the order or reliability of
message delivery.

##### ObjectReceiveStream

A receive message stream which guarantees that messages are received in the same
order in which they were sent, and that no messages are missed.

##### ObjectSendStream

A send message stream which guarantees that messages are delivered in the same order
in which they were sent, without missing any messages in the middle.

##### ObjectStream

A bidirectional message stream which guarantees the order and reliability of message
delivery.

##### ByteReceiveStream

An interface for receiving bytes from a single peer.

Iterating this byte stream will yield a byte string of arbitrary length, but no more
than 65536 bytes.

**M√©thodes :**

- `__aiter__()`

##### ByteSendStream

An interface for sending bytes to a single peer.

##### ByteStream

A bidirectional byte stream.

##### Listener

An interface for objects that let you accept incoming connections.

#### Fonctions

##### __aiter__

##### __aiter__

---

### _subprocesses

#### Classes

##### Process

An asynchronous version of :class:`subprocess.Popen`.

**M√©thodes :**

- `terminate()`
- `kill()`
- `send_signal()`
- `pid()`
- `returncode()`
- `stdin()`
- `stdout()`
- `stderr()`

#### Fonctions

##### terminate

Terminates the process, gracefully if possible.

On Windows, this calls ``TerminateProcess()``.
On POSIX systems, this sends ``SIGTERM`` to the process.

.. seealso:: :meth:`subprocess.Popen.terminate`

##### kill

Kills the process.

On Windows, this calls ``TerminateProcess()``.
On POSIX systems, this sends ``SIGKILL`` to the process.

.. seealso:: :meth:`subprocess.Popen.kill`

##### send_signal

Send a signal to the subprocess.

.. seealso:: :meth:`subprocess.Popen.send_signal`

:param signal: the signal number (e.g. :data:`signal.SIGHUP`)

**Param√®tres :**

- `signal`

##### pid

The process ID of the process.

##### returncode

The return code of the process. If the process has not yet terminated, this will
be ``None``.

##### stdin

The stream for the standard input of the process.

##### stdout

The stream for the standard output of the process.

##### stderr

The stream for the standard error output of the process.

---

### _tasks

#### Classes

##### TaskStatus

**M√©thodes :**

- `started()`
- `started()`
- `started()`

##### TaskGroup

Groups several asynchronous tasks together.

:ivar cancel_scope: the cancel scope inherited by all child tasks
:vartype cancel_scope: CancelScope

.. note:: On asyncio, support for eager task factories is considered to be
    **experimental**. In particular, they don't follow the usual semantics of new
    tasks being scheduled on the next iteration of the event loop, and may thus
    cause unexpected behavior in code that wasn't written with such semantics in
    mind.

**M√©thodes :**

- `start_soon()`

#### Fonctions

##### started

##### started

**Param√®tres :**

- `value`

##### started

Signal that the task has started.

:param value: object passed back to the starter of the task

**Param√®tres :**

- `value`

##### start_soon

Start a new task in this task group.

:param func: a coroutine function
:param args: positional arguments to call the function with
:param name: name of the task, for the purposes of introspection and debugging

.. versionadded:: 3.0

**Param√®tres :**

- `func`

---

### _testing

#### Classes

##### TestRunner

Encapsulates a running event loop. Every call made through this object will use the
same event loop.

**M√©thodes :**

- `__enter__()`
- `__exit__()`
- `run_asyncgen_fixture()`
- `run_fixture()`
- `run_test()`

#### Fonctions

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### run_asyncgen_fixture

Run an async generator fixture.

:param fixture_func: the fixture function
:param kwargs: keyword arguments to call the fixture function with
:return: an iterator yielding the value yielded from the async generator

**Param√®tres :**

- `fixture_func`
- `kwargs`

##### run_fixture

Run an async fixture.

:param fixture_func: the fixture function
:param kwargs: keyword arguments to call the fixture function with
:return: the return value of the fixture function

**Param√®tres :**

- `fixture_func`
- `kwargs`

##### run_test

Run an async test function.

:param test_func: the test function
:param kwargs: keyword arguments to call the test function with

**Param√®tres :**

- `test_func`
- `kwargs`

---

### buffered

#### Classes

##### BufferedByteReceiveStream

Wraps any bytes-based receive stream and uses a buffer to provide sophisticated
receiving capabilities in the form of a byte stream.

**M√©thodes :**

- `buffer()`
- `extra_attributes()`

#### Fonctions

##### buffer

The bytes currently in the buffer.

##### extra_attributes

---

### file

#### Classes

##### FileStreamAttribute

##### _BaseFileStream

**M√©thodes :**

- `__init__()`
- `extra_attributes()`

##### FileReadStream

A byte stream that reads from a file in the file system.

:param file: a file that has been opened for reading in binary mode

.. versionadded:: 3.0

##### FileWriteStream

A byte stream that writes to a file in the file system.

:param file: a file that has been opened for writing in binary mode

.. versionadded:: 3.0

#### Fonctions

##### __init__

**Param√®tres :**

- `file`

##### extra_attributes

---

### memory

#### Classes

##### MemoryObjectStreamStatistics

##### MemoryObjectItemReceiver

**M√©thodes :**

- `__repr__()`

##### MemoryObjectStreamState

**M√©thodes :**

- `statistics()`

##### MemoryObjectReceiveStream

**M√©thodes :**

- `__post_init__()`
- `receive_nowait()`
- `clone()`
- `close()`
- `statistics()`
- `__enter__()`
- `__exit__()`
- `__del__()`

##### MemoryObjectSendStream

**M√©thodes :**

- `__post_init__()`
- `send_nowait()`
- `clone()`
- `close()`
- `statistics()`
- `__enter__()`
- `__exit__()`
- `__del__()`

#### Fonctions

##### __repr__

##### statistics

##### __post_init__

##### receive_nowait

Receive the next item if it can be done without waiting.

:return: the received item
:raises ~anyio.ClosedResourceError: if this send stream has been closed
:raises ~anyio.EndOfStream: if the buffer is empty and this stream has been
    closed from the sending end
:raises ~anyio.WouldBlock: if there are no items in the buffer and no tasks
    waiting to send

##### clone

Create a clone of this receive stream.

Each clone can be closed separately. Only when all clones have been closed will
the receiving end of the memory stream be considered closed by the sending ends.

:return: the cloned stream

##### close

Close the stream.

This works the exact same way as :meth:`aclose`, but is provided as a special
case for the benefit of synchronous callbacks.

##### statistics

Return statistics about the current state of this stream.

.. versionadded:: 3.0

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __del__

##### __post_init__

##### send_nowait

Send an item immediately if it can be done without waiting.

:param item: the item to send
:raises ~anyio.ClosedResourceError: if this send stream has been closed
:raises ~anyio.BrokenResourceError: if the stream has been closed from the
    receiving end
:raises ~anyio.WouldBlock: if the buffer is full and there are no tasks waiting
    to receive

**Param√®tres :**

- `item`

##### clone

Create a clone of this send stream.

Each clone can be closed separately. Only when all clones have been closed will
the sending end of the memory stream be considered closed by the receiving ends.

:return: the cloned stream

##### close

Close the stream.

This works the exact same way as :meth:`aclose`, but is provided as a special
case for the benefit of synchronous callbacks.

##### statistics

Return statistics about the current state of this stream.

.. versionadded:: 3.0

##### __enter__

##### __exit__

**Param√®tres :**

- `exc_type`
- `exc_val`
- `exc_tb`

##### __del__

---

### stapled

#### Classes

##### StapledByteStream

Combines two byte streams into a single, bidirectional byte stream.

Extra attributes will be provided from both streams, with the receive stream
providing the values in case of a conflict.

:param ByteSendStream send_stream: the sending byte stream
:param ByteReceiveStream receive_stream: the receiving byte stream

**M√©thodes :**

- `extra_attributes()`

##### StapledObjectStream

Combines two object streams into a single, bidirectional object stream.

Extra attributes will be provided from both streams, with the receive stream
providing the values in case of a conflict.

:param ObjectSendStream send_stream: the sending object stream
:param ObjectReceiveStream receive_stream: the receiving object stream

**M√©thodes :**

- `extra_attributes()`

##### MultiListener

Combines multiple listeners into one, serving connections from all of them at once.

Any MultiListeners in the given collection of listeners will have their listeners
moved into this one.

Extra attributes are provided from each listener, with each successive listener
overriding any conflicting attributes from the previous one.

:param listeners: listeners to serve
:type listeners: Sequence[Listener[T_Stream]]

**M√©thodes :**

- `__post_init__()`
- `extra_attributes()`

#### Fonctions

##### extra_attributes

##### extra_attributes

##### __post_init__

##### extra_attributes

---

### text

#### Classes

##### TextReceiveStream

Stream wrapper that decodes bytes to strings using the given encoding.

Decoding is done using :class:`~codecs.IncrementalDecoder` which returns any
completely received unicode characters as soon as they come in.

:param transport_stream: any bytes-based receive stream
:param encoding: character encoding to use for decoding bytes to strings (defaults
    to ``utf-8``)
:param errors: handling scheme for decoding errors (defaults to ``strict``; see the
    `codecs module documentation`_ for a comprehensive list of options)

.. _codecs module documentation:
    https://docs.python.org/3/library/codecs.html#codec-objects

**M√©thodes :**

- `__post_init__()`
- `extra_attributes()`

##### TextSendStream

Sends strings to the wrapped stream as bytes using the given encoding.

:param AnyByteSendStream transport_stream: any bytes-based send stream
:param str encoding: character encoding to use for encoding strings to bytes
    (defaults to ``utf-8``)
:param str errors: handling scheme for encoding errors (defaults to ``strict``; see
    the `codecs module documentation`_ for a comprehensive list of options)

.. _codecs module documentation:
    https://docs.python.org/3/library/codecs.html#codec-objects

**M√©thodes :**

- `__post_init__()`
- `extra_attributes()`

##### TextStream

A bidirectional stream that decodes bytes to strings on receive and encodes strings
to bytes on send.

Extra attributes will be provided from both streams, with the receive stream
providing the values in case of a conflict.

:param AnyByteStream transport_stream: any bytes-based stream
:param str encoding: character encoding to use for encoding/decoding strings to/from
    bytes (defaults to ``utf-8``)
:param str errors: handling scheme for encoding errors (defaults to ``strict``; see
    the `codecs module documentation`_ for a comprehensive list of options)

.. _codecs module documentation:
    https://docs.python.org/3/library/codecs.html#codec-objects

**M√©thodes :**

- `__post_init__()`
- `extra_attributes()`

#### Fonctions

##### __post_init__

**Param√®tres :**

- `encoding`
- `errors`

##### extra_attributes

##### __post_init__

**Param√®tres :**

- `encoding`

##### extra_attributes

##### __post_init__

**Param√®tres :**

- `encoding`
- `errors`

##### extra_attributes

---

### tls

#### Classes

##### TLSAttribute

Contains Transport Layer Security related attributes.

##### TLSStream

A stream wrapper that encrypts all sent data and decrypts received data.

This class has no public initializer; use :meth:`wrap` instead.
All extra attributes from :class:`~TLSAttribute` are supported.

:var AnyByteStream transport_stream: the wrapped stream

**M√©thodes :**

- `extra_attributes()`

##### TLSListener

A convenience listener that wraps another listener and auto-negotiates a TLS session
on every accepted connection.

If the TLS handshake times out or raises an exception,
:meth:`handle_handshake_error` is called to do whatever post-mortem processing is
deemed necessary.

Supports only the :attr:`~TLSAttribute.standard_compatible` extra attribute.

:param Listener listener: the listener to wrap
:param ssl_context: the SSL context object
:param standard_compatible: a flag passed through to :meth:`TLSStream.wrap`
:param handshake_timeout: time limit for the TLS handshake
    (passed to :func:`~anyio.fail_after`)

**M√©thodes :**

- `extra_attributes()`

#### Fonctions

##### extra_attributes

##### extra_attributes

---

### ai_robust

Module IA robuste pour Athalia - Version corrig√©e
Gestion des mod√®les IA avec fallback intelligent

#### Classes

##### AIModel

Mod√®les IA disponibles.

##### PromptContext

Contextes de prompts.

##### RobustAI

Gestionnaire IA robuste avec fallback intelligent.

**M√©thodes :**

- `__init__()`
- `generate_blueprint()`
- `_extract_project_name()`
- `review_code()`
- `generate_documentation()`
- `classify_project_complexity()`
- `get_dynamic_prompt()`
- `_get_dynamic_prompt()`
- `_classify_project_complexity()`
- `generate_bluelogger()`
- `_detect_available_models()`
- `_build_fallback_chain()`
- `_load_prompt_templates()`
- `generate_response()`
- `_call_model()`
- `_call_ollama()`
- `_mock_response()`

##### BlueprintProxy

**M√©thodes :**

- `__init__()`
- `info()`

#### Fonctions

##### robust_ai

Fonction factory pour cr√©er une instance RobustAI.

##### fallback_ia

Fallback IA multi-mod√®les (Qwen, Mistral, Ollama, Claude, GPT, Mock...).

**Param√®tres :**

- `prompt`
- `models`

##### query_qwen

Appel local √† Qwen 7B via Ollama.

**Param√®tres :**

- `prompt`

##### query_mistral

Appel local √† Mistral 7B via Ollama.

**Param√®tres :**

- `prompt`

##### __init__

Initialise le gestionnaire IA.

##### generate_blueprint

G√©n√®re un blueprint de projet √† partir d'une id√©e.

**Param√®tres :**

- `idea`

##### _extract_project_name

Extrait un nom de projet de l'id√©e.

**Param√®tres :**

- `idea`

##### review_code

G√©n√®re une revue de code mock√©e.

**Param√®tres :**

- `code`
- `filename`
- `project_type`
- `current_score`

##### generate_documentation

G√©n√®re une documentation technique mock√©e.

**Param√®tres :**

- `project_name`
- `project_type`
- `modules`

##### classify_project_complexity

Classifie la complexit√© d'un projet (mock).

**Param√®tres :**

- `codebase_path`

##### get_dynamic_prompt

Retourne un prompt dynamique mock√© selon le contexte.

**Param√®tres :**

- `context`

##### _get_dynamic_prompt

Alias priv√© pour compatibilit√© avec les tests.

**Param√®tres :**

- `context`

##### _classify_project_complexity

Alias priv√© pour compatibilit√© avec les tests.

**Param√®tres :**

- `codebase_path`

##### generate_bluelogger

Proxy pour compatibilit√© avec les tests.

##### _detect_available_models

D√©tecte les mod√®les IA disponibles.

##### _build_fallback_chain

Construit la cha√Æne de fallback.

##### _load_prompt_templates

Charge les templates de prompts dynamiques.

##### generate_response

G√©n√®re une r√©ponse IA robuste avec fallback.

**Param√®tres :**

- `context`
- `distillation`

##### _call_model

Appelle un mod√®le IA sp√©cifique.

**Param√®tres :**

- `model`
- `prompt`

##### _call_ollama

Appelle Ollama avec un mod√®le sp√©cifique.

**Param√®tres :**

- `model_name`
- `prompt`
- `timeout`

##### _mock_response

R√©ponse mock pour les tests.

**Param√®tres :**

- `prompt`

##### __init__

**Param√®tres :**

- `parent`

##### info

---

### advanced_analytics

#### Classes

##### AdvancedAnalytics

**M√©thodes :**

- `__init__()`
- `run()`
- `_analyze_complexity()`
- `_calculate_complexity()`
- `_analyze_coverage()`
- `_analyze_performance()`
- `_analyze_quality()`
- `_analyze_evolution()`
- `_generate_dashboard()`
- `_generate_summary()`
- `print_report()`

#### Fonctions

##### enrich_genesis_md

**Param√®tres :**

- `outdir`
- `infos`
- `perf_log`
- `test_log`

##### __init__

**Param√®tres :**

- `project_path`

##### run

Lance lanalyse compl√®te du projet

##### _analyze_complexity

Analyse la complexit√© du projet

##### _calculate_complexity

Calcule la complexit√© cyclomatique dun fichier

**Param√®tres :**

- `tree`

##### _analyze_coverage

Analyse la couverture du projet

##### _analyze_performance

Analyse les m√©triques de performance du projet

##### _analyze_quality

Analyse la qualit√© du projet

##### _analyze_evolution

Analyse l√©volution du projet

##### _generate_dashboard

G√©n√®re un dashboard HTML

##### _generate_summary

G√©n√®re un r√©sum√© des m√©triques

##### print_report

Affiche le rapport danalyse

---

### analytics

üìä MODULE ANALYTICS ATHALIA
===========================
Module d'analyse et de m√©triques de projets.
Fournit des analyses de base pour les tests.

#### Fonctions

##### analyze_project

Analyser un projet et retourner des m√©triques de base

**Param√®tres :**

- `project_path`

##### generate_heatmap_data

G√©n√©rer des donn√©es pour une heatmap de complexit√©

**Param√®tres :**

- `project_path`

##### generate_technical_debt_analysis

Analyser la dette technique du projet

**Param√®tres :**

- `project_path`

##### generate_analytics_html

G√©n√©rer un rapport HTML danalytics

**Param√®tres :**

- `project_path`

---

### architecture_analyzer

üèóÔ∏è ANALYSEUR D'ARCHITECTURE
============================
Module d'analyse d'architecture pour comprendre la structure
du projet, les d√©pendances et les relations entre modules.

#### Classes

##### ModuleAnalysis

Analyse d'un module

##### PerformanceIssue

Probl√®me de performance

##### ArchitectureMapping

Mapping de l'architecture compl√®te

##### ArchitectureAnalyzer

Analyseur d'architecture pour comprendre la structure du projet

**M√©thodes :**

- `__init__()`
- `_init_database()`
- `_load_config()`
- `analyze_entire_architecture()`
- `_analyze_all_modules()`
- `_analyze_single_module()`
- `_extract_dependencies()`
- `_detect_module_issues()`
- `_calculate_performance_score()`
- `_detect_duplicates()`
- `_analyze_performance()`
- `_build_dependency_graph()`
- `_generate_recommendations()`
- `_save_architecture_analysis()`
- `get_optimization_plan()`
- `generate_intelligent_coordination()`

#### Fonctions

##### __init__

**Param√®tres :**

- `root_path`

##### _init_database

Initialiser la base de donn√©es d'architecture

##### _load_config

Charger la configuration

##### analyze_entire_architecture

Analyser l'architecture compl√®te du projet

##### _analyze_all_modules

Analyser tous les modules du projet

##### _analyze_single_module

Analyser un module individuel

**Param√®tres :**

- `file_path`
- `module_type`

##### _extract_dependencies

Extraire les d√©pendances d'un module

**Param√®tres :**

- `imports`
- `module_type`

##### _detect_module_issues

D√©tecter les probl√®mes dans un module

**Param√®tres :**

- `file_analysis`

##### _calculate_performance_score

Calculer un score de performance pour un module

**Param√®tres :**

- `file_analysis`

##### _detect_duplicates

D√©tecter les doublons entre modules

**Param√®tres :**

- `modules`

##### _analyze_performance

Analyser les probl√®mes de performance

**Param√®tres :**

- `modules`

##### _build_dependency_graph

Construire le graphe de d√©pendances

**Param√®tres :**

- `modules`

##### _generate_recommendations

G√©n√©rer des recommandations d'architecture

**Param√®tres :**

- `modules`
- `duplicates`
- `performance_issues`

##### _save_architecture_analysis

Sauvegarder l'analyse d'architecture

**Param√®tres :**

- `architecture`

##### get_optimization_plan

Obtenir un plan d'optimisation bas√© sur l'analyse

##### generate_intelligent_coordination

G√©n√©rer des recommandations de coordination intelligente

---

### ast_analyzer

üîç ANALYSEUR AST DE BASE
========================
Module d'analyse AST pour extraire les informations de base
des fichiers Python. Utilis√© par les autres modules d'analyse.

#### Classes

##### ASTNodeInfo

Informations extraites d'un n≈ìud AST

##### FileAnalysis

Analyse compl√®te d'un fichier Python

##### ASTAnalyzer

Analyseur AST de base pour extraire les informations structurelles

**M√©thodes :**

- `__init__()`
- `analyze_file()`
- `_extract_functions()`
- `_extract_classes()`
- `_extract_conditionals()`
- `_extract_loops()`
- `_extract_imports()`
- `_create_function_signature()`
- `_create_class_signature()`
- `_create_conditional_signature()`
- `_create_loop_signature()`
- `_extract_node_content()`
- `_normalize_code()`
- `_calculate_node_complexity()`
- `_calculate_complexity()`

#### Fonctions

##### __init__

##### analyze_file

Analyser un fichier Python et extraire toutes les informations

**Param√®tres :**

- `file_path`

##### _extract_functions

Extraire toutes les fonctions du fichier

**Param√®tres :**

- `tree`
- `content`
- `file_path`

##### _extract_classes

Extraire toutes les classes du fichier

**Param√®tres :**

- `tree`
- `content`
- `file_path`

##### _extract_conditionals

Extraire toutes les structures conditionnelles

**Param√®tres :**

- `tree`
- `content`
- `file_path`

##### _extract_loops

Extraire toutes les boucles

**Param√®tres :**

- `tree`
- `content`
- `file_path`

##### _extract_imports

Extraire tous les imports

**Param√®tres :**

- `tree`

##### _create_function_signature

Cr√©er une signature unique pour une fonction

**Param√®tres :**

- `node`
- `code`

##### _create_class_signature

Cr√©er une signature unique pour une classe

**Param√®tres :**

- `node`
- `code`

##### _create_conditional_signature

Cr√©er une signature unique pour une condition

**Param√®tres :**

- `node`
- `code`

##### _create_loop_signature

Cr√©er une signature unique pour une boucle

**Param√®tres :**

- `node`
- `code`

##### _extract_node_content

Extraire le contenu d'un n≈ìud AST

**Param√®tres :**

- `node`
- `code`

##### _normalize_code

Normaliser le code pour la comparaison

**Param√®tres :**

- `code`

##### _calculate_node_complexity

Calculer la complexit√© cyclomatique d'un n≈ìud

**Param√®tres :**

- `node`

##### _calculate_complexity

Calculer la complexit√© globale d'un arbre AST

**Param√®tres :**

- `tree`

---

### audit

Fichier de compatibilit√© pour laudit
Redirige vers intelligent_auditor.py pour maintenir la compatibilit√©

#### Classes

##### ProjectAuditor

Alias pour compatibilit√© avec lancien audit.py

**M√©thodes :**

- `__init__()`
- `audit_project()`

##### Audit

Alias pour compatibilit√© avec les tests

**M√©thodes :**

- `__init__()`
- `audit_project()`

#### Fonctions

##### audit_project_intelligent

Fonction de compatibilit√© pour audit_project_intelligent

**Param√®tres :**

- `project_path`

##### generate_audit_report

Fonction de compatibilit√© pour generate_audit_report

**Param√®tres :**

- `project_path`

##### __init__

**Param√®tres :**

- `project_path`

##### audit_project

M√©thode de compatibilit√©

##### __init__

**Param√®tres :**

- `project_path`

##### audit_project

M√©thode de compatibilit√©

---

### auto_cicd

#### Classes

##### AutoCICD

G√©n√©rateur de CI / CD

**M√©thodes :**

- `__init__()`
- `setup_cicd()`
- `_analyze_project()`
- `_detect_project_type()`
- `_detect_languages()`
- `_extract_dependencies()`
- `_find_entry_points()`
- `_has_tests()`
- `_has_documentation()`
- `_generate_github_actions()`
- `_generate_docker_config()`
- `_generate_deployment_config()`
- `_save_cicd_configs()`
- `_get_created_files()`

#### Fonctions

##### generate_github_ci_yaml

**Param√®tres :**

- `outdir`

##### __init__

##### setup_cicd

Configuration compl√®te CI / CD pour un projet

**Param√®tres :**

- `project_path`

##### _analyze_project

Analyse du projet pour la CI/CD

##### _detect_project_type

D√©tection du type de projet

##### _detect_languages

D√©tection des langages du projet

##### _extract_dependencies

Extraction des d√©pendances du projet

##### _find_entry_points

Trouve les points dentr√©e du projet

##### _has_tests

V√©rifie si le projet a des tests

##### _has_documentation

V√©rifie si le projet a de la documentation

##### _generate_github_actions

G√©n√®re les workflows GitHub Actions

##### _generate_docker_config

G√©n√®re la configuration Docker

##### _generate_deployment_config

G√©n√®re la configuration de d√©ploiement

##### _save_cicd_configs

**Param√®tres :**

- `github_actions`
- `docker_config`
- `deployment_config`

##### _get_created_files

---

### auto_cleaner

#### Classes

##### AutoCleaner

Nettoyeur automatique pour Athalia

**M√©thodes :**

- `__init__()`
- `clean_project()`
- `run()`
- `_clean_system_files()`
- `_clean_cache_files()`
- `_clean_backup_files()`
- `_clean_temp_files()`
- `_clean_duplicate_files()`
- `_clean_empty_directories()`
- `_clean_old_files()`
- `_clean_large_files()`
- `_safe_remove_file()`
- `_safe_remove_dir()`
- `_is_code_file()`
- `_is_important_file()`
- `_is_empty_directory()`
- `_calculate_file_hash()`
- `_generate_cleanup_report()`
- `_generate_summary()`
- `optimize_project_structure()`
- `_organize_files()`

#### Fonctions

##### main

Point dentr√©e du module AutoCleaner

##### __init__

**Param√®tres :**

- `project_path`

##### clean_project

Nettoyage complet dun projet

**Param√®tres :**

- `dry_run`

##### run

M√©thode run() pour lorchestrateur - ex√©cute le nettoyage

##### _clean_system_files

Nettoyage des fichiers syst√®me

**Param√®tres :**

- `project_path`

##### _clean_cache_files

Nettoyage des fichiers de cache

**Param√®tres :**

- `project_path`

##### _clean_backup_files

Nettoyage des fichiers de sauvegarde

**Param√®tres :**

- `project_path`

##### _clean_temp_files

Nettoyage des fichiers temporaires

**Param√®tres :**

- `project_path`

##### _clean_duplicate_files

Nettoyage des fichiers dupliqu√©s

**Param√®tres :**

- `project_path`

##### _clean_empty_directories

Nettoyage des r√©pertoires vides

**Param√®tres :**

- `project_path`

##### _clean_old_files

Nettoyage des fichiers anciens

**Param√®tres :**

- `project_path`

##### _clean_large_files

Nettoyage des fichiers volumineux

**Param√®tres :**

- `project_path`

##### _safe_remove_file

Suppression s√©curis√©e dun fichier

**Param√®tres :**

- `file_path`
- `reason`

##### _safe_remove_dir

Suppression s√©curis√©e dun r√©pertoire

**Param√®tres :**

- `dir_path`
- `reason`

##### _is_code_file

D√©termine si un fichier est un fichier de code

**Param√®tres :**

- `file_path`

##### _is_important_file

D√©termine si un fichier est important (ex: config, requirements, etc.)

**Param√®tres :**

- `file_path`

##### _is_empty_directory

V√©rifie si un r√©pertoire est vide

**Param√®tres :**

- `dir_path`

##### _calculate_file_hash

Calcule le hash dun fichier

**Param√®tres :**

- `file_path`

##### _generate_cleanup_report

G√©n√®re le rapport de nettoyage

##### _generate_summary

G√©n√®re un r√©sum√© du nettoyage

##### optimize_project_structure

Optimise la structure du projet

**Param√®tres :**

- `project_path`

##### _organize_files

Organise les fichiers dans la structure du projet

**Param√®tres :**

- `project_path`
- `optimizations`

---

### auto_tester

#### Classes

##### AutoTester

G√©n√©rateur de tests pour Athalia

**M√©thodes :**

- `__init__()`
- `run()`
- `generate_tests()`
- `_analyze_modules()`
- `_generate_unit_tests()`
- `_generate_module_unit_tests()`
- `_generate_integration_tests()`
- `_generate_performance_tests()`
- `_save_tests()`
- `_cleanup_generated_tests()`
- `_run_tests()`
- `_get_created_files()`
- `generate_test_report()`

#### Fonctions

##### main

Point dentr√©e principal

##### __init__

**Param√®tres :**

- `project_path`

##### run

M√©thode run() pour lorchestrateur - ex√©cute les tests

##### generate_tests

G√©n√©ration compl√®te de tests pour un projet

**Param√®tres :**

- `project_path`

##### _analyze_modules

Analyse les modules Python du projet

##### _generate_unit_tests

G√©n√®re les tests f

**Param√®tres :**

- `modules`

##### _generate_module_unit_tests

G√©n√®re les tests unitaires pour un module

**Param√®tres :**

- `module`

##### _generate_integration_tests

G√©n√®re les tests dint√©gration

**Param√®tres :**

- `modules`

##### _generate_performance_tests

G√©n√®re les tests de performance

**Param√®tres :**

- `modules`

##### _save_tests

Sauvegarde les tests f

**Param√®tres :**

- `unit_tests`
- `integration_tests`
- `performance_tests`

##### _cleanup_generated_tests

Nettoie les fichiers de tests auto-g√©n√©r√©s apr√®s ex√©cution

##### _run_tests

Ex√©cute les tests g√©n√©r√©s et collecte les r√©sultats

##### _get_created_files

Retourne la liste des fichiers cr√©√©s

##### generate_test_report

G√©n√®re un rapport de tests

---

### auto_documenter

#### Classes

##### AutoDocumenter

G√©n√©rateur de documentation automatique

**M√©thodes :**

- `__init__()`
- `_load_translations()`
- `run()`
- `document_project()`
- `_analyze_project()`
- `_extract_description()`
- `_extract_version()`
- `_extract_author()`
- `_extract_license()`
- `_extract_dependencies()`
- `_find_entry_points()`
- `_analyze_modules()`
- `_analyze_classes()`
- `_analyze_functions()`
- `_generate_readme()`
- `_generate_api_documentation()`
- `_generate_setup_guide()`
- `_generate_usage_guide()`
- `_save_documents()`
- `_get_created_files()`

#### Fonctions

##### main

Point dentr√©e du script

##### __init__

**Param√®tres :**

- `project_path`
- `lang`

##### _load_translations

**Param√®tres :**

- `lang`

##### run

M√©thode run() pour lorchestrateur - ex√©cute la documentation

##### document_project

Documentation compl√®te dun projet

**Param√®tres :**

- `project_path`

##### _analyze_project

Analyse du projet pour la documentation

##### _extract_description

Extrait la description du projet

##### _extract_version

Extrait la version du projet

##### _extract_author

Extrait lauteur du projet

##### _extract_license

Extrait la licence du projet

##### _extract_dependencies

Extrait les d√©pendances du projet

##### _find_entry_points

Trouve les points dentr√©e du projet

##### _analyze_modules

Analyse les modules du projet

##### _analyze_classes

Analyse les classes du projet

**Param√®tres :**

- `modules`

##### _analyze_functions

Analyse les fonctions du projet

**Param√®tres :**

- `modules`

##### _generate_readme

G√©n√®re le README du projet

##### _generate_api_documentation

G√©n√®re la documentation API du projet

##### _generate_setup_guide

G√©n√®re le guide dinstallation du projet

##### _generate_usage_guide

G√©n√®re le guide dutilisation du projet

##### _save_documents

Sauvegarde les documents g√©n√©r√©s

**Param√®tres :**

- `readme`
- `api_docs`
- `setup_guide`
- `usage_guide`

##### _get_created_files

---

### ai_robust_broken

Module IA robuste pour Athalia
Gestion des mod√®les IA avec fallback intelligent

#### Classes

##### AIModel

Mod√®les IA disponibles.

##### PromptContext

Contextes de prompts.

##### RobustAI

Gestionnaire IA robuste avec fallback intelligent.

**M√©thodes :**

- `__init__()`
- `generate_blueprint()`
- `_extract_project_name()`
- `review_code()`
- `generate_documentation()`
- `classify_project_complexity()`
- `get_dynamic_prompt()`
- `generate_bluelogger()`
- `generate_blueprint_mock()`
- `save_blueprint()`
- `scan_existing_project()`
- `_detect_available_models()`
- `_build_fallback_chain()`
- `_load_prompt_templates()`
- `generate_response()`
- `_call_model()`
- `_classify_project_complexity()`
- `_get_dynamic_prompt()`
- `_call_ollama()`
- `_mock_response()`

##### _BlueprintProxy

**M√©thodes :**

- `__init__()`
- `info()`

#### Fonctions

##### robust_ai

Fonction factory pour cr√©er une instance RobustAI.

##### fallback_ia

Fallback IA multi-mod√®les (Qwen, Mistral, Ollama, Claude, GPT, Mock...)

**Param√®tres :**

- `prompt`
- `models`

##### query_qwen

Appel local √† Qwen 7B via Ollama.

**Param√®tres :**

- `prompt`

##### query_mistral

Appel local √† Mistral 7B via Ollama.

**Param√®tres :**

- `prompt`

##### __init__

Initialise le gestionnaire IA.

##### generate_blueprint

G√©n√®re un blueprint de projet √† partir dune id√©e.

**Param√®tres :**

- `idea`

##### _extract_project_name

Extrait un nom de projet de lid√©e

**Param√®tres :**

- `idea`

##### review_code

G√©n√®re une revue de code mock√©e.

**Param√®tres :**

- `code`
- `filename`
- `project_type`
- `current_score`

##### generate_documentation

G√©n√®re une documentation technique mock√©e.

**Param√®tres :**

- `project_name`
- `project_type`
- `modules`

##### classify_project_complexity

Classifie la complexit√© dun projet (mock).

**Param√®tres :**

- `codebase_path`

##### get_dynamic_prompt

Retourne un prompt dynamique mock√© selon le contexte.

**Param√®tres :**

- `context`

##### generate_bluelogger

##### generate_blueprint_mock

##### save_blueprint

##### scan_existing_project

##### _detect_available_models

D√©tecte les mod√®les IA disponibles.

##### _build_fallback_chain

Construit la cha√Æne de fallback.

##### _load_prompt_templates

Charge les templates de prompts dynamiques.

##### generate_response

G√©n√®re une r√©ponse IA robuste avec fallback.

**Param√®tres :**

- `context`
- `distillation`

##### _call_model

Appelle un mod√®le IA sp√©cifique.

**Param√®tres :**

- `model`
- `prompt`

##### _classify_project_complexity

Alias priv√© pour compatibilit√© avec les tests.

**Param√®tres :**

- `codebase_path`

##### _get_dynamic_prompt

Alias priv√© pour compatibilit√© avec les tests.
Accepte PromptContext ou str et fait un .format sur le template.

**Param√®tres :**

- `context`

##### _call_ollama

Appelle Ollama avec un mod√®le sp√©cifique et timeout param√©trable.

**Param√®tres :**

- `model_name`
- `prompt`
- `timeout`

##### _mock_response

R√©ponse mock pour les tests.

**Param√®tres :**

- `prompt`

##### __init__

**Param√®tres :**

- `parent`

##### info

---

### autocomplete_engine

#### Classes

##### BaseAutocompleteEngine

**M√©thodes :**

- `suggest()`

##### SimpleAutocompleteEngine

**M√©thodes :**

- `suggest()`

##### OllamaAutocompleteEngine

**M√©thodes :**

- `__init__()`
- `suggest()`

#### Fonctions

##### suggest

Retourne une liste de suggestions d'autocompl√©tion pour un prompt donn√©.

**Param√®tres :**

- `prompt`
- `max_suggestions`

##### suggest

**Param√®tres :**

- `prompt`
- `max_suggestions`

##### __init__

**Param√®tres :**

- `model_name`
- `host`

##### suggest

**Param√®tres :**

- `prompt`
- `max_suggestions`

---

### autocomplete_server

#### Classes

##### AutocompleteRequest

##### AutocompleteResponse

#### Fonctions

##### get_engine

##### autocomplete

**Param√®tres :**

- `request`

---

### ci

#### Fonctions

##### generate_github_ci_yaml

**Param√®tres :**

- `outdir`

##### add_coverage_badge

**Param√®tres :**

- `outdir`

---

### code_linter

#### Classes

##### CodeLinter

Linter de code pour Athalia

**M√©thodes :**

- `__init__()`
- `run()`
- `_run_flake8()`
- `_run_black()`
- `_run_isort()`
- `_run_mypy()`
- `_run_bandit()`
- `_calculate_score()`
- `print_report()`

#### Fonctions

##### __init__

**Param√®tres :**

- `project_path`
- `auto_fix`

##### run

Lance lanalyse de qualit√© du projet

##### _run_flake8

Ex√©cution de Flake8

##### _run_black

Ex√©cution de Black

##### _run_isort

Ex√©cution de isort

##### _run_mypy

Ex√©cution de MyPy

##### _run_bandit

Ex√©cution de Bandit pour la s√©curit√©

##### _calculate_score

Calcul du score de qualit√©

##### print_report

Affichage du rapport de linting

---

### cleanup

#### Fonctions

##### clean_old_tests_and_caches

Supprime les anciens fichiers de test non-suffix√©s et les caches Python dans le projet cible.
Log chaque suppression pour audit. Retourne la liste des fichiers supprim√©s.

**Param√®tres :**

- `outdir`

##### clean_macos_files

Supprime automatiquement les fichiers macOS parasites et temporaires dans tout le projet.
Inclut les fichiers syst√®me macOS sp√©cifiques comme .!44956!*.clean
Retourne la liste des fichiers supprim√©s.

**Param√®tres :**

- `directory`

---

### cli

Interface CLI pour Athalia avec IA robuste.

#### Fonctions

##### cli

Athalia-G√©n√©rateur de projets IA intelligent.

**Param√®tres :**

- `verbose`

##### generate

G√©n√®re un projet complet √† partir dune id√©e.

**Param√®tres :**

- `idea`
- `output`
- `dry_run`

##### audit

Audit intelligent dun projet existant.

**Param√®tres :**

- `project_path`

##### ai_status

Affiche le statut de lIA robuste.

##### test_ai

Teste lIA robuste avec une id√©e de projet.

**Param√®tres :**

- `idea`

---

### dashboard

#### Fonctions

##### show_benchmarks

##### main

---

### generation

Module de g√©n√©ration simplifi√© pour Athalia
Version simplifi√©e sans f-strings complexes

#### Fonctions

##### generate_blueprint_mock

G√©n√®re un blueprint mock pour les tests.

**Param√®tres :**

- `idea`

##### extract_project_name

Extrait un nom de projet de l'id√©e.

**Param√®tres :**

- `idea`

##### generate_project

G√©n√®re un projet √† partir d'un blueprint.

**Param√®tres :**

- `blueprint`
- `outdir`

##### generate_readme

G√©n√®re un README basique.

**Param√®tres :**

- `blueprint`
- `project_path`

##### generate_main_code

G√©n√®re le code principal.

**Param√®tres :**

- `blueprint`
- `project_path`

##### generate_test_code

G√©n√®re le code de test.

**Param√®tres :**

- `blueprint`
- `project_path`

##### generate_requirements

G√©n√®re un fichier requirements.txt basique.

**Param√®tres :**

- `blueprint`
- `project_path`

##### save_blueprint

Sauvegarde un blueprint dans un fichier YAML.

**Param√®tres :**

- `blueprint`
- `outdir`

##### inject_booster_ia_elements

Injecte les √©l√©ments Booster IA.

**Param√®tres :**

- `outdir`

##### scan_existing_project

Scanne un projet existant.

**Param√®tres :**

- `outdir`

##### merge_or_suffix_file

Fusionne ou suffixe un fichier.

**Param√®tres :**

- `file_path`
- `content`
- `file_type`
- `section_header`

##### backup_file

Cr√©e une sauvegarde d'un fichier.

**Param√®tres :**

- `file_path`

##### generate_api_docs

G√©n√®re la documentation API.

**Param√®tres :**

- `blueprint`

##### generate_dockerfile

G√©n√®re un Dockerfile.

**Param√®tres :**

- `blueprint`

##### generate_docker_compose

G√©n√®re un docker-compose.yml.

**Param√®tres :**

- `blueprint`

---

### config_manager

#### Classes

##### AthaliaConfig

Configuration centralis√©e d'f

##### ConfigManager

Gestionnaire de configuration f

**M√©thodes :**

- `__init__()`
- `_load_config()`
- `_merge_yaml_config()`
- `_merge_env_config()`
- `_setup_logging()`
- `get()`
- `is_module_enabled()`
- `get_enabled_plugins()`
- `get_available_templates()`
- `get_cleanup_patterns()`
- `set()`
- `validate_config()`
- `merge_configs()`
- `resolve_environment_variables()`
- `to_dict()`

#### Fonctions

##### load_config

Charge une configuration depuis un fichier YAML

Args:
    config_path: Chemin vers le fichier de configuration

Returns:
    Dict contenant la configuration charg√©e

**Param√®tres :**

- `config_path`

##### save_config

Sauvegarde une configuration vers un fichier YAML

Args:
    config: Configuration √† sauvegarder
    config_path: Chemin vers le fichier de destination

Returns:
    True si la sauvegarde a r√©ussi, False sinon

**Param√®tres :**

- `config`
- `config_path`

##### __init__

**Param√®tres :**

- `config_file`

##### _load_config

Charge la configuration depuis le fichier YAML et les variables d'f

##### _merge_yaml_config

Fusionne la configuration YAML avec la config par f

**Param√®tres :**

- `config`
- `yaml_data`

##### _merge_env_config

Surcharge la configuration avec les variables d'f

**Param√®tres :**

- `config`

##### _setup_logging

Configure le logging selon la f

##### get

R√©cup√®re une valeur de configuration

**Param√®tres :**

- `key`
- `default`

##### is_module_enabled

V√©rifie si un module est f

**Param√®tres :**

- `module_name`

##### get_enabled_plugins

R√©cup√®re la liste des plugins f

##### get_available_templates

R√©cup√®re la liste des templates f

##### get_cleanup_patterns

R√©cup√®re les patterns de f

##### set

D√©finit une valeur de configuration

**Param√®tres :**

- `key`
- `value`

##### validate_config

Valide une configuration

**Param√®tres :**

- `config`

##### merge_configs

Fusionne deux configurations

**Param√®tres :**

- `base_config`
- `override_config`

##### resolve_environment_variables

R√©sout les variables d'environnement dans une configuration

**Param√®tres :**

- `config`

##### to_dict

Convertit la configuration en f

---

### onboarding

Module onboarding, guides, scripts d'installation.

#### Fonctions

##### generate_onboarding_md

**Param√®tres :**

- `blueprint`
- `outdir`

##### generate_onboard_cli

**Param√®tres :**

- `blueprint`
- `outdir`

##### generate_onboarding_html_advanced

**Param√®tres :**

- `blueprint`
- `outdir`

---

### cache_manager

Gestionnaire de cache intelligent pour Athalia
Optimisation des performances avec cache LRU

#### Classes

##### AnalysisCache

Gestionnaire de cache intelligent pour les analyses.

**M√©thodes :**

- `__init__()`
- `_generate_cache_key()`
- `_get_cache_file_path()`
- `_is_cache_valid()`
- `get()`
- `set()`
- `_cleanup_cache()`
- `clear()`
- `get_stats()`

#### Fonctions

##### cached_analysis

D√©corateur pour mettre en cache les analyses.

Args:
    func: Fonction √† d√©corer
    
Returns:
    Fonction d√©cor√©e avec cache

**Param√®tres :**

- `func`

##### get_cache_stats

Retourne les statistiques du cache global.

Returns:
    Statistiques du cache

##### clear_cache

Vide le cache global.

##### cached_function

D√©corateur pour cache LRU simple.

Args:
    max_size: Taille maximale du cache
    
Returns:
    D√©corateur

**Param√®tres :**

- `max_size`

##### analyze_project_structure

Analyse la structure d'un projet (exemple).

Args:
    project_path: Chemin du projet
    detailed: Analyse d√©taill√©e
    
Returns:
    R√©sultat de l'analyse

**Param√®tres :**

- `project_path`
- `detailed`

##### __init__

Initialise le gestionnaire de cache.

Args:
    cache_dir: R√©pertoire de stockage du cache
    max_size: Taille maximale du cache en entr√©es
    ttl_hours: Dur√©e de vie du cache en heures

**Param√®tres :**

- `cache_dir`
- `max_size`
- `ttl_hours`

##### _generate_cache_key

G√©n√®re une cl√© de cache unique.

Args:
    project_path: Chemin du projet
    analysis_type: Type d'analyse
    **kwargs: Param√®tres suppl√©mentaires
    
Returns:
    Cl√© de cache unique

**Param√®tres :**

- `project_path`
- `analysis_type`

##### _get_cache_file_path

Retourne le chemin du fichier de cache.

**Param√®tres :**

- `cache_key`

##### _is_cache_valid

V√©rifie si le cache est encore valide.

Args:
    cache_file: Chemin du fichier de cache
    
Returns:
    True si le cache est valide

**Param√®tres :**

- `cache_file`

##### get

R√©cup√®re un r√©sultat du cache.

Args:
    project_path: Chemin du projet
    analysis_type: Type d'analyse
    **kwargs: Param√®tres suppl√©mentaires
    
Returns:
    R√©sultat du cache ou None si non trouv√©

**Param√®tres :**

- `project_path`
- `analysis_type`

##### set

Stocke un r√©sultat dans le cache.

Args:
    project_path: Chemin du projet
    analysis_type: Type d'analyse
    result: R√©sultat √† stocker
    **kwargs: Param√®tres suppl√©mentaires

**Param√®tres :**

- `project_path`
- `analysis_type`
- `result`

##### _cleanup_cache

Nettoie le cache en supprimant les entr√©es expir√©es.

##### clear

Vide compl√®tement le cache.

##### get_stats

Retourne les statistiques du cache.

Returns:
    Statistiques du cache

##### wrapper

**Param√®tres :**

- `project_path`

---

### correction_optimizer

Syst√®me d'optimisation de la correction automatique pour Athalia/Arkalia
Am√©liore le taux de r√©ussite de 80% √† 95%+ en utilisant des techniques avanc√©es

#### Classes

##### CorrectionResult

R√©sultat d'une correction

##### CorrectionOptimizer

Optimiseur de correction automatique avec techniques avanc√©es

**M√©thodes :**

- `__init__()`
- `optimize_correction()`
- `_apply_basic_corrections()`
- `_apply_ast_corrections()`
- `_apply_contextual_corrections()`
- `_analyze_syntax_error()`
- `_fix_indentation_error()`
- `_fix_bracket_balance()`
- `_fix_string_issues()`
- `_analyze_context()`
- `_validate_correction()`
- `_learn_from_correction()`
- `_extract_patterns()`
- `get_correction_stats()`

#### Fonctions

##### optimize_correction

Fonction utilitaire pour optimiser une correction

**Param√®tres :**

- `file_path`
- `content`

##### get_correction_stats

Fonction utilitaire pour obtenir les statistiques de correction

##### __init__

##### optimize_correction

Correction optimis√©e multi-passes avec apprentissage

**Param√®tres :**

- `file_path`
- `content`

##### _apply_basic_corrections

Applique les corrections basiques

**Param√®tres :**

- `content`

##### _apply_ast_corrections

Corrections bas√©es sur l'analyse AST

**Param√®tres :**

- `content`

##### _apply_contextual_corrections

Corrections contextuelles bas√©es sur l'analyse du code

**Param√®tres :**

- `content`

##### _analyze_syntax_error

Analyse une erreur de syntaxe pour d√©terminer le type de correction

**Param√®tres :**

- `error`
- `content`

##### _fix_indentation_error

Corrige les erreurs d'indentation

**Param√®tres :**

- `content`
- `error_info`

##### _fix_bracket_balance

Corrige les probl√®mes de parenth√®ses/accolades

**Param√®tres :**

- `content`
- `error_info`

##### _fix_string_issues

Corrige les probl√®mes de cha√Ænes de caract√®res

**Param√®tres :**

- `content`
- `error_info`

##### _analyze_context

Analyse le contexte du code pour les corrections contextuelles

**Param√®tres :**

- `lines`

##### _validate_correction

Valide que la correction a fonctionn√©

**Param√®tres :**

- `content`

##### _learn_from_correction

Apprend des corrections pour am√©liorer les futures corrections

**Param√®tres :**

- `file_path`
- `original`
- `corrected`
- `success`

##### _extract_patterns

Extrait des patterns de correction

**Param√®tres :**

- `original`
- `corrected`

##### get_correction_stats

R√©cup√®re les statistiques de correction

---

### intelligent_analyzer

üß† ANALYSEUR INTELLIGENT ATHALIA - ORCHESTRATEUR PRINCIPAL
==========================================================
Orchestrateur principal qui coordonne tous les modules d'analyse :
- AST Analyzer (analyse de base)
- Pattern Detector (d√©tection de patterns et doublons)
- Architecture Analyzer (analyse d'architecture)
- Performance Analyzer (analyse de performance)

#### Classes

##### ComprehensiveAnalysis

Analyse compl√®te du projet

##### IntelligentAnalyzer

Orchestrateur principal de l'analyse intelligente

**M√©thodes :**

- `__init__()`
- `analyze_project_comprehensive()`
- `_perform_ast_analysis()`
- `_calculate_overall_score()`
- `_generate_comprehensive_recommendations()`
- `_create_optimization_plan()`
- `_save_comprehensive_analysis()`
- `get_learning_insights()`
- `generate_intelligent_coordination()`
- `orchestrate_with_unified()`

#### Fonctions

##### main

Fonction principale pour l'analyse en ligne de commande

##### __init__

**Param√®tres :**

- `root_path`

##### analyze_project_comprehensive

Analyser un projet de mani√®re compl√®te avec tous les modules

**Param√®tres :**

- `project_path`

##### _perform_ast_analysis

Effectuer l'analyse AST de base

**Param√®tres :**

- `project_path`

##### _calculate_overall_score

Calculer le score global bas√© sur toutes les analyses

**Param√®tres :**

- `ast_analysis`
- `pattern_analysis`
- `architecture_analysis`
- `performance_analysis`

##### _generate_comprehensive_recommendations

G√©n√©rer des recommandations globales

**Param√®tres :**

- `pattern_analysis`
- `architecture_analysis`
- `performance_analysis`

##### _create_optimization_plan

Cr√©er un plan d'optimisation global

**Param√®tres :**

- `pattern_analysis`
- `architecture_analysis`
- `performance_analysis`

##### _save_comprehensive_analysis

Sauvegarder l'analyse compl√®te

**Param√®tres :**

- `analysis`

##### get_learning_insights

Obtenir des insights d'apprentissage de tous les modules

##### generate_intelligent_coordination

G√©n√©rer une coordination intelligente

##### orchestrate_with_unified

Utiliser l'orchestrateur unifi√© pour une orchestration compl√®te

**Param√®tres :**

- `project_path`
- `config`

---

### intelligent_auditor

#### Classes

##### IntelligentAuditor

Auditeur intelligent pour analyse automatique des projets

**M√©thodes :**

- `__init__()`
- `run()`
- `audit_project()`
- `_analyze_project_info()`
- `_detect_project_type()`
- `_calculate_project_size()`
- `_is_code_file()`
- `_detect_languages()`
- `_detect_dependencies()`
- `_get_last_modified()`
- `_analyze_code_quality()`
- `_analyze_complexity()`
- `_calculate_cyclomatic_complexity()`
- `_analyze_style()`
- `_analyze_code_documentation()`
- `_analyze_naming_conventions()`
- `_analyze_security()`
- `_detect_security_vulnerabilities()`
- `_detect_secrets()`
- `_analyze_permissions()`
- `_analyze_performance()`
- `_analyze_file_sizes()`
- `_analyze_imports()`
- `_estimate_memory_usage()`
- `_analyze_documentation()`
- `_check_readme()`
- `_check_api_documentation()`
- `_check_guides()`
- `_analyze_testing()`
- `_analyze_test_coverage()`
- `_find_test_files()`
- `_analyze_test_quality()`
- `_analyze_structure()`
- `_analyze_organization()`
- `_analyze_structure_naming()`
- `_analyze_modularity()`
- `_calculate_score()`
- `_generate_recommendations()`
- `generate_report()`

#### Fonctions

##### main

Point dentr√©e

##### __init__

**Param√®tres :**

- `project_path`

##### run

M√©thode run() pour lorchestrateur - ex√©cute laudit

##### audit_project

Audit complet dun projet

**Param√®tres :**

- `project_path`

##### _analyze_project_info

Analyse des informations du projet

##### _detect_project_type

D√©tection automatique du type de projet

##### _calculate_project_size

Calcul de la taille du projet

##### _is_code_file

D√©termine si un fichier est un fichier de code

**Param√®tres :**

- `file_path`

##### _detect_languages

D√©tection des langages du projet

##### _detect_dependencies

D√©tection des d√©pendances du projet

##### _get_last_modified

Date de derni√®re modification

##### _analyze_code_quality

Analyse de la qualit√© du code

##### _analyze_complexity

Analyse de la complexit√© du code

##### _calculate_cyclomatic_complexity

Calcul de la complexit√© cyclomatique dun fichier

**Param√®tres :**

- `tree`

##### _analyze_style

Analyse du style du code

##### _analyze_code_documentation

Analyse de la documentation du code

##### _analyze_naming_conventions

Analyse des conventions de nommage

##### _analyze_security

Analyse de la s√©curit√©

##### _detect_security_vulnerabilities

D√©tection des vuln√©rabilit√©s de s√©curit√©

##### _detect_secrets

D√©tection de secrets

##### _analyze_permissions

Analyse des permissions des fichiers

##### _analyze_performance

Analyse de la performance

##### _analyze_file_sizes

Analyse de la taille des fichiers

##### _analyze_imports

Analyse des imports

##### _estimate_memory_usage

Estimation de la list_datausage

##### _analyze_documentation

Analyse de la documentation

##### _check_readme

V√©rification du README

##### _check_api_documentation

V√©rification de la documentation API

##### _check_guides

V√©rification des guides

##### _analyze_testing

Analyse des tests

##### _analyze_test_coverage

Analyse de la couverture de tests

##### _find_test_files

Trouve les fichiers de tests

##### _analyze_test_quality

Analyse de la qualit√© des tests

##### _analyze_structure

Analyse de la structure du projet

##### _analyze_organization

Analyse de lorganisation des dossiers

##### _analyze_structure_naming

Analyse du nommage des fichiers et dossiers

##### _analyze_modularity

Analyse de la modularit√©

##### _calculate_score

Calcul du score global

##### _generate_recommendations

G√©n√©ration des recommandations

##### generate_report

G√©n√®re un rapport daudit

---

### intelligent_memory

üß† M√âMOIRE INTELLIGENTE ATHALIA
===============================
Syst√®me de m√©moire qui :
- Apprend de chaque erreur et correction
- Pr√©dit les probl√®mes futurs
- Sugg√®re des corrections automatiques
- Maintient un historique d'apprentissage
- Am√©liore la qualit√© du code continuellement

#### Classes

##### LearningEvent

√âv√©nement d'apprentissage

##### Prediction

Pr√©diction bas√©e sur l'apprentissage

##### CorrectionSuggestion

Suggestion de correction

##### IntelligentMemory

Syst√®me de m√©moire intelligente pour Athalia

**M√©thodes :**

- `__init__()`
- `_init_database()`
- `learn_from_error()`
- `learn_from_correction()`
- `learn_from_duplicate()`
- `predict_issues()`
- `suggest_corrections()`
- `get_learning_insights()`
- `_record_learning_event()`
- `_analyze_code_pattern()`
- `_normalize_code()`
- `_update_pattern_learning()`
- `_generate_predictions_from_error()`
- `_find_similar_patterns()`
- `_check_antipatterns()`
- `_check_potential_duplicates()`
- `_calculate_code_similarity()`
- `_save_correction_suggestion()`

#### Fonctions

##### main

Test du syst√®me de m√©moire intelligente

##### __init__

**Param√®tres :**

- `root_path`

##### _init_database

Initialiser la base de donn√©es de m√©moire

##### learn_from_error

Apprendre d'une erreur

**Param√®tres :**

- `error_description`
- `code_snippet`
- `location`
- `severity`
- `context`

##### learn_from_correction

Apprendre d'une correction

**Param√®tres :**

- `original_code`
- `corrected_code`
- `reason`
- `location`
- `success`
- `context`

##### learn_from_duplicate

Apprendre d'un doublon d√©tect√©

**Param√®tres :**

- `duplicate_items`
- `locations`
- `similarity_score`
- `context`

##### predict_issues

Pr√©dire les probl√®mes potentiels

**Param√®tres :**

- `code_snippet`
- `context`

##### suggest_corrections

Sugg√©rer des corrections bas√©es sur l'apprentissage

**Param√®tres :**

- `problematic_code`
- `issue_description`

##### get_learning_insights

Obtenir des insights d'apprentissage

##### _record_learning_event

Enregistrer un √©v√©nement d'apprentissage

**Param√®tres :**

- `event_type`
- `description`
- `code_snippet`
- `location`
- `severity`
- `success`
- `resolution`
- `context`

##### _analyze_code_pattern

Analyser et cr√©er un hash du pattern de code

**Param√®tres :**

- `code`

##### _normalize_code

Normaliser le code pour la comparaison

**Param√®tres :**

- `code`

##### _update_pattern_learning

Mettre √† jour l'apprentissage d'un pattern

**Param√®tres :**

- `pattern_hash`
- `pattern_type`
- `success`

##### _generate_predictions_from_error

G√©n√©rer des pr√©dictions bas√©es sur une erreur

**Param√®tres :**

- `error_description`
- `code_snippet`
- `pattern_hash`

##### _find_similar_patterns

Trouver des patterns similaires

**Param√®tres :**

- `pattern_hash`

##### _check_antipatterns

V√©rifier les anti-patterns connus

**Param√®tres :**

- `code_snippet`

##### _check_potential_duplicates

V√©rifier les doublons potentiels

**Param√®tres :**

- `code_snippet`

##### _calculate_code_similarity

Calculer la similarit√© entre deux codes

**Param√®tres :**

- `code1`
- `code2`

##### _save_correction_suggestion

Sauvegarder une suggestion de correction

**Param√®tres :**

- `original_code`
- `corrected_code`
- `reason`
- `success`

---

### ready_check

#### Fonctions

##### open_patch

**Param√®tres :**

- `file`
- `mode`

##### check_ready

**Param√®tres :**

- `project_path`

---

### main

#### Fonctions

##### signal_handler

Gestionnaire de signal pour arr√™t propre

**Param√®tres :**

- `signum`
- `frame`

##### menu

##### safe_input

Entr√©e s√©curis√©e avec gestion derreurs.

**Param√®tres :**

- `prompt`

##### surveillance_mode

Mode surveillance avec arr√™t automatique

##### main

**Param√®tres :**

- `test_mode`

##### log_main

**Param√®tres :**

- `msg`
- `level`

---

### logger_advanced

Syst√®me de logging avanc√© pour Athalia/Arkalia
Logging intelligent avec rotation, compression et analyse automatique

#### Classes

##### AthaliaLogger

Syst√®me de logging avanc√© pour Athalia/Arkalia

**M√©thodes :**

- `__init__()`
- `_setup_loggers()`
- `_create_logger()`
- `log_main()`
- `log_validation()`
- `log_correction()`
- `log_performance()`
- `log_error()`
- `get_validation_stats()`
- `get_correction_stats()`
- `get_performance_stats()`
- `get_error_stats()`
- `_cleanup_worker()`
- `start_cleanup_worker()`
- `stop_cleanup_worker()`
- `_cleanup_old_logs()`
- `_compress_old_logs()`
- `export_metrics()`

#### Fonctions

##### log_main

Log dans le logger principal

**Param√®tres :**

- `message`
- `level`

##### log_validation

Log des r√©sultats de validation

**Param√®tres :**

- `test_name`
- `result`
- `duration`

##### log_correction

Log des corrections automatiques

**Param√®tres :**

- `file_path`
- `correction_type`
- `success`
- `old_content`
- `new_content`
- `duration`

##### log_performance

Log des m√©triques de performance

**Param√®tres :**

- `operation`
- `duration`
- `memory_mb`
- `cpu_percent`

##### log_error

Log des erreurs

**Param√®tres :**

- `error`
- `context`

##### __init__

**Param√®tres :**

- `log_dir`

##### _setup_loggers

Configure tous les loggers

##### _create_logger

Cr√©e un logger avec rotation et compression

**Param√®tres :**

- `name`
- `log_file`
- `level`

##### log_main

Log dans le logger principal

**Param√®tres :**

- `message`
- `level`

##### log_validation

Log des r√©sultats de validation

**Param√®tres :**

- `test_name`
- `result`
- `duration`

##### log_correction

Log des corrections automatiques

**Param√®tres :**

- `file_path`
- `correction_type`
- `success`
- `old_content`
- `new_content`
- `duration`

##### log_performance

Log des m√©triques de performance

**Param√®tres :**

- `operation`
- `duration`
- `memory_mb`
- `cpu_percent`

##### log_error

Log des erreurs

**Param√®tres :**

- `error`
- `context`

##### get_validation_stats

R√©cup√®re les statistiques de validation

**Param√®tres :**

- `hours`

##### get_correction_stats

R√©cup√®re les statistiques de correction

**Param√®tres :**

- `hours`

##### get_performance_stats

R√©cup√®re les statistiques de performance

**Param√®tres :**

- `hours`

##### get_error_stats

R√©cup√®re les statistiques d'erreurs

**Param√®tres :**

- `hours`

##### _cleanup_worker

Thread de nettoyage automatique des logs

##### start_cleanup_worker

D√©marre le thread de nettoyage

##### stop_cleanup_worker

Arr√™te le thread de nettoyage

##### _cleanup_old_logs

Nettoie les anciens logs

##### _compress_old_logs

Compresse les logs anciens

##### export_metrics

Exporte toutes les m√©triques

**Param√®tres :**

- `output_file`

---

### generation_simple

Module de g√©n√©ration simplifi√© pour Athalia
Version simplifi√©e sans f-strings complexes

#### Fonctions

##### generate_blueprint_mock

G√©n√®re un blueprint mock pour les tests.

**Param√®tres :**

- `idea`

##### extract_project_name

Extrait un nom de projet de l'id√©e.

**Param√®tres :**

- `idea`

##### generate_project

G√©n√®re un projet √† partir d'un blueprint.

**Param√®tres :**

- `blueprint`
- `outdir`

##### generate_readme

G√©n√®re un README basique.

**Param√®tres :**

- `blueprint`
- `project_path`

##### generate_main_code

G√©n√®re le code principal.

**Param√®tres :**

- `blueprint`
- `project_path`

##### generate_test_code

G√©n√®re le code de test.

**Param√®tres :**

- `blueprint`
- `project_path`

##### save_blueprint

Sauvegarde un blueprint dans un fichier YAML.

**Param√®tres :**

- `blueprint`
- `outdir`

##### inject_booster_ia_elements

Injecte les √©l√©ments Booster IA.

**Param√®tres :**

- `outdir`

##### scan_existing_project

Scanne un projet existant.

**Param√®tres :**

- `outdir`

##### merge_or_suffix_file

Fusionne ou suffixe un fichier.

**Param√®tres :**

- `file_path`
- `content`
- `file_type`
- `section_header`

##### backup_file

Cr√©e une sauvegarde d'un fichier.

**Param√®tres :**

- `file_path`

##### generate_api_docs

G√©n√®re la documentation API.

**Param√®tres :**

- `blueprint`

##### generate_dockerfile

G√©n√®re un Dockerfile.

**Param√®tres :**

- `blueprint`

##### generate_docker_compose

G√©n√®re un docker-compose.yml.

**Param√®tres :**

- `blueprint`

---

### multi_file_editor

Module d'√©dition/correction multi-fichiers pour Athalia/Arkalia.
Permet d'appliquer des corrections/refactoring sur plusieurs fichiers en une seule commande,
avec logs et rollback.

#### Classes

##### MultiFileEditor

**M√©thodes :**

- `__init__()`
- `backup_file()`
- `apply_corrections()`
- `rollback()`

#### Fonctions

##### __init__

**Param√®tres :**

- `backup_dir`

##### backup_file

**Param√®tres :**

- `file_path`

##### apply_corrections

Applique la fonction de correction √† chaque fichier.
:param files: Liste des chemins de fichiers √† corriger
:param correction_fn: Fonction qui prend le contenu du fichier et
                     retourne le contenu corrig√©
:return: Dictionnaire de r√©sultats (succ√®s, erreurs, logs)

**Param√®tres :**

- `files`
- `correction_fn`

##### rollback

Restaure tous les fichiers depuis les backups.

##### dummy_correction

**Param√®tres :**

- `content`

---

### pattern_detector

üîç D√âTECTEUR DE PATTERNS ET DOUBLONS
====================================
Module sp√©cialis√© dans la d√©tection de patterns de code,
doublons et anti-patterns. Utilise l'analyseur AST de base.

#### Classes

##### CodePattern

Pattern de code d√©tect√©

##### DuplicateAnalysis

Analyse de doublons

##### AntiPattern

Anti-pattern d√©tect√©

##### PatternDetector

D√©tecteur de patterns et doublons

**M√©thodes :**

- `__init__()`
- `_init_database()`
- `_load_patterns()`
- `analyze_project_patterns()`
- `_extract_patterns_from_file()`
- `_detect_duplicates()`
- `_calculate_similarity()`
- `_detect_antipatterns()`
- `_save_analysis_results()`
- `_generate_recommendations()`
- `get_learning_insights()`

#### Fonctions

##### __init__

**Param√®tres :**

- `root_path`

##### _init_database

Initialiser la base de donn√©es

##### _load_patterns

Charger les patterns depuis la base de donn√©es

##### analyze_project_patterns

Analyser les patterns d'un projet complet

**Param√®tres :**

- `project_path`

##### _extract_patterns_from_file

Extraire les patterns d'un fichier analys√©

**Param√®tres :**

- `file_analysis`

##### _detect_duplicates

D√©tecter les doublons parmi les patterns

**Param√®tres :**

- `patterns`

##### _calculate_similarity

Calculer la similarit√© entre deux patterns

**Param√®tres :**

- `pattern1`
- `pattern2`

##### _detect_antipatterns

D√©tecter les anti-patterns

**Param√®tres :**

- `patterns`

##### _save_analysis_results

Sauvegarder les r√©sultats d'analyse

**Param√®tres :**

- `patterns`
- `duplicates`
- `antipatterns`

##### _generate_recommendations

G√©n√©rer des recommandations bas√©es sur l'analyse

**Param√®tres :**

- `duplicates`
- `antipatterns`

##### get_learning_insights

Obtenir des insights d'apprentissage

---

### performance_analyzer

‚ö° ANALYSEUR DE PERFORMANCE
===========================
Module sp√©cialis√© dans l'analyse des performances du code,
d√©tection des goulots d'√©tranglement et optimisation.

#### Classes

##### PerformanceMetric

M√©trique de performance

##### PerformanceIssue

Probl√®me de performance d√©tect√©

##### PerformanceReport

Rapport de performance complet

##### PerformanceAnalyzer

Analyseur de performance pour d√©tecter les goulots d'√©tranglement

**M√©thodes :**

- `__init__()`
- `_init_database()`
- `analyze_project_performance()`
- `_analyze_file_performance()`
- `_detect_performance_issues()`
- `_get_metric_status()`
- `_calculate_overall_score()`
- `_get_metric_weight()`
- `_calculate_metric_score()`
- `_generate_performance_recommendations()`
- `_identify_optimization_opportunities()`
- `_save_performance_report()`
- `profile_function()`
- `get_performance_insights()`

#### Fonctions

##### __init__

**Param√®tres :**

- `root_path`

##### _init_database

Initialiser la base de donn√©es de performance

##### analyze_project_performance

Analyser les performances d'un projet complet

**Param√®tres :**

- `project_path`

##### _analyze_file_performance

Analyser les performances d'un fichier

**Param√®tres :**

- `file_analysis`

##### _detect_performance_issues

D√©tecter les probl√®mes de performance dans un fichier

**Param√®tres :**

- `file_analysis`

##### _get_metric_status

D√©terminer le statut d'une m√©trique

**Param√®tres :**

- `value`
- `threshold`
- `reverse`

##### _calculate_overall_score

Calculer le score de performance global

**Param√®tres :**

- `metrics`

##### _get_metric_weight

Obtenir le poids d'une m√©trique

**Param√®tres :**

- `metric_type`

##### _calculate_metric_score

Calculer le score d'une m√©trique

**Param√®tres :**

- `metric`

##### _generate_performance_recommendations

G√©n√©rer des recommandations de performance

**Param√®tres :**

- `issues`

##### _identify_optimization_opportunities

Identifier les opportunit√©s d'optimisation

**Param√®tres :**

- `issues`

##### _save_performance_report

Sauvegarder le rapport de performance

**Param√®tres :**

- `report`

##### profile_function

Profiler une fonction sp√©cifique

**Param√®tres :**

- `function_path`
- `function_name`

##### get_performance_insights

Obtenir des insights de performance

---

### plugins_manager

#### Fonctions

##### list_plugins

Liste tous les plugins disponibles.

##### load_plugin

Charge dynamiquement un plugin par nom.

**Param√®tres :**

- `name`

##### run_all_plugins

Ex√©cute la fonction run() de tous les plugins et retourne les r√©sultats.

---

### plugins_validator

#### Fonctions

##### validate_plugin

Valide un plugin Python : h√©ritage, m√©thode run / execute, docstring.

**Param√®tres :**

- `path`

---

### security

Module s√©curit√©, audit, scan de secrets, prompts s√©curit√©.

#### Fonctions

##### security_audit_project

Audit de s√©curit√© dun projet

**Param√®tres :**

- `project_path`

---

### project_importer

#### Classes

##### ProjectImporter

**M√©thodes :**

- `__init__()`
- `import_project()`
- `_scan_structure()`
- `_detect_project_type()`
- `_analyze_code_quality()`
- `_generate_correction_blueprint()`
- `_suggest_modules()`
- `_suggest_structure()`
- `_suggest_dependencies()`
- `_suggest_prompts()`
- `_suggest_enhancements()`

#### Fonctions

##### __init__

##### import_project

Importe et analyse un projet existant.

**Param√®tres :**

- `project_path`

##### _scan_structure

Analyse la structure du projet.

**Param√®tres :**

- `project_path`

##### _detect_project_type

D√©tecte automatiquement le type de projet.

**Param√®tres :**

- `project_path`
- `structure`

##### _analyze_code_quality

Analyse la qualit√© du code.

**Param√®tres :**

- `project_path`

##### _generate_correction_blueprint

G√©n√®re un blueprint de correction pour le projet.

**Param√®tres :**

- `project_path`
- `structure`
- `project_type`
- `quality_analysis`

##### _suggest_modules

Sugg√®re des modules selon le type de projet.

**Param√®tres :**

- `project_type`

##### _suggest_structure

G√®re une structure am√©lior√©e.

**Param√®tres :**

- `structure`

##### _suggest_dependencies

Sugg√®re des d√©pendances selon le type de projet.

**Param√®tres :**

- `project_type`

##### _suggest_prompts

Sugg√®re des prompts selon le type de projet.

**Param√®tres :**

- `project_type`

##### _suggest_enhancements

Sugg√®re des am√©liorations sp√©cifiques.

**Param√®tres :**

- `project_type`
- `quality_analysis`

---

### security_auditor

#### Classes

##### SecurityAuditor

Auditeur de s√©curit√© pour Athalia

**M√©thodes :**

- `__init__()`
- `run()`
- `_check_dependencies()`
- `_check_code_vulnerabilities()`
- `_check_secrets()`
- `_check_permissions()`
- `_check_encryption()`
- `_calculate_score()`
- `print_report()`

#### Fonctions

##### __init__

**Param√®tres :**

- `project_path`

##### run

Lance laudit de s√©curit√©

##### _check_dependencies

V√©rification des d√©pendances

##### _check_code_vulnerabilities

V√©rification des vuln√©rabilit√©s dans le code

##### _check_secrets

V√©rification des secrets

##### _check_permissions

V√©rification des permissions des fichiers

##### _check_encryption

V√©rification de lutilisation du chiffrement

##### _calculate_score

Calcul du score de s√©curit√©

##### print_report

Affichage du rapport de s√©curit√©

---

### unified_orchestrator

Orchestrateur unifi√© pour Athalia - Industrialisation IA compl√®te

#### Classes

##### BackupSystem

Syst√®me de sauvegarde simplifi√©

##### OrchestrationTask

T√¢che d'orchestration unifi√©e

##### IntelligentInsight

Insight intelligent unifi√©

##### IndustrializationStep

√âtape d'industrialisation

##### UnifiedOrchestrator

Orchestrateur unifi√© pour l'industrialisation IA

**M√©thodes :**

- `__init__()`
- `_init_database()`
- `_init_components()`
- `orchestrate_project_complete()`
- `_run_industrialization()`
- `_run_audit()`
- `_run_linting()`
- `_run_security_audit()`
- `_run_analytics()`
- `_run_cleanup()`
- `_run_documentation()`
- `_run_testing()`
- `_run_cicd()`
- `_run_robotics_audit()`
- `_generate_predictions()`
- `_generate_optimizations()`
- `_learn_from_results()`
- `_generate_unified_report()`
- `_save_unified_results()`
- `get_orchestration_insights()`
- `_run_plugins()`
- `phase2_backup()`
- `get_phase2_backup_stats()`
- `validate_phase2_inputs()`
- `run_phase2_backup()`
- `run_phase2_error_handling()`
- `_run_templates()`
- `orchestrate_with_phase2_features()`

#### Fonctions

##### get_backup_system

Obtenir le syst√®me de sauvegarde

##### standardize_cli_script

Standardiser le script CLI

##### cli_entry

Point d'entr√©e CLI

##### error_handler

D√©corateur de gestion d'erreur

**Param√®tres :**

- `func`

##### orchestrator_auto_backup

Sauvegarde automatique de l'orchestrateur

##### orchestrator_main

Fonction principale de l'orchestrateur

##### main_orchestrator

Point d'entr√©e principal pour compatibilit√©

##### __init__

**Param√®tres :**

- `root_path`

##### _init_database

Initialiser la base de donn√©es

##### _init_components

Initialiser les composants disponibles

##### orchestrate_project_complete

Orchestrer l'industrialisation compl√®te d'un projet

**Param√®tres :**

- `project_path`
- `config`

##### _run_industrialization

Ex√©cuter l'industrialisation

**Param√®tres :**

- `project_path`

##### _run_audit

Ex√©cuter l'audit

**Param√®tres :**

- `project_path`

##### _run_linting

Ex√©cuter le linting

**Param√®tres :**

- `project_path`

##### _run_security_audit

Ex√©cuter l'audit de s√©curit√©

**Param√®tres :**

- `project_path`

##### _run_analytics

Ex√©cuter l'analyse

**Param√®tres :**

- `project_path`

##### _run_cleanup

Ex√©cuter le nettoyage

**Param√®tres :**

- `project_path`

##### _run_documentation

Ex√©cuter la documentation

**Param√®tres :**

- `project_path`

##### _run_testing

Ex√©cuter les tests

**Param√®tres :**

- `project_path`

##### _run_cicd

Ex√©cuter le CI/CD

**Param√®tres :**

- `project_path`

##### _run_robotics_audit

Ex√©cuter l'audit robotique

**Param√®tres :**

- `project_path`

##### _generate_predictions

G√©n√©rer des pr√©dictions intelligentes

**Param√®tres :**

- `project_path`

##### _generate_optimizations

G√©n√©rer des optimisations intelligentes

**Param√®tres :**

- `project_path`

##### _learn_from_results

Apprendre des r√©sultats pour am√©liorer les futures ex√©cutions

**Param√®tres :**

- `results`

##### _generate_unified_report

G√©n√©rer un rapport unifi√©

**Param√®tres :**

- `results`

##### _save_unified_results

Sauvegarder les r√©sultats unifi√©s

**Param√®tres :**

- `results`

##### get_orchestration_insights

Obtenir les insights d'orchestration

##### _run_plugins

Ex√©cuter les plugins

**Param√®tres :**

- `project_path`

##### phase2_backup

Sauvegarde Phase 2

**Param√®tres :**

- `project_path`

##### get_phase2_backup_stats

Obtenir les statistiques de sauvegarde Phase 2

##### validate_phase2_inputs

Valider les entr√©es Phase 2

**Param√®tres :**

- `inputs`
- `required_fields`

##### run_phase2_backup

Ex√©cuter la sauvegarde Phase 2

**Param√®tres :**

- `backup_type`

##### run_phase2_error_handling

Gestion d'erreur Phase 2

**Param√®tres :**

- `operation`

##### _run_templates

Ex√©cuter les templates

**Param√®tres :**

- `project_path`

##### orchestrate_with_phase2_features

Orchestrer avec les fonctionnalit√©s Phase 2

**Param√®tres :**

- `project_path`

##### wrapper

---

### auto_correction_advanced

Module d'auto-correction avanc√©e pour Athalia
Correction intelligente de code, suggestions d'am√©lioration, refactoring automatique

#### Classes

##### AutoCorrectionAvancee

Module d'auto-correction avanc√©e avec correction intelligente

**M√©thodes :**

- `__init__()`
- `analyser_et_corriger()`
- `_corriger_syntaxe_avancee()`
- `_corriger_erreur_syntaxe()`
- `_corriger_indentation()`
- `_corriger_parentheses()`
- `_corriger_guillemets()`
- `_corriger_virgules()`
- `_optimiser_code()`
- `_optimiser_list_comprehensions()`
- `_optimiser_imports()`
- `_optimiser_boucles()`
- `_refactoring_automatique()`
- `_extraire_methodes()`
- `_renommer_variables()`
- `_simplifier_conditions()`
- `_corriger_anti_patterns()`
- `_ameliorer_lisibilite()`
- `generer_rapport()`

#### Fonctions

##### main

Fonction principale pour test

##### __init__

**Param√®tres :**

- `project_path`

##### analyser_et_corriger

Analyse compl√®te et correction automatique du code

**Param√®tres :**

- `dry_run`

##### _corriger_syntaxe_avancee

Correction syntaxique avanc√©e avec analyse AST

**Param√®tres :**

- `dry_run`

##### _corriger_erreur_syntaxe

Correction intelligente d'erreur de syntaxe

**Param√®tres :**

- `fichier`
- `contenu`
- `erreur`

##### _corriger_indentation

Correction automatique de l'indentation

**Param√®tres :**

- `lignes`
- `ligne_erreur`

##### _corriger_parentheses

Correction automatique des parenth√®ses

**Param√®tres :**

- `lignes`
- `ligne_erreur`

##### _corriger_guillemets

Correction automatique des guillemets

**Param√®tres :**

- `lignes`
- `ligne_erreur`

##### _corriger_virgules

Correction automatique des virgules manquantes

**Param√®tres :**

- `lignes`
- `ligne_erreur`

##### _optimiser_code

Optimisation automatique du code

**Param√®tres :**

- `dry_run`

##### _optimiser_list_comprehensions

Optimisation des list comprehensions

**Param√®tres :**

- `contenu`

##### _optimiser_imports

Optimisation des imports

**Param√®tres :**

- `contenu`

##### _optimiser_boucles

Optimisation des boucles

**Param√®tres :**

- `contenu`

##### _refactoring_automatique

Refactoring automatique du code

**Param√®tres :**

- `dry_run`

##### _extraire_methodes

Extraction automatique de m√©thodes

**Param√®tres :**

- `contenu`

##### _renommer_variables

Renommage automatique de variables

**Param√®tres :**

- `contenu`

##### _simplifier_conditions

Simplification automatique de conditions

**Param√®tres :**

- `contenu`

##### _corriger_anti_patterns

Correction des anti-patterns

**Param√®tres :**

- `dry_run`

##### _ameliorer_lisibilite

Am√©lioration de la lisibilit√©

**Param√®tres :**

- `dry_run`

##### generer_rapport

G√©n√©ration d'un rapport d√©taill√©

**Param√®tres :**

- `resultats`

---

### dashboard_unified

#### Classes

##### DashboardUnifieSimple

Dashboard unifi√© simplifi√© avec rapports fonctionnels

**M√©thodes :**

- `__init__()`
- `_init_database()`
- `enregistrer_metrique()`
- `enregistrer_evenement()`
- `enregistrer_rapport()`
- `obtenir_metriques_temps_reel()`
- `generer_rapport_consolide()`
- `ajouter_section_distillation()`
- `generer_dashboard_html()`
- `ouvrir_dashboard()`

#### Fonctions

##### main

Fonction principale pour test du f

##### __init__

**Param√®tres :**

- `db_path`

##### _init_database

Initialisation de la base de donn√©es

##### enregistrer_metrique

Enregistrement une m√©trique

**Param√®tres :**

- `type_metrique`
- `valeur`
- `projet`
- `details`

##### enregistrer_evenement

Enregistrement un √©v√©nement

**Param√®tres :**

- `type_evenement`
- `projet`
- `utilisateur`
- `duree`
- `statut`
- `details`

##### enregistrer_rapport

Enregistrement un rapport

**Param√®tres :**

- `type_rapport`
- `projet`
- `contenu`
- `score_qualite`
- `score_securite`

##### obtenir_metriques_temps_reel

Obtention des m√©triques en temps r√©el

##### generer_rapport_consolide

G√©n√©ration d'un rapport consolid√©

##### ajouter_section_distillation

Ajoute une section Distillation IA au dashboard (exemple statique).

**Param√®tres :**

- `file_handle`

##### generer_dashboard_html

G√©n√©ration d'un dashboard HTML moderne et valide

**Param√®tres :**

- `output_file`

##### ouvrir_dashboard

Ouverture du dashboard dans le navigateur

---

### user_profiles_advanced

Module de gestion des profils utilisateur avanc√©s pour Athalia
Gestion des pr√©f√©rences, historique, statistiques et personnalisation

#### Classes

##### ProfilUtilisateur

Profil utilisateur avec pr√©f√©rences et historique

**M√©thodes :**

- `__init__()`
- `to_dict()`
- `from_dict()`

##### GestionnaireProfils

Gestionnaire de profils utilisateur avanc√©

**M√©thodes :**

- `__init__()`
- `_init_database()`
- `creer_profil()`
- `obtenir_profil()`
- `mettre_a_jour_profil()`
- `enregistrer_action()`
- `enregistrer_consultation_projet()`
- `obtenir_statistiques()`
- `generer_rapport_profil()`
- `lister_profils()`
- `supprimer_profil()`
- `exporter_profil()`
- `importer_profil()`

#### Fonctions

##### main

Fonction principale pour test

##### __init__

**Param√®tres :**

- `nom`
- `email`
- `preferences`

##### to_dict

Conversion en dictionnaire

##### from_dict

Cr√©ation depuis un dictionnaire

**Param√®tres :**

- `cls`
- `data`

##### __init__

**Param√®tres :**

- `db_path`

##### _init_database

Initialisation de la base de donn√©es

##### creer_profil

Cr√©ation d'un nouveau profil

**Param√®tres :**

- `nom`
- `email`
- `preferences`

##### obtenir_profil

R√©cup√©ration d'un profil par nom

**Param√®tres :**

- `nom`

##### mettre_a_jour_profil

Mise √† jour d'un profil

**Param√®tres :**

- `profil`

##### enregistrer_action

Enregistrement d'une action utilisateur

**Param√®tres :**

- `nom_profil`
- `action`
- `details`

##### enregistrer_consultation_projet

Enregistrement de la consultation d'un projet

**Param√®tres :**

- `nom_profil`
- `chemin_projet`
- `duree`

##### obtenir_statistiques

Obtention des statistiques d'un profil

**Param√®tres :**

- `nom_profil`

##### generer_rapport_profil

G√©n√©ration d'un rapport d√©taill√© pour un profil

**Param√®tres :**

- `nom_profil`

##### lister_profils

Liste de tous les profils

##### supprimer_profil

Suppression d'un profil

**Param√®tres :**

- `nom`

##### exporter_profil

Export d'un profil vers un fichier JSON

**Param√®tres :**

- `nom`
- `fichier_destination`

##### importer_profil

Import d'un profil depuis un fichier JSON

**Param√®tres :**

- `fichier_source`

---

### ath_context_prompt

---

### audit_agent

#### Classes

##### AuditAgent

Agent d'audit simplifi√© pour les tests

**M√©thodes :**

- `__init__()`
- `act()`

#### Fonctions

##### __init__

##### act

**Param√®tres :**

- `prompt`

---

### context_prompt

#### Fonctions

##### score_prompt

**Param√®tres :**

- `prompt`
- `filename`
- `content`

##### detect_prompts_scoring

**Param√®tres :**

- `filepath`

##### detect_prompt_semantic

**Param√®tres :**

- `filepath`

##### show_prompts

**Param√®tres :**

- `scored`
- `semantic_prompt`

##### main

---

### unified_agent

Agent unifi√© pour Athalia - Combine les fonctionnalit√©s de
network_agent et qwen_agent

#### Classes

##### UnifiedAgent

Agent unifi√© pour toutes les t√¢ches IA

**M√©thodes :**

- `__init__()`
- `act()`
- `_process_prompt()`
- `_synthesize_responses()`

##### AuditAgent

Agent d'audit sp√©cialis√©

**M√©thodes :**

- `__init__()`

##### CorrectionAgent

Agent de correction sp√©cialis√©

**M√©thodes :**

- `__init__()`

##### SynthesisAgent

Agent de synth√®se sp√©cialis√©

**M√©thodes :**

- `__init__()`

##### QwenAgent

Agent Qwen sp√©cialis√© (compatibilit√©)

**M√©thodes :**

- `__init__()`

#### Fonctions

##### __init__

**Param√®tres :**

- `agent_type`

##### act

Action principale de l'agent

**Param√®tres :**

- `prompt`
- `responses`

##### _process_prompt

Traite un prompt avec l'IA

**Param√®tres :**

- `prompt`

##### _synthesize_responses

Synth√©tise plusieurs r√©ponses

**Param√®tres :**

- `prompt`
- `responses`

##### __init__

##### __init__

##### __init__

##### __init__

---

### project_classifier

#### Fonctions

##### classify_project

Analyse l'id√©e du projet et retourne le type appropri√©.

Args:
    idea: Description du projet en une phrase

Returns:
    ProjectType: Type de projet d√©tect√©

**Param√®tres :**

- `idea`

##### get_project_name

G√©n√®re un nom de projet appropri√© bas√© sur l'id√©e et le type.

Args:
    idea: Description du projet
    project_type: Type de projet d√©tect√©

Returns:
    str: Nom de projet g√©n√©r√©

**Param√®tres :**

- `idea`
- `project_type`

---

### project_types

#### Classes

##### ProjectType

Types de projets support√©s.

#### Fonctions

##### get_project_config

Retourne la configuration sp√©cialis√©e pour un type de projet.

**Param√®tres :**

- `project_type`

---

### adaptive_distillation

Distillation adaptative pour Athalia/Arkalia
- Pond√©ration dynamique selon pr√©f√©rences et feedback utilisateur
- Historique sauvegard√©/charg√© en JSON

#### Classes

##### AdaptiveDistiller

**M√©thodes :**

- `__init__()`
- `distill_responses()`
- `update_preferences()`
- `apply_learned_weights()`
- `ensemble_fusion()`
- `save_history()`
- `load_history()`

#### Fonctions

##### __init__

Initialise le distillateur adaptatif.
:param history_path: Chemin du fichier JSON pour l'historique (optionnel)

**Param√®tres :**

- `history_path`

##### distill_responses

Fusionne les r√©ponses IA en tenant compte des pr√©f√©rences et du feedback utilisateur.
:param responses: Liste de r√©ponses IA
:param context: Contexte optionnel
:return: R√©ponse distill√©e

**Param√®tres :**

- `responses`
- `context`

##### update_preferences

Met √† jour les pr√©f√©rences et le feedback selon la r√©ponse choisie et le succ√®s/√©chec.
:param chosen_response: R√©ponse s√©lectionn√©e
:param responses: Liste des r√©ponses propos√©es
:param success: Succ√®s (True) ou √©chec (False) de la r√©ponse

**Param√®tres :**

- `chosen_response`
- `responses`
- `success`

##### apply_learned_weights

Trie les r√©ponses selon leur poids appris et taux de succ√®s.
:param responses: Liste de r√©ponses IA
:return: Liste tri√©e

**Param√®tres :**

- `responses`

##### ensemble_fusion

Fusionne les r√©ponses (majority voting par d√©faut).
:param responses: Liste de r√©ponses pond√©r√©es
:param context: Contexte optionnel
:return: R√©ponse fusionn√©e

**Param√®tres :**

- `responses`
- `context`

##### save_history

Sauvegarde l'historique et les poids en JSON.

##### load_history

Charge l'historique et les poids depuis un JSON si disponible.

##### score

**Param√®tres :**

- `r`

---

### audit_distiller

Module de distillation d'audits pour Athalia/Arkalia
Fusionne et pond√®re plusieurs audits (s√©curit√©, qualit√©, performance...)

#### Classes

##### AuditDistiller

**M√©thodes :**

- `__init__()`
- `distill()`

#### Fonctions

##### __init__

**Param√®tres :**

- `weights`

##### distill

Fusionne plusieurs audits en un score global et des recommandations synth√©tiques.
:param audits: Liste de r√©sultats d'audit (dict)
:return: Audit distill√© (dict)

**Param√®tres :**

- `audits`

---

### code_genetics

Code Genetics pour Athalia/Arkalia
- Croisement, mutation, s√©lection, √©volution de solutions IA

#### Classes

##### CodeGenetics

**M√©thodes :**

- `crossover()`
- `mutate()`
- `select()`
- `evolve()`

#### Fonctions

##### crossover

Croisement de solutions : m√©lange al√©atoire de fragments de chaque solution.
:param solutions: Liste de solutions (str)
:return: Nouvelle solution crois√©e

**Param√®tres :**

- `solutions`

##### mutate

Mutation simple : modifie al√©atoirement des mots de la solution.
:param solution: Solution √† muter
:param mutation_rate: Taux de mutation (0-1)
:return: Solution mut√©e

**Param√®tres :**

- `solution`
- `mutation_rate`

##### select

S√©lectionne les meilleures solutions selon un score.
:param solutions: Liste de solutions
:param scorer: Fonction de scoring (str -> float)
:param top_k: Nombre de solutions √† garder
:return: Liste des meilleures solutions

**Param√®tres :**

- `solutions`
- `scorer`
- `top_k`

##### evolve

Fait √©voluer les solutions sur plusieurs g√©n√©rations (croisement, mutation, s√©lection).
:param solutions: Liste initiale
:param scorer: Fonction de scoring
:param generations: Nombre de g√©n√©rations
:param mutation_rate: Taux de mutation
:return: Meilleure solution finale

**Param√®tres :**

- `solutions`
- `scorer`
- `generations`
- `mutation_rate`

---

### correction_distiller

Module de distillation de corrections IA pour Athalia/Arkalia
Fusionne, score et s√©lectionne la meilleure correction parmi plusieurs suggestions IA.

#### Classes

##### CorrectionDistiller

**M√©thodes :**

- `__init__()`
- `distill()`

#### Fonctions

##### __init__

**Param√®tres :**

- `strategy`

##### distill

S√©lectionne ou fusionne la meilleure correction IA.
:param corrections: Liste de corrections propos√©es (str)
:param scores: Scores optionnels pour chaque correction
:param context: Contexte optionnel
:return: Correction distill√©e (str)

**Param√®tres :**

- `corrections`
- `scores`
- `context`

---

### multimodal_distiller

Distillation multimodale pour Athalia/Arkalia
- Fusionne r√©ponses texte et image (LLaVA)
- Appel r√©el √† LLaVA via RobustAI (Ollama)

#### Classes

##### MultimodalDistiller

**M√©thodes :**

- `distill()`
- `call_llava()`

#### Fonctions

##### distill

Fusionne les r√©ponses texte et image en utilisant LLaVA (Ollama) et
d'autres mod√®les si besoin.
:param text_prompts: Liste de prompts texte
:param image_paths: Liste de chemins d'images (un par prompt ou global)
:param context: Contexte optionnel
:return: R√©ponse multimodale fusionn√©e

**Param√®tres :**

- `text_prompts`
- `image_paths`
- `context`

##### call_llava

Appelle LLaVA via Ollama pour une analyse multimodale (texte + image).
:param prompt: Prompt texte
:param image_path: Chemin de l'image √† analyser
:return: R√©ponse de LLaVA (str)

**Param√®tres :**

- `prompt`
- `image_path`

---

### predictive_cache

Caching pr√©dictif pour Athalia/Arkalia
- Anticipation contextuelle, pr√©-g√©n√©ration, invalidation intelligente, stats

#### Classes

##### PredictiveCache

**M√©thodes :**

- `__init__()`
- `get()`
- `set()`
- `predict_key()`
- `pre_generate()`
- `invalidate()`
- `get_stats()`

#### Fonctions

##### __init__

:param ttl: Dur√©e de vie (en secondes) d'une entr√©e (0 = infini)

**Param√®tres :**

- `ttl`

##### get

**Param√®tres :**

- `key`

##### set

**Param√®tres :**

- `key`
- `value`

##### predict_key

**Param√®tres :**

- `context`

##### pre_generate

Pr√©-g√©n√®re une r√©ponse pour un contexte donn√© (si non d√©j√† en cache).
:param context: Contexte (dict)
:param generator: Fonction qui g√©n√®re la valeur √† stocker

**Param√®tres :**

- `context`
- `generator`

##### invalidate

Supprime une entr√©e du cache.

**Param√®tres :**

- `key`

##### get_stats

Retourne les statistiques d'utilisation du cache.

---

### quality_scorer

Module de scoring de qualit√© pour Athalia/Arkalia
√âvalue la pertinence d'une solution IA ou d'une correction selon plusieurs crit√®res.

#### Classes

##### QualityScorer

**M√©thodes :**

- `__init__()`
- `score()`

#### Fonctions

##### __init__

**Param√®tres :**

- `weights`

##### score

√âvalue la qualit√© d'une solution IA.
:param solution: Solution √† scorer (str, dict, ...)
:param context: Contexte optionnel
:return: Score de qualit√© (float)

**Param√®tres :**

- `solution`
- `context`

---

### response_distiller

Module de distillation de r√©ponses IA pour Athalia/Arkalia
Permet de fusionner plusieurs r√©ponses IA en une solution optimale
(voting, stacking, bagging, consensus scoring...)

#### Classes

##### ResponseDistiller

**M√©thodes :**

- `__init__()`
- `distill()`
- `majority_voting()`
- `stacking()`
- `bagging()`
- `consensus_scoring()`
- `creative_fusion()`

#### Fonctions

##### distill_responses

Fonction utilitaire pour distiller une liste de r√©ponses IA.

**Param√®tres :**

- `responses`
- `strategy`
- `context`

##### __init__

**Param√®tres :**

- `strategy`

##### distill

Fusionne plusieurs r√©ponses IA selon la strat√©gie choisie.
:param responses: Liste de r√©ponses IA (str)
:param context: Contexte optionnel (pour scoring avanc√©)
:return: R√©ponse distill√©e (str)

**Param√®tres :**

- `responses`
- `context`

##### majority_voting

Retourne la r√©ponse la plus fr√©quente (majorit√©).

**Param√®tres :**

- `responses`

##### stacking

Concat√®ne les parties communes, puis les parties uniques.

**Param√®tres :**

- `responses`
- `context`

##### bagging

Retourne une r√©ponse al√©atoire parmi les plus fr√©quentes (bagging).

**Param√®tres :**

- `responses`

##### consensus_scoring

Retourne la plus longue sous-cha√Æne commune ET les parties divergentes.

**Param√®tres :**

- `responses`

##### creative_fusion

Fusion cr√©ative : m√©lange de fragments, ajout d'un tag IA, et concat unique.

**Param√®tres :**

- `responses`

##### lcs

**Param√®tres :**

- `a`
- `b`

---

### docker_robotics

Docker Robotics Manager - Gestion Docker pour projets robotiques
===============================================================

Gestion sp√©cialis√©e Docker pour projets Reachy/ROS2 :
- Configuration Docker Compose
- Variables d'environnement ROS
- Volumes et networking
- Images sp√©cialis√©es

#### Classes

##### DockerServiceConfig

Configuration d'un service Docker

##### DockerValidationResult

R√©sultat de validation Docker

##### DockerRoboticsManager

Gestionnaire Docker sp√©cialis√© robotique

**M√©thodes :**

- `__init__()`
- `validate_docker_setup()`
- `_parse_service_config()`
- `_validate_reachy_service()`
- `create_reachy_compose_template()`
- `create_dockerfile_template()`
- `create_start_script_template()`
- `setup_reachy_environment()`
- `run_docker_compose()`
- `generate_docker_report()`

#### Fonctions

##### __init__

**Param√®tres :**

- `project_path`

##### validate_docker_setup

Valider la configuration Docker

##### _parse_service_config

Parser la configuration d'un service

**Param√®tres :**

- `name`
- `config`

##### _validate_reachy_service

Valider sp√©cifiquement le service Reachy

**Param√®tres :**

- `service`
- `issues`
- `recommendations`

##### create_reachy_compose_template

Cr√©er un template docker-compose.yaml pour Reachy

##### create_dockerfile_template

Cr√©er un template Dockerfile pour Reachy

##### create_start_script_template

Cr√©er un template de script de d√©marrage

##### setup_reachy_environment

Configurer l'environnement Docker pour Reachy

##### run_docker_compose

Lancer docker-compose

**Param√®tres :**

- `service`

##### generate_docker_report

G√©n√©rer rapport Docker

**Param√®tres :**

- `result`

---

### reachy_auditor

Reachy Auditor - Audit sp√©cialis√© pour projets Reachy/ROS2
==========================================================

Audit complet des projets robotiques Reachy :
- Validation workspace ROS2
- Contr√¥le Docker/Containers
- Analyse Rust/Cargo
- V√©rification structure projet
- Tests de connectivit√©

#### Classes

##### ReachyAuditResult

R√©sultat d'audit Reachy

##### ReachyAuditor

Auditeur sp√©cialis√© pour projets Reachy/ROS2

**M√©thodes :**

- `__init__()`
- `audit_complete()`
- `_audit_ros2()`
- `_audit_docker()`
- `_audit_rust()`
- `_audit_structure()`
- `generate_report()`
- `save_report()`

#### Fonctions

##### __init__

**Param√®tres :**

- `project_path`

##### audit_complete

Audit complet du projet Reachy

##### _audit_ros2

Audit sp√©cifique ROS2

##### _audit_docker

Audit Docker/Containers

##### _audit_rust

Audit Rust/Cargo

##### _audit_structure

Audit structure g√©n√©rale du projet

##### generate_report

G√©n√©rer rapport d'audit

**Param√®tres :**

- `result`

##### save_report

Sauvegarder le rapport

**Param√®tres :**

- `result`
- `output_path`

---

### robotics_ci

Robotics CI - CI/CD sp√©cialis√© pour projets robotiques
======================================================

Syst√®me CI/CD adapt√© aux projets Reachy/ROS2 :
- Tests ROS2
- Build Docker
- Compilation Rust
- Validation robotique
- D√©ploiement automatis√©

#### Classes

##### CIConfig

Configuration CI/CD

##### CIResult

R√©sultat d'ex√©cution CI/CD

##### RoboticsCI

Syst√®me CI/CD sp√©cialis√© robotique

**M√©thodes :**

- `__init__()`
- `create_github_workflow()`
- `create_docker_compose_ci()`
- `run_ci_pipeline()`
- `_run_ros2_validation()`
- `_run_docker_build()`
- `_run_rust_build()`
- `_run_tests()`
- `_run_deployment()`
- `_collect_artifacts()`
- `generate_ci_report()`
- `setup_ci_environment()`

#### Fonctions

##### __init__

**Param√®tres :**

- `project_path`

##### create_github_workflow

Cr√©er un workflow GitHub Actions pour robotique

##### create_docker_compose_ci

Cr√©er docker-compose pour CI

##### run_ci_pipeline

Ex√©cuter le pipeline CI complet

**Param√®tres :**

- `config`

##### _run_ros2_validation

Ex√©cuter validation ROS2

##### _run_docker_build

Ex√©cuter build Docker

##### _run_rust_build

Ex√©cuter build Rust

##### _run_tests

Ex√©cuter tests

##### _run_deployment

Ex√©cuter d√©ploiement

##### _collect_artifacts

Collecter artifacts

##### generate_ci_report

G√©n√©rer rapport CI

**Param√®tres :**

- `result`

##### setup_ci_environment

Configurer l'environnement CI

---

### ros2_validator

ROS2 Validator - Validation sp√©cialis√©e ROS2
============================================

Validation compl√®te des workspaces ROS2 :
- Structure workspace
- Packages et d√©pendances
- Launch files
- URDF/XACRO
- Build system

#### Classes

##### ROS2PackageInfo

Informations sur un package ROS2

##### ROS2ValidationResult

R√©sultat de validation ROS2

##### ROS2Validator

Validateur sp√©cialis√© ROS2

**M√©thodes :**

- `__init__()`
- `validate_workspace()`
- `_analyze_package()`
- `_detect_package_type()`
- `_check_build_system()`
- `validate_launch_files()`
- `validate_urdf_files()`
- `generate_validation_report()`

#### Fonctions

##### __init__

**Param√®tres :**

- `workspace_path`

##### validate_workspace

Validation compl√®te du workspace ROS2

##### _analyze_package

Analyser un package ROS2

**Param√®tres :**

- `package_dir`

##### _detect_package_type

D√©tecter le type de package ROS2

**Param√®tres :**

- `package_dir`

##### _check_build_system

V√©rifier si le build system est configur√©

##### validate_launch_files

Valider les fichiers launch

##### validate_urdf_files

Valider les fichiers URDF/XACRO

##### generate_validation_report

G√©n√©rer rapport de validation

**Param√®tres :**

- `result`

---

### rust_analyzer

Analyseur de projets Rust pour Athalia Robotics

#### Classes

##### CargoDependency

D√©pendance Cargo

##### RustProjectInfo

Informations sur un projet Rust

##### RustAnalysisResult

R√©sultat d'analyse Rust

##### RustAnalyzer

Analyseur de projets Rust pour la robotique

**M√©thodes :**

- `__init__()`
- `analyze_rust_projects()`
- `_analyze_cargo_project()`
- `_parse_dependencies()`
- `_is_robotics_dependency()`
- `_analyze_build_targets()`
- `_check_rust_build_system()`
- `_calculate_optimization_score()`
- `_generate_recommendations()`
- `validate_cargo_toml()`
- `generate_rust_report()`
- `create_rust_template()`

#### Fonctions

##### __init__

**Param√®tres :**

- `project_path`

##### analyze_rust_projects

Analyse tous les projets Rust dans le r√©pertoire

##### _analyze_cargo_project

Analyse un projet Cargo sp√©cifique

**Param√®tres :**

- `cargo_file`

##### _parse_dependencies

Parser les d√©pendances Cargo

**Param√®tres :**

- `deps_dict`

##### _is_robotics_dependency

V√©rifier si c'est une d√©pendance robotique

**Param√®tres :**

- `dep`

##### _analyze_build_targets

Analyser les targets de build

**Param√®tres :**

- `project_path`

##### _check_rust_build_system

V√©rifier si le build system Rust est configur√©

##### _calculate_optimization_score

Calculer le score d'optimisation

**Param√®tres :**

- `projects`

##### _generate_recommendations

G√©n√©rer des recommandations bas√©es sur l'analyse

**Param√®tres :**

- `projects`
- `issues`
- `recommendations`

##### validate_cargo_toml

Valider et parser un fichier Cargo.toml

**Param√®tres :**

- `cargo_file`

##### generate_rust_report

G√©n√©rer un rapport d'analyse Rust

**Param√®tres :**

- `result`

##### create_rust_template

Cr√©er un template de projet Rust robotique

**Param√®tres :**

- `project_name`

---

### artistic_templates

#### Fonctions

##### get_artistic_templates

Retourne les templates de code pour projets artistiques.

---

### base_templates

#### Fonctions

##### get_base_templates

Retourne les templates de base pour tous les projets.

---

### ath-audit

#### Fonctions

##### main

---

### ath-backup

Script de sauvegarde pour Athalia

#### Classes

##### BackupManager

Gestionnaire de sauvegardes pour Athalia

**M√©thodes :**

- `__init__()`
- `create_backup()`
- `_copy_file()`
- `_copy_directory()`
- `_should_exclude()`
- `list_backups()`
- `restore_backup()`

#### Fonctions

##### main

Point d'entr√©e principal

##### __init__

**Param√®tres :**

- `project_root`

##### create_backup

Cr√©e une nouvelle sauvegarde

**Param√®tres :**

- `backup_name`

##### _copy_file

Copie un fichier en respectant les exclusions

**Param√®tres :**

- `src`
- `dst_dir`
- `exclude_patterns`

##### _copy_directory

Copie un r√©pertoire en respectant les exclusions

**Param√®tres :**

- `src`
- `dst_dir`
- `exclude_patterns`

##### _should_exclude

V√©rifie si un chemin doit √™tre exclu

**Param√®tres :**

- `path`
- `exclude_patterns`

##### list_backups

Liste toutes les sauvegardes disponibles

##### restore_backup

Restaure une sauvegarde

**Param√®tres :**

- `backup_name`
- `target_dir`

---

### ath-build

#### Fonctions

##### main

---

### ath-coverage

#### Fonctions

##### main

---

### ath-lint

#### Fonctions

##### main

---

### ath-test

#### Fonctions

##### main

---

### monitor_processes

Moniteur de processus Athalia

#### Classes

##### AthaliaProcessMonitor

Moniteur pour les processus athalia_core.main

**M√©thodes :**

- `__init__()`
- `find_athalia_processes()`
- `kill_duplicate_processes()`
- `monitor_processes()`
- `get_process_stats()`

#### Fonctions

##### main

Fonction principale

##### __init__

##### find_athalia_processes

Trouve tous les processus athalia_core.main

##### kill_duplicate_processes

Arr√™te les processus en double, garde le plus ancien par d√©faut

**Param√®tres :**

- `keep_oldest`

##### monitor_processes

Surveille les processus en continu

**Param√®tres :**

- `interval`
- `max_duration`

##### get_process_stats

Retourne les statistiques des processus

---

### validation_continue

Validation Continue d'Athalia/Arkalia
Surveillance en temps r√©el de la qualit√© et d√©tection de r√©gressions

#### Classes

##### ValidationContinue

**M√©thodes :**

- `__init__()`
- `test_rapide()`
- `test_demarrage()`
- `test_imports()`
- `test_generation_mini()`
- `test_correction_basique()`
- `detecter_regression()`
- `demarrer_surveillance()`
- `arreter_surveillance()`
- `alerter_regression()`
- `generer_rapport_alerte()`
- `sauvegarder_historique()`
- `charger_historique()`
- `generer_rapport_tendance()`

#### Fonctions

##### __init__

**Param√®tres :**

- `intervalle_minutes`

##### test_rapide

Test rapide de validation (version all√©g√©e)

##### test_demarrage

Test de d√©marrage d'Athalia

##### test_imports

Test des imports critiques

##### test_generation_mini

Test de g√©n√©ration minimal

##### test_correction_basique

Test de correction basique

##### detecter_regression

D√©tecte une r√©gression par rapport √† l'historique

**Param√®tres :**

- `validation_actuelle`

##### demarrer_surveillance

D√©marre la surveillance continue

##### arreter_surveillance

Arr√™te la surveillance continue

##### alerter_regression

G√©n√®re une alerte en cas de r√©gression

**Param√®tres :**

- `validation`
- `regression`

##### generer_rapport_alerte

G√©n√®re un rapport d'alerte d√©taill√©

**Param√®tres :**

- `alerte`

##### sauvegarder_historique

Sauvegarde l'historique des validations

##### charger_historique

Charge l'historique des validations

##### generer_rapport_tendance

G√©n√®re un rapport de tendance bas√© sur l'historique

##### boucle_surveillance

---

### validation_dashboard_simple

Dashboard de Validation Simple - Athalia/Arkalia
Interface web pour visualiser les r√©sultats de validation

#### Classes

##### ValidationDashboardHandler

**M√©thodes :**

- `do_GET()`
- `do_POST()`
- `send_validation_result()`
- `send_history()`
- `end_headers()`

#### Fonctions

##### run_dashboard

Lance le dashboard de validation

**Param√®tres :**

- `port`

##### do_GET

##### do_POST

##### send_validation_result

Envoie le r√©sultat de validation en temps r√©el

##### send_history

Envoie l'historique des validations

##### end_headers

---

### validation_objective

Validation Objective d'Athalia/Arkalia
Tests qui ne peuvent pas mentir - Mesures concr√®tes et ind√©pendantes

#### Classes

##### ValidationObjective

**M√©thodes :**

- `__init__()`
- `test_generation_et_compilation()`
- `test_correction_reelle()`
- `test_robustesse_cas_limites()`
- `test_performance_benchmark()`
- `test_qualite_code_genere()`
- `validation_complete()`
- `generer_rapport_objectif()`

#### Fonctions

##### __init__

##### test_generation_et_compilation

Test 1: Le code g√©n√©r√© compile-t-il vraiment ?

##### test_correction_reelle

Test 2: Athalia corrige-t-il vraiment les erreurs ?

##### test_robustesse_cas_limites

Test 3: Athalia g√®re-t-il gracieusement les cas d'erreur ?

##### test_performance_benchmark

Test 4: Performance vs solution manuelle

##### test_qualite_code_genere

Test 5: Qualit√© objective du code g√©n√©r√©

##### validation_complete

Validation compl√®te objective

##### generer_rapport_objectif

G√©n√®re un rapport objectif et d√©taill√©

**Param√®tres :**

- `resultats`
- `temps_total`

---

### quick_performance_test

Test de performance rapide pour Athalia
Version cibl√©e et rapide

#### Fonctions

##### quick_performance_test

Test de performance rapide.

##### analyze_modules

Analyse rapide des modules.

##### print_summary

Affiche un r√©sum√©.

**Param√®tres :**

- `results`
- `analysis`

##### main

Fonction principale.

---

### test_athalia_performance

Test de performance d'Athalia avec cache

#### Fonctions

##### test_athalia_performance

Test de performance d'Athalia.

##### test_multiple_runs

Test avec plusieurs ex√©cutions pour valider le cache.

##### print_summary

Affiche un r√©sum√© des r√©sultats.

**Param√®tres :**

- `results`
- `multiple_results`

##### main

Fonction principale.

---

