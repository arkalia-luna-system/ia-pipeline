#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Validation Objective d'Athalia/Arkalia
Tests qui ne peuvent pas mentir - Mesures concr√®tes et ind√©pendantes
"""

from datetime import datetime
import json
import os
from pathlib import Path
import subprocess
import time

# Import du validateur de s√©curit√©
try:
    from athalia_core.security_validator import SecurityError, validate_and_run
except ImportError:
    # Fallback si le module n'est pas disponible
    def validate_and_run(command, **kwargs) -> subprocess.CompletedProcess:
        return subprocess.run(command, **kwargs)

    class SecurityError(Exception):
        pass


class ValidationObjective:
    def __init__(self) -> None:
        self.resultats: dict = {}
        self.seuils_critiques: dict = {
            "temps_max_generation": 30.0,  # 30 secondes max pour g√©n√©rer un projet
            "temps_max_correction": 10.0,  # 10 secondes max pour corriger
            "taux_compilation_min": 80.0,  # 80% du code g√©n√©r√© doit compiler
            "taux_succes_min": 85.0,  # 85% de succ√®s minimum
            "memoire_max": 1000.0,  # 1GB max
        }

    def test_generation_et_compilation(self) -> dict:
        """Test 1: Le code g√©n√©r√© compile-t-il vraiment ?"""
        print("üîç Test 1: G√©n√©ration et compilation...")

        start = time.time()

        # Cr√©e un projet test avec Athalia
        projet_test = f"/tmp/test_athalia_{int(time.time())}"
        os.makedirs(projet_test, exist_ok=True)

        # Cr√©e un fichier Python simple pour tester
        with open(f"{projet_test}/main.py", "w") as f:
            f.write(
                """def hello():
    print("Hello World")
    return "OK"

if __name__ == "__main__":
    hello()
"""
            )

        cmd = [
            "python",
            "bin/athalia_unified.py",
            projet_test,
            "--action",
            "complete",
            "--auto-fix",
        ]

        try:
            # Utilisation du validateur de s√©curit√©
            result = validate_and_run(cmd, timeout=60)
            temps_generation = time.time() - start

            if result.returncode != 0:
                return {
                    "succes": False,
                    "erreur": f"G√©n√©ration √©chou√©e: {result.stderr}",
                    "temps": temps_generation,
                }

            # V√©rifie que le projet a √©t√© cr√©√©
            if not os.path.exists(projet_test):
                return {
                    "succes": False,
                    "erreur": "Projet non cr√©√©",
                    "temps": temps_generation,
                }

            # Test de compilation de tous les fichiers Python g√©n√©r√©s
            fichiers_python = list(Path(projet_test).glob("**/*.py"))
            compilation_ok = 0
            erreurs_compilation = []

            for py_file in fichiers_python:
                try:
                    with open(py_file, "r", encoding="utf-8") as f:
                        code = f.read()
                    compile(code, str(py_file), "exec")
                    compilation_ok += 1
                except Exception as e:
                    erreurs_compilation.append(f"{py_file}: {str(e)}")

            taux_compilation = (
                (compilation_ok / len(fichiers_python)) * 100 if fichiers_python else 0
            )

            return {
                "succes": (
                    taux_compilation >= self.seuils_critiques["taux_compilation_min"]
                ),
                "temps": temps_generation,
                "fichiers_generes": len(fichiers_python),
                "compilation_ok": compilation_ok,
                "taux_compilation": taux_compilation,
                "erreurs_compilation": erreurs_compilation,
                "projet_creer": True,
            }

        except subprocess.TimeoutExpired:
            return {
                "succes": False,
                "erreur": "Timeout - G√©n√©ration trop lente",
                "temps": 60,
            }
        except Exception as e:
            return {
                "succes": False,
                "erreur": f"Exception: {str(e)}",
                "temps": time.time() - start,
            }

    def test_correction_reelle(self) -> dict:
        """Test 2: Athalia corrige-t-il vraiment les erreurs ?"""
        print("üîç Test 2: Correction d'erreurs...")

        # Cr√©e un fichier avec des erreurs volontaires (plus r√©alistes)
        code_avec_erreurs = """
def fonction_cassee():
    x = 1
    y = 2
    return x + y + z  # Erreur: z n'existe pas

def autre_fonction( ):  # Erreur: espace mal plac√©
    pass

def fonction_syntaxe():
    if True:
        print("Erreur de syntaxe")  # Erreur corrig√©e
"""

        fichier_test = "/tmp/code_avec_erreurs.py"
        with open(fichier_test, "w", encoding="utf-8") as f:
            f.write(code_avec_erreurs)

        start = time.time()

        # Utilise Athalia pour corriger
        cmd = [
            "python",
            "bin/athalia_unified.py",
            fichier_test,
            "--action",
            "correct",
            "--auto-fix",
        ]

        try:
            result = validate_and_run(cmd, timeout=30)
            temps_correction = time.time() - start

            if result.returncode != 0:
                return {
                    "succes": False,
                    "erreur": f"Correction √©chou√©e: {result.stderr}",
                    "temps": temps_correction,
                }

            # V√©rifie que le fichier corrig√© existe
            fichier_corrige = f"{fichier_test}.corrected"
            if not os.path.exists(fichier_corrige):
                return {
                    "succes": False,
                    "erreur": "Fichier corrig√© non cr√©√©",
                    "temps": temps_correction,
                }

            # Test de compilation du fichier corrig√©
            try:
                with open(fichier_corrige, "r", encoding="utf-8") as f:
                    code_corrige = f.read()
                compile(code_corrige, fichier_corrige, "exec")
                compilation_ok = True
            except Exception as e:
                compilation_ok = False
                erreur_compilation = str(e)

            return {
                "succes": (
                    compilation_ok
                    and temps_correction
                    <= self.seuils_critiques["temps_max_correction"]
                ),
                "temps": temps_correction,
                "compilation_ok": compilation_ok,
                "erreur_compilation": (
                    erreur_compilation if not compilation_ok else None
                ),
                "fichier_corrige": fichier_corrige,
            }

        except subprocess.TimeoutExpired:
            return {
                "succes": False,
                "erreur": "Timeout - Correction trop lente",
                "temps": 30,
            }
        except Exception as e:
            return {
                "succes": False,
                "erreur": f"Exception: {str(e)}",
                "temps": time.time() - start,
            }

    def test_robustesse_cas_limites(self) -> dict:
        """Test 3: Athalia g√®re-t-il les cas limites ?"""
        print("üîç Test 3: Robustesse cas limites...")

        cas_limites = [
            {"nom": "Fichier vide", "contenu": "", "attendu": "Gestion d'erreur"},
            {
                "nom": "Fichier tr√®s long",
                "contenu": "print('test')\n" * 10000,
                "attendu": "Traitement sans crash",
            },
            {
                "nom": "Caract√®res sp√©ciaux",
                "contenu": "print('√©√†√ß√π‚Ç¨¬£¬•')",
                "attendu": "Encodage correct",
            },
            {
                "nom": "Syntaxe invalide",
                "contenu": "def test():\n    if True:\n        print('test'",
                "attendu": "D√©tection d'erreur",
            },
        ]

        resultats_cas_limites = []
        temps_total = 0

        for cas in cas_limites:
            start = time.time()
            fichier_test = f"/tmp/cas_limite_{cas['nom'].replace(' ', '_')}.py"

            with open(fichier_test, "w", encoding="utf-8") as f:
                f.write(cas["contenu"])

            cmd = [
                "python",
                "bin/athalia_unified.py",
                fichier_test,
                "--action",
                "analyze",
            ]

            try:
                result = validate_and_run(cmd, timeout=10)
                temps_cas = time.time() - start
                temps_total += temps_cas

                resultats_cas_limites.append(
                    {
                        "cas": cas["nom"],
                        "succes": result.returncode == 0,
                        "temps": temps_cas,
                        "attendu": cas["attendu"],
                        "resultat": "OK" if result.returncode == 0 else "ERREUR",
                    }
                )

            except Exception as e:
                temps_cas = time.time() - start
                temps_total += temps_cas
                resultats_cas_limites.append(
                    {
                        "cas": cas["nom"],
                        "succes": False,
                        "temps": temps_cas,
                        "attendu": cas["attendu"],
                        "resultat": f"EXCEPTION: {str(e)}",
                    }
                )

        taux_succes = (
            sum(1 for r in resultats_cas_limites if r["succes"])
            / len(resultats_cas_limites)
            * 100
        )

        return {
            "succes": taux_succes >= 75,  # 75% de succ√®s minimum
            "temps": temps_total,
            "taux_succes": taux_succes,
            "cas_testes": len(cas_limites),
            "resultats_detailles": resultats_cas_limites,
        }

    def test_performance_benchmark(self) -> dict:
        """Test 4: Performance et benchmark"""
        print("üîç Test 4: Performance benchmark...")

        # Test de performance sur un projet simple
        projet_benchmark = f"/tmp/benchmark_athalia_{int(time.time())}"
        os.makedirs(projet_benchmark, exist_ok=True)

        # Cr√©e plusieurs fichiers pour tester
        for i in range(10):
            with open(f"{projet_benchmark}/file_{i}.py", "w") as f:
                f.write(
                    f"""
def fonction_{i}():
    return {i}

if __name__ == "__main__":
    print(fonction_{i}())
"""
                )

        start = time.time()
        cmd = [
            "python",
            "bin/athalia_unified.py",
            projet_benchmark,
            "--action",
            "complete",
            "--auto-fix",
        ]

        try:
            result = validate_and_run(cmd, timeout=120)
            temps_total = time.time() - start

            # Mesure de la m√©moire utilis√©e (approximative)
            import psutil

            process = psutil.Process()
            memoire_utilisee = process.memory_info().rss / 1024 / 1024  # MB

            return {
                "succes": (
                    result.returncode == 0
                    and temps_total <= self.seuils_critiques["temps_max_generation"]
                    and memoire_utilisee <= self.seuils_critiques["memoire_max"]
                ),
                "temps": temps_total,
                "memoire_mb": memoire_utilisee,
                "fichiers_traites": 10,
                "performance_ok": temps_total <= 30,
            }

        except Exception as e:
            return {
                "succes": False,
                "erreur": f"Benchmark √©chou√©: {str(e)}",
                "temps": time.time() - start,
            }

    def test_qualite_code_genere(self) -> dict:
        """Test 5: Qualit√© du code g√©n√©r√©"""
        print("üîç Test 5: Qualit√© du code g√©n√©r√©...")

        # Test avec un projet plus complexe
        projet_qualite = f"/tmp/qualite_athalia_{int(time.time())}"
        os.makedirs(projet_qualite, exist_ok=True)

        # Cr√©e un fichier avec des probl√®mes de qualit√©
        code_problematique = """
import os
import sys
import time
import datetime
import json
import subprocess
import pathlib
import shutil
import tempfile
import logging
import argparse
import configparser
import csv
import xml.etree.ElementTree as ET
import yaml
import toml
import requests
import urllib.parse
import hashlib
import base64
import zlib
import gzip
import bz2
import lzma
import pickle
import shelve
import sqlite3
import threading
import multiprocessing
import asyncio
import concurrent.futures
import queue
import collections
import itertools
import functools
import operator
import math
import random
import statistics
import decimal
import fractions
import cmath
import array
import struct
import mmap
import select
import socket
import ssl
import http.client
import urllib.request
import urllib.error
import urllib.parse
import email
import smtplib
import poplib
import imaplib
import ftplib
import telnetlib
import nntplib
import smtpd
import http.server
import socketserver
import xmlrpc.client
import xmlrpc.server
import webbrowser
import cgi
import cgitb
import wsgiref.simple_server
import wsgiref.util
import wsgiref.validate
import wsgiref.handlers
import wsgiref.headers
import wsgiref.responder
import wsgiref.simple_server
import wsgiref.util
import wsgiref.validate
import wsgiref.handlers
import wsgiref.headers
import wsgiref.responder

def fonction_tres_longue_avec_beaucoup_de_parametres(param1, param2, param3, param4, param5, param6, param7, param8, param9, param10):
    # Cette fonction est trop longue et a trop de param√®tres
    resultat = 0
    for i in range(1000):
        resultat += i
        if i % 100 == 0:
            print(f"Progression: {i}")
    return resultat

class ClasseAvecBeaucoupDeMethodes:
    def __init__(self):
        self.valeur = 0
    
    def methode1(self):
        pass
    
    def methode2(self):
        pass
    
    def methode3(self):
        pass
    
    def methode4(self):
        pass
    
    def methode5(self):
        pass
    
    def methode6(self):
        pass
    
    def methode7(self):
        pass
    
    def methode8(self):
        pass
    
    def methode9(self):
        pass
    
    def methode10(self):
        pass

# Code dupliqu√©
def fonction1():
    x = 1
    y = 2
    return x + y

def fonction2():
    x = 1
    y = 2
    return x + y

# Variables non utilis√©es
variable_non_utilisee = "test"
"""

        with open(f"{projet_qualite}/code_problematique.py", "w") as f:
            f.write(code_problematique)

        start = time.time()
        cmd = [
            "python",
            "bin/athalia_unified.py",
            projet_qualite,
            "--action",
            "improve",
            "--auto-fix",
        ]

        try:
            result = validate_and_run(cmd, timeout=60)
            temps_amelioration = time.time() - start

            if result.returncode != 0:
                return {
                    "succes": False,
                    "erreur": f"Am√©lioration √©chou√©e: {result.stderr}",
                    "temps": temps_amelioration,
                }

            # Analyse de la qualit√© apr√®s am√©lioration
            fichier_ameliore = f"{projet_qualite}/code_problematique.py.improved"
            if os.path.exists(fichier_ameliore):
                with open(fichier_ameliore, "r") as f:
                    code_ameliore = f.read()

                # Mesures de qualit√© simples
                lignes_code = len(code_ameliore.split("\n"))
                fonctions = code_ameliore.count("def ")
                classes = code_ameliore.count("class ")
                imports = code_ameliore.count("import ")

                return {
                    "succes": True,
                    "temps": temps_amelioration,
                    "lignes_code": lignes_code,
                    "fonctions": fonctions,
                    "classes": classes,
                    "imports": imports,
                    "qualite_amelioree": True,
                }
            else:
                return {
                    "succes": False,
                    "erreur": "Fichier am√©lior√© non cr√©√©",
                    "temps": temps_amelioration,
                }

        except Exception as e:
            return {
                "succes": False,
                "erreur": f"Test qualit√© √©chou√©: {str(e)}",
                "temps": time.time() - start,
            }

    def validation_complete(self) -> dict:
        """Ex√©cute tous les tests de validation"""
        print("üöÄ D√©marrage de la validation objective compl√®te...")

        start_total = time.time()

        # Ex√©cute tous les tests
        self.resultats["generation_compilation"] = self.test_generation_et_compilation()
        self.resultats["correction_reelle"] = self.test_correction_reelle()
        self.resultats["robustesse_cas_limites"] = self.test_robustesse_cas_limites()
        self.resultats["performance_benchmark"] = self.test_performance_benchmark()
        self.resultats["qualite_code_genere"] = self.test_qualite_code_genere()

        temps_total = time.time() - start_total

        # Calcule le score global
        tests_reussis = sum(
            1 for r in self.resultats.values() if r.get("succes", False)
        )
        score_global = (tests_reussis / len(self.resultats)) * 100

        validation_reussie = score_global >= self.seuils_critiques["taux_succes_min"]

        print(f"‚úÖ Validation termin√©e en {temps_total:.2f}s")
        print(
            f"üìä Score global: {score_global:.1f}% ({tests_reussis}/{len(self.resultats)} tests r√©ussis)"
        )
        print(f"üéØ Validation {'R√âUSSIE' if validation_reussie else '√âCHOU√âE'}")

        return {
            "validation_reussie": validation_reussie,
            "score_global": score_global,
            "temps_total": temps_total,
            "tests_reussis": tests_reussis,
            "total_tests": len(self.resultats),
            "resultats_detailles": self.resultats,
        }

    def generer_rapport_objectif(self, resultats, temps_total):
        """G√©n√®re un rapport d√©taill√© de la validation"""
        rapport = {
            "timestamp": datetime.now().isoformat(),
            "validation_objective": "Athalia/Arkalia",
            "temps_total": temps_total,
            "score_global": resultats["score_global"],
            "validation_reussie": resultats["validation_reussie"],
            "seuils_critiques": self.seuils_critiques,
            "resultats_detailles": resultats["resultats_detailles"],
        }

        # Sauvegarde le rapport
        rapport_file = (
            f"validation_objective_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(rapport_file, "w", encoding="utf-8") as f:
            json.dump(rapport, f, indent=2, ensure_ascii=False)

        print(f"üìÑ Rapport sauvegard√©: {rapport_file}")
        return rapport_file


def main():
    """Fonction principale"""
    print("üéØ Validation Objective d'Athalia/Arkalia")
    print("=" * 50)

    validator = ValidationObjective()

    try:
        resultats = validator.validation_complete()
        rapport_file = validator.generer_rapport_objectif(
            resultats, resultats["temps_total"]
        )

        if resultats["validation_reussie"]:
            print("üéâ Validation objective R√âUSSIE !")
            return 0
        else:
            print("‚ùå Validation objective √âCHOU√âE !")
            return 1

    except Exception as e:
        print(f"üí• Erreur critique: {str(e)}")
        return 2


if __name__ == "__main__":
    exit(main())
