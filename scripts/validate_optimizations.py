#!/usr/bin/env python3
"""
Script de validation finale des optimisations de tests.
VÃ©rifie que les optimisations sont robustes et n'ont pas cassÃ© la fonctionnalitÃ©.
"""

import subprocess
import time
from pathlib import Path
from typing import Dict


class OptimizationValidator:
    """Validateur des optimisations de tests."""

    def __init__(self):
        self.validation_results = {}
        self.test_suites = [
            {
                "name": "Tests de Performance OptimisÃ©s",
                "path": "tests/performance/test_performance_optimization.py",
                "expected_tests": 18,
            },
            {
                "name": "Tests d'IntÃ©gration YAML",
                "path": "tests/integration/test_yaml_validity.py",
                "expected_tests": 15,
            },
            {
                "name": "Tests d'IA Robust",
                "path": "tests/unit/ai/test_ai_robust_integration.py",
                "expected_tests": 8,
            },
            {
                "name": "Tests de Cache Manager",
                "path": "tests/unit/test_cache_manager_complete.py",
                "expected_tests": 25,
            },
            {
                "name": "Tests d'Audit Intelligent",
                "path": "tests/unit/test_audit_intelligent.py",
                "expected_tests": 8,
            },
        ]

    def run_test_suite(self, suite: Dict) -> Dict:
        """ExÃ©cute une suite de tests et mesure ses performances."""
        print(f"\nğŸ” Validation: {suite['name']}")
        print("-" * 50)

        start_time = time.time()

        try:
            # ExÃ©cuter la suite de tests
            result = subprocess.run(
                [
                    "python",
                    "-m",
                    "pytest",
                    suite["path"],
                    "-v",
                    "--tb=short",
                    "--no-cov",
                ],
                capture_output=True,
                text=True,
                timeout=120,
                cwd=Path(__file__).parent.parent,
            )

            end_time = time.time()
            execution_time = end_time - start_time

            # Analyser les rÃ©sultats
            output_lines = result.stdout.split("\n")
            test_count = 0
            passed_tests = 0
            failed_tests = 0

            for line in output_lines:
                if "PASSED" in line:
                    passed_tests += 1
                    test_count += 1
                elif "FAILED" in line:
                    failed_tests += 1
                    test_count += 1
                elif "ERROR" in line:
                    failed_tests += 1
                    test_count += 1

            return {
                "success": result.returncode == 0,
                "execution_time": execution_time,
                "total_tests": test_count,
                "passed_tests": passed_tests,
                "failed_tests": failed_tests,
                "expected_tests": suite["expected_tests"],
                "output": result.stdout,
                "error": result.stderr,
                "return_code": result.returncode,
            }

        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "execution_time": 120.0,
                "total_tests": 0,
                "passed_tests": 0,
                "failed_tests": 0,
                "expected_tests": suite["expected_tests"],
                "output": "",
                "error": "Timeout aprÃ¨s 120 secondes",
                "return_code": -1,
            }
        except Exception as e:
            return {
                "success": False,
                "execution_time": 0,
                "total_tests": 0,
                "passed_tests": 0,
                "failed_tests": 0,
                "expected_tests": suite["expected_tests"],
                "output": "",
                "error": str(e),
                "return_code": -1,
            }

    def validate_optimizations(self) -> Dict:
        """Valide toutes les optimisations."""
        print("ğŸš€ DÃ©marrage de la validation des optimisations")
        print("=" * 60)

        total_execution_time = 0
        total_tests = 0
        total_passed = 0
        total_failed = 0

        for suite in self.test_suites:
            result = self.run_test_suite(suite)
            self.validation_results[suite["name"]] = result

            # Afficher les rÃ©sultats
            if result["success"]:
                print(f"âœ… {suite['name']}: SUCCÃˆS")
                print(f"   â±ï¸  Temps: {result['execution_time']:.2f}s")
                print(
                    f"   ğŸ“Š Tests: {result['passed_tests']}/{result['total_tests']} rÃ©ussis"
                )

                if result["total_tests"] != result["expected_tests"]:
                    print(
                        f"   âš ï¸  Attention: {result['total_tests']} tests trouvÃ©s, {result['expected_tests']} attendus"
                    )
            else:
                print(f"âŒ {suite['name']}: Ã‰CHEC")
                print(f"   â±ï¸  Temps: {result['execution_time']:.2f}s")
                print(
                    f"   ğŸ“Š Tests: {result['passed_tests']}/{result['total_tests']} rÃ©ussis"
                )
                print(f"   ğŸš¨ Erreur: {result['error']}")

            # Accumuler les statistiques
            total_execution_time += result["execution_time"]
            total_tests += result["total_tests"]
            total_passed += result["passed_tests"]
            total_failed += result["failed_tests"]

        return {
            "total_execution_time": total_execution_time,
            "total_tests": total_tests,
            "total_passed": total_passed,
            "total_failed": total_failed,
            "success_rate": (
                (total_passed / total_tests * 100) if total_tests > 0 else 0
            ),
        }

    def generate_validation_report(self) -> str:
        """GÃ©nÃ¨re un rapport de validation."""
        report = []
        report.append("# Rapport de Validation des Optimisations")
        report.append("")
        report.append("## RÃ©sumÃ© de la Validation")
        report.append("")

        total_execution_time = 0
        total_tests = 0
        total_passed = 0
        total_failed = 0

        for suite_name, result in self.validation_results.items():
            total_execution_time += result["execution_time"]
            total_tests += result["total_tests"]
            total_passed += result["passed_tests"]
            total_failed += result["failed_tests"]

            report.append(f"### {suite_name}")
            report.append(
                f"- **Statut**: {'âœ… SUCCÃˆS' if result['success'] else 'âŒ Ã‰CHEC'}"
            )
            report.append(f"- **Temps d'exÃ©cution**: {result['execution_time']:.2f}s")
            report.append(f"- **Tests exÃ©cutÃ©s**: {result['total_tests']}")
            report.append(f"- **Tests rÃ©ussis**: {result['passed_tests']}")
            report.append(f"- **Tests Ã©chouÃ©s**: {result['failed_tests']}")

            if result["total_tests"] != result["expected_tests"]:
                report.append(
                    f"- **âš ï¸  Attention**: {result['total_tests']} tests trouvÃ©s, {result['expected_tests']} attendus"
                )

            if not result["success"]:
                report.append(f"- **Erreur**: {result['error']}")

            report.append("")

        report.append("## Statistiques Globales")
        report.append("")
        report.append(f"- **Temps total d'exÃ©cution**: {total_execution_time:.2f}s")
        report.append(f"- **Total des tests**: {total_tests}")
        report.append(f"- **Tests rÃ©ussis**: {total_passed}")
        report.append(f"- **Tests Ã©chouÃ©s**: {total_failed}")
        report.append(
            f"- **Taux de succÃ¨s**: {total_passed/total_tests*100:.1f}%"
            if total_tests > 0
            else "- **Taux de succÃ¨s**: N/A"
        )

        # Ã‰valuation de la validation
        report.append("")
        report.append("## Ã‰valuation de la Validation")
        report.append("")

        if total_failed == 0 and total_tests > 0:
            report.append("âœ… **VALIDATION RÃ‰USSIE**")
            report.append("- Tous les tests optimisÃ©s passent avec succÃ¨s")
            report.append("- Les optimisations n'ont pas cassÃ© la fonctionnalitÃ©")
            report.append("- Les performances sont amÃ©liorÃ©es")
        else:
            report.append("âŒ **VALIDATION Ã‰CHOUÃ‰E**")
            report.append(f"- {total_failed} tests ont Ã©chouÃ©")
            report.append("- Des problÃ¨mes ont Ã©tÃ© dÃ©tectÃ©s")
            report.append("- RÃ©vision des optimisations nÃ©cessaire")

        return "\n".join(report)

    def save_validation_report(
        self, filename: str = "optimization_validation_report.md"
    ):
        """Sauvegarde le rapport de validation."""
        report = self.generate_validation_report()
        report_path = Path(__file__).parent / filename

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        print(f"\nğŸ“„ Rapport de validation sauvegardÃ©: {report_path}")
        return report_path


def main():
    """Fonction principale."""
    print("ğŸš€ DÃ©marrage de la validation des optimisations")
    print("=" * 60)

    # VÃ©rifier que nous sommes dans l'environnement virtuel
    if not Path(".venv").exists():
        print("âŒ Erreur: Environnement virtuel non trouvÃ©")
        print("   Veuillez activer l'environnement virtuel: source .venv/bin/activate")
        return 1

    validator = OptimizationValidator()

    try:
        # ExÃ©cuter la validation
        stats = validator.validate_optimizations()

        # GÃ©nÃ©rer et sauvegarder le rapport
        report_path = validator.save_validation_report()

        print("\n" + "=" * 60)
        print("âœ… Validation terminÃ©e!")
        print(f"ğŸ“Š Rapport disponible: {report_path}")

        # Afficher un rÃ©sumÃ© final
        print("\nğŸ“ˆ RÃ©sumÃ© de la validation:")
        print(f"   Temps total: {stats['total_execution_time']:.2f}s")
        print(f"   Tests totaux: {stats['total_tests']}")
        print(f"   Tests rÃ©ussis: {stats['total_passed']}")
        print(f"   Tests Ã©chouÃ©s: {stats['total_failed']}")
        print(f"   Taux de succÃ¨s: {stats['success_rate']:.1f}%")

        if stats["total_failed"] == 0:
            print("\nğŸ‰ Toutes les optimisations sont validÃ©es avec succÃ¨s!")
            return 0
        else:
            print(
                f"\nâš ï¸  {stats['total_failed']} tests ont Ã©chouÃ©. RÃ©vision nÃ©cessaire."
            )
            return 1

    except KeyboardInterrupt:
        print("\nâš ï¸  Validation interrompue par l'utilisateur")
        return 1
    except Exception as e:
        print(f"\nâŒ Erreur lors de la validation: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
